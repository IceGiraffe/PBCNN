20-03-23 17:27-INFO-{'session_length': 24, 'height': 32, 'width': 32, 'num_labels': 8, 'learning_rate': 0.005, 'filter_sizes': [3, 4, 5, 6], 'num_filters': 64, 'filter_sizes_hierarchical': [3, 4, 5], 'num_fitlers_hierarchical': 64, 'is_train': True, 'early_stop': False, 'is_tuning': False}
20-03-23 17:27-WARNING-From ../utils.py:129: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

20-03-23 17:27-WARNING-From ../model/train.py:105: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

20-03-23 17:27-WARNING-From ../model/siamese_network.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

20-03-23 17:27-WARNING-From ../model/siamese_network.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

20-03-23 17:27-WARNING-From ../model/siamese_network.py:69: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

20-03-23 17:27-WARNING-From ../model/utils/utils.py:26: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f67190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f67190>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-From ../model/utils/utils.py:45: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling1D instead.
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3f8c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3f8c990>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f671d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f671d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3f67e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3f67e50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f67150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f67150>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3708f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3708f50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f671d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3f671d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3f67190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3f67190>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-From ../model/utils/modules.py:205: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
20-03-23 17:27-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f86b48bfa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f86b48bfa50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3698410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3698410>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b35f6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b35f6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b35f6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b35f6110>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b35f6c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b35f6c10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3698e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3698e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b366b610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b366b610>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-From ../model/utils/modules.py:240: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
20-03-23 17:27-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b35f6750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b35f6750>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-From ../model/utils/modules.py:242: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
20-03-23 17:27-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f86b366bd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f86b366bd50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-From ../model/utils/modules.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3572750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3572750>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b35b01d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b35b01d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3509ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3509ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b36b78d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b36b78d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b34c16d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b34c16d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3585950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3585950>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b36c2250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b36c2250>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b36c2250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b36c2250>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f86b355b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f86b355b550>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3509ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3509ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b353c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b353c710>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3730f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b3730f50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3730f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b3730f50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b34d5210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f86b34d5210>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b34b3c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f86b34b3c10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b34c0850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b34c0850>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f86b3730dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f86b3730dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b3398190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b3398190>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b3f67610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f86b3f67610>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 17:27-WARNING-From ../model/base_model.py:132: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

20-03-23 17:27-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20-03-23 17:27-WARNING-From ../model/train.py:113: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

20-03-23 17:28-INFO-Epoch 0, Batch 1, Global step 1:
20-03-23 17:28-INFO-training batch loss: 4.8609; avg_loss: 4.8609
20-03-23 17:28-INFO-training batch acc: 0.3984; avg_acc: 0.3984
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 2, Global step 2:
20-03-23 17:28-INFO-training batch loss: 22.2052; avg_loss: 13.5331
20-03-23 17:28-INFO-training batch acc: 0.5938; avg_acc: 0.4961
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 3, Global step 3:
20-03-23 17:28-INFO-training batch loss: 13.0148; avg_loss: 13.3603
20-03-23 17:28-INFO-training batch acc: 0.5547; avg_acc: 0.5156
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 4, Global step 4:
20-03-23 17:28-INFO-training batch loss: 1.1845; avg_loss: 10.3163
20-03-23 17:28-INFO-training batch acc: 0.5000; avg_acc: 0.5117
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 5, Global step 5:
20-03-23 17:28-INFO-training batch loss: 0.8703; avg_loss: 8.4271
20-03-23 17:28-INFO-training batch acc: 0.5234; avg_acc: 0.5141
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 6, Global step 6:
20-03-23 17:28-INFO-training batch loss: 1.8407; avg_loss: 7.3294
20-03-23 17:28-INFO-training batch acc: 0.3438; avg_acc: 0.4857
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 7, Global step 7:
20-03-23 17:28-INFO-training batch loss: 1.1319; avg_loss: 6.4440
20-03-23 17:28-INFO-training batch acc: 0.6172; avg_acc: 0.5045
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 8, Global step 8:
20-03-23 17:28-INFO-training batch loss: 1.0690; avg_loss: 5.7722
20-03-23 17:28-INFO-training batch acc: 0.5469; avg_acc: 0.5098
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 9, Global step 9:
20-03-23 17:28-INFO-training batch loss: 1.0549; avg_loss: 5.2480
20-03-23 17:28-INFO-training batch acc: 0.4297; avg_acc: 0.5009
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 10, Global step 10:
20-03-23 17:28-INFO-training batch loss: 0.7585; avg_loss: 4.7991
20-03-23 17:28-INFO-training batch acc: 0.5469; avg_acc: 0.5055
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 11, Global step 11:
20-03-23 17:28-INFO-training batch loss: 0.6587; avg_loss: 4.4227
20-03-23 17:28-INFO-training batch acc: 0.6484; avg_acc: 0.5185
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 12, Global step 12:
20-03-23 17:28-INFO-training batch loss: 0.7987; avg_loss: 4.1207
20-03-23 17:28-INFO-training batch acc: 0.5703; avg_acc: 0.5228
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 13, Global step 13:
20-03-23 17:28-INFO-training batch loss: 0.6542; avg_loss: 3.8540
20-03-23 17:28-INFO-training batch acc: 0.5859; avg_acc: 0.5276
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 14, Global step 14:
20-03-23 17:28-INFO-training batch loss: 0.7339; avg_loss: 3.6312
20-03-23 17:28-INFO-training batch acc: 0.4844; avg_acc: 0.5246
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 15, Global step 15:
20-03-23 17:28-INFO-training batch loss: 0.6801; avg_loss: 3.4344
20-03-23 17:28-INFO-training batch acc: 0.5859; avg_acc: 0.5286
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 16, Global step 16:
20-03-23 17:28-INFO-training batch loss: 0.6308; avg_loss: 3.2592
20-03-23 17:28-INFO-training batch acc: 0.6172; avg_acc: 0.5342
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 17, Global step 17:
20-03-23 17:28-INFO-training batch loss: 0.7092; avg_loss: 3.1092
20-03-23 17:28-INFO-training batch acc: 0.5469; avg_acc: 0.5349
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 18, Global step 18:
20-03-23 17:28-INFO-training batch loss: 0.7102; avg_loss: 2.9759
20-03-23 17:28-INFO-training batch acc: 0.6094; avg_acc: 0.5391
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 19, Global step 19:
20-03-23 17:28-INFO-training batch loss: 0.7142; avg_loss: 2.8569
20-03-23 17:28-INFO-training batch acc: 0.5469; avg_acc: 0.5395
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 20, Global step 20:
20-03-23 17:28-INFO-training batch loss: 0.6263; avg_loss: 2.7454
20-03-23 17:28-INFO-training batch acc: 0.6250; avg_acc: 0.5437
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 21, Global step 21:
20-03-23 17:28-INFO-training batch loss: 0.6506; avg_loss: 2.6456
20-03-23 17:28-INFO-training batch acc: 0.6484; avg_acc: 0.5487
20-03-23 17:28-INFO-
20-03-23 17:28-INFO-Epoch 0, Batch 22, Global step 22:
20-03-23 17:28-INFO-training batch loss: 0.7182; avg_loss: 2.5580
20-03-23 17:28-INFO-training batch acc: 0.5312; avg_acc: 0.5479
20-03-23 17:28-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 23, Global step 23:
20-03-23 17:29-INFO-training batch loss: 0.7077; avg_loss: 2.4775
20-03-23 17:29-INFO-training batch acc: 0.5469; avg_acc: 0.5479
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 24, Global step 24:
20-03-23 17:29-INFO-training batch loss: 0.6610; avg_loss: 2.4019
20-03-23 17:29-INFO-training batch acc: 0.5781; avg_acc: 0.5492
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 25, Global step 25:
20-03-23 17:29-INFO-training batch loss: 0.6450; avg_loss: 2.3316
20-03-23 17:29-INFO-training batch acc: 0.6094; avg_acc: 0.5516
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 26, Global step 26:
20-03-23 17:29-INFO-training batch loss: 0.6444; avg_loss: 2.2667
20-03-23 17:29-INFO-training batch acc: 0.6172; avg_acc: 0.5541
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 27, Global step 27:
20-03-23 17:29-INFO-training batch loss: 0.6719; avg_loss: 2.2076
20-03-23 17:29-INFO-training batch acc: 0.5859; avg_acc: 0.5553
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 28, Global step 28:
20-03-23 17:29-INFO-training batch loss: 0.6397; avg_loss: 2.1516
20-03-23 17:29-INFO-training batch acc: 0.5938; avg_acc: 0.5566
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 29, Global step 29:
20-03-23 17:29-INFO-training batch loss: 0.7189; avg_loss: 2.1022
20-03-23 17:29-INFO-training batch acc: 0.5312; avg_acc: 0.5558
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 30, Global step 30:
20-03-23 17:29-INFO-training batch loss: 0.6741; avg_loss: 2.0546
20-03-23 17:29-INFO-training batch acc: 0.5859; avg_acc: 0.5568
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 31, Global step 31:
20-03-23 17:29-INFO-training batch loss: 0.6702; avg_loss: 2.0100
20-03-23 17:29-INFO-training batch acc: 0.5781; avg_acc: 0.5575
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 32, Global step 32:
20-03-23 17:29-INFO-training batch loss: 0.6676; avg_loss: 1.9680
20-03-23 17:29-INFO-training batch acc: 0.5391; avg_acc: 0.5569
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 33, Global step 33:
20-03-23 17:29-INFO-training batch loss: 0.6617; avg_loss: 1.9284
20-03-23 17:29-INFO-training batch acc: 0.5781; avg_acc: 0.5575
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 34, Global step 34:
20-03-23 17:29-INFO-training batch loss: 0.6943; avg_loss: 1.8921
20-03-23 17:29-INFO-training batch acc: 0.5234; avg_acc: 0.5565
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 35, Global step 35:
20-03-23 17:29-INFO-training batch loss: 0.6926; avg_loss: 1.8579
20-03-23 17:29-INFO-training batch acc: 0.5469; avg_acc: 0.5563
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 36, Global step 36:
20-03-23 17:29-INFO-training batch loss: 0.6831; avg_loss: 1.8252
20-03-23 17:29-INFO-training batch acc: 0.5078; avg_acc: 0.5549
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 37, Global step 37:
20-03-23 17:29-INFO-training batch loss: 0.6661; avg_loss: 1.7939
20-03-23 17:29-INFO-training batch acc: 0.5703; avg_acc: 0.5553
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 38, Global step 38:
20-03-23 17:29-INFO-training batch loss: 0.6607; avg_loss: 1.7641
20-03-23 17:29-INFO-training batch acc: 0.6250; avg_acc: 0.5572
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 39, Global step 39:
20-03-23 17:29-INFO-training batch loss: 0.6408; avg_loss: 1.7353
20-03-23 17:29-INFO-training batch acc: 0.5625; avg_acc: 0.5573
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 40, Global step 40:
20-03-23 17:29-INFO-training batch loss: 0.6831; avg_loss: 1.7090
20-03-23 17:29-INFO-training batch acc: 0.5547; avg_acc: 0.5572
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 41, Global step 41:
20-03-23 17:29-INFO-training batch loss: 0.6731; avg_loss: 1.6837
20-03-23 17:29-INFO-training batch acc: 0.6250; avg_acc: 0.5589
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 42, Global step 42:
20-03-23 17:29-INFO-training batch loss: 0.6936; avg_loss: 1.6601
20-03-23 17:29-INFO-training batch acc: 0.5703; avg_acc: 0.5592
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 43, Global step 43:
20-03-23 17:29-INFO-training batch loss: 0.6859; avg_loss: 1.6375
20-03-23 17:29-INFO-training batch acc: 0.5859; avg_acc: 0.5598
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 44, Global step 44:
20-03-23 17:29-INFO-training batch loss: 0.6577; avg_loss: 1.6152
20-03-23 17:29-INFO-training batch acc: 0.5938; avg_acc: 0.5605
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 45, Global step 45:
20-03-23 17:29-INFO-training batch loss: 0.6520; avg_loss: 1.5938
20-03-23 17:29-INFO-training batch acc: 0.6250; avg_acc: 0.5620
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 46, Global step 46:
20-03-23 17:29-INFO-training batch loss: 0.6571; avg_loss: 1.5734
20-03-23 17:29-INFO-training batch acc: 0.5859; avg_acc: 0.5625
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 47, Global step 47:
20-03-23 17:29-INFO-training batch loss: 0.6639; avg_loss: 1.5541
20-03-23 17:29-INFO-training batch acc: 0.6172; avg_acc: 0.5637
20-03-23 17:29-INFO-
20-03-23 17:29-INFO-Epoch 0, Batch 48, Global step 48:
20-03-23 17:29-INFO-training batch loss: 0.6103; avg_loss: 1.5344
20-03-23 17:29-INFO-training batch acc: 0.6484; avg_acc: 0.5654
20-03-23 17:29-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 49, Global step 49:
20-03-23 17:30-INFO-training batch loss: 0.6236; avg_loss: 1.5158
20-03-23 17:30-INFO-training batch acc: 0.6562; avg_acc: 0.5673
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 50, Global step 50:
20-03-23 17:30-INFO-training batch loss: 0.6861; avg_loss: 1.4992
20-03-23 17:30-INFO-training batch acc: 0.5391; avg_acc: 0.5667
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 51, Global step 51:
20-03-23 17:30-INFO-training batch loss: 0.6814; avg_loss: 1.4832
20-03-23 17:30-INFO-training batch acc: 0.5781; avg_acc: 0.5669
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 52, Global step 52:
20-03-23 17:30-INFO-training batch loss: 0.6404; avg_loss: 1.4670
20-03-23 17:30-INFO-training batch acc: 0.6562; avg_acc: 0.5687
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 53, Global step 53:
20-03-23 17:30-INFO-training batch loss: 0.6521; avg_loss: 1.4516
20-03-23 17:30-INFO-training batch acc: 0.6328; avg_acc: 0.5699
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 54, Global step 54:
20-03-23 17:30-INFO-training batch loss: 0.6431; avg_loss: 1.4366
20-03-23 17:30-INFO-training batch acc: 0.5938; avg_acc: 0.5703
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 55, Global step 55:
20-03-23 17:30-INFO-training batch loss: 0.6381; avg_loss: 1.4221
20-03-23 17:30-INFO-training batch acc: 0.6172; avg_acc: 0.5712
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 56, Global step 56:
20-03-23 17:30-INFO-training batch loss: 0.6039; avg_loss: 1.4075
20-03-23 17:30-INFO-training batch acc: 0.6484; avg_acc: 0.5725
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 57, Global step 57:
20-03-23 17:30-INFO-training batch loss: 0.6307; avg_loss: 1.3939
20-03-23 17:30-INFO-training batch acc: 0.6719; avg_acc: 0.5743
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 58, Global step 58:
20-03-23 17:30-INFO-training batch loss: 0.5981; avg_loss: 1.3802
20-03-23 17:30-INFO-training batch acc: 0.7031; avg_acc: 0.5765
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 59, Global step 59:
20-03-23 17:30-INFO-training batch loss: 0.6180; avg_loss: 1.3673
20-03-23 17:30-INFO-training batch acc: 0.7031; avg_acc: 0.5787
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 60, Global step 60:
20-03-23 17:30-INFO-training batch loss: 0.6056; avg_loss: 1.3546
20-03-23 17:30-INFO-training batch acc: 0.6719; avg_acc: 0.5802
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 61, Global step 61:
20-03-23 17:30-INFO-training batch loss: 0.6092; avg_loss: 1.3423
20-03-23 17:30-INFO-training batch acc: 0.6719; avg_acc: 0.5817
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 62, Global step 62:
20-03-23 17:30-INFO-training batch loss: 0.6389; avg_loss: 1.3310
20-03-23 17:30-INFO-training batch acc: 0.6875; avg_acc: 0.5834
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 63, Global step 63:
20-03-23 17:30-INFO-training batch loss: 0.6010; avg_loss: 1.3194
20-03-23 17:30-INFO-training batch acc: 0.6719; avg_acc: 0.5848
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 64, Global step 64:
20-03-23 17:30-INFO-training batch loss: 0.6361; avg_loss: 1.3087
20-03-23 17:30-INFO-training batch acc: 0.6172; avg_acc: 0.5853
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 65, Global step 65:
20-03-23 17:30-INFO-training batch loss: 0.6200; avg_loss: 1.2981
20-03-23 17:30-INFO-training batch acc: 0.6172; avg_acc: 0.5858
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 66, Global step 66:
20-03-23 17:30-INFO-training batch loss: 0.5193; avg_loss: 1.2863
20-03-23 17:30-INFO-training batch acc: 0.7891; avg_acc: 0.5889
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 67, Global step 67:
20-03-23 17:30-INFO-training batch loss: 0.5246; avg_loss: 1.2750
20-03-23 17:30-INFO-training batch acc: 0.8281; avg_acc: 0.5925
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 68, Global step 68:
20-03-23 17:30-INFO-training batch loss: 0.5143; avg_loss: 1.2638
20-03-23 17:30-INFO-training batch acc: 0.7969; avg_acc: 0.5955
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 69, Global step 69:
20-03-23 17:30-INFO-training batch loss: 0.4602; avg_loss: 1.2521
20-03-23 17:30-INFO-training batch acc: 0.8359; avg_acc: 0.5990
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 70, Global step 70:
20-03-23 17:30-INFO-training batch loss: 0.4526; avg_loss: 1.2407
20-03-23 17:30-INFO-training batch acc: 0.8203; avg_acc: 0.6021
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 71, Global step 71:
20-03-23 17:30-INFO-training batch loss: 0.4657; avg_loss: 1.2298
20-03-23 17:30-INFO-training batch acc: 0.8438; avg_acc: 0.6055
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 72, Global step 72:
20-03-23 17:30-INFO-training batch loss: 0.3904; avg_loss: 1.2181
20-03-23 17:30-INFO-training batch acc: 0.8516; avg_acc: 0.6089
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 73, Global step 73:
20-03-23 17:30-INFO-training batch loss: 0.4396; avg_loss: 1.2075
20-03-23 17:30-INFO-training batch acc: 0.8359; avg_acc: 0.6121
20-03-23 17:30-INFO-
20-03-23 17:30-INFO-Epoch 0, Batch 74, Global step 74:
20-03-23 17:30-INFO-training batch loss: 0.3794; avg_loss: 1.1963
20-03-23 17:30-INFO-training batch acc: 0.8203; avg_acc: 0.6149
20-03-23 17:30-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 75, Global step 75:
20-03-23 17:31-INFO-training batch loss: 0.4370; avg_loss: 1.1862
20-03-23 17:31-INFO-training batch acc: 0.7500; avg_acc: 0.6167
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 76, Global step 76:
20-03-23 17:31-INFO-training batch loss: 0.3128; avg_loss: 1.1747
20-03-23 17:31-INFO-training batch acc: 0.8516; avg_acc: 0.6198
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 77, Global step 77:
20-03-23 17:31-INFO-training batch loss: 0.3570; avg_loss: 1.1640
20-03-23 17:31-INFO-training batch acc: 0.8281; avg_acc: 0.6225
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 78, Global step 78:
20-03-23 17:31-INFO-training batch loss: 0.3021; avg_loss: 1.1530
20-03-23 17:31-INFO-training batch acc: 0.8828; avg_acc: 0.6258
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 79, Global step 79:
20-03-23 17:31-INFO-training batch loss: 0.3051; avg_loss: 1.1423
20-03-23 17:31-INFO-training batch acc: 0.8672; avg_acc: 0.6289
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 80, Global step 80:
20-03-23 17:31-INFO-training batch loss: 0.3287; avg_loss: 1.1321
20-03-23 17:31-INFO-training batch acc: 0.8672; avg_acc: 0.6318
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 81, Global step 81:
20-03-23 17:31-INFO-training batch loss: 0.2505; avg_loss: 1.1212
20-03-23 17:31-INFO-training batch acc: 0.8906; avg_acc: 0.6350
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 82, Global step 82:
20-03-23 17:31-INFO-training batch loss: 0.3301; avg_loss: 1.1116
20-03-23 17:31-INFO-training batch acc: 0.8516; avg_acc: 0.6377
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 83, Global step 83:
20-03-23 17:31-INFO-training batch loss: 0.2891; avg_loss: 1.1017
20-03-23 17:31-INFO-training batch acc: 0.8984; avg_acc: 0.6408
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 84, Global step 84:
20-03-23 17:31-INFO-training batch loss: 0.2984; avg_loss: 1.0921
20-03-23 17:31-INFO-training batch acc: 0.8750; avg_acc: 0.6436
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 85, Global step 85:
20-03-23 17:31-INFO-training batch loss: 0.2431; avg_loss: 1.0821
20-03-23 17:31-INFO-training batch acc: 0.8984; avg_acc: 0.6466
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 86, Global step 86:
20-03-23 17:31-INFO-training batch loss: 0.2739; avg_loss: 1.0727
20-03-23 17:31-INFO-training batch acc: 0.8906; avg_acc: 0.6494
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 87, Global step 87:
20-03-23 17:31-INFO-training batch loss: 0.2320; avg_loss: 1.0630
20-03-23 17:31-INFO-training batch acc: 0.8750; avg_acc: 0.6520
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 88, Global step 88:
20-03-23 17:31-INFO-training batch loss: 0.2079; avg_loss: 1.0533
20-03-23 17:31-INFO-training batch acc: 0.9531; avg_acc: 0.6555
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 89, Global step 89:
20-03-23 17:31-INFO-training batch loss: 0.1516; avg_loss: 1.0432
20-03-23 17:31-INFO-training batch acc: 0.9609; avg_acc: 0.6589
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 90, Global step 90:
20-03-23 17:31-INFO-training batch loss: 0.1207; avg_loss: 1.0329
20-03-23 17:31-INFO-training batch acc: 0.9375; avg_acc: 0.6620
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 91, Global step 91:
20-03-23 17:31-INFO-training batch loss: 0.2528; avg_loss: 1.0244
20-03-23 17:31-INFO-training batch acc: 0.9141; avg_acc: 0.6647
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 92, Global step 92:
20-03-23 17:31-INFO-training batch loss: 0.1240; avg_loss: 1.0146
20-03-23 17:31-INFO-training batch acc: 0.9453; avg_acc: 0.6678
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 93, Global step 93:
20-03-23 17:31-INFO-training batch loss: 0.3150; avg_loss: 1.0071
20-03-23 17:31-INFO-training batch acc: 0.9219; avg_acc: 0.6705
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 94, Global step 94:
20-03-23 17:31-INFO-training batch loss: 0.1973; avg_loss: 0.9984
20-03-23 17:31-INFO-training batch acc: 0.9219; avg_acc: 0.6732
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 95, Global step 95:
20-03-23 17:31-INFO-training batch loss: 0.1432; avg_loss: 0.9894
20-03-23 17:31-INFO-training batch acc: 0.9531; avg_acc: 0.6762
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 96, Global step 96:
20-03-23 17:31-INFO-training batch loss: 0.3045; avg_loss: 0.9823
20-03-23 17:31-INFO-training batch acc: 0.8750; avg_acc: 0.6782
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 97, Global step 97:
20-03-23 17:31-INFO-training batch loss: 0.1338; avg_loss: 0.9736
20-03-23 17:31-INFO-training batch acc: 0.9453; avg_acc: 0.6810
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 98, Global step 98:
20-03-23 17:31-INFO-training batch loss: 0.1005; avg_loss: 0.9647
20-03-23 17:31-INFO-training batch acc: 0.9766; avg_acc: 0.6840
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 99, Global step 99:
20-03-23 17:31-INFO-training batch loss: 0.1462; avg_loss: 0.9564
20-03-23 17:31-INFO-training batch acc: 0.9609; avg_acc: 0.6868
20-03-23 17:31-INFO-
20-03-23 17:31-INFO-Epoch 0, Batch 100, Global step 100:
20-03-23 17:31-INFO-training batch loss: 0.1867; avg_loss: 0.9487
20-03-23 17:31-INFO-training batch acc: 0.9375; avg_acc: 0.6893
20-03-23 17:31-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 101, Global step 101:
20-03-23 17:32-INFO-training batch loss: 0.0908; avg_loss: 0.9402
20-03-23 17:32-INFO-training batch acc: 0.9609; avg_acc: 0.6920
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 102, Global step 102:
20-03-23 17:32-INFO-training batch loss: 0.0801; avg_loss: 0.9318
20-03-23 17:32-INFO-training batch acc: 0.9766; avg_acc: 0.6948
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 103, Global step 103:
20-03-23 17:32-INFO-training batch loss: 0.0973; avg_loss: 0.9237
20-03-23 17:32-INFO-training batch acc: 0.9531; avg_acc: 0.6973
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 104, Global step 104:
20-03-23 17:32-INFO-training batch loss: 0.0911; avg_loss: 0.9157
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7000
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 105, Global step 105:
20-03-23 17:32-INFO-training batch loss: 0.1031; avg_loss: 0.9079
20-03-23 17:32-INFO-training batch acc: 0.9531; avg_acc: 0.7025
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 106, Global step 106:
20-03-23 17:32-INFO-training batch loss: 0.1999; avg_loss: 0.9012
20-03-23 17:32-INFO-training batch acc: 0.9375; avg_acc: 0.7047
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 107, Global step 107:
20-03-23 17:32-INFO-training batch loss: 0.1972; avg_loss: 0.8947
20-03-23 17:32-INFO-training batch acc: 0.9219; avg_acc: 0.7067
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 108, Global step 108:
20-03-23 17:32-INFO-training batch loss: 0.1529; avg_loss: 0.8878
20-03-23 17:32-INFO-training batch acc: 0.9453; avg_acc: 0.7089
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 109, Global step 109:
20-03-23 17:32-INFO-training batch loss: 0.1064; avg_loss: 0.8806
20-03-23 17:32-INFO-training batch acc: 0.9609; avg_acc: 0.7112
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 110, Global step 110:
20-03-23 17:32-INFO-training batch loss: 0.1671; avg_loss: 0.8741
20-03-23 17:32-INFO-training batch acc: 0.9297; avg_acc: 0.7132
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 111, Global step 111:
20-03-23 17:32-INFO-training batch loss: 0.1048; avg_loss: 0.8672
20-03-23 17:32-INFO-training batch acc: 0.9531; avg_acc: 0.7154
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 112, Global step 112:
20-03-23 17:32-INFO-training batch loss: 0.0522; avg_loss: 0.8599
20-03-23 17:32-INFO-training batch acc: 0.9922; avg_acc: 0.7178
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 113, Global step 113:
20-03-23 17:32-INFO-training batch loss: 0.1263; avg_loss: 0.8534
20-03-23 17:32-INFO-training batch acc: 0.9688; avg_acc: 0.7201
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 114, Global step 114:
20-03-23 17:32-INFO-training batch loss: 0.1406; avg_loss: 0.8472
20-03-23 17:32-INFO-training batch acc: 0.9297; avg_acc: 0.7219
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 115, Global step 115:
20-03-23 17:32-INFO-training batch loss: 0.0599; avg_loss: 0.8403
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7242
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 116, Global step 116:
20-03-23 17:32-INFO-training batch loss: 0.0646; avg_loss: 0.8336
20-03-23 17:32-INFO-training batch acc: 0.9688; avg_acc: 0.7263
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 117, Global step 117:
20-03-23 17:32-INFO-training batch loss: 0.0837; avg_loss: 0.8272
20-03-23 17:32-INFO-training batch acc: 0.9766; avg_acc: 0.7284
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 118, Global step 118:
20-03-23 17:32-INFO-training batch loss: 0.0306; avg_loss: 0.8205
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7306
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 119, Global step 119:
20-03-23 17:32-INFO-training batch loss: 0.1006; avg_loss: 0.8144
20-03-23 17:32-INFO-training batch acc: 0.9688; avg_acc: 0.7326
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 120, Global step 120:
20-03-23 17:32-INFO-training batch loss: 0.0636; avg_loss: 0.8082
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7347
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 121, Global step 121:
20-03-23 17:32-INFO-training batch loss: 0.0427; avg_loss: 0.8019
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7368
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 122, Global step 122:
20-03-23 17:32-INFO-training batch loss: 0.0496; avg_loss: 0.7957
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7388
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 123, Global step 123:
20-03-23 17:32-INFO-training batch loss: 0.0750; avg_loss: 0.7898
20-03-23 17:32-INFO-training batch acc: 0.9766; avg_acc: 0.7407
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 124, Global step 124:
20-03-23 17:32-INFO-training batch loss: 0.0336; avg_loss: 0.7837
20-03-23 17:32-INFO-training batch acc: 0.9844; avg_acc: 0.7427
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 125, Global step 125:
20-03-23 17:32-INFO-training batch loss: 0.0542; avg_loss: 0.7779
20-03-23 17:32-INFO-training batch acc: 0.9688; avg_acc: 0.7445
20-03-23 17:32-INFO-
20-03-23 17:32-INFO-Epoch 0, Batch 126, Global step 126:
20-03-23 17:32-INFO-training batch loss: 0.0255; avg_loss: 0.7719
20-03-23 17:32-INFO-training batch acc: 0.9922; avg_acc: 0.7465
20-03-23 17:32-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 127, Global step 127:
20-03-23 17:33-INFO-training batch loss: 0.0407; avg_loss: 0.7662
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7484
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 128, Global step 128:
20-03-23 17:33-INFO-training batch loss: 0.0219; avg_loss: 0.7603
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7504
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 129, Global step 129:
20-03-23 17:33-INFO-training batch loss: 0.0360; avg_loss: 0.7547
20-03-23 17:33-INFO-training batch acc: 0.9766; avg_acc: 0.7521
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 130, Global step 130:
20-03-23 17:33-INFO-training batch loss: 0.0547; avg_loss: 0.7493
20-03-23 17:33-INFO-training batch acc: 0.9844; avg_acc: 0.7539
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 131, Global step 131:
20-03-23 17:33-INFO-training batch loss: 0.0214; avg_loss: 0.7438
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7558
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 132, Global step 132:
20-03-23 17:33-INFO-training batch loss: 0.0406; avg_loss: 0.7385
20-03-23 17:33-INFO-training batch acc: 0.9844; avg_acc: 0.7575
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 133, Global step 133:
20-03-23 17:33-INFO-training batch loss: 0.0321; avg_loss: 0.7332
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7593
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 134, Global step 134:
20-03-23 17:33-INFO-training batch loss: 0.0146; avg_loss: 0.7278
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7610
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 135, Global step 135:
20-03-23 17:33-INFO-training batch loss: 0.0852; avg_loss: 0.7230
20-03-23 17:33-INFO-training batch acc: 0.9531; avg_acc: 0.7624
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 136, Global step 136:
20-03-23 17:33-INFO-training batch loss: 0.0357; avg_loss: 0.7180
20-03-23 17:33-INFO-training batch acc: 0.9844; avg_acc: 0.7641
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 137, Global step 137:
20-03-23 17:33-INFO-training batch loss: 0.0309; avg_loss: 0.7130
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7657
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 138, Global step 138:
20-03-23 17:33-INFO-training batch loss: 0.1064; avg_loss: 0.7086
20-03-23 17:33-INFO-training batch acc: 0.9688; avg_acc: 0.7672
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 139, Global step 139:
20-03-23 17:33-INFO-training batch loss: 0.0309; avg_loss: 0.7037
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7688
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 140, Global step 140:
20-03-23 17:33-INFO-training batch loss: 0.0141; avg_loss: 0.6988
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7704
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 141, Global step 141:
20-03-23 17:33-INFO-training batch loss: 0.0444; avg_loss: 0.6941
20-03-23 17:33-INFO-training batch acc: 0.9844; avg_acc: 0.7719
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 142, Global step 142:
20-03-23 17:33-INFO-training batch loss: 0.0241; avg_loss: 0.6894
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7735
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 143, Global step 143:
20-03-23 17:33-INFO-training batch loss: 0.0367; avg_loss: 0.6848
20-03-23 17:33-INFO-training batch acc: 0.9844; avg_acc: 0.7750
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 144, Global step 144:
20-03-23 17:33-INFO-training batch loss: 0.0785; avg_loss: 0.6806
20-03-23 17:33-INFO-training batch acc: 0.9766; avg_acc: 0.7764
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 145, Global step 145:
20-03-23 17:33-INFO-training batch loss: 0.0229; avg_loss: 0.6761
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7779
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 146, Global step 146:
20-03-23 17:33-INFO-training batch loss: 0.0288; avg_loss: 0.6717
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7794
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 147, Global step 147:
20-03-23 17:33-INFO-training batch loss: 0.0122; avg_loss: 0.6672
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7809
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 148, Global step 148:
20-03-23 17:33-INFO-training batch loss: 0.0133; avg_loss: 0.6628
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7824
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 149, Global step 149:
20-03-23 17:33-INFO-training batch loss: 0.0421; avg_loss: 0.6586
20-03-23 17:33-INFO-training batch acc: 0.9844; avg_acc: 0.7838
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 150, Global step 150:
20-03-23 17:33-INFO-training batch loss: 0.0171; avg_loss: 0.6543
20-03-23 17:33-INFO-training batch acc: 0.9922; avg_acc: 0.7852
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 151, Global step 151:
20-03-23 17:33-INFO-training batch loss: 0.0083; avg_loss: 0.6500
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7866
20-03-23 17:33-INFO-
20-03-23 17:33-INFO-Epoch 0, Batch 152, Global step 152:
20-03-23 17:33-INFO-training batch loss: 0.0099; avg_loss: 0.6458
20-03-23 17:33-INFO-training batch acc: 1.0000; avg_acc: 0.7880
20-03-23 17:33-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 153, Global step 153:
20-03-23 17:34-INFO-training batch loss: 0.0206; avg_loss: 0.6417
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.7893
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 154, Global step 154:
20-03-23 17:34-INFO-training batch loss: 0.0056; avg_loss: 0.6376
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.7907
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 155, Global step 155:
20-03-23 17:34-INFO-training batch loss: 0.0130; avg_loss: 0.6336
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.7920
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 156, Global step 156:
20-03-23 17:34-INFO-training batch loss: 0.0156; avg_loss: 0.6296
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.7933
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 157, Global step 157:
20-03-23 17:34-INFO-training batch loss: 0.0319; avg_loss: 0.6258
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.7945
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 158, Global step 158:
20-03-23 17:34-INFO-training batch loss: 0.0135; avg_loss: 0.6219
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.7958
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 159, Global step 159:
20-03-23 17:34-INFO-training batch loss: 0.0067; avg_loss: 0.6181
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.7971
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 160, Global step 160:
20-03-23 17:34-INFO-training batch loss: 0.0158; avg_loss: 0.6143
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.7983
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 161, Global step 161:
20-03-23 17:34-INFO-training batch loss: 0.0060; avg_loss: 0.6105
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.7996
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 162, Global step 162:
20-03-23 17:34-INFO-training batch loss: 0.0064; avg_loss: 0.6068
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8008
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 163, Global step 163:
20-03-23 17:34-INFO-training batch loss: 0.0026; avg_loss: 0.6031
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8021
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 164, Global step 164:
20-03-23 17:34-INFO-training batch loss: 0.0158; avg_loss: 0.5995
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8032
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 165, Global step 165:
20-03-23 17:34-INFO-training batch loss: 0.0049; avg_loss: 0.5959
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8044
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 166, Global step 166:
20-03-23 17:34-INFO-training batch loss: 0.0170; avg_loss: 0.5924
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8055
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 167, Global step 167:
20-03-23 17:34-INFO-training batch loss: 0.0179; avg_loss: 0.5890
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8067
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 168, Global step 168:
20-03-23 17:34-INFO-training batch loss: 0.0069; avg_loss: 0.5855
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8078
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 169, Global step 169:
20-03-23 17:34-INFO-training batch loss: 0.0191; avg_loss: 0.5822
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8089
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 170, Global step 170:
20-03-23 17:34-INFO-training batch loss: 0.0059; avg_loss: 0.5788
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8100
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 171, Global step 171:
20-03-23 17:34-INFO-training batch loss: 0.0099; avg_loss: 0.5754
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8111
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 172, Global step 172:
20-03-23 17:34-INFO-training batch loss: 0.0101; avg_loss: 0.5722
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8122
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 173, Global step 173:
20-03-23 17:34-INFO-training batch loss: 0.0246; avg_loss: 0.5690
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8133
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 174, Global step 174:
20-03-23 17:34-INFO-training batch loss: 0.0030; avg_loss: 0.5657
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8143
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 175, Global step 175:
20-03-23 17:34-INFO-training batch loss: 0.0085; avg_loss: 0.5626
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8154
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 176, Global step 176:
20-03-23 17:34-INFO-training batch loss: 0.0342; avg_loss: 0.5596
20-03-23 17:34-INFO-training batch acc: 0.9922; avg_acc: 0.8164
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 177, Global step 177:
20-03-23 17:34-INFO-training batch loss: 0.0107; avg_loss: 0.5564
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8174
20-03-23 17:34-INFO-
20-03-23 17:34-INFO-Epoch 0, Batch 178, Global step 178:
20-03-23 17:34-INFO-training batch loss: 0.0049; avg_loss: 0.5534
20-03-23 17:34-INFO-training batch acc: 1.0000; avg_acc: 0.8184
20-03-23 17:34-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 179, Global step 179:
20-03-23 17:35-INFO-training batch loss: 0.0052; avg_loss: 0.5503
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8194
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 180, Global step 180:
20-03-23 17:35-INFO-training batch loss: 0.0140; avg_loss: 0.5473
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8204
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 181, Global step 181:
20-03-23 17:35-INFO-training batch loss: 0.0052; avg_loss: 0.5443
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8214
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 182, Global step 182:
20-03-23 17:35-INFO-training batch loss: 0.0604; avg_loss: 0.5417
20-03-23 17:35-INFO-training batch acc: 0.9844; avg_acc: 0.8223
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 183, Global step 183:
20-03-23 17:35-INFO-training batch loss: 0.0026; avg_loss: 0.5387
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8233
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 184, Global step 184:
20-03-23 17:35-INFO-training batch loss: 0.0022; avg_loss: 0.5358
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8242
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 185, Global step 185:
20-03-23 17:35-INFO-training batch loss: 0.0044; avg_loss: 0.5329
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8252
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 186, Global step 186:
20-03-23 17:35-INFO-training batch loss: 0.0078; avg_loss: 0.5301
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8261
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 187, Global step 187:
20-03-23 17:35-INFO-training batch loss: 0.0095; avg_loss: 0.5273
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8270
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 188, Global step 188:
20-03-23 17:35-INFO-training batch loss: 0.0030; avg_loss: 0.5245
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8280
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 189, Global step 189:
20-03-23 17:35-INFO-training batch loss: 0.0179; avg_loss: 0.5218
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8288
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 190, Global step 190:
20-03-23 17:35-INFO-training batch loss: 0.0119; avg_loss: 0.5192
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8297
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 191, Global step 191:
20-03-23 17:35-INFO-training batch loss: 0.0106; avg_loss: 0.5165
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8306
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 192, Global step 192:
20-03-23 17:35-INFO-training batch loss: 0.0118; avg_loss: 0.5139
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8315
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 193, Global step 193:
20-03-23 17:35-INFO-training batch loss: 0.0162; avg_loss: 0.5113
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8323
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 194, Global step 194:
20-03-23 17:35-INFO-training batch loss: 0.0349; avg_loss: 0.5088
20-03-23 17:35-INFO-training batch acc: 0.9844; avg_acc: 0.8331
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 195, Global step 195:
20-03-23 17:35-INFO-training batch loss: 0.0094; avg_loss: 0.5063
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8339
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 196, Global step 196:
20-03-23 17:35-INFO-training batch loss: 0.0076; avg_loss: 0.5037
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8348
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 197, Global step 197:
20-03-23 17:35-INFO-training batch loss: 0.0215; avg_loss: 0.5013
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8356
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 198, Global step 198:
20-03-23 17:35-INFO-training batch loss: 0.0231; avg_loss: 0.4989
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8364
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 199, Global step 199:
20-03-23 17:35-INFO-training batch loss: 0.0030; avg_loss: 0.4964
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8372
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 200, Global step 200:
20-03-23 17:35-INFO-training batch loss: 0.0139; avg_loss: 0.4940
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8380
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 201, Global step 201:
20-03-23 17:35-INFO-training batch loss: 0.0035; avg_loss: 0.4915
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8388
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 202, Global step 202:
20-03-23 17:35-INFO-training batch loss: 0.0022; avg_loss: 0.4891
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8396
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 203, Global step 203:
20-03-23 17:35-INFO-training batch loss: 0.0077; avg_loss: 0.4867
20-03-23 17:35-INFO-training batch acc: 1.0000; avg_acc: 0.8404
20-03-23 17:35-INFO-
20-03-23 17:35-INFO-Epoch 0, Batch 204, Global step 204:
20-03-23 17:35-INFO-training batch loss: 0.0103; avg_loss: 0.4844
20-03-23 17:35-INFO-training batch acc: 0.9922; avg_acc: 0.8411
20-03-23 17:35-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 205, Global step 205:
20-03-23 17:36-INFO-training batch loss: 0.0045; avg_loss: 0.4821
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8419
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 206, Global step 206:
20-03-23 17:36-INFO-training batch loss: 0.0030; avg_loss: 0.4797
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8427
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 207, Global step 207:
20-03-23 17:36-INFO-training batch loss: 0.0090; avg_loss: 0.4775
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8434
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 208, Global step 208:
20-03-23 17:36-INFO-training batch loss: 0.0081; avg_loss: 0.4752
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8442
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 209, Global step 209:
20-03-23 17:36-INFO-training batch loss: 0.0024; avg_loss: 0.4729
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8449
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 210, Global step 210:
20-03-23 17:36-INFO-training batch loss: 0.0018; avg_loss: 0.4707
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8457
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 211, Global step 211:
20-03-23 17:36-INFO-training batch loss: 0.0100; avg_loss: 0.4685
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8464
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 212, Global step 212:
20-03-23 17:36-INFO-training batch loss: 0.0019; avg_loss: 0.4663
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8471
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 213, Global step 213:
20-03-23 17:36-INFO-training batch loss: 0.0082; avg_loss: 0.4642
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8478
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 214, Global step 214:
20-03-23 17:36-INFO-training batch loss: 0.0032; avg_loss: 0.4620
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8485
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 215, Global step 215:
20-03-23 17:36-INFO-training batch loss: 0.0017; avg_loss: 0.4599
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8492
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 216, Global step 216:
20-03-23 17:36-INFO-training batch loss: 0.0021; avg_loss: 0.4577
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8499
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 217, Global step 217:
20-03-23 17:36-INFO-training batch loss: 0.0236; avg_loss: 0.4557
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8506
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 218, Global step 218:
20-03-23 17:36-INFO-training batch loss: 0.0150; avg_loss: 0.4537
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8512
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 219, Global step 219:
20-03-23 17:36-INFO-training batch loss: 0.0021; avg_loss: 0.4517
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8519
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 220, Global step 220:
20-03-23 17:36-INFO-training batch loss: 0.0075; avg_loss: 0.4496
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8526
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 221, Global step 221:
20-03-23 17:36-INFO-training batch loss: 0.0067; avg_loss: 0.4476
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8532
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 222, Global step 222:
20-03-23 17:36-INFO-training batch loss: 0.0282; avg_loss: 0.4457
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8538
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 223, Global step 223:
20-03-23 17:36-INFO-training batch loss: 0.0220; avg_loss: 0.4438
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8545
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 224, Global step 224:
20-03-23 17:36-INFO-training batch loss: 0.0029; avg_loss: 0.4419
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8551
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 225, Global step 225:
20-03-23 17:36-INFO-training batch loss: 0.0199; avg_loss: 0.4400
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8557
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 226, Global step 226:
20-03-23 17:36-INFO-training batch loss: 0.0280; avg_loss: 0.4382
20-03-23 17:36-INFO-training batch acc: 0.9844; avg_acc: 0.8563
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 227, Global step 227:
20-03-23 17:36-INFO-training batch loss: 0.0037; avg_loss: 0.4363
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8569
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 228, Global step 228:
20-03-23 17:36-INFO-training batch loss: 0.0015; avg_loss: 0.4344
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8576
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 229, Global step 229:
20-03-23 17:36-INFO-training batch loss: 0.0227; avg_loss: 0.4326
20-03-23 17:36-INFO-training batch acc: 0.9922; avg_acc: 0.8581
20-03-23 17:36-INFO-
20-03-23 17:36-INFO-Epoch 0, Batch 230, Global step 230:
20-03-23 17:36-INFO-training batch loss: 0.0048; avg_loss: 0.4307
20-03-23 17:36-INFO-training batch acc: 1.0000; avg_acc: 0.8588
20-03-23 17:36-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 231, Global step 231:
20-03-23 17:37-INFO-training batch loss: 0.0138; avg_loss: 0.4289
20-03-23 17:37-INFO-training batch acc: 0.9922; avg_acc: 0.8593
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 232, Global step 232:
20-03-23 17:37-INFO-training batch loss: 0.0025; avg_loss: 0.4271
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8599
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 233, Global step 233:
20-03-23 17:37-INFO-training batch loss: 0.0012; avg_loss: 0.4252
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8605
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 234, Global step 234:
20-03-23 17:37-INFO-training batch loss: 0.0031; avg_loss: 0.4234
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8611
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 235, Global step 235:
20-03-23 17:37-INFO-training batch loss: 0.0023; avg_loss: 0.4216
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8617
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 236, Global step 236:
20-03-23 17:37-INFO-training batch loss: 0.0103; avg_loss: 0.4199
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8623
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 237, Global step 237:
20-03-23 17:37-INFO-training batch loss: 0.0046; avg_loss: 0.4181
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8629
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 238, Global step 238:
20-03-23 17:37-INFO-training batch loss: 0.0104; avg_loss: 0.4164
20-03-23 17:37-INFO-training batch acc: 0.9922; avg_acc: 0.8634
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 239, Global step 239:
20-03-23 17:37-INFO-training batch loss: 0.0179; avg_loss: 0.4148
20-03-23 17:37-INFO-training batch acc: 0.9922; avg_acc: 0.8640
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 240, Global step 240:
20-03-23 17:37-INFO-training batch loss: 0.0114; avg_loss: 0.4131
20-03-23 17:37-INFO-training batch acc: 0.9922; avg_acc: 0.8645
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 241, Global step 241:
20-03-23 17:37-INFO-training batch loss: 0.0115; avg_loss: 0.4114
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8651
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 242, Global step 242:
20-03-23 17:37-INFO-training batch loss: 0.0034; avg_loss: 0.4097
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8656
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 243, Global step 243:
20-03-23 17:37-INFO-training batch loss: 0.0055; avg_loss: 0.4081
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8662
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 244, Global step 244:
20-03-23 17:37-INFO-training batch loss: 0.0009; avg_loss: 0.4064
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8667
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 245, Global step 245:
20-03-23 17:37-INFO-training batch loss: 0.0015; avg_loss: 0.4047
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8673
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 246, Global step 246:
20-03-23 17:37-INFO-training batch loss: 0.0030; avg_loss: 0.4031
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8678
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 247, Global step 247:
20-03-23 17:37-INFO-training batch loss: 0.0022; avg_loss: 0.4015
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8684
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 248, Global step 248:
20-03-23 17:37-INFO-training batch loss: 0.0082; avg_loss: 0.3999
20-03-23 17:37-INFO-training batch acc: 0.9922; avg_acc: 0.8689
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 249, Global step 249:
20-03-23 17:37-INFO-training batch loss: 0.0106; avg_loss: 0.3983
20-03-23 17:37-INFO-training batch acc: 0.9922; avg_acc: 0.8694
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 250, Global step 250:
20-03-23 17:37-INFO-training batch loss: 0.0055; avg_loss: 0.3968
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8699
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 251, Global step 251:
20-03-23 17:37-INFO-training batch loss: 0.0097; avg_loss: 0.3952
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8704
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 252, Global step 252:
20-03-23 17:37-INFO-training batch loss: 0.0044; avg_loss: 0.3937
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8709
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 253, Global step 253:
20-03-23 17:37-INFO-training batch loss: 0.0020; avg_loss: 0.3921
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8714
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 254, Global step 254:
20-03-23 17:37-INFO-training batch loss: 0.0062; avg_loss: 0.3906
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8719
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 255, Global step 255:
20-03-23 17:37-INFO-training batch loss: 0.0025; avg_loss: 0.3891
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8724
20-03-23 17:37-INFO-
20-03-23 17:37-INFO-Epoch 0, Batch 256, Global step 256:
20-03-23 17:37-INFO-training batch loss: 0.0013; avg_loss: 0.3876
20-03-23 17:37-INFO-training batch acc: 1.0000; avg_acc: 0.8729
20-03-23 17:37-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 257, Global step 257:
20-03-23 17:38-INFO-training batch loss: 0.0009; avg_loss: 0.3861
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8734
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 258, Global step 258:
20-03-23 17:38-INFO-training batch loss: 0.0025; avg_loss: 0.3846
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8739
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 259, Global step 259:
20-03-23 17:38-INFO-training batch loss: 0.0162; avg_loss: 0.3832
20-03-23 17:38-INFO-training batch acc: 0.9922; avg_acc: 0.8744
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 260, Global step 260:
20-03-23 17:38-INFO-training batch loss: 0.0032; avg_loss: 0.3817
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8748
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 261, Global step 261:
20-03-23 17:38-INFO-training batch loss: 0.0080; avg_loss: 0.3803
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8753
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 262, Global step 262:
20-03-23 17:38-INFO-training batch loss: 0.0034; avg_loss: 0.3788
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8758
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 263, Global step 263:
20-03-23 17:38-INFO-training batch loss: 0.0008; avg_loss: 0.3774
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8763
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 264, Global step 264:
20-03-23 17:38-INFO-training batch loss: 0.0007; avg_loss: 0.3760
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8767
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 265, Global step 265:
20-03-23 17:38-INFO-training batch loss: 0.0009; avg_loss: 0.3745
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8772
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 266, Global step 266:
20-03-23 17:38-INFO-training batch loss: 0.0266; avg_loss: 0.3732
20-03-23 17:38-INFO-training batch acc: 0.9922; avg_acc: 0.8776
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 267, Global step 267:
20-03-23 17:38-INFO-training batch loss: 0.0040; avg_loss: 0.3718
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8781
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 268, Global step 268:
20-03-23 17:38-INFO-training batch loss: 0.0013; avg_loss: 0.3705
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8786
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 269, Global step 269:
20-03-23 17:38-INFO-training batch loss: 0.0014; avg_loss: 0.3691
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8790
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 270, Global step 270:
20-03-23 17:38-INFO-training batch loss: 0.0214; avg_loss: 0.3678
20-03-23 17:38-INFO-training batch acc: 0.9844; avg_acc: 0.8794
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 271, Global step 271:
20-03-23 17:38-INFO-training batch loss: 0.0066; avg_loss: 0.3665
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8798
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 272, Global step 272:
20-03-23 17:38-INFO-training batch loss: 0.0007; avg_loss: 0.3651
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8803
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 273, Global step 273:
20-03-23 17:38-INFO-training batch loss: 0.0041; avg_loss: 0.3638
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8807
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 274, Global step 274:
20-03-23 17:38-INFO-training batch loss: 0.0019; avg_loss: 0.3625
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8812
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 275, Global step 275:
20-03-23 17:38-INFO-training batch loss: 0.0011; avg_loss: 0.3612
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8816
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 276, Global step 276:
20-03-23 17:38-INFO-training batch loss: 0.0015; avg_loss: 0.3599
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8820
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 277, Global step 277:
20-03-23 17:38-INFO-training batch loss: 0.0012; avg_loss: 0.3586
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8824
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 278, Global step 278:
20-03-23 17:38-INFO-training batch loss: 0.0016; avg_loss: 0.3573
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8829
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 279, Global step 279:
20-03-23 17:38-INFO-training batch loss: 0.0016; avg_loss: 0.3560
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8833
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 280, Global step 280:
20-03-23 17:38-INFO-training batch loss: 0.0063; avg_loss: 0.3548
20-03-23 17:38-INFO-training batch acc: 0.9922; avg_acc: 0.8837
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 281, Global step 281:
20-03-23 17:38-INFO-training batch loss: 0.0040; avg_loss: 0.3535
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8841
20-03-23 17:38-INFO-
20-03-23 17:38-INFO-Epoch 0, Batch 282, Global step 282:
20-03-23 17:38-INFO-training batch loss: 0.0026; avg_loss: 0.3523
20-03-23 17:38-INFO-training batch acc: 1.0000; avg_acc: 0.8845
20-03-23 17:38-INFO-
20-03-23 17:39-INFO-Epoch 0, Batch 283, Global step 283:
20-03-23 17:39-INFO-training batch loss: 0.0020; avg_loss: 0.3510
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 0.8849
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 0, Batch 284, Global step 284:
20-03-23 17:39-INFO-training batch loss: 0.0006; avg_loss: 0.3498
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 0.8853
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 0, training batch loss: 0.0006; avg_loss: 0.3498
20-03-23 17:39-INFO-Epoch 0, training batch accuracy: 1.0000; avg_accuracy: 0.8853
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 0, evaluating batch loss: 1.0119; avg_loss: 0.3820
20-03-23 17:39-INFO-Epoch 0, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9429
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 1, Global step 285:
20-03-23 17:39-INFO-training batch loss: 0.0016; avg_loss: 0.0016
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 2, Global step 286:
20-03-23 17:39-INFO-training batch loss: 0.0049; avg_loss: 0.0033
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 3, Global step 287:
20-03-23 17:39-INFO-training batch loss: 0.0013; avg_loss: 0.0026
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 4, Global step 288:
20-03-23 17:39-INFO-training batch loss: 0.0014; avg_loss: 0.0023
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 5, Global step 289:
20-03-23 17:39-INFO-training batch loss: 0.0034; avg_loss: 0.0025
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 6, Global step 290:
20-03-23 17:39-INFO-training batch loss: 0.0048; avg_loss: 0.0029
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 7, Global step 291:
20-03-23 17:39-INFO-training batch loss: 0.0071; avg_loss: 0.0035
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 8, Global step 292:
20-03-23 17:39-INFO-training batch loss: 0.0021; avg_loss: 0.0033
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 9, Global step 293:
20-03-23 17:39-INFO-training batch loss: 0.0024; avg_loss: 0.0032
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 10, Global step 294:
20-03-23 17:39-INFO-training batch loss: 0.0002; avg_loss: 0.0029
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 11, Global step 295:
20-03-23 17:39-INFO-training batch loss: 0.0059; avg_loss: 0.0032
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 12, Global step 296:
20-03-23 17:39-INFO-training batch loss: 0.0007; avg_loss: 0.0030
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 13, Global step 297:
20-03-23 17:39-INFO-training batch loss: 0.0008; avg_loss: 0.0028
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 14, Global step 298:
20-03-23 17:39-INFO-training batch loss: 0.0027; avg_loss: 0.0028
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 15, Global step 299:
20-03-23 17:39-INFO-training batch loss: 0.0010; avg_loss: 0.0027
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 16, Global step 300:
20-03-23 17:39-INFO-training batch loss: 0.0003; avg_loss: 0.0025
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 17, Global step 301:
20-03-23 17:39-INFO-training batch loss: 0.0003; avg_loss: 0.0024
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 18, Global step 302:
20-03-23 17:39-INFO-training batch loss: 0.0003; avg_loss: 0.0023
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 19, Global step 303:
20-03-23 17:39-INFO-training batch loss: 0.0006; avg_loss: 0.0022
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:39-INFO-Epoch 1, Batch 20, Global step 304:
20-03-23 17:39-INFO-training batch loss: 0.0011; avg_loss: 0.0021
20-03-23 17:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:39-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 21, Global step 305:
20-03-23 17:40-INFO-training batch loss: 0.0012; avg_loss: 0.0021
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 22, Global step 306:
20-03-23 17:40-INFO-training batch loss: 0.0023; avg_loss: 0.0021
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 23, Global step 307:
20-03-23 17:40-INFO-training batch loss: 0.0008; avg_loss: 0.0021
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 24, Global step 308:
20-03-23 17:40-INFO-training batch loss: 0.0002; avg_loss: 0.0020
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 25, Global step 309:
20-03-23 17:40-INFO-training batch loss: 0.0003; avg_loss: 0.0019
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 26, Global step 310:
20-03-23 17:40-INFO-training batch loss: 0.0008; avg_loss: 0.0019
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 27, Global step 311:
20-03-23 17:40-INFO-training batch loss: 0.0018; avg_loss: 0.0019
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 28, Global step 312:
20-03-23 17:40-INFO-training batch loss: 0.0005; avg_loss: 0.0018
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 29, Global step 313:
20-03-23 17:40-INFO-training batch loss: 0.0010; avg_loss: 0.0018
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 30, Global step 314:
20-03-23 17:40-INFO-training batch loss: 0.0003; avg_loss: 0.0017
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 31, Global step 315:
20-03-23 17:40-INFO-training batch loss: 0.0003; avg_loss: 0.0017
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 32, Global step 316:
20-03-23 17:40-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 33, Global step 317:
20-03-23 17:40-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 34, Global step 318:
20-03-23 17:40-INFO-training batch loss: 0.0003; avg_loss: 0.0016
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 35, Global step 319:
20-03-23 17:40-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 36, Global step 320:
20-03-23 17:40-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 37, Global step 321:
20-03-23 17:40-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 38, Global step 322:
20-03-23 17:40-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 39, Global step 323:
20-03-23 17:40-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 40, Global step 324:
20-03-23 17:40-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 41, Global step 325:
20-03-23 17:40-INFO-training batch loss: 0.0001; avg_loss: 0.0014
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 42, Global step 326:
20-03-23 17:40-INFO-training batch loss: 0.0008; avg_loss: 0.0014
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 43, Global step 327:
20-03-23 17:40-INFO-training batch loss: 0.0009; avg_loss: 0.0014
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 44, Global step 328:
20-03-23 17:40-INFO-training batch loss: 0.0009; avg_loss: 0.0013
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 45, Global step 329:
20-03-23 17:40-INFO-training batch loss: 0.0001; avg_loss: 0.0013
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 46, Global step 330:
20-03-23 17:40-INFO-training batch loss: 0.0003; avg_loss: 0.0013
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:40-INFO-Epoch 1, Batch 47, Global step 331:
20-03-23 17:40-INFO-training batch loss: 0.0006; avg_loss: 0.0013
20-03-23 17:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:40-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 48, Global step 332:
20-03-23 17:41-INFO-training batch loss: 0.0003; avg_loss: 0.0013
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 49, Global step 333:
20-03-23 17:41-INFO-training batch loss: 0.0017; avg_loss: 0.0013
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 50, Global step 334:
20-03-23 17:41-INFO-training batch loss: 0.0002; avg_loss: 0.0013
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 51, Global step 335:
20-03-23 17:41-INFO-training batch loss: 0.0018; avg_loss: 0.0013
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 52, Global step 336:
20-03-23 17:41-INFO-training batch loss: 0.0004; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 53, Global step 337:
20-03-23 17:41-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 54, Global step 338:
20-03-23 17:41-INFO-training batch loss: 0.0007; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 55, Global step 339:
20-03-23 17:41-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 56, Global step 340:
20-03-23 17:41-INFO-training batch loss: 0.0010; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 57, Global step 341:
20-03-23 17:41-INFO-training batch loss: 0.0029; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 58, Global step 342:
20-03-23 17:41-INFO-training batch loss: 0.0002; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 59, Global step 343:
20-03-23 17:41-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 60, Global step 344:
20-03-23 17:41-INFO-training batch loss: 0.0001; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 61, Global step 345:
20-03-23 17:41-INFO-training batch loss: 0.0009; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 62, Global step 346:
20-03-23 17:41-INFO-training batch loss: 0.0001; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 63, Global step 347:
20-03-23 17:41-INFO-training batch loss: 0.0001; avg_loss: 0.0011
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 64, Global step 348:
20-03-23 17:41-INFO-training batch loss: 0.0002; avg_loss: 0.0011
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 65, Global step 349:
20-03-23 17:41-INFO-training batch loss: 0.0061; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 0.9922; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 66, Global step 350:
20-03-23 17:41-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 67, Global step 351:
20-03-23 17:41-INFO-training batch loss: 0.0006; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 68, Global step 352:
20-03-23 17:41-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 69, Global step 353:
20-03-23 17:41-INFO-training batch loss: 0.0010; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 70, Global step 354:
20-03-23 17:41-INFO-training batch loss: 0.0016; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 71, Global step 355:
20-03-23 17:41-INFO-training batch loss: 0.0012; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 72, Global step 356:
20-03-23 17:41-INFO-training batch loss: 0.0027; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:41-INFO-Epoch 1, Batch 73, Global step 357:
20-03-23 17:41-INFO-training batch loss: 0.0008; avg_loss: 0.0012
20-03-23 17:41-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:41-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 74, Global step 358:
20-03-23 17:42-INFO-training batch loss: 0.0019; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 75, Global step 359:
20-03-23 17:42-INFO-training batch loss: 0.0002; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 76, Global step 360:
20-03-23 17:42-INFO-training batch loss: 0.0002; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 77, Global step 361:
20-03-23 17:42-INFO-training batch loss: 0.0004; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 78, Global step 362:
20-03-23 17:42-INFO-training batch loss: 0.0003; avg_loss: 0.0011
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 79, Global step 363:
20-03-23 17:42-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 80, Global step 364:
20-03-23 17:42-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 81, Global step 365:
20-03-23 17:42-INFO-training batch loss: 0.0090; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 0.9922; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 82, Global step 366:
20-03-23 17:42-INFO-training batch loss: 0.0002; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 83, Global step 367:
20-03-23 17:42-INFO-training batch loss: 0.0026; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 84, Global step 368:
20-03-23 17:42-INFO-training batch loss: 0.0013; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 85, Global step 369:
20-03-23 17:42-INFO-training batch loss: 0.0007; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 86, Global step 370:
20-03-23 17:42-INFO-training batch loss: 0.0006; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 87, Global step 371:
20-03-23 17:42-INFO-training batch loss: 0.0014; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 88, Global step 372:
20-03-23 17:42-INFO-training batch loss: 0.0005; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 89, Global step 373:
20-03-23 17:42-INFO-training batch loss: 0.0017; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 90, Global step 374:
20-03-23 17:42-INFO-training batch loss: 0.0024; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 91, Global step 375:
20-03-23 17:42-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 92, Global step 376:
20-03-23 17:42-INFO-training batch loss: 0.0005; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 93, Global step 377:
20-03-23 17:42-INFO-training batch loss: 0.0002; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 94, Global step 378:
20-03-23 17:42-INFO-training batch loss: 0.0005; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 95, Global step 379:
20-03-23 17:42-INFO-training batch loss: 0.0003; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 96, Global step 380:
20-03-23 17:42-INFO-training batch loss: 0.0019; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 97, Global step 381:
20-03-23 17:42-INFO-training batch loss: 0.0004; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 98, Global step 382:
20-03-23 17:42-INFO-training batch loss: 0.0013; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 99, Global step 383:
20-03-23 17:42-INFO-training batch loss: 0.0004; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:42-INFO-Epoch 1, Batch 100, Global step 384:
20-03-23 17:42-INFO-training batch loss: 0.0020; avg_loss: 0.0012
20-03-23 17:42-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:42-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 101, Global step 385:
20-03-23 17:43-INFO-training batch loss: 0.0199; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 0.9922; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 102, Global step 386:
20-03-23 17:43-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 103, Global step 387:
20-03-23 17:43-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 104, Global step 388:
20-03-23 17:43-INFO-training batch loss: 0.0002; avg_loss: 0.0013
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 105, Global step 389:
20-03-23 17:43-INFO-training batch loss: 0.0000; avg_loss: 0.0013
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 106, Global step 390:
20-03-23 17:43-INFO-training batch loss: 0.0003; avg_loss: 0.0013
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 107, Global step 391:
20-03-23 17:43-INFO-training batch loss: 0.0004; avg_loss: 0.0013
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 108, Global step 392:
20-03-23 17:43-INFO-training batch loss: 0.0116; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 109, Global step 393:
20-03-23 17:43-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 110, Global step 394:
20-03-23 17:43-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 111, Global step 395:
20-03-23 17:43-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 112, Global step 396:
20-03-23 17:43-INFO-training batch loss: 0.0006; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 113, Global step 397:
20-03-23 17:43-INFO-training batch loss: 0.0031; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 114, Global step 398:
20-03-23 17:43-INFO-training batch loss: 0.0088; avg_loss: 0.0015
20-03-23 17:43-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 115, Global step 399:
20-03-23 17:43-INFO-training batch loss: 0.0009; avg_loss: 0.0015
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 116, Global step 400:
20-03-23 17:43-INFO-training batch loss: 0.0012; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 117, Global step 401:
20-03-23 17:43-INFO-training batch loss: 0.0009; avg_loss: 0.0014
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 118, Global step 402:
20-03-23 17:43-INFO-training batch loss: 0.0058; avg_loss: 0.0015
20-03-23 17:43-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 119, Global step 403:
20-03-23 17:43-INFO-training batch loss: 0.0054; avg_loss: 0.0015
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 120, Global step 404:
20-03-23 17:43-INFO-training batch loss: 0.0144; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 0.9922; avg_acc: 0.9995
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 121, Global step 405:
20-03-23 17:43-INFO-training batch loss: 0.0015; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 122, Global step 406:
20-03-23 17:43-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 123, Global step 407:
20-03-23 17:43-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 124, Global step 408:
20-03-23 17:43-INFO-training batch loss: 0.0010; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 125, Global step 409:
20-03-23 17:43-INFO-training batch loss: 0.0051; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:43-INFO-Epoch 1, Batch 126, Global step 410:
20-03-23 17:43-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 17:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:43-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 127, Global step 411:
20-03-23 17:44-INFO-training batch loss: 0.0002; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 128, Global step 412:
20-03-23 17:44-INFO-training batch loss: 0.0013; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 129, Global step 413:
20-03-23 17:44-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 130, Global step 414:
20-03-23 17:44-INFO-training batch loss: 0.0026; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 131, Global step 415:
20-03-23 17:44-INFO-training batch loss: 0.0007; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 132, Global step 416:
20-03-23 17:44-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 133, Global step 417:
20-03-23 17:44-INFO-training batch loss: 0.0020; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 134, Global step 418:
20-03-23 17:44-INFO-training batch loss: 0.0004; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 135, Global step 419:
20-03-23 17:44-INFO-training batch loss: 0.0038; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 136, Global step 420:
20-03-23 17:44-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 137, Global step 421:
20-03-23 17:44-INFO-training batch loss: 0.0004; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 138, Global step 422:
20-03-23 17:44-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 139, Global step 423:
20-03-23 17:44-INFO-training batch loss: 0.0002; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 140, Global step 424:
20-03-23 17:44-INFO-training batch loss: 0.0018; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 141, Global step 425:
20-03-23 17:44-INFO-training batch loss: 0.0027; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 142, Global step 426:
20-03-23 17:44-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 143, Global step 427:
20-03-23 17:44-INFO-training batch loss: 0.0003; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 144, Global step 428:
20-03-23 17:44-INFO-training batch loss: 0.0008; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 145, Global step 429:
20-03-23 17:44-INFO-training batch loss: 0.0003; avg_loss: 0.0016
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 146, Global step 430:
20-03-23 17:44-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 147, Global step 431:
20-03-23 17:44-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 148, Global step 432:
20-03-23 17:44-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 149, Global step 433:
20-03-23 17:44-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 150, Global step 434:
20-03-23 17:44-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 151, Global step 435:
20-03-23 17:44-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 152, Global step 436:
20-03-23 17:44-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:44-INFO-Epoch 1, Batch 153, Global step 437:
20-03-23 17:44-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:44-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 154, Global step 438:
20-03-23 17:45-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 155, Global step 439:
20-03-23 17:45-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 156, Global step 440:
20-03-23 17:45-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 157, Global step 441:
20-03-23 17:45-INFO-training batch loss: 0.0030; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 158, Global step 442:
20-03-23 17:45-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 159, Global step 443:
20-03-23 17:45-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 160, Global step 444:
20-03-23 17:45-INFO-training batch loss: 0.0018; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 161, Global step 445:
20-03-23 17:45-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 162, Global step 446:
20-03-23 17:45-INFO-training batch loss: 0.0001; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 163, Global step 447:
20-03-23 17:45-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 164, Global step 448:
20-03-23 17:45-INFO-training batch loss: 0.0047; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 165, Global step 449:
20-03-23 17:45-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 166, Global step 450:
20-03-23 17:45-INFO-training batch loss: 0.0026; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 167, Global step 451:
20-03-23 17:45-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 168, Global step 452:
20-03-23 17:45-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 169, Global step 453:
20-03-23 17:45-INFO-training batch loss: 0.0106; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 170, Global step 454:
20-03-23 17:45-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 171, Global step 455:
20-03-23 17:45-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 172, Global step 456:
20-03-23 17:45-INFO-training batch loss: 0.0019; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 173, Global step 457:
20-03-23 17:45-INFO-training batch loss: 0.0044; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 174, Global step 458:
20-03-23 17:45-INFO-training batch loss: 0.0033; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 175, Global step 459:
20-03-23 17:45-INFO-training batch loss: 0.0034; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 176, Global step 460:
20-03-23 17:45-INFO-training batch loss: 0.0015; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 177, Global step 461:
20-03-23 17:45-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 178, Global step 462:
20-03-23 17:45-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 17:45-INFO-
20-03-23 17:45-INFO-Epoch 1, Batch 179, Global step 463:
20-03-23 17:45-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 17:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:45-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 180, Global step 464:
20-03-23 17:46-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 181, Global step 465:
20-03-23 17:46-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 182, Global step 466:
20-03-23 17:46-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 183, Global step 467:
20-03-23 17:46-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 184, Global step 468:
20-03-23 17:46-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 185, Global step 469:
20-03-23 17:46-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 186, Global step 470:
20-03-23 17:46-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 187, Global step 471:
20-03-23 17:46-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 188, Global step 472:
20-03-23 17:46-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 189, Global step 473:
20-03-23 17:46-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 190, Global step 474:
20-03-23 17:46-INFO-training batch loss: 0.0033; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 191, Global step 475:
20-03-23 17:46-INFO-training batch loss: 0.0038; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 192, Global step 476:
20-03-23 17:46-INFO-training batch loss: 0.0024; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 193, Global step 477:
20-03-23 17:46-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 194, Global step 478:
20-03-23 17:46-INFO-training batch loss: 0.0016; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 195, Global step 479:
20-03-23 17:46-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 196, Global step 480:
20-03-23 17:46-INFO-training batch loss: 0.0021; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 197, Global step 481:
20-03-23 17:46-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 198, Global step 482:
20-03-23 17:46-INFO-training batch loss: 0.0058; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 199, Global step 483:
20-03-23 17:46-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 200, Global step 484:
20-03-23 17:46-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 201, Global step 485:
20-03-23 17:46-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 202, Global step 486:
20-03-23 17:46-INFO-training batch loss: 0.0031; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 203, Global step 487:
20-03-23 17:46-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 204, Global step 488:
20-03-23 17:46-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 205, Global step 489:
20-03-23 17:46-INFO-training batch loss: 0.0009; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:46-INFO-Epoch 1, Batch 206, Global step 490:
20-03-23 17:46-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:46-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 207, Global step 491:
20-03-23 17:47-INFO-training batch loss: 0.0009; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 208, Global step 492:
20-03-23 17:47-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 209, Global step 493:
20-03-23 17:47-INFO-training batch loss: 0.0051; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 210, Global step 494:
20-03-23 17:47-INFO-training batch loss: 0.0029; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 211, Global step 495:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 212, Global step 496:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 213, Global step 497:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 214, Global step 498:
20-03-23 17:47-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 215, Global step 499:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 216, Global step 500:
20-03-23 17:47-INFO-training batch loss: 0.0040; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 217, Global step 501:
20-03-23 17:47-INFO-training batch loss: 0.0009; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 218, Global step 502:
20-03-23 17:47-INFO-training batch loss: 0.0019; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 219, Global step 503:
20-03-23 17:47-INFO-training batch loss: 0.0020; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 220, Global step 504:
20-03-23 17:47-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 221, Global step 505:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 222, Global step 506:
20-03-23 17:47-INFO-training batch loss: 0.0013; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 223, Global step 507:
20-03-23 17:47-INFO-training batch loss: 0.0078; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 224, Global step 508:
20-03-23 17:47-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 225, Global step 509:
20-03-23 17:47-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 226, Global step 510:
20-03-23 17:47-INFO-training batch loss: 0.0072; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 227, Global step 511:
20-03-23 17:47-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 228, Global step 512:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 229, Global step 513:
20-03-23 17:47-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 230, Global step 514:
20-03-23 17:47-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 231, Global step 515:
20-03-23 17:47-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:47-INFO-Epoch 1, Batch 232, Global step 516:
20-03-23 17:47-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:47-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:47-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 233, Global step 517:
20-03-23 17:48-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 234, Global step 518:
20-03-23 17:48-INFO-training batch loss: 0.0016; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 235, Global step 519:
20-03-23 17:48-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 236, Global step 520:
20-03-23 17:48-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 237, Global step 521:
20-03-23 17:48-INFO-training batch loss: 0.0001; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 238, Global step 522:
20-03-23 17:48-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 239, Global step 523:
20-03-23 17:48-INFO-training batch loss: 0.0016; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 240, Global step 524:
20-03-23 17:48-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 241, Global step 525:
20-03-23 17:48-INFO-training batch loss: 0.0002; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 242, Global step 526:
20-03-23 17:48-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 243, Global step 527:
20-03-23 17:48-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 244, Global step 528:
20-03-23 17:48-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 245, Global step 529:
20-03-23 17:48-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 246, Global step 530:
20-03-23 17:48-INFO-training batch loss: 0.0011; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 247, Global step 531:
20-03-23 17:48-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 248, Global step 532:
20-03-23 17:48-INFO-training batch loss: 0.0017; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 249, Global step 533:
20-03-23 17:48-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 250, Global step 534:
20-03-23 17:48-INFO-training batch loss: 0.0016; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 251, Global step 535:
20-03-23 17:48-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 252, Global step 536:
20-03-23 17:48-INFO-training batch loss: 0.0001; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 253, Global step 537:
20-03-23 17:48-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 254, Global step 538:
20-03-23 17:48-INFO-training batch loss: 0.0010; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 255, Global step 539:
20-03-23 17:48-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 256, Global step 540:
20-03-23 17:48-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:48-INFO-Epoch 1, Batch 257, Global step 541:
20-03-23 17:48-INFO-training batch loss: 0.0016; avg_loss: 0.0014
20-03-23 17:48-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:48-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 258, Global step 542:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 259, Global step 543:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 260, Global step 544:
20-03-23 17:49-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 261, Global step 545:
20-03-23 17:49-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 262, Global step 546:
20-03-23 17:49-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 263, Global step 547:
20-03-23 17:49-INFO-training batch loss: 0.0001; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 264, Global step 548:
20-03-23 17:49-INFO-training batch loss: 0.0006; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 265, Global step 549:
20-03-23 17:49-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 266, Global step 550:
20-03-23 17:49-INFO-training batch loss: 0.0001; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 267, Global step 551:
20-03-23 17:49-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 268, Global step 552:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 269, Global step 553:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 270, Global step 554:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 271, Global step 555:
20-03-23 17:49-INFO-training batch loss: 0.0003; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 272, Global step 556:
20-03-23 17:49-INFO-training batch loss: 0.0015; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 273, Global step 557:
20-03-23 17:49-INFO-training batch loss: 0.0065; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 274, Global step 558:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 275, Global step 559:
20-03-23 17:49-INFO-training batch loss: 0.0002; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 276, Global step 560:
20-03-23 17:49-INFO-training batch loss: 0.0007; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 277, Global step 561:
20-03-23 17:49-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 278, Global step 562:
20-03-23 17:49-INFO-training batch loss: 0.0021; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 279, Global step 563:
20-03-23 17:49-INFO-training batch loss: 0.0015; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 280, Global step 564:
20-03-23 17:49-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 281, Global step 565:
20-03-23 17:49-INFO-training batch loss: 0.0010; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:49-INFO-Epoch 1, Batch 282, Global step 566:
20-03-23 17:49-INFO-training batch loss: 0.0023; avg_loss: 0.0014
20-03-23 17:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:49-INFO-
20-03-23 17:50-INFO-Epoch 1, Batch 283, Global step 567:
20-03-23 17:50-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 1, Batch 284, Global step 568:
20-03-23 17:50-INFO-training batch loss: 0.0012; avg_loss: 0.0014
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 1, training batch loss: 0.0012; avg_loss: 0.0014
20-03-23 17:50-INFO-Epoch 1, training batch accuracy: 1.0000; avg_accuracy: 0.9997
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 1, evaluating batch loss: 0.8681; avg_loss: 0.3025
20-03-23 17:50-INFO-Epoch 1, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9616
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 1, Global step 569:
20-03-23 17:50-INFO-training batch loss: 0.0005; avg_loss: 0.0005
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 2, Global step 570:
20-03-23 17:50-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 3, Global step 571:
20-03-23 17:50-INFO-training batch loss: 0.0006; avg_loss: 0.0005
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 4, Global step 572:
20-03-23 17:50-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 5, Global step 573:
20-03-23 17:50-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 6, Global step 574:
20-03-23 17:50-INFO-training batch loss: 0.0009; avg_loss: 0.0005
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 7, Global step 575:
20-03-23 17:50-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 8, Global step 576:
20-03-23 17:50-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 9, Global step 577:
20-03-23 17:50-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 10, Global step 578:
20-03-23 17:50-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 11, Global step 579:
20-03-23 17:50-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 12, Global step 580:
20-03-23 17:50-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 13, Global step 581:
20-03-23 17:50-INFO-training batch loss: 0.0009; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 14, Global step 582:
20-03-23 17:50-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 15, Global step 583:
20-03-23 17:50-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 16, Global step 584:
20-03-23 17:50-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 17, Global step 585:
20-03-23 17:50-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 18, Global step 586:
20-03-23 17:50-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 19, Global step 587:
20-03-23 17:50-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:50-INFO-Epoch 2, Batch 20, Global step 588:
20-03-23 17:50-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:50-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 21, Global step 589:
20-03-23 17:51-INFO-training batch loss: 0.0009; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 22, Global step 590:
20-03-23 17:51-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 23, Global step 591:
20-03-23 17:51-INFO-training batch loss: 0.0009; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 24, Global step 592:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 25, Global step 593:
20-03-23 17:51-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 26, Global step 594:
20-03-23 17:51-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 27, Global step 595:
20-03-23 17:51-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 28, Global step 596:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 29, Global step 597:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 30, Global step 598:
20-03-23 17:51-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 31, Global step 599:
20-03-23 17:51-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 32, Global step 600:
20-03-23 17:51-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 33, Global step 601:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 34, Global step 602:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 35, Global step 603:
20-03-23 17:51-INFO-training batch loss: 0.0009; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 36, Global step 604:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 37, Global step 605:
20-03-23 17:51-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 38, Global step 606:
20-03-23 17:51-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 39, Global step 607:
20-03-23 17:51-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 40, Global step 608:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 41, Global step 609:
20-03-23 17:51-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 42, Global step 610:
20-03-23 17:51-INFO-training batch loss: 0.0011; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 43, Global step 611:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 44, Global step 612:
20-03-23 17:51-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 45, Global step 613:
20-03-23 17:51-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:51-INFO-Epoch 2, Batch 46, Global step 614:
20-03-23 17:51-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 17:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:51-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 47, Global step 615:
20-03-23 17:52-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 48, Global step 616:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 49, Global step 617:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 50, Global step 618:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 51, Global step 619:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 52, Global step 620:
20-03-23 17:52-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 53, Global step 621:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 54, Global step 622:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 55, Global step 623:
20-03-23 17:52-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 56, Global step 624:
20-03-23 17:52-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 57, Global step 625:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 58, Global step 626:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 59, Global step 627:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 60, Global step 628:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 61, Global step 629:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 62, Global step 630:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 63, Global step 631:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 64, Global step 632:
20-03-23 17:52-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 65, Global step 633:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 66, Global step 634:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 67, Global step 635:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 68, Global step 636:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 69, Global step 637:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 70, Global step 638:
20-03-23 17:52-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 71, Global step 639:
20-03-23 17:52-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:52-INFO-Epoch 2, Batch 72, Global step 640:
20-03-23 17:52-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:52-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 73, Global step 641:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 74, Global step 642:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 75, Global step 643:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 76, Global step 644:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 77, Global step 645:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 78, Global step 646:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 79, Global step 647:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 80, Global step 648:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 81, Global step 649:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 82, Global step 650:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 83, Global step 651:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 84, Global step 652:
20-03-23 17:53-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 85, Global step 653:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 86, Global step 654:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 87, Global step 655:
20-03-23 17:53-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 88, Global step 656:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 89, Global step 657:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 90, Global step 658:
20-03-23 17:53-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 91, Global step 659:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 92, Global step 660:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 93, Global step 661:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 94, Global step 662:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 95, Global step 663:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 96, Global step 664:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 97, Global step 665:
20-03-23 17:53-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:53-INFO-Epoch 2, Batch 98, Global step 666:
20-03-23 17:53-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:53-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 99, Global step 667:
20-03-23 17:54-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 100, Global step 668:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 101, Global step 669:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 102, Global step 670:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 103, Global step 671:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 104, Global step 672:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 105, Global step 673:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 106, Global step 674:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 107, Global step 675:
20-03-23 17:54-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 108, Global step 676:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 109, Global step 677:
20-03-23 17:54-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 110, Global step 678:
20-03-23 17:54-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 111, Global step 679:
20-03-23 17:54-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 112, Global step 680:
20-03-23 17:54-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 113, Global step 681:
20-03-23 17:54-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 114, Global step 682:
20-03-23 17:54-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 115, Global step 683:
20-03-23 17:54-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 116, Global step 684:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 117, Global step 685:
20-03-23 17:54-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 118, Global step 686:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 119, Global step 687:
20-03-23 17:54-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 120, Global step 688:
20-03-23 17:54-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 121, Global step 689:
20-03-23 17:54-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 122, Global step 690:
20-03-23 17:54-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 123, Global step 691:
20-03-23 17:54-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:54-INFO-Epoch 2, Batch 124, Global step 692:
20-03-23 17:54-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:54-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 125, Global step 693:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 126, Global step 694:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 127, Global step 695:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 128, Global step 696:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 129, Global step 697:
20-03-23 17:55-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 130, Global step 698:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 131, Global step 699:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 132, Global step 700:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 133, Global step 701:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 134, Global step 702:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 135, Global step 703:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 136, Global step 704:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 137, Global step 705:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 138, Global step 706:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 139, Global step 707:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 140, Global step 708:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 141, Global step 709:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 142, Global step 710:
20-03-23 17:55-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 143, Global step 711:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 144, Global step 712:
20-03-23 17:55-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 145, Global step 713:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 146, Global step 714:
20-03-23 17:55-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 147, Global step 715:
20-03-23 17:55-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 148, Global step 716:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 149, Global step 717:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:55-INFO-Epoch 2, Batch 150, Global step 718:
20-03-23 17:55-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:55-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 151, Global step 719:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 152, Global step 720:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 153, Global step 721:
20-03-23 17:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 154, Global step 722:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 155, Global step 723:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 156, Global step 724:
20-03-23 17:56-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 157, Global step 725:
20-03-23 17:56-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 158, Global step 726:
20-03-23 17:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 159, Global step 727:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 160, Global step 728:
20-03-23 17:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 161, Global step 729:
20-03-23 17:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 162, Global step 730:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 163, Global step 731:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 164, Global step 732:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 165, Global step 733:
20-03-23 17:56-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 166, Global step 734:
20-03-23 17:56-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 167, Global step 735:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 168, Global step 736:
20-03-23 17:56-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 169, Global step 737:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 170, Global step 738:
20-03-23 17:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 171, Global step 739:
20-03-23 17:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 172, Global step 740:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 173, Global step 741:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 174, Global step 742:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 175, Global step 743:
20-03-23 17:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 176, Global step 744:
20-03-23 17:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:56-INFO-Epoch 2, Batch 177, Global step 745:
20-03-23 17:56-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:56-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 178, Global step 746:
20-03-23 17:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 179, Global step 747:
20-03-23 17:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 180, Global step 748:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 181, Global step 749:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 182, Global step 750:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 183, Global step 751:
20-03-23 17:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 184, Global step 752:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 185, Global step 753:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 186, Global step 754:
20-03-23 17:57-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 187, Global step 755:
20-03-23 17:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 188, Global step 756:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 189, Global step 757:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 190, Global step 758:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 191, Global step 759:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 192, Global step 760:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 193, Global step 761:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 194, Global step 762:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 195, Global step 763:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 196, Global step 764:
20-03-23 17:57-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 197, Global step 765:
20-03-23 17:57-INFO-training batch loss: 0.0011; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 198, Global step 766:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 199, Global step 767:
20-03-23 17:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 200, Global step 768:
20-03-23 17:57-INFO-training batch loss: 0.0012; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 201, Global step 769:
20-03-23 17:57-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 202, Global step 770:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:57-INFO-Epoch 2, Batch 203, Global step 771:
20-03-23 17:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:57-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 204, Global step 772:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 205, Global step 773:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 206, Global step 774:
20-03-23 17:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 207, Global step 775:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 208, Global step 776:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 209, Global step 777:
20-03-23 17:58-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 210, Global step 778:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 211, Global step 779:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 212, Global step 780:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 213, Global step 781:
20-03-23 17:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 214, Global step 782:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 215, Global step 783:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 216, Global step 784:
20-03-23 17:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 217, Global step 785:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 218, Global step 786:
20-03-23 17:58-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 219, Global step 787:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 220, Global step 788:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 221, Global step 789:
20-03-23 17:58-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 222, Global step 790:
20-03-23 17:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 223, Global step 791:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 224, Global step 792:
20-03-23 17:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 225, Global step 793:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 226, Global step 794:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 227, Global step 795:
20-03-23 17:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 228, Global step 796:
20-03-23 17:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 229, Global step 797:
20-03-23 17:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:58-INFO-Epoch 2, Batch 230, Global step 798:
20-03-23 17:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:58-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 231, Global step 799:
20-03-23 17:59-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 232, Global step 800:
20-03-23 17:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 233, Global step 801:
20-03-23 17:59-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 234, Global step 802:
20-03-23 17:59-INFO-training batch loss: 0.0014; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 235, Global step 803:
20-03-23 17:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 236, Global step 804:
20-03-23 17:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 237, Global step 805:
20-03-23 17:59-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 238, Global step 806:
20-03-23 17:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 239, Global step 807:
20-03-23 17:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 240, Global step 808:
20-03-23 17:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 241, Global step 809:
20-03-23 17:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 242, Global step 810:
20-03-23 17:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 243, Global step 811:
20-03-23 17:59-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 244, Global step 812:
20-03-23 17:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 245, Global step 813:
20-03-23 17:59-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 246, Global step 814:
20-03-23 17:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 247, Global step 815:
20-03-23 17:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 248, Global step 816:
20-03-23 17:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 249, Global step 817:
20-03-23 17:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 250, Global step 818:
20-03-23 17:59-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 251, Global step 819:
20-03-23 17:59-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 252, Global step 820:
20-03-23 17:59-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 253, Global step 821:
20-03-23 17:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 254, Global step 822:
20-03-23 17:59-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 255, Global step 823:
20-03-23 17:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 17:59-INFO-Epoch 2, Batch 256, Global step 824:
20-03-23 17:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 17:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 17:59-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 257, Global step 825:
20-03-23 18:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 258, Global step 826:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 259, Global step 827:
20-03-23 18:00-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 260, Global step 828:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 261, Global step 829:
20-03-23 18:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 262, Global step 830:
20-03-23 18:00-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 263, Global step 831:
20-03-23 18:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 264, Global step 832:
20-03-23 18:00-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 265, Global step 833:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 266, Global step 834:
20-03-23 18:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 267, Global step 835:
20-03-23 18:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 268, Global step 836:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 269, Global step 837:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 270, Global step 838:
20-03-23 18:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 271, Global step 839:
20-03-23 18:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 272, Global step 840:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 273, Global step 841:
20-03-23 18:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 274, Global step 842:
20-03-23 18:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 275, Global step 843:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 276, Global step 844:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 277, Global step 845:
20-03-23 18:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 278, Global step 846:
20-03-23 18:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 279, Global step 847:
20-03-23 18:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 280, Global step 848:
20-03-23 18:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 281, Global step 849:
20-03-23 18:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:00-INFO-Epoch 2, Batch 282, Global step 850:
20-03-23 18:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:00-INFO-
20-03-23 18:01-INFO-Epoch 2, Batch 283, Global step 851:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 2, Batch 284, Global step 852:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 2, training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:01-INFO-Epoch 2, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 2, evaluating batch loss: 0.9140; avg_loss: 0.3098
20-03-23 18:01-INFO-Epoch 2, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9554
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 1, Global step 853:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 2, Global step 854:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 3, Global step 855:
20-03-23 18:01-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 4, Global step 856:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 5, Global step 857:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 6, Global step 858:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 7, Global step 859:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 8, Global step 860:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 9, Global step 861:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 10, Global step 862:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 11, Global step 863:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 12, Global step 864:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 13, Global step 865:
20-03-23 18:01-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 14, Global step 866:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 15, Global step 867:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 16, Global step 868:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 17, Global step 869:
20-03-23 18:01-INFO-training batch loss: 0.0007; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 18, Global step 870:
20-03-23 18:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 19, Global step 871:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 20, Global step 872:
20-03-23 18:01-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:01-INFO-Epoch 3, Batch 21, Global step 873:
20-03-23 18:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:01-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 22, Global step 874:
20-03-23 18:02-INFO-training batch loss: 0.0009; avg_loss: 0.0002
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 23, Global step 875:
20-03-23 18:02-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 24, Global step 876:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 25, Global step 877:
20-03-23 18:02-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 26, Global step 878:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 27, Global step 879:
20-03-23 18:02-INFO-training batch loss: 0.0016; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 28, Global step 880:
20-03-23 18:02-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 29, Global step 881:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 30, Global step 882:
20-03-23 18:02-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 31, Global step 883:
20-03-23 18:02-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 32, Global step 884:
20-03-23 18:02-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 33, Global step 885:
20-03-23 18:02-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 34, Global step 886:
20-03-23 18:02-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 35, Global step 887:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 36, Global step 888:
20-03-23 18:02-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 37, Global step 889:
20-03-23 18:02-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 38, Global step 890:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 39, Global step 891:
20-03-23 18:02-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 40, Global step 892:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 41, Global step 893:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 42, Global step 894:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 43, Global step 895:
20-03-23 18:02-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 44, Global step 896:
20-03-23 18:02-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 45, Global step 897:
20-03-23 18:02-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 46, Global step 898:
20-03-23 18:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 47, Global step 899:
20-03-23 18:02-INFO-training batch loss: 0.0021; avg_loss: 0.0004
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:02-INFO-Epoch 3, Batch 48, Global step 900:
20-03-23 18:02-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:02-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 49, Global step 901:
20-03-23 18:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 50, Global step 902:
20-03-23 18:03-INFO-training batch loss: 0.0007; avg_loss: 0.0004
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 51, Global step 903:
20-03-23 18:03-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 52, Global step 904:
20-03-23 18:03-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 53, Global step 905:
20-03-23 18:03-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 54, Global step 906:
20-03-23 18:03-INFO-training batch loss: 0.0048; avg_loss: 0.0004
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 55, Global step 907:
20-03-23 18:03-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 56, Global step 908:
20-03-23 18:03-INFO-training batch loss: 0.0028; avg_loss: 0.0005
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 57, Global step 909:
20-03-23 18:03-INFO-training batch loss: 0.0006; avg_loss: 0.0005
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 58, Global step 910:
20-03-23 18:03-INFO-training batch loss: 0.0073; avg_loss: 0.0006
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 59, Global step 911:
20-03-23 18:03-INFO-training batch loss: 0.0004; avg_loss: 0.0006
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 60, Global step 912:
20-03-23 18:03-INFO-training batch loss: 0.0005; avg_loss: 0.0006
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 61, Global step 913:
20-03-23 18:03-INFO-training batch loss: 0.0022; avg_loss: 0.0006
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 62, Global step 914:
20-03-23 18:03-INFO-training batch loss: 0.0024; avg_loss: 0.0006
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 63, Global step 915:
20-03-23 18:03-INFO-training batch loss: 0.0011; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 64, Global step 916:
20-03-23 18:03-INFO-training batch loss: 0.0046; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 65, Global step 917:
20-03-23 18:03-INFO-training batch loss: 0.0006; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 66, Global step 918:
20-03-23 18:03-INFO-training batch loss: 0.0022; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 67, Global step 919:
20-03-23 18:03-INFO-training batch loss: 0.0011; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 68, Global step 920:
20-03-23 18:03-INFO-training batch loss: 0.0004; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 69, Global step 921:
20-03-23 18:03-INFO-training batch loss: 0.0016; avg_loss: 0.0007
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 70, Global step 922:
20-03-23 18:03-INFO-training batch loss: 0.0012; avg_loss: 0.0008
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 71, Global step 923:
20-03-23 18:03-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 72, Global step 924:
20-03-23 18:03-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 73, Global step 925:
20-03-23 18:03-INFO-training batch loss: 0.0046; avg_loss: 0.0008
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:03-INFO-Epoch 3, Batch 74, Global step 926:
20-03-23 18:03-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 18:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:03-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 75, Global step 927:
20-03-23 18:04-INFO-training batch loss: 0.0012; avg_loss: 0.0008
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 76, Global step 928:
20-03-23 18:04-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 77, Global step 929:
20-03-23 18:04-INFO-training batch loss: 0.0021; avg_loss: 0.0008
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 78, Global step 930:
20-03-23 18:04-INFO-training batch loss: 0.0054; avg_loss: 0.0009
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 79, Global step 931:
20-03-23 18:04-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 80, Global step 932:
20-03-23 18:04-INFO-training batch loss: 0.0075; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 81, Global step 933:
20-03-23 18:04-INFO-training batch loss: 0.0003; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 82, Global step 934:
20-03-23 18:04-INFO-training batch loss: 0.0003; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 83, Global step 935:
20-03-23 18:04-INFO-training batch loss: 0.0038; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 84, Global step 936:
20-03-23 18:04-INFO-training batch loss: 0.0027; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 85, Global step 937:
20-03-23 18:04-INFO-training batch loss: 0.0020; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 86, Global step 938:
20-03-23 18:04-INFO-training batch loss: 0.0003; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 87, Global step 939:
20-03-23 18:04-INFO-training batch loss: 0.0032; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 88, Global step 940:
20-03-23 18:04-INFO-training batch loss: 0.0022; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 89, Global step 941:
20-03-23 18:04-INFO-training batch loss: 0.0003; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 90, Global step 942:
20-03-23 18:04-INFO-training batch loss: 0.0011; avg_loss: 0.0010
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 91, Global step 943:
20-03-23 18:04-INFO-training batch loss: 0.0057; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 92, Global step 944:
20-03-23 18:04-INFO-training batch loss: 0.0039; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 93, Global step 945:
20-03-23 18:04-INFO-training batch loss: 0.0004; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 94, Global step 946:
20-03-23 18:04-INFO-training batch loss: 0.0004; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 95, Global step 947:
20-03-23 18:04-INFO-training batch loss: 0.0002; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 96, Global step 948:
20-03-23 18:04-INFO-training batch loss: 0.0004; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 97, Global step 949:
20-03-23 18:04-INFO-training batch loss: 0.0007; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 98, Global step 950:
20-03-23 18:04-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 99, Global step 951:
20-03-23 18:04-INFO-training batch loss: 0.0008; avg_loss: 0.0011
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 100, Global step 952:
20-03-23 18:04-INFO-training batch loss: 0.0126; avg_loss: 0.0012
20-03-23 18:04-INFO-training batch acc: 0.9922; avg_acc: 0.9999
20-03-23 18:04-INFO-
20-03-23 18:04-INFO-Epoch 3, Batch 101, Global step 953:
20-03-23 18:04-INFO-training batch loss: 0.0026; avg_loss: 0.0012
20-03-23 18:04-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:04-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 102, Global step 954:
20-03-23 18:05-INFO-training batch loss: 0.0004; avg_loss: 0.0012
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 103, Global step 955:
20-03-23 18:05-INFO-training batch loss: 0.0019; avg_loss: 0.0012
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 104, Global step 956:
20-03-23 18:05-INFO-training batch loss: 0.0033; avg_loss: 0.0012
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 105, Global step 957:
20-03-23 18:05-INFO-training batch loss: 0.0090; avg_loss: 0.0013
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 106, Global step 958:
20-03-23 18:05-INFO-training batch loss: 0.0030; avg_loss: 0.0013
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 107, Global step 959:
20-03-23 18:05-INFO-training batch loss: 0.0008; avg_loss: 0.0013
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 108, Global step 960:
20-03-23 18:05-INFO-training batch loss: 0.0018; avg_loss: 0.0013
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 109, Global step 961:
20-03-23 18:05-INFO-training batch loss: 0.0019; avg_loss: 0.0013
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 110, Global step 962:
20-03-23 18:05-INFO-training batch loss: 0.0010; avg_loss: 0.0013
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 111, Global step 963:
20-03-23 18:05-INFO-training batch loss: 0.0200; avg_loss: 0.0015
20-03-23 18:05-INFO-training batch acc: 0.9922; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 112, Global step 964:
20-03-23 18:05-INFO-training batch loss: 0.0016; avg_loss: 0.0015
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 113, Global step 965:
20-03-23 18:05-INFO-training batch loss: 0.0031; avg_loss: 0.0015
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 114, Global step 966:
20-03-23 18:05-INFO-training batch loss: 0.0049; avg_loss: 0.0015
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 115, Global step 967:
20-03-23 18:05-INFO-training batch loss: 0.0392; avg_loss: 0.0019
20-03-23 18:05-INFO-training batch acc: 0.9766; avg_acc: 0.9997
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 116, Global step 968:
20-03-23 18:05-INFO-training batch loss: 0.1211; avg_loss: 0.0029
20-03-23 18:05-INFO-training batch acc: 0.9375; avg_acc: 0.9991
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 117, Global step 969:
20-03-23 18:05-INFO-training batch loss: 0.0070; avg_loss: 0.0029
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 118, Global step 970:
20-03-23 18:05-INFO-training batch loss: 0.2889; avg_loss: 0.0053
20-03-23 18:05-INFO-training batch acc: 0.9062; avg_acc: 0.9983
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 119, Global step 971:
20-03-23 18:05-INFO-training batch loss: 0.0482; avg_loss: 0.0057
20-03-23 18:05-INFO-training batch acc: 0.9766; avg_acc: 0.9982
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 120, Global step 972:
20-03-23 18:05-INFO-training batch loss: 0.0385; avg_loss: 0.0060
20-03-23 18:05-INFO-training batch acc: 0.9844; avg_acc: 0.9980
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 121, Global step 973:
20-03-23 18:05-INFO-training batch loss: 0.0811; avg_loss: 0.0066
20-03-23 18:05-INFO-training batch acc: 0.9766; avg_acc: 0.9979
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 122, Global step 974:
20-03-23 18:05-INFO-training batch loss: 0.1014; avg_loss: 0.0074
20-03-23 18:05-INFO-training batch acc: 0.9688; avg_acc: 0.9976
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 123, Global step 975:
20-03-23 18:05-INFO-training batch loss: 0.0483; avg_loss: 0.0077
20-03-23 18:05-INFO-training batch acc: 0.9844; avg_acc: 0.9975
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 124, Global step 976:
20-03-23 18:05-INFO-training batch loss: 0.0719; avg_loss: 0.0082
20-03-23 18:05-INFO-training batch acc: 0.9688; avg_acc: 0.9973
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 125, Global step 977:
20-03-23 18:05-INFO-training batch loss: 0.0792; avg_loss: 0.0088
20-03-23 18:05-INFO-training batch acc: 0.9766; avg_acc: 0.9971
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 126, Global step 978:
20-03-23 18:05-INFO-training batch loss: 0.0757; avg_loss: 0.0093
20-03-23 18:05-INFO-training batch acc: 0.9688; avg_acc: 0.9969
20-03-23 18:05-INFO-
20-03-23 18:05-INFO-Epoch 3, Batch 127, Global step 979:
20-03-23 18:05-INFO-training batch loss: 0.0174; avg_loss: 0.0094
20-03-23 18:05-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:05-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 128, Global step 980:
20-03-23 18:06-INFO-training batch loss: 0.0612; avg_loss: 0.0098
20-03-23 18:06-INFO-training batch acc: 0.9766; avg_acc: 0.9968
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 129, Global step 981:
20-03-23 18:06-INFO-training batch loss: 0.0437; avg_loss: 0.0101
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9967
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 130, Global step 982:
20-03-23 18:06-INFO-training batch loss: 0.0474; avg_loss: 0.0103
20-03-23 18:06-INFO-training batch acc: 0.9766; avg_acc: 0.9966
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 131, Global step 983:
20-03-23 18:06-INFO-training batch loss: 0.0985; avg_loss: 0.0110
20-03-23 18:06-INFO-training batch acc: 0.9531; avg_acc: 0.9962
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 132, Global step 984:
20-03-23 18:06-INFO-training batch loss: 0.0117; avg_loss: 0.0110
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 133, Global step 985:
20-03-23 18:06-INFO-training batch loss: 0.0186; avg_loss: 0.0111
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9962
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 134, Global step 986:
20-03-23 18:06-INFO-training batch loss: 0.0754; avg_loss: 0.0116
20-03-23 18:06-INFO-training batch acc: 0.9844; avg_acc: 0.9962
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 135, Global step 987:
20-03-23 18:06-INFO-training batch loss: 0.0163; avg_loss: 0.0116
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 136, Global step 988:
20-03-23 18:06-INFO-training batch loss: 0.0326; avg_loss: 0.0118
20-03-23 18:06-INFO-training batch acc: 0.9844; avg_acc: 0.9961
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 137, Global step 989:
20-03-23 18:06-INFO-training batch loss: 0.0355; avg_loss: 0.0119
20-03-23 18:06-INFO-training batch acc: 0.9844; avg_acc: 0.9960
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 138, Global step 990:
20-03-23 18:06-INFO-training batch loss: 0.0337; avg_loss: 0.0121
20-03-23 18:06-INFO-training batch acc: 0.9844; avg_acc: 0.9959
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 139, Global step 991:
20-03-23 18:06-INFO-training batch loss: 0.0129; avg_loss: 0.0121
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9959
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 140, Global step 992:
20-03-23 18:06-INFO-training batch loss: 0.0254; avg_loss: 0.0122
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9959
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 141, Global step 993:
20-03-23 18:06-INFO-training batch loss: 0.0269; avg_loss: 0.0123
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9958
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 142, Global step 994:
20-03-23 18:06-INFO-training batch loss: 0.0552; avg_loss: 0.0126
20-03-23 18:06-INFO-training batch acc: 0.9766; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 143, Global step 995:
20-03-23 18:06-INFO-training batch loss: 0.0018; avg_loss: 0.0125
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 144, Global step 996:
20-03-23 18:06-INFO-training batch loss: 0.0435; avg_loss: 0.0127
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 145, Global step 997:
20-03-23 18:06-INFO-training batch loss: 0.0283; avg_loss: 0.0128
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 146, Global step 998:
20-03-23 18:06-INFO-training batch loss: 0.0021; avg_loss: 0.0128
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 147, Global step 999:
20-03-23 18:06-INFO-training batch loss: 0.0021; avg_loss: 0.0127
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 148, Global step 1000:
20-03-23 18:06-INFO-training batch loss: 0.0014; avg_loss: 0.0126
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 149, Global step 1001:
20-03-23 18:06-INFO-training batch loss: 0.0308; avg_loss: 0.0127
20-03-23 18:06-INFO-training batch acc: 0.9766; avg_acc: 0.9956
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 150, Global step 1002:
20-03-23 18:06-INFO-training batch loss: 0.0164; avg_loss: 0.0128
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 151, Global step 1003:
20-03-23 18:06-INFO-training batch loss: 0.0029; avg_loss: 0.0127
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 152, Global step 1004:
20-03-23 18:06-INFO-training batch loss: 0.0146; avg_loss: 0.0127
20-03-23 18:06-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 153, Global step 1005:
20-03-23 18:06-INFO-training batch loss: 0.0237; avg_loss: 0.0128
20-03-23 18:06-INFO-training batch acc: 0.9844; avg_acc: 0.9956
20-03-23 18:06-INFO-
20-03-23 18:06-INFO-Epoch 3, Batch 154, Global step 1006:
20-03-23 18:06-INFO-training batch loss: 0.0040; avg_loss: 0.0127
20-03-23 18:06-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 18:06-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 155, Global step 1007:
20-03-23 18:07-INFO-training batch loss: 0.0006; avg_loss: 0.0126
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 156, Global step 1008:
20-03-23 18:07-INFO-training batch loss: 0.0118; avg_loss: 0.0126
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 157, Global step 1009:
20-03-23 18:07-INFO-training batch loss: 0.0066; avg_loss: 0.0126
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 158, Global step 1010:
20-03-23 18:07-INFO-training batch loss: 0.0123; avg_loss: 0.0126
20-03-23 18:07-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 159, Global step 1011:
20-03-23 18:07-INFO-training batch loss: 0.0010; avg_loss: 0.0125
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 160, Global step 1012:
20-03-23 18:07-INFO-training batch loss: 0.0023; avg_loss: 0.0125
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 161, Global step 1013:
20-03-23 18:07-INFO-training batch loss: 0.0146; avg_loss: 0.0125
20-03-23 18:07-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 162, Global step 1014:
20-03-23 18:07-INFO-training batch loss: 0.0035; avg_loss: 0.0124
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 163, Global step 1015:
20-03-23 18:07-INFO-training batch loss: 0.0178; avg_loss: 0.0125
20-03-23 18:07-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 164, Global step 1016:
20-03-23 18:07-INFO-training batch loss: 0.0074; avg_loss: 0.0124
20-03-23 18:07-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 165, Global step 1017:
20-03-23 18:07-INFO-training batch loss: 0.0026; avg_loss: 0.0124
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 166, Global step 1018:
20-03-23 18:07-INFO-training batch loss: 0.0049; avg_loss: 0.0123
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 167, Global step 1019:
20-03-23 18:07-INFO-training batch loss: 0.0374; avg_loss: 0.0125
20-03-23 18:07-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 168, Global step 1020:
20-03-23 18:07-INFO-training batch loss: 0.0052; avg_loss: 0.0124
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 169, Global step 1021:
20-03-23 18:07-INFO-training batch loss: 0.0038; avg_loss: 0.0124
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 170, Global step 1022:
20-03-23 18:07-INFO-training batch loss: 0.0147; avg_loss: 0.0124
20-03-23 18:07-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 171, Global step 1023:
20-03-23 18:07-INFO-training batch loss: 0.0034; avg_loss: 0.0123
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 172, Global step 1024:
20-03-23 18:07-INFO-training batch loss: 0.0015; avg_loss: 0.0123
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 173, Global step 1025:
20-03-23 18:07-INFO-training batch loss: 0.0023; avg_loss: 0.0122
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 174, Global step 1026:
20-03-23 18:07-INFO-training batch loss: 0.0046; avg_loss: 0.0122
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 175, Global step 1027:
20-03-23 18:07-INFO-training batch loss: 0.0006; avg_loss: 0.0121
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 176, Global step 1028:
20-03-23 18:07-INFO-training batch loss: 0.0041; avg_loss: 0.0121
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 177, Global step 1029:
20-03-23 18:07-INFO-training batch loss: 0.0034; avg_loss: 0.0120
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 178, Global step 1030:
20-03-23 18:07-INFO-training batch loss: 0.0019; avg_loss: 0.0120
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 179, Global step 1031:
20-03-23 18:07-INFO-training batch loss: 0.0055; avg_loss: 0.0119
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 18:07-INFO-
20-03-23 18:07-INFO-Epoch 3, Batch 180, Global step 1032:
20-03-23 18:07-INFO-training batch loss: 0.0031; avg_loss: 0.0119
20-03-23 18:07-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 18:07-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 181, Global step 1033:
20-03-23 18:08-INFO-training batch loss: 0.0005; avg_loss: 0.0118
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 182, Global step 1034:
20-03-23 18:08-INFO-training batch loss: 0.0014; avg_loss: 0.0117
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 183, Global step 1035:
20-03-23 18:08-INFO-training batch loss: 0.0007; avg_loss: 0.0117
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 184, Global step 1036:
20-03-23 18:08-INFO-training batch loss: 0.0007; avg_loss: 0.0116
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 185, Global step 1037:
20-03-23 18:08-INFO-training batch loss: 0.0007; avg_loss: 0.0116
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 186, Global step 1038:
20-03-23 18:08-INFO-training batch loss: 0.0024; avg_loss: 0.0115
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 187, Global step 1039:
20-03-23 18:08-INFO-training batch loss: 0.0012; avg_loss: 0.0115
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 188, Global step 1040:
20-03-23 18:08-INFO-training batch loss: 0.0055; avg_loss: 0.0114
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 189, Global step 1041:
20-03-23 18:08-INFO-training batch loss: 0.0006; avg_loss: 0.0114
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 190, Global step 1042:
20-03-23 18:08-INFO-training batch loss: 0.0022; avg_loss: 0.0113
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 191, Global step 1043:
20-03-23 18:08-INFO-training batch loss: 0.0075; avg_loss: 0.0113
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 192, Global step 1044:
20-03-23 18:08-INFO-training batch loss: 0.0020; avg_loss: 0.0113
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 193, Global step 1045:
20-03-23 18:08-INFO-training batch loss: 0.0036; avg_loss: 0.0112
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 194, Global step 1046:
20-03-23 18:08-INFO-training batch loss: 0.0022; avg_loss: 0.0112
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 195, Global step 1047:
20-03-23 18:08-INFO-training batch loss: 0.0007; avg_loss: 0.0111
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 196, Global step 1048:
20-03-23 18:08-INFO-training batch loss: 0.0032; avg_loss: 0.0111
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 197, Global step 1049:
20-03-23 18:08-INFO-training batch loss: 0.0009; avg_loss: 0.0110
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 198, Global step 1050:
20-03-23 18:08-INFO-training batch loss: 0.0074; avg_loss: 0.0110
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 199, Global step 1051:
20-03-23 18:08-INFO-training batch loss: 0.0027; avg_loss: 0.0110
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 200, Global step 1052:
20-03-23 18:08-INFO-training batch loss: 0.0008; avg_loss: 0.0109
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 201, Global step 1053:
20-03-23 18:08-INFO-training batch loss: 0.0002; avg_loss: 0.0109
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 202, Global step 1054:
20-03-23 18:08-INFO-training batch loss: 0.0003; avg_loss: 0.0108
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 203, Global step 1055:
20-03-23 18:08-INFO-training batch loss: 0.0004; avg_loss: 0.0108
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 204, Global step 1056:
20-03-23 18:08-INFO-training batch loss: 0.0004; avg_loss: 0.0107
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 205, Global step 1057:
20-03-23 18:08-INFO-training batch loss: 0.0004; avg_loss: 0.0107
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 206, Global step 1058:
20-03-23 18:08-INFO-training batch loss: 0.0003; avg_loss: 0.0106
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 18:08-INFO-
20-03-23 18:08-INFO-Epoch 3, Batch 207, Global step 1059:
20-03-23 18:08-INFO-training batch loss: 0.0010; avg_loss: 0.0106
20-03-23 18:08-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 18:08-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 208, Global step 1060:
20-03-23 18:09-INFO-training batch loss: 0.0006; avg_loss: 0.0105
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 209, Global step 1061:
20-03-23 18:09-INFO-training batch loss: 0.0005; avg_loss: 0.0105
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 210, Global step 1062:
20-03-23 18:09-INFO-training batch loss: 0.0024; avg_loss: 0.0104
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 211, Global step 1063:
20-03-23 18:09-INFO-training batch loss: 0.0012; avg_loss: 0.0104
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 212, Global step 1064:
20-03-23 18:09-INFO-training batch loss: 0.0006; avg_loss: 0.0103
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 213, Global step 1065:
20-03-23 18:09-INFO-training batch loss: 0.0083; avg_loss: 0.0103
20-03-23 18:09-INFO-training batch acc: 0.9922; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 214, Global step 1066:
20-03-23 18:09-INFO-training batch loss: 0.0006; avg_loss: 0.0103
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 215, Global step 1067:
20-03-23 18:09-INFO-training batch loss: 0.0003; avg_loss: 0.0102
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 216, Global step 1068:
20-03-23 18:09-INFO-training batch loss: 0.0027; avg_loss: 0.0102
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 217, Global step 1069:
20-03-23 18:09-INFO-training batch loss: 0.0064; avg_loss: 0.0102
20-03-23 18:09-INFO-training batch acc: 0.9922; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 218, Global step 1070:
20-03-23 18:09-INFO-training batch loss: 0.0005; avg_loss: 0.0101
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 219, Global step 1071:
20-03-23 18:09-INFO-training batch loss: 0.0004; avg_loss: 0.0101
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 220, Global step 1072:
20-03-23 18:09-INFO-training batch loss: 0.0009; avg_loss: 0.0101
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 221, Global step 1073:
20-03-23 18:09-INFO-training batch loss: 0.0002; avg_loss: 0.0100
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 222, Global step 1074:
20-03-23 18:09-INFO-training batch loss: 0.0031; avg_loss: 0.0100
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 223, Global step 1075:
20-03-23 18:09-INFO-training batch loss: 0.0010; avg_loss: 0.0099
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 224, Global step 1076:
20-03-23 18:09-INFO-training batch loss: 0.0008; avg_loss: 0.0099
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 225, Global step 1077:
20-03-23 18:09-INFO-training batch loss: 0.0002; avg_loss: 0.0099
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 226, Global step 1078:
20-03-23 18:09-INFO-training batch loss: 0.0003; avg_loss: 0.0098
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 227, Global step 1079:
20-03-23 18:09-INFO-training batch loss: 0.0016; avg_loss: 0.0098
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 228, Global step 1080:
20-03-23 18:09-INFO-training batch loss: 0.0003; avg_loss: 0.0097
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 229, Global step 1081:
20-03-23 18:09-INFO-training batch loss: 0.0004; avg_loss: 0.0097
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 230, Global step 1082:
20-03-23 18:09-INFO-training batch loss: 0.0002; avg_loss: 0.0097
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 231, Global step 1083:
20-03-23 18:09-INFO-training batch loss: 0.0010; avg_loss: 0.0096
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 232, Global step 1084:
20-03-23 18:09-INFO-training batch loss: 0.0006; avg_loss: 0.0096
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:09-INFO-
20-03-23 18:09-INFO-Epoch 3, Batch 233, Global step 1085:
20-03-23 18:09-INFO-training batch loss: 0.0005; avg_loss: 0.0095
20-03-23 18:09-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:09-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 234, Global step 1086:
20-03-23 18:10-INFO-training batch loss: 0.0004; avg_loss: 0.0095
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 235, Global step 1087:
20-03-23 18:10-INFO-training batch loss: 0.0014; avg_loss: 0.0095
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 236, Global step 1088:
20-03-23 18:10-INFO-training batch loss: 0.0006; avg_loss: 0.0094
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 237, Global step 1089:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0094
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 238, Global step 1090:
20-03-23 18:10-INFO-training batch loss: 0.0003; avg_loss: 0.0093
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 239, Global step 1091:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0093
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 240, Global step 1092:
20-03-23 18:10-INFO-training batch loss: 0.0126; avg_loss: 0.0093
20-03-23 18:10-INFO-training batch acc: 0.9922; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 241, Global step 1093:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0093
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 242, Global step 1094:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0092
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 243, Global step 1095:
20-03-23 18:10-INFO-training batch loss: 0.0008; avg_loss: 0.0092
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 244, Global step 1096:
20-03-23 18:10-INFO-training batch loss: 0.0003; avg_loss: 0.0092
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 245, Global step 1097:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0091
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 246, Global step 1098:
20-03-23 18:10-INFO-training batch loss: 0.0044; avg_loss: 0.0091
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 247, Global step 1099:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0091
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 248, Global step 1100:
20-03-23 18:10-INFO-training batch loss: 0.0001; avg_loss: 0.0090
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 249, Global step 1101:
20-03-23 18:10-INFO-training batch loss: 0.0003; avg_loss: 0.0090
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 250, Global step 1102:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0090
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 251, Global step 1103:
20-03-23 18:10-INFO-training batch loss: 0.0004; avg_loss: 0.0089
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 252, Global step 1104:
20-03-23 18:10-INFO-training batch loss: 0.0003; avg_loss: 0.0089
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 253, Global step 1105:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0089
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 254, Global step 1106:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0088
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 255, Global step 1107:
20-03-23 18:10-INFO-training batch loss: 0.0004; avg_loss: 0.0088
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 256, Global step 1108:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0088
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 257, Global step 1109:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0087
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 258, Global step 1110:
20-03-23 18:10-INFO-training batch loss: 0.0002; avg_loss: 0.0087
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:10-INFO-
20-03-23 18:10-INFO-Epoch 3, Batch 259, Global step 1111:
20-03-23 18:10-INFO-training batch loss: 0.0004; avg_loss: 0.0087
20-03-23 18:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:10-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 260, Global step 1112:
20-03-23 18:11-INFO-training batch loss: 0.0005; avg_loss: 0.0086
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 261, Global step 1113:
20-03-23 18:11-INFO-training batch loss: 0.0017; avg_loss: 0.0086
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 262, Global step 1114:
20-03-23 18:11-INFO-training batch loss: 0.0001; avg_loss: 0.0086
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 263, Global step 1115:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0086
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 264, Global step 1116:
20-03-23 18:11-INFO-training batch loss: 0.0003; avg_loss: 0.0085
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 265, Global step 1117:
20-03-23 18:11-INFO-training batch loss: 0.0019; avg_loss: 0.0085
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 266, Global step 1118:
20-03-23 18:11-INFO-training batch loss: 0.0019; avg_loss: 0.0085
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 267, Global step 1119:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0084
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 268, Global step 1120:
20-03-23 18:11-INFO-training batch loss: 0.0001; avg_loss: 0.0084
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 269, Global step 1121:
20-03-23 18:11-INFO-training batch loss: 0.0001; avg_loss: 0.0084
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 270, Global step 1122:
20-03-23 18:11-INFO-training batch loss: 0.0006; avg_loss: 0.0084
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 271, Global step 1123:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0083
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 272, Global step 1124:
20-03-23 18:11-INFO-training batch loss: 0.0004; avg_loss: 0.0083
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 273, Global step 1125:
20-03-23 18:11-INFO-training batch loss: 0.0004; avg_loss: 0.0083
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 274, Global step 1126:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0082
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 275, Global step 1127:
20-03-23 18:11-INFO-training batch loss: 0.0003; avg_loss: 0.0082
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 276, Global step 1128:
20-03-23 18:11-INFO-training batch loss: 0.0007; avg_loss: 0.0082
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 277, Global step 1129:
20-03-23 18:11-INFO-training batch loss: 0.0001; avg_loss: 0.0081
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 278, Global step 1130:
20-03-23 18:11-INFO-training batch loss: 0.0001; avg_loss: 0.0081
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 279, Global step 1131:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0081
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 280, Global step 1132:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0081
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 281, Global step 1133:
20-03-23 18:11-INFO-training batch loss: 0.0001; avg_loss: 0.0080
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 282, Global step 1134:
20-03-23 18:11-INFO-training batch loss: 0.0006; avg_loss: 0.0080
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 283, Global step 1135:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0080
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, Batch 284, Global step 1136:
20-03-23 18:11-INFO-training batch loss: 0.0002; avg_loss: 0.0080
20-03-23 18:11-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 18:11-INFO-
20-03-23 18:11-INFO-Epoch 3, training batch loss: 0.0002; avg_loss: 0.0080
20-03-23 18:11-INFO-Epoch 3, training batch accuracy: 1.0000; avg_accuracy: 0.9974
20-03-23 18:11-INFO-
20-03-23 18:12-INFO-Epoch 3, evaluating batch loss: 0.9779; avg_loss: 0.3469
20-03-23 18:12-INFO-Epoch 3, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9554
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 1, Global step 1137:
20-03-23 18:12-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 2, Global step 1138:
20-03-23 18:12-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 3, Global step 1139:
20-03-23 18:12-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 4, Global step 1140:
20-03-23 18:12-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 5, Global step 1141:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 6, Global step 1142:
20-03-23 18:12-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 7, Global step 1143:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 8, Global step 1144:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 9, Global step 1145:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 10, Global step 1146:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 11, Global step 1147:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 12, Global step 1148:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 13, Global step 1149:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 14, Global step 1150:
20-03-23 18:12-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 15, Global step 1151:
20-03-23 18:12-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 16, Global step 1152:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 17, Global step 1153:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 18, Global step 1154:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 19, Global step 1155:
20-03-23 18:12-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 20, Global step 1156:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 21, Global step 1157:
20-03-23 18:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 22, Global step 1158:
20-03-23 18:12-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 23, Global step 1159:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:12-INFO-Epoch 4, Batch 24, Global step 1160:
20-03-23 18:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:12-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 25, Global step 1161:
20-03-23 18:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 26, Global step 1162:
20-03-23 18:13-INFO-training batch loss: 0.0007; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 27, Global step 1163:
20-03-23 18:13-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 28, Global step 1164:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 29, Global step 1165:
20-03-23 18:13-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 30, Global step 1166:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 31, Global step 1167:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 32, Global step 1168:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 33, Global step 1169:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 34, Global step 1170:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 35, Global step 1171:
20-03-23 18:13-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 36, Global step 1172:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 37, Global step 1173:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 38, Global step 1174:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 39, Global step 1175:
20-03-23 18:13-INFO-training batch loss: 0.0007; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 40, Global step 1176:
20-03-23 18:13-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 41, Global step 1177:
20-03-23 18:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 42, Global step 1178:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 43, Global step 1179:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 44, Global step 1180:
20-03-23 18:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 45, Global step 1181:
20-03-23 18:13-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 46, Global step 1182:
20-03-23 18:13-INFO-training batch loss: 0.0031; avg_loss: 0.0003
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 47, Global step 1183:
20-03-23 18:13-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 48, Global step 1184:
20-03-23 18:13-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 49, Global step 1185:
20-03-23 18:13-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:13-INFO-Epoch 4, Batch 50, Global step 1186:
20-03-23 18:13-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:13-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 51, Global step 1187:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 52, Global step 1188:
20-03-23 18:14-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 53, Global step 1189:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 54, Global step 1190:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 55, Global step 1191:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 56, Global step 1192:
20-03-23 18:14-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 57, Global step 1193:
20-03-23 18:14-INFO-training batch loss: 0.0019; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 58, Global step 1194:
20-03-23 18:14-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 59, Global step 1195:
20-03-23 18:14-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 60, Global step 1196:
20-03-23 18:14-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 61, Global step 1197:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 62, Global step 1198:
20-03-23 18:14-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 63, Global step 1199:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 64, Global step 1200:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 65, Global step 1201:
20-03-23 18:14-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 66, Global step 1202:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 67, Global step 1203:
20-03-23 18:14-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 68, Global step 1204:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 69, Global step 1205:
20-03-23 18:14-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 70, Global step 1206:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 71, Global step 1207:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 72, Global step 1208:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 73, Global step 1209:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 74, Global step 1210:
20-03-23 18:14-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 75, Global step 1211:
20-03-23 18:14-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 76, Global step 1212:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:14-INFO-Epoch 4, Batch 77, Global step 1213:
20-03-23 18:14-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:14-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 78, Global step 1214:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 79, Global step 1215:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 80, Global step 1216:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 81, Global step 1217:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 82, Global step 1218:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 83, Global step 1219:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 84, Global step 1220:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 85, Global step 1221:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 86, Global step 1222:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 87, Global step 1223:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 88, Global step 1224:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 89, Global step 1225:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 90, Global step 1226:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 91, Global step 1227:
20-03-23 18:15-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 92, Global step 1228:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 93, Global step 1229:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 94, Global step 1230:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 95, Global step 1231:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 96, Global step 1232:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 97, Global step 1233:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 98, Global step 1234:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 99, Global step 1235:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 100, Global step 1236:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 101, Global step 1237:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 102, Global step 1238:
20-03-23 18:15-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 103, Global step 1239:
20-03-23 18:15-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:15-INFO-Epoch 4, Batch 104, Global step 1240:
20-03-23 18:15-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:15-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 105, Global step 1241:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 106, Global step 1242:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 107, Global step 1243:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 108, Global step 1244:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 109, Global step 1245:
20-03-23 18:16-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 110, Global step 1246:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 111, Global step 1247:
20-03-23 18:16-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 112, Global step 1248:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 113, Global step 1249:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 114, Global step 1250:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 115, Global step 1251:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 116, Global step 1252:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 117, Global step 1253:
20-03-23 18:16-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 118, Global step 1254:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 119, Global step 1255:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 120, Global step 1256:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 121, Global step 1257:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 122, Global step 1258:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 123, Global step 1259:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 124, Global step 1260:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 125, Global step 1261:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 126, Global step 1262:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 127, Global step 1263:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 128, Global step 1264:
20-03-23 18:16-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 129, Global step 1265:
20-03-23 18:16-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:16-INFO-Epoch 4, Batch 130, Global step 1266:
20-03-23 18:16-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:16-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 131, Global step 1267:
20-03-23 18:17-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 132, Global step 1268:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 133, Global step 1269:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 134, Global step 1270:
20-03-23 18:17-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 135, Global step 1271:
20-03-23 18:17-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 136, Global step 1272:
20-03-23 18:17-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 137, Global step 1273:
20-03-23 18:17-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 138, Global step 1274:
20-03-23 18:17-INFO-training batch loss: 0.0020; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 139, Global step 1275:
20-03-23 18:17-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 140, Global step 1276:
20-03-23 18:17-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 141, Global step 1277:
20-03-23 18:17-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 142, Global step 1278:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 143, Global step 1279:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 144, Global step 1280:
20-03-23 18:17-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 145, Global step 1281:
20-03-23 18:17-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 146, Global step 1282:
20-03-23 18:17-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 147, Global step 1283:
20-03-23 18:17-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 148, Global step 1284:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 149, Global step 1285:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 150, Global step 1286:
20-03-23 18:17-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 151, Global step 1287:
20-03-23 18:17-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 152, Global step 1288:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 153, Global step 1289:
20-03-23 18:17-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 154, Global step 1290:
20-03-23 18:17-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 155, Global step 1291:
20-03-23 18:17-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 156, Global step 1292:
20-03-23 18:17-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:17-INFO-Epoch 4, Batch 157, Global step 1293:
20-03-23 18:17-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:17-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 158, Global step 1294:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 159, Global step 1295:
20-03-23 18:18-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 160, Global step 1296:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 161, Global step 1297:
20-03-23 18:18-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 162, Global step 1298:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 163, Global step 1299:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 164, Global step 1300:
20-03-23 18:18-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 165, Global step 1301:
20-03-23 18:18-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 166, Global step 1302:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 167, Global step 1303:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 168, Global step 1304:
20-03-23 18:18-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 169, Global step 1305:
20-03-23 18:18-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 170, Global step 1306:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 171, Global step 1307:
20-03-23 18:18-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 172, Global step 1308:
20-03-23 18:18-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 173, Global step 1309:
20-03-23 18:18-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 174, Global step 1310:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 175, Global step 1311:
20-03-23 18:18-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 176, Global step 1312:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 177, Global step 1313:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 178, Global step 1314:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 179, Global step 1315:
20-03-23 18:18-INFO-training batch loss: 0.0016; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 180, Global step 1316:
20-03-23 18:18-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 181, Global step 1317:
20-03-23 18:18-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 182, Global step 1318:
20-03-23 18:18-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:18-INFO-Epoch 4, Batch 183, Global step 1319:
20-03-23 18:18-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:18-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 184, Global step 1320:
20-03-23 18:19-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 185, Global step 1321:
20-03-23 18:19-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 186, Global step 1322:
20-03-23 18:19-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 187, Global step 1323:
20-03-23 18:19-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 188, Global step 1324:
20-03-23 18:19-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 189, Global step 1325:
20-03-23 18:19-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 190, Global step 1326:
20-03-23 18:19-INFO-training batch loss: 0.0017; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 191, Global step 1327:
20-03-23 18:19-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 192, Global step 1328:
20-03-23 18:19-INFO-training batch loss: 0.0012; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 193, Global step 1329:
20-03-23 18:19-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 194, Global step 1330:
20-03-23 18:19-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 195, Global step 1331:
20-03-23 18:19-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 196, Global step 1332:
20-03-23 18:19-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 197, Global step 1333:
20-03-23 18:19-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 198, Global step 1334:
20-03-23 18:19-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 199, Global step 1335:
20-03-23 18:19-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 200, Global step 1336:
20-03-23 18:19-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 201, Global step 1337:
20-03-23 18:19-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 202, Global step 1338:
20-03-23 18:19-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 203, Global step 1339:
20-03-23 18:19-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 204, Global step 1340:
20-03-23 18:19-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 205, Global step 1341:
20-03-23 18:19-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 206, Global step 1342:
20-03-23 18:19-INFO-training batch loss: 0.0012; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 207, Global step 1343:
20-03-23 18:19-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 208, Global step 1344:
20-03-23 18:19-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 209, Global step 1345:
20-03-23 18:19-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:19-INFO-Epoch 4, Batch 210, Global step 1346:
20-03-23 18:19-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:19-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:19-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 211, Global step 1347:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 212, Global step 1348:
20-03-23 18:20-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 213, Global step 1349:
20-03-23 18:20-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 214, Global step 1350:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 215, Global step 1351:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 216, Global step 1352:
20-03-23 18:20-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 217, Global step 1353:
20-03-23 18:20-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 218, Global step 1354:
20-03-23 18:20-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 219, Global step 1355:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 220, Global step 1356:
20-03-23 18:20-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 221, Global step 1357:
20-03-23 18:20-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 222, Global step 1358:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 223, Global step 1359:
20-03-23 18:20-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 224, Global step 1360:
20-03-23 18:20-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 225, Global step 1361:
20-03-23 18:20-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 226, Global step 1362:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 227, Global step 1363:
20-03-23 18:20-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 228, Global step 1364:
20-03-23 18:20-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 229, Global step 1365:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 230, Global step 1366:
20-03-23 18:20-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 231, Global step 1367:
20-03-23 18:20-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 232, Global step 1368:
20-03-23 18:20-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 233, Global step 1369:
20-03-23 18:20-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 234, Global step 1370:
20-03-23 18:20-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 235, Global step 1371:
20-03-23 18:20-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:20-INFO-Epoch 4, Batch 236, Global step 1372:
20-03-23 18:20-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:20-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:20-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 237, Global step 1373:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 238, Global step 1374:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 239, Global step 1375:
20-03-23 18:21-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 240, Global step 1376:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 241, Global step 1377:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 242, Global step 1378:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 243, Global step 1379:
20-03-23 18:21-INFO-training batch loss: 0.0035; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 244, Global step 1380:
20-03-23 18:21-INFO-training batch loss: 0.0015; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 245, Global step 1381:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 246, Global step 1382:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 247, Global step 1383:
20-03-23 18:21-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 248, Global step 1384:
20-03-23 18:21-INFO-training batch loss: 0.0014; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 249, Global step 1385:
20-03-23 18:21-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 250, Global step 1386:
20-03-23 18:21-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 251, Global step 1387:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 252, Global step 1388:
20-03-23 18:21-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 253, Global step 1389:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 254, Global step 1390:
20-03-23 18:21-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 255, Global step 1391:
20-03-23 18:21-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 256, Global step 1392:
20-03-23 18:21-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 257, Global step 1393:
20-03-23 18:21-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 258, Global step 1394:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 259, Global step 1395:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 260, Global step 1396:
20-03-23 18:21-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 261, Global step 1397:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 262, Global step 1398:
20-03-23 18:21-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:21-INFO-Epoch 4, Batch 263, Global step 1399:
20-03-23 18:21-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:21-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:21-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 264, Global step 1400:
20-03-23 18:22-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 265, Global step 1401:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 266, Global step 1402:
20-03-23 18:22-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 267, Global step 1403:
20-03-23 18:22-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 268, Global step 1404:
20-03-23 18:22-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 269, Global step 1405:
20-03-23 18:22-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 270, Global step 1406:
20-03-23 18:22-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 271, Global step 1407:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 272, Global step 1408:
20-03-23 18:22-INFO-training batch loss: 0.0012; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 273, Global step 1409:
20-03-23 18:22-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 274, Global step 1410:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 275, Global step 1411:
20-03-23 18:22-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 276, Global step 1412:
20-03-23 18:22-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 277, Global step 1413:
20-03-23 18:22-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 278, Global step 1414:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 279, Global step 1415:
20-03-23 18:22-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 280, Global step 1416:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 281, Global step 1417:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 282, Global step 1418:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 283, Global step 1419:
20-03-23 18:22-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, Batch 284, Global step 1420:
20-03-23 18:22-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:22-INFO-Epoch 4, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 4, evaluating batch loss: 0.6398; avg_loss: 0.2456
20-03-23 18:22-INFO-Epoch 4, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9554
20-03-23 18:22-INFO-
20-03-23 18:22-INFO-Epoch 5, Batch 1, Global step 1421:
20-03-23 18:22-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:22-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:22-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 2, Global step 1422:
20-03-23 18:23-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 3, Global step 1423:
20-03-23 18:23-INFO-training batch loss: 0.0014; avg_loss: 0.0007
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 4, Global step 1424:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0006
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 5, Global step 1425:
20-03-23 18:23-INFO-training batch loss: 0.0001; avg_loss: 0.0005
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 6, Global step 1426:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0005
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 7, Global step 1427:
20-03-23 18:23-INFO-training batch loss: 0.0009; avg_loss: 0.0005
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 8, Global step 1428:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0005
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 9, Global step 1429:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0005
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 10, Global step 1430:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 11, Global step 1431:
20-03-23 18:23-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 12, Global step 1432:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 13, Global step 1433:
20-03-23 18:23-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 14, Global step 1434:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 15, Global step 1435:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 16, Global step 1436:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 17, Global step 1437:
20-03-23 18:23-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 18, Global step 1438:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 19, Global step 1439:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 20, Global step 1440:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 21, Global step 1441:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 22, Global step 1442:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 23, Global step 1443:
20-03-23 18:23-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 24, Global step 1444:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 25, Global step 1445:
20-03-23 18:23-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 26, Global step 1446:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 27, Global step 1447:
20-03-23 18:23-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:23-INFO-Epoch 5, Batch 28, Global step 1448:
20-03-23 18:23-INFO-training batch loss: 0.0010; avg_loss: 0.0004
20-03-23 18:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:23-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 29, Global step 1449:
20-03-23 18:24-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 30, Global step 1450:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 31, Global step 1451:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 32, Global step 1452:
20-03-23 18:24-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 33, Global step 1453:
20-03-23 18:24-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 34, Global step 1454:
20-03-23 18:24-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 35, Global step 1455:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 36, Global step 1456:
20-03-23 18:24-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 37, Global step 1457:
20-03-23 18:24-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 38, Global step 1458:
20-03-23 18:24-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 39, Global step 1459:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 40, Global step 1460:
20-03-23 18:24-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 41, Global step 1461:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 42, Global step 1462:
20-03-23 18:24-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 43, Global step 1463:
20-03-23 18:24-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 44, Global step 1464:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 45, Global step 1465:
20-03-23 18:24-INFO-training batch loss: 0.0020; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 46, Global step 1466:
20-03-23 18:24-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 47, Global step 1467:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 48, Global step 1468:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 49, Global step 1469:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 50, Global step 1470:
20-03-23 18:24-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 51, Global step 1471:
20-03-23 18:24-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 52, Global step 1472:
20-03-23 18:24-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 53, Global step 1473:
20-03-23 18:24-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 54, Global step 1474:
20-03-23 18:24-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:24-INFO-Epoch 5, Batch 55, Global step 1475:
20-03-23 18:24-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:24-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 56, Global step 1476:
20-03-23 18:25-INFO-training batch loss: 0.0007; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 57, Global step 1477:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 58, Global step 1478:
20-03-23 18:25-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 59, Global step 1479:
20-03-23 18:25-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 60, Global step 1480:
20-03-23 18:25-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 61, Global step 1481:
20-03-23 18:25-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 62, Global step 1482:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 63, Global step 1483:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 64, Global step 1484:
20-03-23 18:25-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 65, Global step 1485:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 66, Global step 1486:
20-03-23 18:25-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 67, Global step 1487:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 68, Global step 1488:
20-03-23 18:25-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 69, Global step 1489:
20-03-23 18:25-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 70, Global step 1490:
20-03-23 18:25-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 71, Global step 1491:
20-03-23 18:25-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 72, Global step 1492:
20-03-23 18:25-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 73, Global step 1493:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 74, Global step 1494:
20-03-23 18:25-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 75, Global step 1495:
20-03-23 18:25-INFO-training batch loss: 0.0009; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 76, Global step 1496:
20-03-23 18:25-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 77, Global step 1497:
20-03-23 18:25-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 78, Global step 1498:
20-03-23 18:25-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 79, Global step 1499:
20-03-23 18:25-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 80, Global step 1500:
20-03-23 18:25-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:25-INFO-Epoch 5, Batch 81, Global step 1501:
20-03-23 18:25-INFO-training batch loss: 0.0007; avg_loss: 0.0004
20-03-23 18:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:25-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 82, Global step 1502:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 83, Global step 1503:
20-03-23 18:26-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 84, Global step 1504:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 85, Global step 1505:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 86, Global step 1506:
20-03-23 18:26-INFO-training batch loss: 0.0011; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 87, Global step 1507:
20-03-23 18:26-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 88, Global step 1508:
20-03-23 18:26-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 89, Global step 1509:
20-03-23 18:26-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 90, Global step 1510:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 91, Global step 1511:
20-03-23 18:26-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 92, Global step 1512:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 93, Global step 1513:
20-03-23 18:26-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 94, Global step 1514:
20-03-23 18:26-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 95, Global step 1515:
20-03-23 18:26-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 96, Global step 1516:
20-03-23 18:26-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 97, Global step 1517:
20-03-23 18:26-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 98, Global step 1518:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 99, Global step 1519:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 100, Global step 1520:
20-03-23 18:26-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 101, Global step 1521:
20-03-23 18:26-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 102, Global step 1522:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 103, Global step 1523:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 104, Global step 1524:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 105, Global step 1525:
20-03-23 18:26-INFO-training batch loss: 0.0007; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 106, Global step 1526:
20-03-23 18:26-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 107, Global step 1527:
20-03-23 18:26-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:26-INFO-Epoch 5, Batch 108, Global step 1528:
20-03-23 18:26-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:26-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:26-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 109, Global step 1529:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 110, Global step 1530:
20-03-23 18:27-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 111, Global step 1531:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 112, Global step 1532:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 113, Global step 1533:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 114, Global step 1534:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 115, Global step 1535:
20-03-23 18:27-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 116, Global step 1536:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 117, Global step 1537:
20-03-23 18:27-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 118, Global step 1538:
20-03-23 18:27-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 119, Global step 1539:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 120, Global step 1540:
20-03-23 18:27-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 121, Global step 1541:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 122, Global step 1542:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 123, Global step 1543:
20-03-23 18:27-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 124, Global step 1544:
20-03-23 18:27-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 125, Global step 1545:
20-03-23 18:27-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 126, Global step 1546:
20-03-23 18:27-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 127, Global step 1547:
20-03-23 18:27-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 128, Global step 1548:
20-03-23 18:27-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 129, Global step 1549:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 130, Global step 1550:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 131, Global step 1551:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 132, Global step 1552:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 133, Global step 1553:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 134, Global step 1554:
20-03-23 18:27-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:27-INFO-Epoch 5, Batch 135, Global step 1555:
20-03-23 18:27-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:27-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:27-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 136, Global step 1556:
20-03-23 18:28-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 137, Global step 1557:
20-03-23 18:28-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 138, Global step 1558:
20-03-23 18:28-INFO-training batch loss: 0.0021; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 139, Global step 1559:
20-03-23 18:28-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 140, Global step 1560:
20-03-23 18:28-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 141, Global step 1561:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 142, Global step 1562:
20-03-23 18:28-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 143, Global step 1563:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 144, Global step 1564:
20-03-23 18:28-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 145, Global step 1565:
20-03-23 18:28-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 146, Global step 1566:
20-03-23 18:28-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 147, Global step 1567:
20-03-23 18:28-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 148, Global step 1568:
20-03-23 18:28-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 149, Global step 1569:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 150, Global step 1570:
20-03-23 18:28-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 151, Global step 1571:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 152, Global step 1572:
20-03-23 18:28-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 153, Global step 1573:
20-03-23 18:28-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 154, Global step 1574:
20-03-23 18:28-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 155, Global step 1575:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 156, Global step 1576:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 157, Global step 1577:
20-03-23 18:28-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 158, Global step 1578:
20-03-23 18:28-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 159, Global step 1579:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 160, Global step 1580:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:28-INFO-Epoch 5, Batch 161, Global step 1581:
20-03-23 18:28-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:28-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 162, Global step 1582:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 163, Global step 1583:
20-03-23 18:29-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 164, Global step 1584:
20-03-23 18:29-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 165, Global step 1585:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 166, Global step 1586:
20-03-23 18:29-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 167, Global step 1587:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 168, Global step 1588:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 169, Global step 1589:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 170, Global step 1590:
20-03-23 18:29-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 171, Global step 1591:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 172, Global step 1592:
20-03-23 18:29-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 173, Global step 1593:
20-03-23 18:29-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 174, Global step 1594:
20-03-23 18:29-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 175, Global step 1595:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 176, Global step 1596:
20-03-23 18:29-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 177, Global step 1597:
20-03-23 18:29-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 178, Global step 1598:
20-03-23 18:29-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 179, Global step 1599:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 180, Global step 1600:
20-03-23 18:29-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 181, Global step 1601:
20-03-23 18:29-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 182, Global step 1602:
20-03-23 18:29-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 183, Global step 1603:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 184, Global step 1604:
20-03-23 18:29-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 185, Global step 1605:
20-03-23 18:29-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 186, Global step 1606:
20-03-23 18:29-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 187, Global step 1607:
20-03-23 18:29-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:29-INFO-Epoch 5, Batch 188, Global step 1608:
20-03-23 18:29-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:29-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 189, Global step 1609:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 190, Global step 1610:
20-03-23 18:30-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 191, Global step 1611:
20-03-23 18:30-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 192, Global step 1612:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 193, Global step 1613:
20-03-23 18:30-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 194, Global step 1614:
20-03-23 18:30-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 195, Global step 1615:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 196, Global step 1616:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 197, Global step 1617:
20-03-23 18:30-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 198, Global step 1618:
20-03-23 18:30-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 199, Global step 1619:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 200, Global step 1620:
20-03-23 18:30-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 201, Global step 1621:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 202, Global step 1622:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 203, Global step 1623:
20-03-23 18:30-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 204, Global step 1624:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 205, Global step 1625:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 206, Global step 1626:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 207, Global step 1627:
20-03-23 18:30-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 208, Global step 1628:
20-03-23 18:30-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 209, Global step 1629:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 210, Global step 1630:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 211, Global step 1631:
20-03-23 18:30-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 212, Global step 1632:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 213, Global step 1633:
20-03-23 18:30-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:30-INFO-Epoch 5, Batch 214, Global step 1634:
20-03-23 18:30-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:30-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 215, Global step 1635:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 216, Global step 1636:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 217, Global step 1637:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 218, Global step 1638:
20-03-23 18:31-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 219, Global step 1639:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 220, Global step 1640:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 221, Global step 1641:
20-03-23 18:31-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 222, Global step 1642:
20-03-23 18:31-INFO-training batch loss: 0.0017; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 223, Global step 1643:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 224, Global step 1644:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 225, Global step 1645:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 226, Global step 1646:
20-03-23 18:31-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 227, Global step 1647:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 228, Global step 1648:
20-03-23 18:31-INFO-training batch loss: 0.0013; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 229, Global step 1649:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 230, Global step 1650:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 231, Global step 1651:
20-03-23 18:31-INFO-training batch loss: 0.0010; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 232, Global step 1652:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 233, Global step 1653:
20-03-23 18:31-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 234, Global step 1654:
20-03-23 18:31-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 235, Global step 1655:
20-03-23 18:31-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 236, Global step 1656:
20-03-23 18:31-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 237, Global step 1657:
20-03-23 18:31-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 238, Global step 1658:
20-03-23 18:31-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 239, Global step 1659:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:31-INFO-Epoch 5, Batch 240, Global step 1660:
20-03-23 18:31-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:31-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 241, Global step 1661:
20-03-23 18:32-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 242, Global step 1662:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 243, Global step 1663:
20-03-23 18:32-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 244, Global step 1664:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 245, Global step 1665:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 246, Global step 1666:
20-03-23 18:32-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 247, Global step 1667:
20-03-23 18:32-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 248, Global step 1668:
20-03-23 18:32-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 249, Global step 1669:
20-03-23 18:32-INFO-training batch loss: 0.0011; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 250, Global step 1670:
20-03-23 18:32-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 251, Global step 1671:
20-03-23 18:32-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 252, Global step 1672:
20-03-23 18:32-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 253, Global step 1673:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 254, Global step 1674:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 255, Global step 1675:
20-03-23 18:32-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 256, Global step 1676:
20-03-23 18:32-INFO-training batch loss: 0.0016; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 257, Global step 1677:
20-03-23 18:32-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 258, Global step 1678:
20-03-23 18:32-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 259, Global step 1679:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 260, Global step 1680:
20-03-23 18:32-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 261, Global step 1681:
20-03-23 18:32-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 262, Global step 1682:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 263, Global step 1683:
20-03-23 18:32-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 264, Global step 1684:
20-03-23 18:32-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 265, Global step 1685:
20-03-23 18:32-INFO-training batch loss: 0.0013; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 266, Global step 1686:
20-03-23 18:32-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:32-INFO-Epoch 5, Batch 267, Global step 1687:
20-03-23 18:32-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:32-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 268, Global step 1688:
20-03-23 18:33-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 269, Global step 1689:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 270, Global step 1690:
20-03-23 18:33-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 271, Global step 1691:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 272, Global step 1692:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 273, Global step 1693:
20-03-23 18:33-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 274, Global step 1694:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 275, Global step 1695:
20-03-23 18:33-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 276, Global step 1696:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 277, Global step 1697:
20-03-23 18:33-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 278, Global step 1698:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 279, Global step 1699:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 280, Global step 1700:
20-03-23 18:33-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 281, Global step 1701:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 282, Global step 1702:
20-03-23 18:33-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 283, Global step 1703:
20-03-23 18:33-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, Batch 284, Global step 1704:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:33-INFO-Epoch 5, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 5, evaluating batch loss: 0.6135; avg_loss: 0.2272
20-03-23 18:33-INFO-Epoch 5, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9538
20-03-23 18:33-INFO-
20-03-23 18:33-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
20-03-23 18:33-INFO-Epoch 6, Batch 1, Global step 1705:
20-03-23 18:33-INFO-training batch loss: 0.0005; avg_loss: 0.0005
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 6, Batch 2, Global step 1706:
20-03-23 18:33-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 6, Batch 3, Global step 1707:
20-03-23 18:33-INFO-training batch loss: 0.0013; avg_loss: 0.0007
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 6, Batch 4, Global step 1708:
20-03-23 18:33-INFO-training batch loss: 0.0002; avg_loss: 0.0006
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 6, Batch 5, Global step 1709:
20-03-23 18:33-INFO-training batch loss: 0.0001; avg_loss: 0.0005
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:33-INFO-Epoch 6, Batch 6, Global step 1710:
20-03-23 18:33-INFO-training batch loss: 0.0005; avg_loss: 0.0005
20-03-23 18:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:33-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 7, Global step 1711:
20-03-23 18:34-INFO-training batch loss: 0.0003; avg_loss: 0.0005
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 8, Global step 1712:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 9, Global step 1713:
20-03-23 18:34-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 10, Global step 1714:
20-03-23 18:34-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 11, Global step 1715:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 12, Global step 1716:
20-03-23 18:34-INFO-training batch loss: 0.0003; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 13, Global step 1717:
20-03-23 18:34-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 14, Global step 1718:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 15, Global step 1719:
20-03-23 18:34-INFO-training batch loss: 0.0009; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 16, Global step 1720:
20-03-23 18:34-INFO-training batch loss: 0.0006; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 17, Global step 1721:
20-03-23 18:34-INFO-training batch loss: 0.0007; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 18, Global step 1722:
20-03-23 18:34-INFO-training batch loss: 0.0004; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 19, Global step 1723:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 20, Global step 1724:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 21, Global step 1725:
20-03-23 18:34-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 22, Global step 1726:
20-03-23 18:34-INFO-training batch loss: 0.0000; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 23, Global step 1727:
20-03-23 18:34-INFO-training batch loss: 0.0001; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 24, Global step 1728:
20-03-23 18:34-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 25, Global step 1729:
20-03-23 18:34-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 26, Global step 1730:
20-03-23 18:34-INFO-training batch loss: 0.0005; avg_loss: 0.0004
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 27, Global step 1731:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 28, Global step 1732:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 29, Global step 1733:
20-03-23 18:34-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 30, Global step 1734:
20-03-23 18:34-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 31, Global step 1735:
20-03-23 18:34-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:34-INFO-Epoch 6, Batch 32, Global step 1736:
20-03-23 18:34-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:34-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 33, Global step 1737:
20-03-23 18:35-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 34, Global step 1738:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 35, Global step 1739:
20-03-23 18:35-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 36, Global step 1740:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 37, Global step 1741:
20-03-23 18:35-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 38, Global step 1742:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 39, Global step 1743:
20-03-23 18:35-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 40, Global step 1744:
20-03-23 18:35-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 41, Global step 1745:
20-03-23 18:35-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 42, Global step 1746:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 43, Global step 1747:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 44, Global step 1748:
20-03-23 18:35-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 45, Global step 1749:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 46, Global step 1750:
20-03-23 18:35-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 47, Global step 1751:
20-03-23 18:35-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 48, Global step 1752:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 49, Global step 1753:
20-03-23 18:35-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 50, Global step 1754:
20-03-23 18:35-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 51, Global step 1755:
20-03-23 18:35-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 52, Global step 1756:
20-03-23 18:35-INFO-training batch loss: 0.0013; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 53, Global step 1757:
20-03-23 18:35-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 54, Global step 1758:
20-03-23 18:35-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 55, Global step 1759:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 56, Global step 1760:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 57, Global step 1761:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 58, Global step 1762:
20-03-23 18:35-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:35-INFO-Epoch 6, Batch 59, Global step 1763:
20-03-23 18:35-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:35-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 60, Global step 1764:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 61, Global step 1765:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 62, Global step 1766:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 63, Global step 1767:
20-03-23 18:36-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 64, Global step 1768:
20-03-23 18:36-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 65, Global step 1769:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 66, Global step 1770:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 67, Global step 1771:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 68, Global step 1772:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 69, Global step 1773:
20-03-23 18:36-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 70, Global step 1774:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 71, Global step 1775:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 72, Global step 1776:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 73, Global step 1777:
20-03-23 18:36-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 74, Global step 1778:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 75, Global step 1779:
20-03-23 18:36-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 76, Global step 1780:
20-03-23 18:36-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 77, Global step 1781:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 78, Global step 1782:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 79, Global step 1783:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 80, Global step 1784:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 81, Global step 1785:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 82, Global step 1786:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 83, Global step 1787:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 84, Global step 1788:
20-03-23 18:36-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 85, Global step 1789:
20-03-23 18:36-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:36-INFO-Epoch 6, Batch 86, Global step 1790:
20-03-23 18:36-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:36-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 87, Global step 1791:
20-03-23 18:37-INFO-training batch loss: 0.0011; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 88, Global step 1792:
20-03-23 18:37-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 89, Global step 1793:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 90, Global step 1794:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 91, Global step 1795:
20-03-23 18:37-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 92, Global step 1796:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 93, Global step 1797:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 94, Global step 1798:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 95, Global step 1799:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 96, Global step 1800:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 97, Global step 1801:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 98, Global step 1802:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 99, Global step 1803:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 100, Global step 1804:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 101, Global step 1805:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 102, Global step 1806:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 103, Global step 1807:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 104, Global step 1808:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 105, Global step 1809:
20-03-23 18:37-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 106, Global step 1810:
20-03-23 18:37-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 107, Global step 1811:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 108, Global step 1812:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 109, Global step 1813:
20-03-23 18:37-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 110, Global step 1814:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 111, Global step 1815:
20-03-23 18:37-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:37-INFO-Epoch 6, Batch 112, Global step 1816:
20-03-23 18:37-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:37-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 113, Global step 1817:
20-03-23 18:38-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 114, Global step 1818:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 115, Global step 1819:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 116, Global step 1820:
20-03-23 18:38-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 117, Global step 1821:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 118, Global step 1822:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 119, Global step 1823:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 120, Global step 1824:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 121, Global step 1825:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 122, Global step 1826:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 123, Global step 1827:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 124, Global step 1828:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 125, Global step 1829:
20-03-23 18:38-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 126, Global step 1830:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 127, Global step 1831:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 128, Global step 1832:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 129, Global step 1833:
20-03-23 18:38-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 130, Global step 1834:
20-03-23 18:38-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 131, Global step 1835:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 132, Global step 1836:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 133, Global step 1837:
20-03-23 18:38-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 134, Global step 1838:
20-03-23 18:38-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 135, Global step 1839:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 136, Global step 1840:
20-03-23 18:38-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 137, Global step 1841:
20-03-23 18:38-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:38-INFO-Epoch 6, Batch 138, Global step 1842:
20-03-23 18:38-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:38-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 139, Global step 1843:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 140, Global step 1844:
20-03-23 18:39-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 141, Global step 1845:
20-03-23 18:39-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 142, Global step 1846:
20-03-23 18:39-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 143, Global step 1847:
20-03-23 18:39-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 144, Global step 1848:
20-03-23 18:39-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 145, Global step 1849:
20-03-23 18:39-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 146, Global step 1850:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 147, Global step 1851:
20-03-23 18:39-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 148, Global step 1852:
20-03-23 18:39-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 149, Global step 1853:
20-03-23 18:39-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 150, Global step 1854:
20-03-23 18:39-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 151, Global step 1855:
20-03-23 18:39-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 152, Global step 1856:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 153, Global step 1857:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 154, Global step 1858:
20-03-23 18:39-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 155, Global step 1859:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 156, Global step 1860:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 157, Global step 1861:
20-03-23 18:39-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 158, Global step 1862:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 159, Global step 1863:
20-03-23 18:39-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 160, Global step 1864:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 161, Global step 1865:
20-03-23 18:39-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 162, Global step 1866:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 163, Global step 1867:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:39-INFO-Epoch 6, Batch 164, Global step 1868:
20-03-23 18:39-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:39-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 165, Global step 1869:
20-03-23 18:40-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 166, Global step 1870:
20-03-23 18:40-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 167, Global step 1871:
20-03-23 18:40-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 168, Global step 1872:
20-03-23 18:40-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 169, Global step 1873:
20-03-23 18:40-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 170, Global step 1874:
20-03-23 18:40-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 171, Global step 1875:
20-03-23 18:40-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 172, Global step 1876:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 173, Global step 1877:
20-03-23 18:40-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 174, Global step 1878:
20-03-23 18:40-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 175, Global step 1879:
20-03-23 18:40-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 176, Global step 1880:
20-03-23 18:40-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 177, Global step 1881:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 178, Global step 1882:
20-03-23 18:40-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 179, Global step 1883:
20-03-23 18:40-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 180, Global step 1884:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 181, Global step 1885:
20-03-23 18:40-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 182, Global step 1886:
20-03-23 18:40-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 183, Global step 1887:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 184, Global step 1888:
20-03-23 18:40-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 185, Global step 1889:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 186, Global step 1890:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 187, Global step 1891:
20-03-23 18:40-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 188, Global step 1892:
20-03-23 18:40-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 189, Global step 1893:
20-03-23 18:40-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 190, Global step 1894:
20-03-23 18:40-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:40-INFO-Epoch 6, Batch 191, Global step 1895:
20-03-23 18:40-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:40-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 192, Global step 1896:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 193, Global step 1897:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 194, Global step 1898:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 195, Global step 1899:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 196, Global step 1900:
20-03-23 18:41-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 197, Global step 1901:
20-03-23 18:41-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 198, Global step 1902:
20-03-23 18:41-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 199, Global step 1903:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 200, Global step 1904:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 201, Global step 1905:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 202, Global step 1906:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 203, Global step 1907:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 204, Global step 1908:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 205, Global step 1909:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 206, Global step 1910:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 207, Global step 1911:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 208, Global step 1912:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 209, Global step 1913:
20-03-23 18:41-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 210, Global step 1914:
20-03-23 18:41-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 211, Global step 1915:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 212, Global step 1916:
20-03-23 18:41-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 213, Global step 1917:
20-03-23 18:41-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 214, Global step 1918:
20-03-23 18:41-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 215, Global step 1919:
20-03-23 18:41-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 216, Global step 1920:
20-03-23 18:41-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:41-INFO-Epoch 6, Batch 217, Global step 1921:
20-03-23 18:41-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:41-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 218, Global step 1922:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 219, Global step 1923:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 220, Global step 1924:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 221, Global step 1925:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 222, Global step 1926:
20-03-23 18:42-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 223, Global step 1927:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 224, Global step 1928:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 225, Global step 1929:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 226, Global step 1930:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 227, Global step 1931:
20-03-23 18:42-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 228, Global step 1932:
20-03-23 18:42-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 229, Global step 1933:
20-03-23 18:42-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 230, Global step 1934:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 231, Global step 1935:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 232, Global step 1936:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 233, Global step 1937:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 234, Global step 1938:
20-03-23 18:42-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 235, Global step 1939:
20-03-23 18:42-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 236, Global step 1940:
20-03-23 18:42-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 237, Global step 1941:
20-03-23 18:42-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 238, Global step 1942:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 239, Global step 1943:
20-03-23 18:42-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 240, Global step 1944:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 241, Global step 1945:
20-03-23 18:42-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 242, Global step 1946:
20-03-23 18:42-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 243, Global step 1947:
20-03-23 18:42-INFO-training batch loss: 0.0012; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:42-INFO-Epoch 6, Batch 244, Global step 1948:
20-03-23 18:42-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:42-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 245, Global step 1949:
20-03-23 18:43-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 246, Global step 1950:
20-03-23 18:43-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 247, Global step 1951:
20-03-23 18:43-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 248, Global step 1952:
20-03-23 18:43-INFO-training batch loss: 0.0014; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 249, Global step 1953:
20-03-23 18:43-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 250, Global step 1954:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 251, Global step 1955:
20-03-23 18:43-INFO-training batch loss: 0.0010; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 252, Global step 1956:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 253, Global step 1957:
20-03-23 18:43-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 254, Global step 1958:
20-03-23 18:43-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 255, Global step 1959:
20-03-23 18:43-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 256, Global step 1960:
20-03-23 18:43-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 257, Global step 1961:
20-03-23 18:43-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 258, Global step 1962:
20-03-23 18:43-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 259, Global step 1963:
20-03-23 18:43-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 260, Global step 1964:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 261, Global step 1965:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 262, Global step 1966:
20-03-23 18:43-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 263, Global step 1967:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 264, Global step 1968:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 265, Global step 1969:
20-03-23 18:43-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 266, Global step 1970:
20-03-23 18:43-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 267, Global step 1971:
20-03-23 18:43-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 268, Global step 1972:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 269, Global step 1973:
20-03-23 18:43-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:43-INFO-Epoch 6, Batch 270, Global step 1974:
20-03-23 18:43-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:43-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 271, Global step 1975:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 272, Global step 1976:
20-03-23 18:44-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 273, Global step 1977:
20-03-23 18:44-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 274, Global step 1978:
20-03-23 18:44-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 275, Global step 1979:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 276, Global step 1980:
20-03-23 18:44-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 277, Global step 1981:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 278, Global step 1982:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 279, Global step 1983:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 280, Global step 1984:
20-03-23 18:44-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 281, Global step 1985:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 282, Global step 1986:
20-03-23 18:44-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 283, Global step 1987:
20-03-23 18:44-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, Batch 284, Global step 1988:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:44-INFO-Epoch 6, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 6, evaluating batch loss: 0.8221; avg_loss: 0.2808
20-03-23 18:44-INFO-Epoch 6, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9616
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 1, Global step 1989:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 2, Global step 1990:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 3, Global step 1991:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 4, Global step 1992:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 5, Global step 1993:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 6, Global step 1994:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 7, Global step 1995:
20-03-23 18:44-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 8, Global step 1996:
20-03-23 18:44-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:44-INFO-Epoch 7, Batch 9, Global step 1997:
20-03-23 18:44-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:44-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 10, Global step 1998:
20-03-23 18:45-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 11, Global step 1999:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 12, Global step 2000:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 13, Global step 2001:
20-03-23 18:45-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 14, Global step 2002:
20-03-23 18:45-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 15, Global step 2003:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 16, Global step 2004:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 17, Global step 2005:
20-03-23 18:45-INFO-training batch loss: 0.0007; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 18, Global step 2006:
20-03-23 18:45-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 19, Global step 2007:
20-03-23 18:45-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 20, Global step 2008:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 21, Global step 2009:
20-03-23 18:45-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 22, Global step 2010:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 23, Global step 2011:
20-03-23 18:45-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 24, Global step 2012:
20-03-23 18:45-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 25, Global step 2013:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 26, Global step 2014:
20-03-23 18:45-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 27, Global step 2015:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 28, Global step 2016:
20-03-23 18:45-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 29, Global step 2017:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 30, Global step 2018:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 31, Global step 2019:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 32, Global step 2020:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 33, Global step 2021:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 34, Global step 2022:
20-03-23 18:45-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:45-INFO-Epoch 7, Batch 35, Global step 2023:
20-03-23 18:45-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:45-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 36, Global step 2024:
20-03-23 18:46-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 37, Global step 2025:
20-03-23 18:46-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 38, Global step 2026:
20-03-23 18:46-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 39, Global step 2027:
20-03-23 18:46-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 40, Global step 2028:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 41, Global step 2029:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 42, Global step 2030:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 43, Global step 2031:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 44, Global step 2032:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 45, Global step 2033:
20-03-23 18:46-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 46, Global step 2034:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 47, Global step 2035:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 48, Global step 2036:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 49, Global step 2037:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 50, Global step 2038:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 51, Global step 2039:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 52, Global step 2040:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 53, Global step 2041:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 54, Global step 2042:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 55, Global step 2043:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 56, Global step 2044:
20-03-23 18:46-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 57, Global step 2045:
20-03-23 18:46-INFO-training batch loss: 0.0009; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 58, Global step 2046:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 59, Global step 2047:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 60, Global step 2048:
20-03-23 18:46-INFO-training batch loss: 0.0008; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 61, Global step 2049:
20-03-23 18:46-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:46-INFO-Epoch 7, Batch 62, Global step 2050:
20-03-23 18:46-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:46-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 63, Global step 2051:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 64, Global step 2052:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 65, Global step 2053:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 66, Global step 2054:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 67, Global step 2055:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 68, Global step 2056:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 69, Global step 2057:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 70, Global step 2058:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 71, Global step 2059:
20-03-23 18:47-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 72, Global step 2060:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 73, Global step 2061:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 74, Global step 2062:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 75, Global step 2063:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 76, Global step 2064:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 77, Global step 2065:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 78, Global step 2066:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 79, Global step 2067:
20-03-23 18:47-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 80, Global step 2068:
20-03-23 18:47-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 81, Global step 2069:
20-03-23 18:47-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 82, Global step 2070:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 83, Global step 2071:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 84, Global step 2072:
20-03-23 18:47-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 85, Global step 2073:
20-03-23 18:47-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 86, Global step 2074:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 87, Global step 2075:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:47-INFO-Epoch 7, Batch 88, Global step 2076:
20-03-23 18:47-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:47-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 89, Global step 2077:
20-03-23 18:48-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 90, Global step 2078:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 91, Global step 2079:
20-03-23 18:48-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 92, Global step 2080:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 93, Global step 2081:
20-03-23 18:48-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 94, Global step 2082:
20-03-23 18:48-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 95, Global step 2083:
20-03-23 18:48-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 96, Global step 2084:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 97, Global step 2085:
20-03-23 18:48-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 98, Global step 2086:
20-03-23 18:48-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 99, Global step 2087:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 100, Global step 2088:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 101, Global step 2089:
20-03-23 18:48-INFO-training batch loss: 0.0009; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 102, Global step 2090:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 103, Global step 2091:
20-03-23 18:48-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 104, Global step 2092:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 105, Global step 2093:
20-03-23 18:48-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 106, Global step 2094:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 107, Global step 2095:
20-03-23 18:48-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 108, Global step 2096:
20-03-23 18:48-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 109, Global step 2097:
20-03-23 18:48-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 110, Global step 2098:
20-03-23 18:48-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 111, Global step 2099:
20-03-23 18:48-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 112, Global step 2100:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 113, Global step 2101:
20-03-23 18:48-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 114, Global step 2102:
20-03-23 18:48-INFO-training batch loss: 0.0015; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:48-INFO-Epoch 7, Batch 115, Global step 2103:
20-03-23 18:48-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:48-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 116, Global step 2104:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 117, Global step 2105:
20-03-23 18:49-INFO-training batch loss: 0.0013; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 118, Global step 2106:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 119, Global step 2107:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 120, Global step 2108:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 121, Global step 2109:
20-03-23 18:49-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 122, Global step 2110:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 123, Global step 2111:
20-03-23 18:49-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 124, Global step 2112:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 125, Global step 2113:
20-03-23 18:49-INFO-training batch loss: 0.0010; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 126, Global step 2114:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 127, Global step 2115:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 128, Global step 2116:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 129, Global step 2117:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 130, Global step 2118:
20-03-23 18:49-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 131, Global step 2119:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 132, Global step 2120:
20-03-23 18:49-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 133, Global step 2121:
20-03-23 18:49-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 134, Global step 2122:
20-03-23 18:49-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 135, Global step 2123:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 136, Global step 2124:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 137, Global step 2125:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 138, Global step 2126:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 139, Global step 2127:
20-03-23 18:49-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 140, Global step 2128:
20-03-23 18:49-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:49-INFO-Epoch 7, Batch 141, Global step 2129:
20-03-23 18:49-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:49-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 142, Global step 2130:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 143, Global step 2131:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 144, Global step 2132:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 145, Global step 2133:
20-03-23 18:50-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 146, Global step 2134:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 147, Global step 2135:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 148, Global step 2136:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 149, Global step 2137:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 150, Global step 2138:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 151, Global step 2139:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 152, Global step 2140:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 153, Global step 2141:
20-03-23 18:50-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 154, Global step 2142:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 155, Global step 2143:
20-03-23 18:50-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 156, Global step 2144:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 157, Global step 2145:
20-03-23 18:50-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 158, Global step 2146:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 159, Global step 2147:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 160, Global step 2148:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 161, Global step 2149:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 162, Global step 2150:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 163, Global step 2151:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 164, Global step 2152:
20-03-23 18:50-INFO-training batch loss: 0.0007; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 165, Global step 2153:
20-03-23 18:50-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 166, Global step 2154:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 167, Global step 2155:
20-03-23 18:50-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:50-INFO-Epoch 7, Batch 168, Global step 2156:
20-03-23 18:50-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:50-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 169, Global step 2157:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 170, Global step 2158:
20-03-23 18:51-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 171, Global step 2159:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 172, Global step 2160:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 173, Global step 2161:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 174, Global step 2162:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 175, Global step 2163:
20-03-23 18:51-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 176, Global step 2164:
20-03-23 18:51-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 177, Global step 2165:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 178, Global step 2166:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 179, Global step 2167:
20-03-23 18:51-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 180, Global step 2168:
20-03-23 18:51-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 181, Global step 2169:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 182, Global step 2170:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 183, Global step 2171:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 184, Global step 2172:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 185, Global step 2173:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 186, Global step 2174:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 187, Global step 2175:
20-03-23 18:51-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 188, Global step 2176:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 189, Global step 2177:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 190, Global step 2178:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 191, Global step 2179:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 192, Global step 2180:
20-03-23 18:51-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 193, Global step 2181:
20-03-23 18:51-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:51-INFO-Epoch 7, Batch 194, Global step 2182:
20-03-23 18:51-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:51-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 195, Global step 2183:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 196, Global step 2184:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 197, Global step 2185:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 198, Global step 2186:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 199, Global step 2187:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 200, Global step 2188:
20-03-23 18:52-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 201, Global step 2189:
20-03-23 18:52-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 202, Global step 2190:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 203, Global step 2191:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 204, Global step 2192:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 205, Global step 2193:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 206, Global step 2194:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 207, Global step 2195:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 208, Global step 2196:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 209, Global step 2197:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 210, Global step 2198:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 211, Global step 2199:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 212, Global step 2200:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 213, Global step 2201:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 214, Global step 2202:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 215, Global step 2203:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 216, Global step 2204:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 217, Global step 2205:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 218, Global step 2206:
20-03-23 18:52-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 219, Global step 2207:
20-03-23 18:52-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 220, Global step 2208:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:52-INFO-Epoch 7, Batch 221, Global step 2209:
20-03-23 18:52-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:52-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 222, Global step 2210:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 223, Global step 2211:
20-03-23 18:53-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 224, Global step 2212:
20-03-23 18:53-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 225, Global step 2213:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 226, Global step 2214:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 227, Global step 2215:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 228, Global step 2216:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 229, Global step 2217:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 230, Global step 2218:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 231, Global step 2219:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 232, Global step 2220:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 233, Global step 2221:
20-03-23 18:53-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 234, Global step 2222:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 235, Global step 2223:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 236, Global step 2224:
20-03-23 18:53-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 237, Global step 2225:
20-03-23 18:53-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 238, Global step 2226:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 239, Global step 2227:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 240, Global step 2228:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 241, Global step 2229:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 242, Global step 2230:
20-03-23 18:53-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 243, Global step 2231:
20-03-23 18:53-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 244, Global step 2232:
20-03-23 18:53-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 245, Global step 2233:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 246, Global step 2234:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:53-INFO-Epoch 7, Batch 247, Global step 2235:
20-03-23 18:53-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:53-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 248, Global step 2236:
20-03-23 18:54-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 249, Global step 2237:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 250, Global step 2238:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 251, Global step 2239:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 252, Global step 2240:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 253, Global step 2241:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 254, Global step 2242:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 255, Global step 2243:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 256, Global step 2244:
20-03-23 18:54-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 257, Global step 2245:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 258, Global step 2246:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 259, Global step 2247:
20-03-23 18:54-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 260, Global step 2248:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 261, Global step 2249:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 262, Global step 2250:
20-03-23 18:54-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 263, Global step 2251:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 264, Global step 2252:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 265, Global step 2253:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 266, Global step 2254:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 267, Global step 2255:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 268, Global step 2256:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 269, Global step 2257:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 270, Global step 2258:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 271, Global step 2259:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 272, Global step 2260:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 273, Global step 2261:
20-03-23 18:54-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:54-INFO-Epoch 7, Batch 274, Global step 2262:
20-03-23 18:54-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:54-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 275, Global step 2263:
20-03-23 18:55-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 276, Global step 2264:
20-03-23 18:55-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 277, Global step 2265:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 278, Global step 2266:
20-03-23 18:55-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 279, Global step 2267:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 280, Global step 2268:
20-03-23 18:55-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 281, Global step 2269:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 282, Global step 2270:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 283, Global step 2271:
20-03-23 18:55-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, Batch 284, Global step 2272:
20-03-23 18:55-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-Epoch 7, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 7, evaluating batch loss: 0.9049; avg_loss: 0.3038
20-03-23 18:55-INFO-Epoch 7, evaluating batch accuracy: 0.8636; avg_accuracy: 0.9493
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 1, Global step 2273:
20-03-23 18:55-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 2, Global step 2274:
20-03-23 18:55-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 3, Global step 2275:
20-03-23 18:55-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 4, Global step 2276:
20-03-23 18:55-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 5, Global step 2277:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 6, Global step 2278:
20-03-23 18:55-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 7, Global step 2279:
20-03-23 18:55-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 8, Global step 2280:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 9, Global step 2281:
20-03-23 18:55-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 10, Global step 2282:
20-03-23 18:55-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 11, Global step 2283:
20-03-23 18:55-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:55-INFO-Epoch 8, Batch 12, Global step 2284:
20-03-23 18:55-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 18:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:55-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 13, Global step 2285:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 14, Global step 2286:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 15, Global step 2287:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 16, Global step 2288:
20-03-23 18:56-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 17, Global step 2289:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 18, Global step 2290:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 19, Global step 2291:
20-03-23 18:56-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 20, Global step 2292:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 21, Global step 2293:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 22, Global step 2294:
20-03-23 18:56-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 23, Global step 2295:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 24, Global step 2296:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 25, Global step 2297:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 26, Global step 2298:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 27, Global step 2299:
20-03-23 18:56-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 28, Global step 2300:
20-03-23 18:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 29, Global step 2301:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 30, Global step 2302:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 31, Global step 2303:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 32, Global step 2304:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 33, Global step 2305:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 34, Global step 2306:
20-03-23 18:56-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 35, Global step 2307:
20-03-23 18:56-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 36, Global step 2308:
20-03-23 18:56-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 37, Global step 2309:
20-03-23 18:56-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 38, Global step 2310:
20-03-23 18:56-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:56-INFO-Epoch 8, Batch 39, Global step 2311:
20-03-23 18:56-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:56-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:56-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 40, Global step 2312:
20-03-23 18:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 41, Global step 2313:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 42, Global step 2314:
20-03-23 18:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 43, Global step 2315:
20-03-23 18:57-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 44, Global step 2316:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 45, Global step 2317:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 46, Global step 2318:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 47, Global step 2319:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 48, Global step 2320:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 49, Global step 2321:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 50, Global step 2322:
20-03-23 18:57-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 51, Global step 2323:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 52, Global step 2324:
20-03-23 18:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 53, Global step 2325:
20-03-23 18:57-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 54, Global step 2326:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 55, Global step 2327:
20-03-23 18:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 56, Global step 2328:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 57, Global step 2329:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 58, Global step 2330:
20-03-23 18:57-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 59, Global step 2331:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 60, Global step 2332:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 61, Global step 2333:
20-03-23 18:57-INFO-training batch loss: 0.0019; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 62, Global step 2334:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 63, Global step 2335:
20-03-23 18:57-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 64, Global step 2336:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:57-INFO-Epoch 8, Batch 65, Global step 2337:
20-03-23 18:57-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:57-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:57-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 66, Global step 2338:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 67, Global step 2339:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 68, Global step 2340:
20-03-23 18:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 69, Global step 2341:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 70, Global step 2342:
20-03-23 18:58-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 71, Global step 2343:
20-03-23 18:58-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 72, Global step 2344:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 73, Global step 2345:
20-03-23 18:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 74, Global step 2346:
20-03-23 18:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 75, Global step 2347:
20-03-23 18:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 76, Global step 2348:
20-03-23 18:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 77, Global step 2349:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 78, Global step 2350:
20-03-23 18:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 79, Global step 2351:
20-03-23 18:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 80, Global step 2352:
20-03-23 18:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 81, Global step 2353:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 82, Global step 2354:
20-03-23 18:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 83, Global step 2355:
20-03-23 18:58-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 84, Global step 2356:
20-03-23 18:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 85, Global step 2357:
20-03-23 18:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 86, Global step 2358:
20-03-23 18:58-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 87, Global step 2359:
20-03-23 18:58-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 88, Global step 2360:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 89, Global step 2361:
20-03-23 18:58-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 90, Global step 2362:
20-03-23 18:58-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:58-INFO-Epoch 8, Batch 91, Global step 2363:
20-03-23 18:58-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 18:58-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:58-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 92, Global step 2364:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 93, Global step 2365:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 94, Global step 2366:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 95, Global step 2367:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 96, Global step 2368:
20-03-23 18:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 97, Global step 2369:
20-03-23 18:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 98, Global step 2370:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 99, Global step 2371:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 100, Global step 2372:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 101, Global step 2373:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 102, Global step 2374:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 103, Global step 2375:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 104, Global step 2376:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 105, Global step 2377:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 106, Global step 2378:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 107, Global step 2379:
20-03-23 18:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 108, Global step 2380:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 109, Global step 2381:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 110, Global step 2382:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 111, Global step 2383:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 112, Global step 2384:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 113, Global step 2385:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 114, Global step 2386:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 115, Global step 2387:
20-03-23 18:59-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 116, Global step 2388:
20-03-23 18:59-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 18:59-INFO-Epoch 8, Batch 117, Global step 2389:
20-03-23 18:59-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 18:59-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 18:59-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 118, Global step 2390:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 119, Global step 2391:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 120, Global step 2392:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 121, Global step 2393:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 122, Global step 2394:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 123, Global step 2395:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 124, Global step 2396:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 125, Global step 2397:
20-03-23 19:00-INFO-training batch loss: 0.0010; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 126, Global step 2398:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 127, Global step 2399:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 128, Global step 2400:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 129, Global step 2401:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 130, Global step 2402:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 131, Global step 2403:
20-03-23 19:00-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 132, Global step 2404:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 133, Global step 2405:
20-03-23 19:00-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 134, Global step 2406:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 135, Global step 2407:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 136, Global step 2408:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 137, Global step 2409:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 138, Global step 2410:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 139, Global step 2411:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 140, Global step 2412:
20-03-23 19:00-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 141, Global step 2413:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 142, Global step 2414:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:00-INFO-Epoch 8, Batch 143, Global step 2415:
20-03-23 19:00-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:00-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:00-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 144, Global step 2416:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 145, Global step 2417:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 146, Global step 2418:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 147, Global step 2419:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 148, Global step 2420:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 149, Global step 2421:
20-03-23 19:01-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 150, Global step 2422:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 151, Global step 2423:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 152, Global step 2424:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 153, Global step 2425:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 154, Global step 2426:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 155, Global step 2427:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 156, Global step 2428:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 157, Global step 2429:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 158, Global step 2430:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 159, Global step 2431:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 160, Global step 2432:
20-03-23 19:01-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 161, Global step 2433:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 162, Global step 2434:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 163, Global step 2435:
20-03-23 19:01-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 164, Global step 2436:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 165, Global step 2437:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 166, Global step 2438:
20-03-23 19:01-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 167, Global step 2439:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 168, Global step 2440:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 169, Global step 2441:
20-03-23 19:01-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:01-INFO-Epoch 8, Batch 170, Global step 2442:
20-03-23 19:01-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:01-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 171, Global step 2443:
20-03-23 19:02-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 172, Global step 2444:
20-03-23 19:02-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 173, Global step 2445:
20-03-23 19:02-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 174, Global step 2446:
20-03-23 19:02-INFO-training batch loss: 0.0011; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 175, Global step 2447:
20-03-23 19:02-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 176, Global step 2448:
20-03-23 19:02-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 177, Global step 2449:
20-03-23 19:02-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 178, Global step 2450:
20-03-23 19:02-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 179, Global step 2451:
20-03-23 19:02-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 180, Global step 2452:
20-03-23 19:02-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 181, Global step 2453:
20-03-23 19:02-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 182, Global step 2454:
20-03-23 19:02-INFO-training batch loss: 0.0019; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 183, Global step 2455:
20-03-23 19:02-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 184, Global step 2456:
20-03-23 19:02-INFO-training batch loss: 0.0009; avg_loss: 0.0002
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 185, Global step 2457:
20-03-23 19:02-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 186, Global step 2458:
20-03-23 19:02-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 187, Global step 2459:
20-03-23 19:02-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 188, Global step 2460:
20-03-23 19:02-INFO-training batch loss: 0.0009; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 189, Global step 2461:
20-03-23 19:02-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 190, Global step 2462:
20-03-23 19:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 191, Global step 2463:
20-03-23 19:02-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 192, Global step 2464:
20-03-23 19:02-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 193, Global step 2465:
20-03-23 19:02-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 194, Global step 2466:
20-03-23 19:02-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 195, Global step 2467:
20-03-23 19:02-INFO-training batch loss: 0.0007; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:02-INFO-Epoch 8, Batch 196, Global step 2468:
20-03-23 19:02-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 19:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:02-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 197, Global step 2469:
20-03-23 19:03-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 198, Global step 2470:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 199, Global step 2471:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 200, Global step 2472:
20-03-23 19:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 201, Global step 2473:
20-03-23 19:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 202, Global step 2474:
20-03-23 19:03-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 203, Global step 2475:
20-03-23 19:03-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 204, Global step 2476:
20-03-23 19:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 205, Global step 2477:
20-03-23 19:03-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 206, Global step 2478:
20-03-23 19:03-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 207, Global step 2479:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 208, Global step 2480:
20-03-23 19:03-INFO-training batch loss: 0.0019; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 209, Global step 2481:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 210, Global step 2482:
20-03-23 19:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 211, Global step 2483:
20-03-23 19:03-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 212, Global step 2484:
20-03-23 19:03-INFO-training batch loss: 0.0010; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 213, Global step 2485:
20-03-23 19:03-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 214, Global step 2486:
20-03-23 19:03-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 215, Global step 2487:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 216, Global step 2488:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 217, Global step 2489:
20-03-23 19:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 218, Global step 2490:
20-03-23 19:03-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 219, Global step 2491:
20-03-23 19:03-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 220, Global step 2492:
20-03-23 19:03-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 221, Global step 2493:
20-03-23 19:03-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 222, Global step 2494:
20-03-23 19:03-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:03-INFO-Epoch 8, Batch 223, Global step 2495:
20-03-23 19:03-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:03-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 224, Global step 2496:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 225, Global step 2497:
20-03-23 19:04-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 226, Global step 2498:
20-03-23 19:04-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 227, Global step 2499:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 228, Global step 2500:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 229, Global step 2501:
20-03-23 19:04-INFO-training batch loss: 0.0023; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 230, Global step 2502:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 231, Global step 2503:
20-03-23 19:04-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 232, Global step 2504:
20-03-23 19:04-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 233, Global step 2505:
20-03-23 19:04-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 234, Global step 2506:
20-03-23 19:04-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 235, Global step 2507:
20-03-23 19:04-INFO-training batch loss: 0.0011; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 236, Global step 2508:
20-03-23 19:04-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 237, Global step 2509:
20-03-23 19:04-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 238, Global step 2510:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 239, Global step 2511:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 240, Global step 2512:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 241, Global step 2513:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 242, Global step 2514:
20-03-23 19:04-INFO-training batch loss: 0.0006; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 243, Global step 2515:
20-03-23 19:04-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 244, Global step 2516:
20-03-23 19:04-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 245, Global step 2517:
20-03-23 19:04-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 246, Global step 2518:
20-03-23 19:04-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 247, Global step 2519:
20-03-23 19:04-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 248, Global step 2520:
20-03-23 19:04-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:04-INFO-Epoch 8, Batch 249, Global step 2521:
20-03-23 19:04-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 19:04-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:04-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 250, Global step 2522:
20-03-23 19:05-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 251, Global step 2523:
20-03-23 19:05-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 252, Global step 2524:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 253, Global step 2525:
20-03-23 19:05-INFO-training batch loss: 0.0008; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 254, Global step 2526:
20-03-23 19:05-INFO-training batch loss: 0.0004; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 255, Global step 2527:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 256, Global step 2528:
20-03-23 19:05-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 257, Global step 2529:
20-03-23 19:05-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 258, Global step 2530:
20-03-23 19:05-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 259, Global step 2531:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 260, Global step 2532:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 261, Global step 2533:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 262, Global step 2534:
20-03-23 19:05-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 263, Global step 2535:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 264, Global step 2536:
20-03-23 19:05-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 265, Global step 2537:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 266, Global step 2538:
20-03-23 19:05-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 267, Global step 2539:
20-03-23 19:05-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 268, Global step 2540:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 269, Global step 2541:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 270, Global step 2542:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 271, Global step 2543:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 272, Global step 2544:
20-03-23 19:05-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 273, Global step 2545:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 274, Global step 2546:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 275, Global step 2547:
20-03-23 19:05-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:05-INFO-Epoch 8, Batch 276, Global step 2548:
20-03-23 19:05-INFO-training batch loss: 0.0003; avg_loss: 0.0003
20-03-23 19:05-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:05-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 277, Global step 2549:
20-03-23 19:06-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 278, Global step 2550:
20-03-23 19:06-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 279, Global step 2551:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 280, Global step 2552:
20-03-23 19:06-INFO-training batch loss: 0.0000; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 281, Global step 2553:
20-03-23 19:06-INFO-training batch loss: 0.0005; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 282, Global step 2554:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 283, Global step 2555:
20-03-23 19:06-INFO-training batch loss: 0.0002; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, Batch 284, Global step 2556:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, training batch loss: 0.0001; avg_loss: 0.0003
20-03-23 19:06-INFO-Epoch 8, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 8, evaluating batch loss: 0.9101; avg_loss: 0.3075
20-03-23 19:06-INFO-Epoch 8, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9538
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 1, Global step 2557:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 2, Global step 2558:
20-03-23 19:06-INFO-training batch loss: 0.0002; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 3, Global step 2559:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 4, Global step 2560:
20-03-23 19:06-INFO-training batch loss: 0.0002; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 5, Global step 2561:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 6, Global step 2562:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 7, Global step 2563:
20-03-23 19:06-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 8, Global step 2564:
20-03-23 19:06-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 9, Global step 2565:
20-03-23 19:06-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 10, Global step 2566:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 11, Global step 2567:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 12, Global step 2568:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 13, Global step 2569:
20-03-23 19:06-INFO-training batch loss: 0.0000; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:06-INFO-Epoch 9, Batch 14, Global step 2570:
20-03-23 19:06-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:06-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 15, Global step 2571:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 16, Global step 2572:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 17, Global step 2573:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 18, Global step 2574:
20-03-23 19:07-INFO-training batch loss: 0.0004; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 19, Global step 2575:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 20, Global step 2576:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 21, Global step 2577:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 22, Global step 2578:
20-03-23 19:07-INFO-training batch loss: 0.0003; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 23, Global step 2579:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 24, Global step 2580:
20-03-23 19:07-INFO-training batch loss: 0.0002; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 25, Global step 2581:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 26, Global step 2582:
20-03-23 19:07-INFO-training batch loss: 0.0004; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 27, Global step 2583:
20-03-23 19:07-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 28, Global step 2584:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0001
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 29, Global step 2585:
20-03-23 19:07-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 30, Global step 2586:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 31, Global step 2587:
20-03-23 19:07-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 32, Global step 2588:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 33, Global step 2589:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 34, Global step 2590:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 35, Global step 2591:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 36, Global step 2592:
20-03-23 19:07-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 37, Global step 2593:
20-03-23 19:07-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 38, Global step 2594:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 39, Global step 2595:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 40, Global step 2596:
20-03-23 19:07-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:07-INFO-Epoch 9, Batch 41, Global step 2597:
20-03-23 19:07-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:07-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:07-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 42, Global step 2598:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 43, Global step 2599:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 44, Global step 2600:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 45, Global step 2601:
20-03-23 19:08-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 46, Global step 2602:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 47, Global step 2603:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 48, Global step 2604:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 49, Global step 2605:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 50, Global step 2606:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 51, Global step 2607:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 52, Global step 2608:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 53, Global step 2609:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 54, Global step 2610:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 55, Global step 2611:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 56, Global step 2612:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 57, Global step 2613:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 58, Global step 2614:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 59, Global step 2615:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 60, Global step 2616:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 61, Global step 2617:
20-03-23 19:08-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 62, Global step 2618:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 63, Global step 2619:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 64, Global step 2620:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 65, Global step 2621:
20-03-23 19:08-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 66, Global step 2622:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:08-INFO-Epoch 9, Batch 67, Global step 2623:
20-03-23 19:08-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:08-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:08-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 68, Global step 2624:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 69, Global step 2625:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 70, Global step 2626:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 71, Global step 2627:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 72, Global step 2628:
20-03-23 19:09-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 73, Global step 2629:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 74, Global step 2630:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 75, Global step 2631:
20-03-23 19:09-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 76, Global step 2632:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 77, Global step 2633:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 78, Global step 2634:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 79, Global step 2635:
20-03-23 19:09-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 80, Global step 2636:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 81, Global step 2637:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 82, Global step 2638:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 83, Global step 2639:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 84, Global step 2640:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 85, Global step 2641:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 86, Global step 2642:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 87, Global step 2643:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 88, Global step 2644:
20-03-23 19:09-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 89, Global step 2645:
20-03-23 19:09-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 90, Global step 2646:
20-03-23 19:09-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 91, Global step 2647:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 92, Global step 2648:
20-03-23 19:09-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 93, Global step 2649:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:09-INFO-Epoch 9, Batch 94, Global step 2650:
20-03-23 19:09-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:09-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:09-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 95, Global step 2651:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 96, Global step 2652:
20-03-23 19:10-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 97, Global step 2653:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 98, Global step 2654:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 99, Global step 2655:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 100, Global step 2656:
20-03-23 19:10-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 101, Global step 2657:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 102, Global step 2658:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 103, Global step 2659:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 104, Global step 2660:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 105, Global step 2661:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 106, Global step 2662:
20-03-23 19:10-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 107, Global step 2663:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 108, Global step 2664:
20-03-23 19:10-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 109, Global step 2665:
20-03-23 19:10-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 110, Global step 2666:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 111, Global step 2667:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 112, Global step 2668:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 113, Global step 2669:
20-03-23 19:10-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 114, Global step 2670:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 115, Global step 2671:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 116, Global step 2672:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 117, Global step 2673:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 118, Global step 2674:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 119, Global step 2675:
20-03-23 19:10-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 120, Global step 2676:
20-03-23 19:10-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:10-INFO-Epoch 9, Batch 121, Global step 2677:
20-03-23 19:10-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:10-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:10-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 122, Global step 2678:
20-03-23 19:11-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 123, Global step 2679:
20-03-23 19:11-INFO-training batch loss: 0.0013; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 124, Global step 2680:
20-03-23 19:11-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 125, Global step 2681:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 126, Global step 2682:
20-03-23 19:11-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 127, Global step 2683:
20-03-23 19:11-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 128, Global step 2684:
20-03-23 19:11-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 129, Global step 2685:
20-03-23 19:11-INFO-training batch loss: 0.0008; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 130, Global step 2686:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 131, Global step 2687:
20-03-23 19:11-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 132, Global step 2688:
20-03-23 19:11-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 133, Global step 2689:
20-03-23 19:11-INFO-training batch loss: 0.0017; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 134, Global step 2690:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 135, Global step 2691:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 136, Global step 2692:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 137, Global step 2693:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 138, Global step 2694:
20-03-23 19:11-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 139, Global step 2695:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 140, Global step 2696:
20-03-23 19:11-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 141, Global step 2697:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 142, Global step 2698:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 143, Global step 2699:
20-03-23 19:11-INFO-training batch loss: 0.0007; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 144, Global step 2700:
20-03-23 19:11-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 145, Global step 2701:
20-03-23 19:11-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 146, Global step 2702:
20-03-23 19:11-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:11-INFO-Epoch 9, Batch 147, Global step 2703:
20-03-23 19:11-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:11-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:11-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 148, Global step 2704:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 149, Global step 2705:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 150, Global step 2706:
20-03-23 19:12-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 151, Global step 2707:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 152, Global step 2708:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 153, Global step 2709:
20-03-23 19:12-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 154, Global step 2710:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 155, Global step 2711:
20-03-23 19:12-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 156, Global step 2712:
20-03-23 19:12-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 157, Global step 2713:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 158, Global step 2714:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 159, Global step 2715:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 160, Global step 2716:
20-03-23 19:12-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 161, Global step 2717:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 162, Global step 2718:
20-03-23 19:12-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 163, Global step 2719:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 164, Global step 2720:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 165, Global step 2721:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 166, Global step 2722:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 167, Global step 2723:
20-03-23 19:12-INFO-training batch loss: 0.0005; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 168, Global step 2724:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 169, Global step 2725:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 170, Global step 2726:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 171, Global step 2727:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 172, Global step 2728:
20-03-23 19:12-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:12-INFO-Epoch 9, Batch 173, Global step 2729:
20-03-23 19:12-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:12-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 174, Global step 2730:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 175, Global step 2731:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 176, Global step 2732:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 177, Global step 2733:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 178, Global step 2734:
20-03-23 19:13-INFO-training batch loss: 0.0008; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 179, Global step 2735:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 180, Global step 2736:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 181, Global step 2737:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 182, Global step 2738:
20-03-23 19:13-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 183, Global step 2739:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 184, Global step 2740:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 185, Global step 2741:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 186, Global step 2742:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 187, Global step 2743:
20-03-23 19:13-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 188, Global step 2744:
20-03-23 19:13-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 189, Global step 2745:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 190, Global step 2746:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 191, Global step 2747:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 192, Global step 2748:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 193, Global step 2749:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 194, Global step 2750:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 195, Global step 2751:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 196, Global step 2752:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 197, Global step 2753:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 198, Global step 2754:
20-03-23 19:13-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 199, Global step 2755:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:13-INFO-Epoch 9, Batch 200, Global step 2756:
20-03-23 19:13-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:13-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:13-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 201, Global step 2757:
20-03-23 19:14-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 202, Global step 2758:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 203, Global step 2759:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 204, Global step 2760:
20-03-23 19:14-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 205, Global step 2761:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 206, Global step 2762:
20-03-23 19:14-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 207, Global step 2763:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 208, Global step 2764:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 209, Global step 2765:
20-03-23 19:14-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 210, Global step 2766:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 211, Global step 2767:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 212, Global step 2768:
20-03-23 19:14-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 213, Global step 2769:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 214, Global step 2770:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 215, Global step 2771:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 216, Global step 2772:
20-03-23 19:14-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 217, Global step 2773:
20-03-23 19:14-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 218, Global step 2774:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 219, Global step 2775:
20-03-23 19:14-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 220, Global step 2776:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 221, Global step 2777:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 222, Global step 2778:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 223, Global step 2779:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 224, Global step 2780:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 225, Global step 2781:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:14-INFO-Epoch 9, Batch 226, Global step 2782:
20-03-23 19:14-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:14-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:14-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 227, Global step 2783:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 228, Global step 2784:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 229, Global step 2785:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 230, Global step 2786:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 231, Global step 2787:
20-03-23 19:15-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 232, Global step 2788:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 233, Global step 2789:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 234, Global step 2790:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 235, Global step 2791:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 236, Global step 2792:
20-03-23 19:15-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 237, Global step 2793:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 238, Global step 2794:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 239, Global step 2795:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 240, Global step 2796:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 241, Global step 2797:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 242, Global step 2798:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 243, Global step 2799:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 244, Global step 2800:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 245, Global step 2801:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 246, Global step 2802:
20-03-23 19:15-INFO-training batch loss: 0.0006; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 247, Global step 2803:
20-03-23 19:15-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 248, Global step 2804:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 249, Global step 2805:
20-03-23 19:15-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 250, Global step 2806:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 251, Global step 2807:
20-03-23 19:15-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 252, Global step 2808:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:15-INFO-Epoch 9, Batch 253, Global step 2809:
20-03-23 19:15-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:15-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:15-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 254, Global step 2810:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 255, Global step 2811:
20-03-23 19:16-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 256, Global step 2812:
20-03-23 19:16-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 257, Global step 2813:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 258, Global step 2814:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 259, Global step 2815:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 260, Global step 2816:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 261, Global step 2817:
20-03-23 19:16-INFO-training batch loss: 0.0004; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 262, Global step 2818:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 263, Global step 2819:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 264, Global step 2820:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 265, Global step 2821:
20-03-23 19:16-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 266, Global step 2822:
20-03-23 19:16-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 267, Global step 2823:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 268, Global step 2824:
20-03-23 19:16-INFO-training batch loss: 0.0000; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 269, Global step 2825:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 270, Global step 2826:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 271, Global step 2827:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 272, Global step 2828:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 273, Global step 2829:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 274, Global step 2830:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 275, Global step 2831:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 276, Global step 2832:
20-03-23 19:16-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 277, Global step 2833:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 278, Global step 2834:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:16-INFO-Epoch 9, Batch 279, Global step 2835:
20-03-23 19:16-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:16-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:16-INFO-
20-03-23 19:17-INFO-Epoch 9, Batch 280, Global step 2836:
20-03-23 19:17-INFO-training batch loss: 0.0003; avg_loss: 0.0002
20-03-23 19:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:17-INFO-
20-03-23 19:17-INFO-Epoch 9, Batch 281, Global step 2837:
20-03-23 19:17-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:17-INFO-
20-03-23 19:17-INFO-Epoch 9, Batch 282, Global step 2838:
20-03-23 19:17-INFO-training batch loss: 0.0002; avg_loss: 0.0002
20-03-23 19:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:17-INFO-
20-03-23 19:17-INFO-Epoch 9, Batch 283, Global step 2839:
20-03-23 19:17-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:17-INFO-
20-03-23 19:17-INFO-Epoch 9, Batch 284, Global step 2840:
20-03-23 19:17-INFO-training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 19:17-INFO-
20-03-23 19:17-INFO-Epoch 9, training batch loss: 0.0001; avg_loss: 0.0002
20-03-23 19:17-INFO-Epoch 9, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 19:17-INFO-
20-03-23 19:17-INFO-Epoch 9, evaluating batch loss: 0.4829; avg_loss: 0.1927
20-03-23 19:17-INFO-Epoch 9, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9554
20-03-23 19:17-INFO-
