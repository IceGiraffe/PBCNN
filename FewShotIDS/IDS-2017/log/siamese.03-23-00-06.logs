20-03-23 00:06-INFO-{'session_length': 24, 'height': 32, 'width': 32, 'num_labels': 8, 'learning_rate': 0.005, 'filter_sizes': [3, 4, 5, 6], 'num_filters': 64, 'filter_sizes_hierarchical': [3, 4, 5], 'num_fitlers_hierarchical': 64, 'is_train': True, 'early_stop': True, 'is_tuning': False}
20-03-23 00:06-WARNING-From ../utils.py:127: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

20-03-23 00:06-WARNING-From ../model/train.py:105: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

20-03-23 00:06-WARNING-From ../model/siamese_network.py:33: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

20-03-23 00:06-WARNING-From ../model/siamese_network.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

20-03-23 00:06-WARNING-From ../model/siamese_network.py:41: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

20-03-23 00:06-WARNING-From ../model/utils/utils.py:26: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206759aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206759aad0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-From ../model/utils/utils.py:45: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling1D instead.
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206759add0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206759add0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20675a1c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20675a1c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20675669d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20675669d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20675a1d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20675a1d50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2067566a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2067566a10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20675a1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20675a1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206697eb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206697eb10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-From ../model/utils/modules.py:205: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
20-03-23 00:06-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f20d604fcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f20d604fcd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066936c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066936c10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20668b8550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20668b8550>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066992ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066992ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2066889e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2066889e90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066936650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066936650>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2066988a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2066988a50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-From ../model/utils/modules.py:240: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
20-03-23 00:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2066931b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2066931b10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-From ../model/utils/modules.py:242: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
20-03-23 00:06-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f20668b8d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f20668b8d50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-From ../model/utils/modules.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206687e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206687e3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206685a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206685a510>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20667f4c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f20667f4c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2067589590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2067589590>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206693ea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206693ea50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20669520d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20669520d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066992e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066992e90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20668c8c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f20668c8c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f2066992e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f2066992e90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066795e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2066795e90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206677d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206677d1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2067589810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f2067589810>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2067589650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f2067589650>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206678c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f206678c550>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206678c390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f206678c390>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f20667d5050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f20667d5050>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f2067512f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f2067512f10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2066781390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2066781390>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f20675a1b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f20675a1b50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 00:06-WARNING-From ../model/base_model.py:132: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

20-03-23 00:06-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20-03-23 00:06-WARNING-From ../model/train.py:113: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

20-03-23 00:06-INFO-Epoch 0, Batch 1, Global step 1:
20-03-23 00:06-INFO-training batch loss: 4.2011; avg_loss: 4.2011
20-03-23 00:06-INFO-training batch acc: 0.5078; avg_acc: 0.5078
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 2, Global step 2:
20-03-23 00:06-INFO-training batch loss: 12.7916; avg_loss: 8.4964
20-03-23 00:06-INFO-training batch acc: 0.5625; avg_acc: 0.5352
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 3, Global step 3:
20-03-23 00:06-INFO-training batch loss: 4.3648; avg_loss: 7.1192
20-03-23 00:06-INFO-training batch acc: 0.6250; avg_acc: 0.5651
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 4, Global step 4:
20-03-23 00:06-INFO-training batch loss: 3.9869; avg_loss: 6.3361
20-03-23 00:06-INFO-training batch acc: 0.5859; avg_acc: 0.5703
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 5, Global step 5:
20-03-23 00:06-INFO-training batch loss: 2.0009; avg_loss: 5.4691
20-03-23 00:06-INFO-training batch acc: 0.5234; avg_acc: 0.5609
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 6, Global step 6:
20-03-23 00:06-INFO-training batch loss: 1.7830; avg_loss: 4.8547
20-03-23 00:06-INFO-training batch acc: 0.6328; avg_acc: 0.5729
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 7, Global step 7:
20-03-23 00:06-INFO-training batch loss: 1.1530; avg_loss: 4.3259
20-03-23 00:06-INFO-training batch acc: 0.5859; avg_acc: 0.5748
20-03-23 00:06-INFO-
20-03-23 00:06-INFO-Epoch 0, Batch 8, Global step 8:
20-03-23 00:06-INFO-training batch loss: 1.0376; avg_loss: 3.9149
20-03-23 00:06-INFO-training batch acc: 0.6250; avg_acc: 0.5811
20-03-23 00:06-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 9, Global step 9:
20-03-23 00:07-INFO-training batch loss: 1.0316; avg_loss: 3.5945
20-03-23 00:07-INFO-training batch acc: 0.5312; avg_acc: 0.5755
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 10, Global step 10:
20-03-23 00:07-INFO-training batch loss: 0.9676; avg_loss: 3.3318
20-03-23 00:07-INFO-training batch acc: 0.6094; avg_acc: 0.5789
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 11, Global step 11:
20-03-23 00:07-INFO-training batch loss: 0.8690; avg_loss: 3.1079
20-03-23 00:07-INFO-training batch acc: 0.6875; avg_acc: 0.5888
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 12, Global step 12:
20-03-23 00:07-INFO-training batch loss: 0.8255; avg_loss: 2.9177
20-03-23 00:07-INFO-training batch acc: 0.6094; avg_acc: 0.5905
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 13, Global step 13:
20-03-23 00:07-INFO-training batch loss: 0.8279; avg_loss: 2.7570
20-03-23 00:07-INFO-training batch acc: 0.5703; avg_acc: 0.5889
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 14, Global step 14:
20-03-23 00:07-INFO-training batch loss: 0.9220; avg_loss: 2.6259
20-03-23 00:07-INFO-training batch acc: 0.6250; avg_acc: 0.5915
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 15, Global step 15:
20-03-23 00:07-INFO-training batch loss: 0.7015; avg_loss: 2.4976
20-03-23 00:07-INFO-training batch acc: 0.6406; avg_acc: 0.5948
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 16, Global step 16:
20-03-23 00:07-INFO-training batch loss: 0.9593; avg_loss: 2.4015
20-03-23 00:07-INFO-training batch acc: 0.6172; avg_acc: 0.5962
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 17, Global step 17:
20-03-23 00:07-INFO-training batch loss: 0.5634; avg_loss: 2.2933
20-03-23 00:07-INFO-training batch acc: 0.6250; avg_acc: 0.5979
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 18, Global step 18:
20-03-23 00:07-INFO-training batch loss: 0.7600; avg_loss: 2.2082
20-03-23 00:07-INFO-training batch acc: 0.6328; avg_acc: 0.5998
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 19, Global step 19:
20-03-23 00:07-INFO-training batch loss: 0.9254; avg_loss: 2.1406
20-03-23 00:07-INFO-training batch acc: 0.5781; avg_acc: 0.5987
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 20, Global step 20:
20-03-23 00:07-INFO-training batch loss: 0.6049; avg_loss: 2.0639
20-03-23 00:07-INFO-training batch acc: 0.6406; avg_acc: 0.6008
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 21, Global step 21:
20-03-23 00:07-INFO-training batch loss: 0.6306; avg_loss: 1.9956
20-03-23 00:07-INFO-training batch acc: 0.6016; avg_acc: 0.6008
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 22, Global step 22:
20-03-23 00:07-INFO-training batch loss: 0.6740; avg_loss: 1.9355
20-03-23 00:07-INFO-training batch acc: 0.5625; avg_acc: 0.5991
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 23, Global step 23:
20-03-23 00:07-INFO-training batch loss: 0.6458; avg_loss: 1.8795
20-03-23 00:07-INFO-training batch acc: 0.6094; avg_acc: 0.5995
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 24, Global step 24:
20-03-23 00:07-INFO-training batch loss: 0.5034; avg_loss: 1.8221
20-03-23 00:07-INFO-training batch acc: 0.6641; avg_acc: 0.6022
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 25, Global step 25:
20-03-23 00:07-INFO-training batch loss: 0.5380; avg_loss: 1.7708
20-03-23 00:07-INFO-training batch acc: 0.7031; avg_acc: 0.6062
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 26, Global step 26:
20-03-23 00:07-INFO-training batch loss: 0.4553; avg_loss: 1.7202
20-03-23 00:07-INFO-training batch acc: 0.7109; avg_acc: 0.6103
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 27, Global step 27:
20-03-23 00:07-INFO-training batch loss: 0.8269; avg_loss: 1.6871
20-03-23 00:07-INFO-training batch acc: 0.7109; avg_acc: 0.6140
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 28, Global step 28:
20-03-23 00:07-INFO-training batch loss: 0.6192; avg_loss: 1.6489
20-03-23 00:07-INFO-training batch acc: 0.5859; avg_acc: 0.6130
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 29, Global step 29:
20-03-23 00:07-INFO-training batch loss: 0.5932; avg_loss: 1.6125
20-03-23 00:07-INFO-training batch acc: 0.6328; avg_acc: 0.6137
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 30, Global step 30:
20-03-23 00:07-INFO-training batch loss: 0.5899; avg_loss: 1.5784
20-03-23 00:07-INFO-training batch acc: 0.6562; avg_acc: 0.6151
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 31, Global step 31:
20-03-23 00:07-INFO-training batch loss: 0.5026; avg_loss: 1.5437
20-03-23 00:07-INFO-training batch acc: 0.6484; avg_acc: 0.6162
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 32, Global step 32:
20-03-23 00:07-INFO-training batch loss: 0.4865; avg_loss: 1.5107
20-03-23 00:07-INFO-training batch acc: 0.6875; avg_acc: 0.6184
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 33, Global step 33:
20-03-23 00:07-INFO-training batch loss: 0.5777; avg_loss: 1.4824
20-03-23 00:07-INFO-training batch acc: 0.6250; avg_acc: 0.6186
20-03-23 00:07-INFO-
20-03-23 00:07-INFO-Epoch 0, Batch 34, Global step 34:
20-03-23 00:07-INFO-training batch loss: 0.6087; avg_loss: 1.4567
20-03-23 00:07-INFO-training batch acc: 0.6328; avg_acc: 0.6190
20-03-23 00:07-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 35, Global step 35:
20-03-23 00:08-INFO-training batch loss: 0.5498; avg_loss: 1.4308
20-03-23 00:08-INFO-training batch acc: 0.6484; avg_acc: 0.6199
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 36, Global step 36:
20-03-23 00:08-INFO-training batch loss: 0.5494; avg_loss: 1.4063
20-03-23 00:08-INFO-training batch acc: 0.6250; avg_acc: 0.6200
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 37, Global step 37:
20-03-23 00:08-INFO-training batch loss: 0.6731; avg_loss: 1.3865
20-03-23 00:08-INFO-training batch acc: 0.6172; avg_acc: 0.6199
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 38, Global step 38:
20-03-23 00:08-INFO-training batch loss: 0.5388; avg_loss: 1.3642
20-03-23 00:08-INFO-training batch acc: 0.6172; avg_acc: 0.6199
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 39, Global step 39:
20-03-23 00:08-INFO-training batch loss: 0.5706; avg_loss: 1.3439
20-03-23 00:08-INFO-training batch acc: 0.6797; avg_acc: 0.6214
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 40, Global step 40:
20-03-23 00:08-INFO-training batch loss: 0.5405; avg_loss: 1.3238
20-03-23 00:08-INFO-training batch acc: 0.6953; avg_acc: 0.6232
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 41, Global step 41:
20-03-23 00:08-INFO-training batch loss: 0.6063; avg_loss: 1.3063
20-03-23 00:08-INFO-training batch acc: 0.6094; avg_acc: 0.6229
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 42, Global step 42:
20-03-23 00:08-INFO-training batch loss: 0.5430; avg_loss: 1.2881
20-03-23 00:08-INFO-training batch acc: 0.6094; avg_acc: 0.6226
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 43, Global step 43:
20-03-23 00:08-INFO-training batch loss: 0.5918; avg_loss: 1.2719
20-03-23 00:08-INFO-training batch acc: 0.6328; avg_acc: 0.6228
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 44, Global step 44:
20-03-23 00:08-INFO-training batch loss: 0.5936; avg_loss: 1.2565
20-03-23 00:08-INFO-training batch acc: 0.6328; avg_acc: 0.6230
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 45, Global step 45:
20-03-23 00:08-INFO-training batch loss: 0.5370; avg_loss: 1.2405
20-03-23 00:08-INFO-training batch acc: 0.6406; avg_acc: 0.6234
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 46, Global step 46:
20-03-23 00:08-INFO-training batch loss: 0.5657; avg_loss: 1.2258
20-03-23 00:08-INFO-training batch acc: 0.7656; avg_acc: 0.6265
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 47, Global step 47:
20-03-23 00:08-INFO-training batch loss: 0.5229; avg_loss: 1.2109
20-03-23 00:08-INFO-training batch acc: 0.6719; avg_acc: 0.6275
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 48, Global step 48:
20-03-23 00:08-INFO-training batch loss: 0.5143; avg_loss: 1.1964
20-03-23 00:08-INFO-training batch acc: 0.6719; avg_acc: 0.6284
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 49, Global step 49:
20-03-23 00:08-INFO-training batch loss: 0.5684; avg_loss: 1.1835
20-03-23 00:08-INFO-training batch acc: 0.7109; avg_acc: 0.6301
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 50, Global step 50:
20-03-23 00:08-INFO-training batch loss: 0.5979; avg_loss: 1.1718
20-03-23 00:08-INFO-training batch acc: 0.6484; avg_acc: 0.6305
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 51, Global step 51:
20-03-23 00:08-INFO-training batch loss: 0.5253; avg_loss: 1.1592
20-03-23 00:08-INFO-training batch acc: 0.6719; avg_acc: 0.6313
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 52, Global step 52:
20-03-23 00:08-INFO-training batch loss: 0.5969; avg_loss: 1.1483
20-03-23 00:08-INFO-training batch acc: 0.6406; avg_acc: 0.6315
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 53, Global step 53:
20-03-23 00:08-INFO-training batch loss: 0.4868; avg_loss: 1.1359
20-03-23 00:08-INFO-training batch acc: 0.7578; avg_acc: 0.6338
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 54, Global step 54:
20-03-23 00:08-INFO-training batch loss: 0.5102; avg_loss: 1.1243
20-03-23 00:08-INFO-training batch acc: 0.7344; avg_acc: 0.6357
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 55, Global step 55:
20-03-23 00:08-INFO-training batch loss: 0.5178; avg_loss: 1.1132
20-03-23 00:08-INFO-training batch acc: 0.6875; avg_acc: 0.6366
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 56, Global step 56:
20-03-23 00:08-INFO-training batch loss: 0.4346; avg_loss: 1.1011
20-03-23 00:08-INFO-training batch acc: 0.7656; avg_acc: 0.6390
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 57, Global step 57:
20-03-23 00:08-INFO-training batch loss: 0.5383; avg_loss: 1.0913
20-03-23 00:08-INFO-training batch acc: 0.6250; avg_acc: 0.6387
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 58, Global step 58:
20-03-23 00:08-INFO-training batch loss: 0.5483; avg_loss: 1.0819
20-03-23 00:08-INFO-training batch acc: 0.6953; avg_acc: 0.6397
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 59, Global step 59:
20-03-23 00:08-INFO-training batch loss: 0.5260; avg_loss: 1.0725
20-03-23 00:08-INFO-training batch acc: 0.7812; avg_acc: 0.6421
20-03-23 00:08-INFO-
20-03-23 00:08-INFO-Epoch 0, Batch 60, Global step 60:
20-03-23 00:08-INFO-training batch loss: 0.4499; avg_loss: 1.0621
20-03-23 00:08-INFO-training batch acc: 0.7891; avg_acc: 0.6445
20-03-23 00:08-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 61, Global step 61:
20-03-23 00:09-INFO-training batch loss: 0.4834; avg_loss: 1.0526
20-03-23 00:09-INFO-training batch acc: 0.7188; avg_acc: 0.6457
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 62, Global step 62:
20-03-23 00:09-INFO-training batch loss: 0.4655; avg_loss: 1.0431
20-03-23 00:09-INFO-training batch acc: 0.7500; avg_acc: 0.6474
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 63, Global step 63:
20-03-23 00:09-INFO-training batch loss: 0.4512; avg_loss: 1.0337
20-03-23 00:09-INFO-training batch acc: 0.7422; avg_acc: 0.6489
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 64, Global step 64:
20-03-23 00:09-INFO-training batch loss: 0.5134; avg_loss: 1.0256
20-03-23 00:09-INFO-training batch acc: 0.7344; avg_acc: 0.6503
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 65, Global step 65:
20-03-23 00:09-INFO-training batch loss: 0.4809; avg_loss: 1.0172
20-03-23 00:09-INFO-training batch acc: 0.7500; avg_acc: 0.6518
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 66, Global step 66:
20-03-23 00:09-INFO-training batch loss: 0.4491; avg_loss: 1.0086
20-03-23 00:09-INFO-training batch acc: 0.7500; avg_acc: 0.6533
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 67, Global step 67:
20-03-23 00:09-INFO-training batch loss: 0.5252; avg_loss: 1.0014
20-03-23 00:09-INFO-training batch acc: 0.7500; avg_acc: 0.6547
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 68, Global step 68:
20-03-23 00:09-INFO-training batch loss: 0.4186; avg_loss: 0.9928
20-03-23 00:09-INFO-training batch acc: 0.7891; avg_acc: 0.6567
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 69, Global step 69:
20-03-23 00:09-INFO-training batch loss: 0.4565; avg_loss: 0.9851
20-03-23 00:09-INFO-training batch acc: 0.8359; avg_acc: 0.6593
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 70, Global step 70:
20-03-23 00:09-INFO-training batch loss: 0.4231; avg_loss: 0.9770
20-03-23 00:09-INFO-training batch acc: 0.7500; avg_acc: 0.6606
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 71, Global step 71:
20-03-23 00:09-INFO-training batch loss: 0.4290; avg_loss: 0.9693
20-03-23 00:09-INFO-training batch acc: 0.7578; avg_acc: 0.6620
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 72, Global step 72:
20-03-23 00:09-INFO-training batch loss: 0.4614; avg_loss: 0.9623
20-03-23 00:09-INFO-training batch acc: 0.6953; avg_acc: 0.6624
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 73, Global step 73:
20-03-23 00:09-INFO-training batch loss: 0.4810; avg_loss: 0.9557
20-03-23 00:09-INFO-training batch acc: 0.7109; avg_acc: 0.6631
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 74, Global step 74:
20-03-23 00:09-INFO-training batch loss: 0.4439; avg_loss: 0.9488
20-03-23 00:09-INFO-training batch acc: 0.7656; avg_acc: 0.6645
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 75, Global step 75:
20-03-23 00:09-INFO-training batch loss: 0.4249; avg_loss: 0.9418
20-03-23 00:09-INFO-training batch acc: 0.7344; avg_acc: 0.6654
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 76, Global step 76:
20-03-23 00:09-INFO-training batch loss: 0.3264; avg_loss: 0.9337
20-03-23 00:09-INFO-training batch acc: 0.8438; avg_acc: 0.6678
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 77, Global step 77:
20-03-23 00:09-INFO-training batch loss: 0.5142; avg_loss: 0.9282
20-03-23 00:09-INFO-training batch acc: 0.7656; avg_acc: 0.6690
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 78, Global step 78:
20-03-23 00:09-INFO-training batch loss: 0.4762; avg_loss: 0.9224
20-03-23 00:09-INFO-training batch acc: 0.7969; avg_acc: 0.6707
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 79, Global step 79:
20-03-23 00:09-INFO-training batch loss: 0.3575; avg_loss: 0.9153
20-03-23 00:09-INFO-training batch acc: 0.8672; avg_acc: 0.6732
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 80, Global step 80:
20-03-23 00:09-INFO-training batch loss: 0.4105; avg_loss: 0.9090
20-03-23 00:09-INFO-training batch acc: 0.8359; avg_acc: 0.6752
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 81, Global step 81:
20-03-23 00:09-INFO-training batch loss: 0.4000; avg_loss: 0.9027
20-03-23 00:09-INFO-training batch acc: 0.8672; avg_acc: 0.6776
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 82, Global step 82:
20-03-23 00:09-INFO-training batch loss: 0.3602; avg_loss: 0.8961
20-03-23 00:09-INFO-training batch acc: 0.8359; avg_acc: 0.6795
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 83, Global step 83:
20-03-23 00:09-INFO-training batch loss: 0.3145; avg_loss: 0.8891
20-03-23 00:09-INFO-training batch acc: 0.9062; avg_acc: 0.6822
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 84, Global step 84:
20-03-23 00:09-INFO-training batch loss: 0.3383; avg_loss: 0.8825
20-03-23 00:09-INFO-training batch acc: 0.8672; avg_acc: 0.6844
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 85, Global step 85:
20-03-23 00:09-INFO-training batch loss: 0.2580; avg_loss: 0.8752
20-03-23 00:09-INFO-training batch acc: 0.9219; avg_acc: 0.6872
20-03-23 00:09-INFO-
20-03-23 00:09-INFO-Epoch 0, Batch 86, Global step 86:
20-03-23 00:09-INFO-training batch loss: 0.3413; avg_loss: 0.8690
20-03-23 00:09-INFO-training batch acc: 0.8750; avg_acc: 0.6894
20-03-23 00:09-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 87, Global step 87:
20-03-23 00:10-INFO-training batch loss: 0.3497; avg_loss: 0.8630
20-03-23 00:10-INFO-training batch acc: 0.8906; avg_acc: 0.6917
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 88, Global step 88:
20-03-23 00:10-INFO-training batch loss: 0.3483; avg_loss: 0.8571
20-03-23 00:10-INFO-training batch acc: 0.9062; avg_acc: 0.6942
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 89, Global step 89:
20-03-23 00:10-INFO-training batch loss: 0.3446; avg_loss: 0.8514
20-03-23 00:10-INFO-training batch acc: 0.9219; avg_acc: 0.6967
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 90, Global step 90:
20-03-23 00:10-INFO-training batch loss: 0.2960; avg_loss: 0.8452
20-03-23 00:10-INFO-training batch acc: 0.9062; avg_acc: 0.6990
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 91, Global step 91:
20-03-23 00:10-INFO-training batch loss: 0.3472; avg_loss: 0.8397
20-03-23 00:10-INFO-training batch acc: 0.9062; avg_acc: 0.7013
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 92, Global step 92:
20-03-23 00:10-INFO-training batch loss: 0.2727; avg_loss: 0.8336
20-03-23 00:10-INFO-training batch acc: 0.9297; avg_acc: 0.7038
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 93, Global step 93:
20-03-23 00:10-INFO-training batch loss: 0.2351; avg_loss: 0.8271
20-03-23 00:10-INFO-training batch acc: 0.9297; avg_acc: 0.7062
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 94, Global step 94:
20-03-23 00:10-INFO-training batch loss: 0.2320; avg_loss: 0.8208
20-03-23 00:10-INFO-training batch acc: 0.9375; avg_acc: 0.7087
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 95, Global step 95:
20-03-23 00:10-INFO-training batch loss: 0.2283; avg_loss: 0.8146
20-03-23 00:10-INFO-training batch acc: 0.8984; avg_acc: 0.7107
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 96, Global step 96:
20-03-23 00:10-INFO-training batch loss: 0.2385; avg_loss: 0.8086
20-03-23 00:10-INFO-training batch acc: 0.9297; avg_acc: 0.7130
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 97, Global step 97:
20-03-23 00:10-INFO-training batch loss: 0.1904; avg_loss: 0.8022
20-03-23 00:10-INFO-training batch acc: 0.9531; avg_acc: 0.7154
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 98, Global step 98:
20-03-23 00:10-INFO-training batch loss: 0.2739; avg_loss: 0.7968
20-03-23 00:10-INFO-training batch acc: 0.9219; avg_acc: 0.7176
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 99, Global step 99:
20-03-23 00:10-INFO-training batch loss: 0.2478; avg_loss: 0.7913
20-03-23 00:10-INFO-training batch acc: 0.9375; avg_acc: 0.7198
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 100, Global step 100:
20-03-23 00:10-INFO-training batch loss: 0.2086; avg_loss: 0.7854
20-03-23 00:10-INFO-training batch acc: 0.9453; avg_acc: 0.7220
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 101, Global step 101:
20-03-23 00:10-INFO-training batch loss: 0.1229; avg_loss: 0.7789
20-03-23 00:10-INFO-training batch acc: 0.9922; avg_acc: 0.7247
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 102, Global step 102:
20-03-23 00:10-INFO-training batch loss: 0.2429; avg_loss: 0.7736
20-03-23 00:10-INFO-training batch acc: 0.9453; avg_acc: 0.7269
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 103, Global step 103:
20-03-23 00:10-INFO-training batch loss: 0.1753; avg_loss: 0.7678
20-03-23 00:10-INFO-training batch acc: 0.9844; avg_acc: 0.7294
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 104, Global step 104:
20-03-23 00:10-INFO-training batch loss: 0.2561; avg_loss: 0.7629
20-03-23 00:10-INFO-training batch acc: 0.9531; avg_acc: 0.7315
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 105, Global step 105:
20-03-23 00:10-INFO-training batch loss: 0.2271; avg_loss: 0.7578
20-03-23 00:10-INFO-training batch acc: 0.9531; avg_acc: 0.7336
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 106, Global step 106:
20-03-23 00:10-INFO-training batch loss: 0.1747; avg_loss: 0.7523
20-03-23 00:10-INFO-training batch acc: 0.9531; avg_acc: 0.7357
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 107, Global step 107:
20-03-23 00:10-INFO-training batch loss: 0.1066; avg_loss: 0.7462
20-03-23 00:10-INFO-training batch acc: 0.9688; avg_acc: 0.7379
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 108, Global step 108:
20-03-23 00:10-INFO-training batch loss: 0.3195; avg_loss: 0.7423
20-03-23 00:10-INFO-training batch acc: 0.9219; avg_acc: 0.7396
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 109, Global step 109:
20-03-23 00:10-INFO-training batch loss: 0.0826; avg_loss: 0.7362
20-03-23 00:10-INFO-training batch acc: 0.9844; avg_acc: 0.7418
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 110, Global step 110:
20-03-23 00:10-INFO-training batch loss: 0.2607; avg_loss: 0.7319
20-03-23 00:10-INFO-training batch acc: 0.9375; avg_acc: 0.7436
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 111, Global step 111:
20-03-23 00:10-INFO-training batch loss: 0.0973; avg_loss: 0.7262
20-03-23 00:10-INFO-training batch acc: 0.9688; avg_acc: 0.7456
20-03-23 00:10-INFO-
20-03-23 00:10-INFO-Epoch 0, Batch 112, Global step 112:
20-03-23 00:10-INFO-training batch loss: 0.2434; avg_loss: 0.7219
20-03-23 00:10-INFO-training batch acc: 0.9219; avg_acc: 0.7472
20-03-23 00:10-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 113, Global step 113:
20-03-23 00:11-INFO-training batch loss: 0.2159; avg_loss: 0.7174
20-03-23 00:11-INFO-training batch acc: 0.9688; avg_acc: 0.7492
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 114, Global step 114:
20-03-23 00:11-INFO-training batch loss: 0.1514; avg_loss: 0.7125
20-03-23 00:11-INFO-training batch acc: 0.9766; avg_acc: 0.7512
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 115, Global step 115:
20-03-23 00:11-INFO-training batch loss: 0.2106; avg_loss: 0.7081
20-03-23 00:11-INFO-training batch acc: 0.9141; avg_acc: 0.7526
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 116, Global step 116:
20-03-23 00:11-INFO-training batch loss: 0.1939; avg_loss: 0.7037
20-03-23 00:11-INFO-training batch acc: 0.9609; avg_acc: 0.7544
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 117, Global step 117:
20-03-23 00:11-INFO-training batch loss: 0.3037; avg_loss: 0.7002
20-03-23 00:11-INFO-training batch acc: 0.9297; avg_acc: 0.7559
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 118, Global step 118:
20-03-23 00:11-INFO-training batch loss: 0.1553; avg_loss: 0.6956
20-03-23 00:11-INFO-training batch acc: 0.9766; avg_acc: 0.7577
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 119, Global step 119:
20-03-23 00:11-INFO-training batch loss: 0.2362; avg_loss: 0.6918
20-03-23 00:11-INFO-training batch acc: 0.9375; avg_acc: 0.7593
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 120, Global step 120:
20-03-23 00:11-INFO-training batch loss: 0.1597; avg_loss: 0.6873
20-03-23 00:11-INFO-training batch acc: 0.9688; avg_acc: 0.7610
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 121, Global step 121:
20-03-23 00:11-INFO-training batch loss: 0.1294; avg_loss: 0.6827
20-03-23 00:11-INFO-training batch acc: 0.9844; avg_acc: 0.7628
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 122, Global step 122:
20-03-23 00:11-INFO-training batch loss: 0.1953; avg_loss: 0.6787
20-03-23 00:11-INFO-training batch acc: 0.9531; avg_acc: 0.7644
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 123, Global step 123:
20-03-23 00:11-INFO-training batch loss: 0.0896; avg_loss: 0.6739
20-03-23 00:11-INFO-training batch acc: 0.9844; avg_acc: 0.7662
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 124, Global step 124:
20-03-23 00:11-INFO-training batch loss: 0.1635; avg_loss: 0.6698
20-03-23 00:11-INFO-training batch acc: 0.9531; avg_acc: 0.7677
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 125, Global step 125:
20-03-23 00:11-INFO-training batch loss: 0.1437; avg_loss: 0.6656
20-03-23 00:11-INFO-training batch acc: 0.9609; avg_acc: 0.7692
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 126, Global step 126:
20-03-23 00:11-INFO-training batch loss: 0.2707; avg_loss: 0.6625
20-03-23 00:11-INFO-training batch acc: 0.9375; avg_acc: 0.7706
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 127, Global step 127:
20-03-23 00:11-INFO-training batch loss: 0.2195; avg_loss: 0.6590
20-03-23 00:11-INFO-training batch acc: 0.9453; avg_acc: 0.7720
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 128, Global step 128:
20-03-23 00:11-INFO-training batch loss: 0.2196; avg_loss: 0.6555
20-03-23 00:11-INFO-training batch acc: 0.9375; avg_acc: 0.7733
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 129, Global step 129:
20-03-23 00:11-INFO-training batch loss: 0.1789; avg_loss: 0.6519
20-03-23 00:11-INFO-training batch acc: 0.9531; avg_acc: 0.7746
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 130, Global step 130:
20-03-23 00:11-INFO-training batch loss: 0.2067; avg_loss: 0.6484
20-03-23 00:11-INFO-training batch acc: 0.9531; avg_acc: 0.7760
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 131, Global step 131:
20-03-23 00:11-INFO-training batch loss: 0.1553; avg_loss: 0.6447
20-03-23 00:11-INFO-training batch acc: 0.9609; avg_acc: 0.7774
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 132, Global step 132:
20-03-23 00:11-INFO-training batch loss: 0.1472; avg_loss: 0.6409
20-03-23 00:11-INFO-training batch acc: 0.9688; avg_acc: 0.7789
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 133, Global step 133:
20-03-23 00:11-INFO-training batch loss: 0.0791; avg_loss: 0.6367
20-03-23 00:11-INFO-training batch acc: 1.0000; avg_acc: 0.7805
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 134, Global step 134:
20-03-23 00:11-INFO-training batch loss: 0.1353; avg_loss: 0.6329
20-03-23 00:11-INFO-training batch acc: 0.9609; avg_acc: 0.7819
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 135, Global step 135:
20-03-23 00:11-INFO-training batch loss: 0.0746; avg_loss: 0.6288
20-03-23 00:11-INFO-training batch acc: 0.9844; avg_acc: 0.7834
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 136, Global step 136:
20-03-23 00:11-INFO-training batch loss: 0.1348; avg_loss: 0.6252
20-03-23 00:11-INFO-training batch acc: 0.9766; avg_acc: 0.7848
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 137, Global step 137:
20-03-23 00:11-INFO-training batch loss: 0.1167; avg_loss: 0.6215
20-03-23 00:11-INFO-training batch acc: 0.9688; avg_acc: 0.7862
20-03-23 00:11-INFO-
20-03-23 00:11-INFO-Epoch 0, Batch 138, Global step 138:
20-03-23 00:11-INFO-training batch loss: 0.1389; avg_loss: 0.6180
20-03-23 00:11-INFO-training batch acc: 0.9688; avg_acc: 0.7875
20-03-23 00:11-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 139, Global step 139:
20-03-23 00:12-INFO-training batch loss: 0.0537; avg_loss: 0.6139
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.7888
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 140, Global step 140:
20-03-23 00:12-INFO-training batch loss: 0.1850; avg_loss: 0.6108
20-03-23 00:12-INFO-training batch acc: 0.9688; avg_acc: 0.7901
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 141, Global step 141:
20-03-23 00:12-INFO-training batch loss: 0.0879; avg_loss: 0.6071
20-03-23 00:12-INFO-training batch acc: 0.9688; avg_acc: 0.7914
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 142, Global step 142:
20-03-23 00:12-INFO-training batch loss: 0.1606; avg_loss: 0.6040
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.7927
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 143, Global step 143:
20-03-23 00:12-INFO-training batch loss: 0.0971; avg_loss: 0.6004
20-03-23 00:12-INFO-training batch acc: 0.9688; avg_acc: 0.7939
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 144, Global step 144:
20-03-23 00:12-INFO-training batch loss: 0.0653; avg_loss: 0.5967
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.7952
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 145, Global step 145:
20-03-23 00:12-INFO-training batch loss: 0.1353; avg_loss: 0.5935
20-03-23 00:12-INFO-training batch acc: 0.9844; avg_acc: 0.7965
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 146, Global step 146:
20-03-23 00:12-INFO-training batch loss: 0.1360; avg_loss: 0.5904
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.7977
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 147, Global step 147:
20-03-23 00:12-INFO-training batch loss: 0.1371; avg_loss: 0.5873
20-03-23 00:12-INFO-training batch acc: 0.9531; avg_acc: 0.7988
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 148, Global step 148:
20-03-23 00:12-INFO-training batch loss: 0.1407; avg_loss: 0.5843
20-03-23 00:12-INFO-training batch acc: 0.9688; avg_acc: 0.7999
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 149, Global step 149:
20-03-23 00:12-INFO-training batch loss: 0.1043; avg_loss: 0.5811
20-03-23 00:12-INFO-training batch acc: 0.9688; avg_acc: 0.8011
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 150, Global step 150:
20-03-23 00:12-INFO-training batch loss: 0.1120; avg_loss: 0.5779
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.8022
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 151, Global step 151:
20-03-23 00:12-INFO-training batch loss: 0.0850; avg_loss: 0.5747
20-03-23 00:12-INFO-training batch acc: 0.9844; avg_acc: 0.8034
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 152, Global step 152:
20-03-23 00:12-INFO-training batch loss: 0.0731; avg_loss: 0.5714
20-03-23 00:12-INFO-training batch acc: 0.9844; avg_acc: 0.8046
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 153, Global step 153:
20-03-23 00:12-INFO-training batch loss: 0.1073; avg_loss: 0.5684
20-03-23 00:12-INFO-training batch acc: 0.9844; avg_acc: 0.8058
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 154, Global step 154:
20-03-23 00:12-INFO-training batch loss: 0.1115; avg_loss: 0.5654
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.8069
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 155, Global step 155:
20-03-23 00:12-INFO-training batch loss: 0.0973; avg_loss: 0.5624
20-03-23 00:12-INFO-training batch acc: 0.9844; avg_acc: 0.8081
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 156, Global step 156:
20-03-23 00:12-INFO-training batch loss: 0.1318; avg_loss: 0.5596
20-03-23 00:12-INFO-training batch acc: 0.9609; avg_acc: 0.8090
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 157, Global step 157:
20-03-23 00:12-INFO-training batch loss: 0.0980; avg_loss: 0.5567
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.8101
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 158, Global step 158:
20-03-23 00:12-INFO-training batch loss: 0.0645; avg_loss: 0.5536
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.8112
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 159, Global step 159:
20-03-23 00:12-INFO-training batch loss: 0.1425; avg_loss: 0.5510
20-03-23 00:12-INFO-training batch acc: 0.9375; avg_acc: 0.8120
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 160, Global step 160:
20-03-23 00:12-INFO-training batch loss: 0.0727; avg_loss: 0.5480
20-03-23 00:12-INFO-training batch acc: 0.9766; avg_acc: 0.8130
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 161, Global step 161:
20-03-23 00:12-INFO-training batch loss: 0.2011; avg_loss: 0.5458
20-03-23 00:12-INFO-training batch acc: 0.9531; avg_acc: 0.8139
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 162, Global step 162:
20-03-23 00:12-INFO-training batch loss: 0.1352; avg_loss: 0.5433
20-03-23 00:12-INFO-training batch acc: 0.9609; avg_acc: 0.8148
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 163, Global step 163:
20-03-23 00:12-INFO-training batch loss: 0.1725; avg_loss: 0.5410
20-03-23 00:12-INFO-training batch acc: 0.9609; avg_acc: 0.8157
20-03-23 00:12-INFO-
20-03-23 00:12-INFO-Epoch 0, Batch 164, Global step 164:
20-03-23 00:12-INFO-training batch loss: 0.0849; avg_loss: 0.5382
20-03-23 00:12-INFO-training batch acc: 0.9844; avg_acc: 0.8167
20-03-23 00:12-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 165, Global step 165:
20-03-23 00:13-INFO-training batch loss: 0.0811; avg_loss: 0.5355
20-03-23 00:13-INFO-training batch acc: 0.9688; avg_acc: 0.8176
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 166, Global step 166:
20-03-23 00:13-INFO-training batch loss: 0.0802; avg_loss: 0.5327
20-03-23 00:13-INFO-training batch acc: 0.9531; avg_acc: 0.8184
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 167, Global step 167:
20-03-23 00:13-INFO-training batch loss: 0.1051; avg_loss: 0.5302
20-03-23 00:13-INFO-training batch acc: 0.9609; avg_acc: 0.8193
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 168, Global step 168:
20-03-23 00:13-INFO-training batch loss: 0.1109; avg_loss: 0.5277
20-03-23 00:13-INFO-training batch acc: 0.9844; avg_acc: 0.8203
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 169, Global step 169:
20-03-23 00:13-INFO-training batch loss: 0.0932; avg_loss: 0.5251
20-03-23 00:13-INFO-training batch acc: 0.9844; avg_acc: 0.8212
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 170, Global step 170:
20-03-23 00:13-INFO-training batch loss: 0.1006; avg_loss: 0.5226
20-03-23 00:13-INFO-training batch acc: 0.9453; avg_acc: 0.8220
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 171, Global step 171:
20-03-23 00:13-INFO-training batch loss: 0.0825; avg_loss: 0.5200
20-03-23 00:13-INFO-training batch acc: 0.9922; avg_acc: 0.8230
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 172, Global step 172:
20-03-23 00:13-INFO-training batch loss: 0.0418; avg_loss: 0.5172
20-03-23 00:13-INFO-training batch acc: 1.0000; avg_acc: 0.8240
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 173, Global step 173:
20-03-23 00:13-INFO-training batch loss: 0.1185; avg_loss: 0.5149
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8249
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 174, Global step 174:
20-03-23 00:13-INFO-training batch loss: 0.1249; avg_loss: 0.5127
20-03-23 00:13-INFO-training batch acc: 0.9609; avg_acc: 0.8257
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 175, Global step 175:
20-03-23 00:13-INFO-training batch loss: 0.0748; avg_loss: 0.5102
20-03-23 00:13-INFO-training batch acc: 0.9922; avg_acc: 0.8266
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 176, Global step 176:
20-03-23 00:13-INFO-training batch loss: 0.0538; avg_loss: 0.5076
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8275
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 177, Global step 177:
20-03-23 00:13-INFO-training batch loss: 0.1893; avg_loss: 0.5058
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8283
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 178, Global step 178:
20-03-23 00:13-INFO-training batch loss: 0.1026; avg_loss: 0.5035
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8291
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 179, Global step 179:
20-03-23 00:13-INFO-training batch loss: 0.1378; avg_loss: 0.5015
20-03-23 00:13-INFO-training batch acc: 0.9844; avg_acc: 0.8300
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 180, Global step 180:
20-03-23 00:13-INFO-training batch loss: 0.0984; avg_loss: 0.4993
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8308
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 181, Global step 181:
20-03-23 00:13-INFO-training batch loss: 0.0465; avg_loss: 0.4968
20-03-23 00:13-INFO-training batch acc: 1.0000; avg_acc: 0.8318
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 182, Global step 182:
20-03-23 00:13-INFO-training batch loss: 0.0899; avg_loss: 0.4945
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8325
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 183, Global step 183:
20-03-23 00:13-INFO-training batch loss: 0.1258; avg_loss: 0.4925
20-03-23 00:13-INFO-training batch acc: 0.9688; avg_acc: 0.8333
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 184, Global step 184:
20-03-23 00:13-INFO-training batch loss: 0.0893; avg_loss: 0.4903
20-03-23 00:13-INFO-training batch acc: 0.9922; avg_acc: 0.8342
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 185, Global step 185:
20-03-23 00:13-INFO-training batch loss: 0.1117; avg_loss: 0.4883
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8349
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 186, Global step 186:
20-03-23 00:13-INFO-training batch loss: 0.1527; avg_loss: 0.4865
20-03-23 00:13-INFO-training batch acc: 0.9688; avg_acc: 0.8356
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 187, Global step 187:
20-03-23 00:13-INFO-training batch loss: 0.1615; avg_loss: 0.4847
20-03-23 00:13-INFO-training batch acc: 0.9766; avg_acc: 0.8364
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 188, Global step 188:
20-03-23 00:13-INFO-training batch loss: 0.2289; avg_loss: 0.4834
20-03-23 00:13-INFO-training batch acc: 0.9609; avg_acc: 0.8371
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 189, Global step 189:
20-03-23 00:13-INFO-training batch loss: 0.0818; avg_loss: 0.4812
20-03-23 00:13-INFO-training batch acc: 0.9844; avg_acc: 0.8378
20-03-23 00:13-INFO-
20-03-23 00:13-INFO-Epoch 0, Batch 190, Global step 190:
20-03-23 00:13-INFO-training batch loss: 0.0606; avg_loss: 0.4790
20-03-23 00:13-INFO-training batch acc: 0.9844; avg_acc: 0.8386
20-03-23 00:13-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 191, Global step 191:
20-03-23 00:14-INFO-training batch loss: 0.1510; avg_loss: 0.4773
20-03-23 00:14-INFO-training batch acc: 0.9688; avg_acc: 0.8393
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 192, Global step 192:
20-03-23 00:14-INFO-training batch loss: 0.1316; avg_loss: 0.4755
20-03-23 00:14-INFO-training batch acc: 0.9609; avg_acc: 0.8399
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 193, Global step 193:
20-03-23 00:14-INFO-training batch loss: 0.1380; avg_loss: 0.4738
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8406
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 194, Global step 194:
20-03-23 00:14-INFO-training batch loss: 0.0621; avg_loss: 0.4716
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8413
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 195, Global step 195:
20-03-23 00:14-INFO-training batch loss: 0.0789; avg_loss: 0.4696
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8421
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 196, Global step 196:
20-03-23 00:14-INFO-training batch loss: 0.1315; avg_loss: 0.4679
20-03-23 00:14-INFO-training batch acc: 0.9688; avg_acc: 0.8427
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 197, Global step 197:
20-03-23 00:14-INFO-training batch loss: 0.0373; avg_loss: 0.4657
20-03-23 00:14-INFO-training batch acc: 1.0000; avg_acc: 0.8435
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 198, Global step 198:
20-03-23 00:14-INFO-training batch loss: 0.0727; avg_loss: 0.4637
20-03-23 00:14-INFO-training batch acc: 0.9922; avg_acc: 0.8443
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 199, Global step 199:
20-03-23 00:14-INFO-training batch loss: 0.0804; avg_loss: 0.4618
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8450
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 200, Global step 200:
20-03-23 00:14-INFO-training batch loss: 0.1347; avg_loss: 0.4602
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8456
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 201, Global step 201:
20-03-23 00:14-INFO-training batch loss: 0.0674; avg_loss: 0.4582
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8463
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 202, Global step 202:
20-03-23 00:14-INFO-training batch loss: 0.0438; avg_loss: 0.4562
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8470
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 203, Global step 203:
20-03-23 00:14-INFO-training batch loss: 0.2133; avg_loss: 0.4550
20-03-23 00:14-INFO-training batch acc: 0.9531; avg_acc: 0.8475
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 204, Global step 204:
20-03-23 00:14-INFO-training batch loss: 0.0890; avg_loss: 0.4532
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8481
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 205, Global step 205:
20-03-23 00:14-INFO-training batch loss: 0.0630; avg_loss: 0.4513
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8487
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 206, Global step 206:
20-03-23 00:14-INFO-training batch loss: 0.1119; avg_loss: 0.4496
20-03-23 00:14-INFO-training batch acc: 0.9688; avg_acc: 0.8493
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 207, Global step 207:
20-03-23 00:14-INFO-training batch loss: 0.1797; avg_loss: 0.4483
20-03-23 00:14-INFO-training batch acc: 0.9609; avg_acc: 0.8499
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 208, Global step 208:
20-03-23 00:14-INFO-training batch loss: 0.0907; avg_loss: 0.4466
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8505
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 209, Global step 209:
20-03-23 00:14-INFO-training batch loss: 0.0469; avg_loss: 0.4447
20-03-23 00:14-INFO-training batch acc: 0.9922; avg_acc: 0.8512
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 210, Global step 210:
20-03-23 00:14-INFO-training batch loss: 0.1129; avg_loss: 0.4431
20-03-23 00:14-INFO-training batch acc: 0.9688; avg_acc: 0.8517
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 211, Global step 211:
20-03-23 00:14-INFO-training batch loss: 0.0851; avg_loss: 0.4414
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8523
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 212, Global step 212:
20-03-23 00:14-INFO-training batch loss: 0.1149; avg_loss: 0.4399
20-03-23 00:14-INFO-training batch acc: 0.9766; avg_acc: 0.8529
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 213, Global step 213:
20-03-23 00:14-INFO-training batch loss: 0.0567; avg_loss: 0.4381
20-03-23 00:14-INFO-training batch acc: 0.9922; avg_acc: 0.8536
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 214, Global step 214:
20-03-23 00:14-INFO-training batch loss: 0.0579; avg_loss: 0.4363
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8542
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 215, Global step 215:
20-03-23 00:14-INFO-training batch loss: 0.0714; avg_loss: 0.4346
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8548
20-03-23 00:14-INFO-
20-03-23 00:14-INFO-Epoch 0, Batch 216, Global step 216:
20-03-23 00:14-INFO-training batch loss: 0.0856; avg_loss: 0.4330
20-03-23 00:14-INFO-training batch acc: 0.9844; avg_acc: 0.8554
20-03-23 00:14-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 217, Global step 217:
20-03-23 00:15-INFO-training batch loss: 0.1880; avg_loss: 0.4318
20-03-23 00:15-INFO-training batch acc: 0.9531; avg_acc: 0.8558
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 218, Global step 218:
20-03-23 00:15-INFO-training batch loss: 0.0855; avg_loss: 0.4303
20-03-23 00:15-INFO-training batch acc: 0.9766; avg_acc: 0.8564
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 219, Global step 219:
20-03-23 00:15-INFO-training batch loss: 0.1102; avg_loss: 0.4288
20-03-23 00:15-INFO-training batch acc: 0.9688; avg_acc: 0.8569
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 220, Global step 220:
20-03-23 00:15-INFO-training batch loss: 0.1324; avg_loss: 0.4274
20-03-23 00:15-INFO-training batch acc: 0.9766; avg_acc: 0.8575
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 221, Global step 221:
20-03-23 00:15-INFO-training batch loss: 0.0734; avg_loss: 0.4258
20-03-23 00:15-INFO-training batch acc: 0.9844; avg_acc: 0.8580
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 222, Global step 222:
20-03-23 00:15-INFO-training batch loss: 0.1117; avg_loss: 0.4244
20-03-23 00:15-INFO-training batch acc: 0.9766; avg_acc: 0.8586
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 223, Global step 223:
20-03-23 00:15-INFO-training batch loss: 0.0482; avg_loss: 0.4227
20-03-23 00:15-INFO-training batch acc: 1.0000; avg_acc: 0.8592
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 224, Global step 224:
20-03-23 00:15-INFO-training batch loss: 0.0440; avg_loss: 0.4211
20-03-23 00:15-INFO-training batch acc: 1.0000; avg_acc: 0.8598
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 225, Global step 225:
20-03-23 00:15-INFO-training batch loss: 0.0703; avg_loss: 0.4195
20-03-23 00:15-INFO-training batch acc: 0.9922; avg_acc: 0.8604
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 226, Global step 226:
20-03-23 00:15-INFO-training batch loss: 0.0689; avg_loss: 0.4179
20-03-23 00:15-INFO-training batch acc: 0.9844; avg_acc: 0.8610
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 227, Global step 227:
20-03-23 00:15-INFO-training batch loss: 0.0729; avg_loss: 0.4164
20-03-23 00:15-INFO-training batch acc: 0.9922; avg_acc: 0.8615
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 228, Global step 228:
20-03-23 00:15-INFO-training batch loss: 0.1304; avg_loss: 0.4152
20-03-23 00:15-INFO-training batch acc: 0.9688; avg_acc: 0.8620
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 229, Global step 229:
20-03-23 00:15-INFO-training batch loss: 0.0579; avg_loss: 0.4136
20-03-23 00:15-INFO-training batch acc: 0.9844; avg_acc: 0.8625
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 230, Global step 230:
20-03-23 00:15-INFO-training batch loss: 0.0209; avg_loss: 0.4119
20-03-23 00:15-INFO-training batch acc: 1.0000; avg_acc: 0.8631
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 231, Global step 231:
20-03-23 00:15-INFO-training batch loss: 0.0913; avg_loss: 0.4105
20-03-23 00:15-INFO-training batch acc: 0.9766; avg_acc: 0.8636
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 232, Global step 232:
20-03-23 00:15-INFO-training batch loss: 0.1138; avg_loss: 0.4092
20-03-23 00:15-INFO-training batch acc: 0.9844; avg_acc: 0.8642
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 233, Global step 233:
20-03-23 00:15-INFO-training batch loss: 0.1592; avg_loss: 0.4082
20-03-23 00:15-INFO-training batch acc: 0.9609; avg_acc: 0.8646
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 234, Global step 234:
20-03-23 00:15-INFO-training batch loss: 0.0326; avg_loss: 0.4066
20-03-23 00:15-INFO-training batch acc: 0.9844; avg_acc: 0.8651
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 235, Global step 235:
20-03-23 00:15-INFO-training batch loss: 0.1308; avg_loss: 0.4054
20-03-23 00:15-INFO-training batch acc: 0.9688; avg_acc: 0.8655
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 236, Global step 236:
20-03-23 00:15-INFO-training batch loss: 0.1380; avg_loss: 0.4043
20-03-23 00:15-INFO-training batch acc: 0.9766; avg_acc: 0.8660
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 237, Global step 237:
20-03-23 00:15-INFO-training batch loss: 0.1008; avg_loss: 0.4030
20-03-23 00:15-INFO-training batch acc: 0.9688; avg_acc: 0.8664
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 238, Global step 238:
20-03-23 00:15-INFO-training batch loss: 0.0949; avg_loss: 0.4017
20-03-23 00:15-INFO-training batch acc: 0.9922; avg_acc: 0.8670
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 239, Global step 239:
20-03-23 00:15-INFO-training batch loss: 0.0618; avg_loss: 0.4003
20-03-23 00:15-INFO-training batch acc: 0.9922; avg_acc: 0.8675
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 240, Global step 240:
20-03-23 00:15-INFO-training batch loss: 0.0351; avg_loss: 0.3987
20-03-23 00:15-INFO-training batch acc: 1.0000; avg_acc: 0.8680
20-03-23 00:15-INFO-
20-03-23 00:15-INFO-Epoch 0, Batch 241, Global step 241:
20-03-23 00:15-INFO-training batch loss: 0.0641; avg_loss: 0.3973
20-03-23 00:15-INFO-training batch acc: 0.9844; avg_acc: 0.8685
20-03-23 00:15-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 242, Global step 242:
20-03-23 00:16-INFO-training batch loss: 0.0317; avg_loss: 0.3958
20-03-23 00:16-INFO-training batch acc: 0.9922; avg_acc: 0.8690
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 243, Global step 243:
20-03-23 00:16-INFO-training batch loss: 0.0766; avg_loss: 0.3945
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8695
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 244, Global step 244:
20-03-23 00:16-INFO-training batch loss: 0.1051; avg_loss: 0.3933
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8700
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 245, Global step 245:
20-03-23 00:16-INFO-training batch loss: 0.1629; avg_loss: 0.3924
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8704
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 246, Global step 246:
20-03-23 00:16-INFO-training batch loss: 0.0845; avg_loss: 0.3911
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8708
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 247, Global step 247:
20-03-23 00:16-INFO-training batch loss: 0.1993; avg_loss: 0.3904
20-03-23 00:16-INFO-training batch acc: 0.9766; avg_acc: 0.8712
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 248, Global step 248:
20-03-23 00:16-INFO-training batch loss: 0.1112; avg_loss: 0.3892
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8717
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 249, Global step 249:
20-03-23 00:16-INFO-training batch loss: 0.1061; avg_loss: 0.3881
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8721
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 250, Global step 250:
20-03-23 00:16-INFO-training batch loss: 0.0716; avg_loss: 0.3868
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8724
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 251, Global step 251:
20-03-23 00:16-INFO-training batch loss: 0.0429; avg_loss: 0.3855
20-03-23 00:16-INFO-training batch acc: 0.9922; avg_acc: 0.8729
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 252, Global step 252:
20-03-23 00:16-INFO-training batch loss: 0.0659; avg_loss: 0.3842
20-03-23 00:16-INFO-training batch acc: 0.9766; avg_acc: 0.8733
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 253, Global step 253:
20-03-23 00:16-INFO-training batch loss: 0.0979; avg_loss: 0.3831
20-03-23 00:16-INFO-training batch acc: 0.9766; avg_acc: 0.8737
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 254, Global step 254:
20-03-23 00:16-INFO-training batch loss: 0.0787; avg_loss: 0.3819
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8742
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 255, Global step 255:
20-03-23 00:16-INFO-training batch loss: 0.0513; avg_loss: 0.3806
20-03-23 00:16-INFO-training batch acc: 0.9922; avg_acc: 0.8746
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 256, Global step 256:
20-03-23 00:16-INFO-training batch loss: 0.1095; avg_loss: 0.3795
20-03-23 00:16-INFO-training batch acc: 0.9609; avg_acc: 0.8750
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 257, Global step 257:
20-03-23 00:16-INFO-training batch loss: 0.0360; avg_loss: 0.3782
20-03-23 00:16-INFO-training batch acc: 1.0000; avg_acc: 0.8755
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 258, Global step 258:
20-03-23 00:16-INFO-training batch loss: 0.0909; avg_loss: 0.3771
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8759
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 259, Global step 259:
20-03-23 00:16-INFO-training batch loss: 0.1021; avg_loss: 0.3760
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8763
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 260, Global step 260:
20-03-23 00:16-INFO-training batch loss: 0.0766; avg_loss: 0.3748
20-03-23 00:16-INFO-training batch acc: 0.9766; avg_acc: 0.8767
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 261, Global step 261:
20-03-23 00:16-INFO-training batch loss: 0.0758; avg_loss: 0.3737
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8771
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 262, Global step 262:
20-03-23 00:16-INFO-training batch loss: 0.0366; avg_loss: 0.3724
20-03-23 00:16-INFO-training batch acc: 0.9922; avg_acc: 0.8775
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 263, Global step 263:
20-03-23 00:16-INFO-training batch loss: 0.1211; avg_loss: 0.3715
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8779
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 264, Global step 264:
20-03-23 00:16-INFO-training batch loss: 0.1026; avg_loss: 0.3704
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8782
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 265, Global step 265:
20-03-23 00:16-INFO-training batch loss: 0.0507; avg_loss: 0.3692
20-03-23 00:16-INFO-training batch acc: 0.9844; avg_acc: 0.8786
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 266, Global step 266:
20-03-23 00:16-INFO-training batch loss: 0.0960; avg_loss: 0.3682
20-03-23 00:16-INFO-training batch acc: 0.9766; avg_acc: 0.8790
20-03-23 00:16-INFO-
20-03-23 00:16-INFO-Epoch 0, Batch 267, Global step 267:
20-03-23 00:16-INFO-training batch loss: 0.0965; avg_loss: 0.3672
20-03-23 00:16-INFO-training batch acc: 0.9688; avg_acc: 0.8793
20-03-23 00:16-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 268, Global step 268:
20-03-23 00:17-INFO-training batch loss: 0.0404; avg_loss: 0.3660
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8798
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 269, Global step 269:
20-03-23 00:17-INFO-training batch loss: 0.0646; avg_loss: 0.3649
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8801
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 270, Global step 270:
20-03-23 00:17-INFO-training batch loss: 0.0341; avg_loss: 0.3636
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8806
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 271, Global step 271:
20-03-23 00:17-INFO-training batch loss: 0.0333; avg_loss: 0.3624
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8810
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 272, Global step 272:
20-03-23 00:17-INFO-training batch loss: 0.0191; avg_loss: 0.3611
20-03-23 00:17-INFO-training batch acc: 1.0000; avg_acc: 0.8814
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 273, Global step 273:
20-03-23 00:17-INFO-training batch loss: 0.1184; avg_loss: 0.3603
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8818
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 274, Global step 274:
20-03-23 00:17-INFO-training batch loss: 0.0597; avg_loss: 0.3592
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8822
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 275, Global step 275:
20-03-23 00:17-INFO-training batch loss: 0.0309; avg_loss: 0.3580
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8826
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 276, Global step 276:
20-03-23 00:17-INFO-training batch loss: 0.0594; avg_loss: 0.3569
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8829
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 277, Global step 277:
20-03-23 00:17-INFO-training batch loss: 0.0862; avg_loss: 0.3559
20-03-23 00:17-INFO-training batch acc: 0.9688; avg_acc: 0.8832
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 278, Global step 278:
20-03-23 00:17-INFO-training batch loss: 0.0440; avg_loss: 0.3548
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8836
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 279, Global step 279:
20-03-23 00:17-INFO-training batch loss: 0.1155; avg_loss: 0.3539
20-03-23 00:17-INFO-training batch acc: 0.9766; avg_acc: 0.8840
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 280, Global step 280:
20-03-23 00:17-INFO-training batch loss: 0.0565; avg_loss: 0.3529
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8843
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 281, Global step 281:
20-03-23 00:17-INFO-training batch loss: 0.0510; avg_loss: 0.3518
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8847
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 282, Global step 282:
20-03-23 00:17-INFO-training batch loss: 0.1004; avg_loss: 0.3509
20-03-23 00:17-INFO-training batch acc: 0.9688; avg_acc: 0.8850
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 283, Global step 283:
20-03-23 00:17-INFO-training batch loss: 0.0677; avg_loss: 0.3499
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8853
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 284, Global step 284:
20-03-23 00:17-INFO-training batch loss: 0.0683; avg_loss: 0.3489
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8857
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 285, Global step 285:
20-03-23 00:17-INFO-training batch loss: 0.0773; avg_loss: 0.3480
20-03-23 00:17-INFO-training batch acc: 0.9766; avg_acc: 0.8860
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 286, Global step 286:
20-03-23 00:17-INFO-training batch loss: 0.0661; avg_loss: 0.3470
20-03-23 00:17-INFO-training batch acc: 0.9688; avg_acc: 0.8863
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 287, Global step 287:
20-03-23 00:17-INFO-training batch loss: 0.0989; avg_loss: 0.3461
20-03-23 00:17-INFO-training batch acc: 0.9688; avg_acc: 0.8866
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 288, Global step 288:
20-03-23 00:17-INFO-training batch loss: 0.0676; avg_loss: 0.3451
20-03-23 00:17-INFO-training batch acc: 0.9766; avg_acc: 0.8869
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 289, Global step 289:
20-03-23 00:17-INFO-training batch loss: 0.0472; avg_loss: 0.3441
20-03-23 00:17-INFO-training batch acc: 0.9922; avg_acc: 0.8873
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 290, Global step 290:
20-03-23 00:17-INFO-training batch loss: 0.1022; avg_loss: 0.3433
20-03-23 00:17-INFO-training batch acc: 0.9688; avg_acc: 0.8876
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 291, Global step 291:
20-03-23 00:17-INFO-training batch loss: 0.1030; avg_loss: 0.3424
20-03-23 00:17-INFO-training batch acc: 0.9609; avg_acc: 0.8878
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 292, Global step 292:
20-03-23 00:17-INFO-training batch loss: 0.0465; avg_loss: 0.3414
20-03-23 00:17-INFO-training batch acc: 0.9844; avg_acc: 0.8881
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, Batch 293, Global step 293:
20-03-23 00:17-INFO-training batch loss: 0.0244; avg_loss: 0.3403
20-03-23 00:17-INFO-training batch acc: 1.0000; avg_acc: 0.8885
20-03-23 00:17-INFO-
20-03-23 00:17-INFO-Epoch 0, training batch loss: 0.0244; avg_loss: 0.3403
20-03-23 00:17-INFO-Epoch 0, training batch accuracy: 1.0000; avg_accuracy: 0.8885
20-03-23 00:17-INFO-
20-03-23 00:18-INFO-Epoch 0, evaluating batch loss: 0.5899; avg_loss: 0.4301
20-03-23 00:18-INFO-Epoch 0, evaluating batch accuracy: 0.8571; avg_accuracy: 0.8998
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 1, Global step 294:
20-03-23 00:18-INFO-training batch loss: 0.0464; avg_loss: 0.0464
20-03-23 00:18-INFO-training batch acc: 0.9766; avg_acc: 0.9766
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 2, Global step 295:
20-03-23 00:18-INFO-training batch loss: 0.0269; avg_loss: 0.0367
20-03-23 00:18-INFO-training batch acc: 0.9922; avg_acc: 0.9844
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 3, Global step 296:
20-03-23 00:18-INFO-training batch loss: 0.0427; avg_loss: 0.0387
20-03-23 00:18-INFO-training batch acc: 0.9844; avg_acc: 0.9844
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 4, Global step 297:
20-03-23 00:18-INFO-training batch loss: 0.0723; avg_loss: 0.0471
20-03-23 00:18-INFO-training batch acc: 0.9844; avg_acc: 0.9844
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 5, Global step 298:
20-03-23 00:18-INFO-training batch loss: 0.0146; avg_loss: 0.0406
20-03-23 00:18-INFO-training batch acc: 1.0000; avg_acc: 0.9875
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 6, Global step 299:
20-03-23 00:18-INFO-training batch loss: 0.0983; avg_loss: 0.0502
20-03-23 00:18-INFO-training batch acc: 0.9766; avg_acc: 0.9857
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 7, Global step 300:
20-03-23 00:18-INFO-training batch loss: 0.0934; avg_loss: 0.0564
20-03-23 00:18-INFO-training batch acc: 0.9844; avg_acc: 0.9855
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 8, Global step 301:
20-03-23 00:18-INFO-training batch loss: 0.1512; avg_loss: 0.0682
20-03-23 00:18-INFO-training batch acc: 0.9609; avg_acc: 0.9824
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 9, Global step 302:
20-03-23 00:18-INFO-training batch loss: 0.1236; avg_loss: 0.0744
20-03-23 00:18-INFO-training batch acc: 0.9609; avg_acc: 0.9800
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 10, Global step 303:
20-03-23 00:18-INFO-training batch loss: 0.0700; avg_loss: 0.0739
20-03-23 00:18-INFO-training batch acc: 0.9766; avg_acc: 0.9797
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 11, Global step 304:
20-03-23 00:18-INFO-training batch loss: 0.1593; avg_loss: 0.0817
20-03-23 00:18-INFO-training batch acc: 0.9375; avg_acc: 0.9759
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 12, Global step 305:
20-03-23 00:18-INFO-training batch loss: 0.0563; avg_loss: 0.0796
20-03-23 00:18-INFO-training batch acc: 0.9844; avg_acc: 0.9766
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 13, Global step 306:
20-03-23 00:18-INFO-training batch loss: 0.0797; avg_loss: 0.0796
20-03-23 00:18-INFO-training batch acc: 0.9688; avg_acc: 0.9760
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 14, Global step 307:
20-03-23 00:18-INFO-training batch loss: 0.1041; avg_loss: 0.0813
20-03-23 00:18-INFO-training batch acc: 0.9688; avg_acc: 0.9754
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 15, Global step 308:
20-03-23 00:18-INFO-training batch loss: 0.0287; avg_loss: 0.0778
20-03-23 00:18-INFO-training batch acc: 0.9922; avg_acc: 0.9766
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 16, Global step 309:
20-03-23 00:18-INFO-training batch loss: 0.0358; avg_loss: 0.0752
20-03-23 00:18-INFO-training batch acc: 0.9922; avg_acc: 0.9775
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 17, Global step 310:
20-03-23 00:18-INFO-training batch loss: 0.0361; avg_loss: 0.0729
20-03-23 00:18-INFO-training batch acc: 1.0000; avg_acc: 0.9789
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 18, Global step 311:
20-03-23 00:18-INFO-training batch loss: 0.0558; avg_loss: 0.0720
20-03-23 00:18-INFO-training batch acc: 0.9922; avg_acc: 0.9796
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 19, Global step 312:
20-03-23 00:18-INFO-training batch loss: 0.0903; avg_loss: 0.0729
20-03-23 00:18-INFO-training batch acc: 0.9609; avg_acc: 0.9786
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 20, Global step 313:
20-03-23 00:18-INFO-training batch loss: 0.0264; avg_loss: 0.0706
20-03-23 00:18-INFO-training batch acc: 0.9922; avg_acc: 0.9793
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 21, Global step 314:
20-03-23 00:18-INFO-training batch loss: 0.0682; avg_loss: 0.0705
20-03-23 00:18-INFO-training batch acc: 0.9766; avg_acc: 0.9792
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 22, Global step 315:
20-03-23 00:18-INFO-training batch loss: 0.0428; avg_loss: 0.0692
20-03-23 00:18-INFO-training batch acc: 0.9844; avg_acc: 0.9794
20-03-23 00:18-INFO-
20-03-23 00:18-INFO-Epoch 1, Batch 23, Global step 316:
20-03-23 00:18-INFO-training batch loss: 0.0597; avg_loss: 0.0688
20-03-23 00:18-INFO-training batch acc: 0.9844; avg_acc: 0.9796
20-03-23 00:18-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 24, Global step 317:
20-03-23 00:19-INFO-training batch loss: 0.0625; avg_loss: 0.0685
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9801
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 25, Global step 318:
20-03-23 00:19-INFO-training batch loss: 0.0849; avg_loss: 0.0692
20-03-23 00:19-INFO-training batch acc: 0.9609; avg_acc: 0.9794
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 26, Global step 319:
20-03-23 00:19-INFO-training batch loss: 0.1256; avg_loss: 0.0714
20-03-23 00:19-INFO-training batch acc: 0.9766; avg_acc: 0.9793
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 27, Global step 320:
20-03-23 00:19-INFO-training batch loss: 0.1309; avg_loss: 0.0736
20-03-23 00:19-INFO-training batch acc: 0.9688; avg_acc: 0.9789
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 28, Global step 321:
20-03-23 00:19-INFO-training batch loss: 0.1518; avg_loss: 0.0764
20-03-23 00:19-INFO-training batch acc: 0.9609; avg_acc: 0.9782
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 29, Global step 322:
20-03-23 00:19-INFO-training batch loss: 0.0664; avg_loss: 0.0760
20-03-23 00:19-INFO-training batch acc: 0.9844; avg_acc: 0.9784
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 30, Global step 323:
20-03-23 00:19-INFO-training batch loss: 0.0780; avg_loss: 0.0761
20-03-23 00:19-INFO-training batch acc: 0.9688; avg_acc: 0.9781
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 31, Global step 324:
20-03-23 00:19-INFO-training batch loss: 0.0383; avg_loss: 0.0749
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9786
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 32, Global step 325:
20-03-23 00:19-INFO-training batch loss: 0.0792; avg_loss: 0.0750
20-03-23 00:19-INFO-training batch acc: 0.9688; avg_acc: 0.9783
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 33, Global step 326:
20-03-23 00:19-INFO-training batch loss: 0.0475; avg_loss: 0.0742
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9787
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 34, Global step 327:
20-03-23 00:19-INFO-training batch loss: 0.0469; avg_loss: 0.0734
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9791
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 35, Global step 328:
20-03-23 00:19-INFO-training batch loss: 0.0310; avg_loss: 0.0722
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9795
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 36, Global step 329:
20-03-23 00:19-INFO-training batch loss: 0.0750; avg_loss: 0.0722
20-03-23 00:19-INFO-training batch acc: 0.9766; avg_acc: 0.9794
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 37, Global step 330:
20-03-23 00:19-INFO-training batch loss: 0.1798; avg_loss: 0.0752
20-03-23 00:19-INFO-training batch acc: 0.9609; avg_acc: 0.9789
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 38, Global step 331:
20-03-23 00:19-INFO-training batch loss: 0.0347; avg_loss: 0.0741
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9792
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 39, Global step 332:
20-03-23 00:19-INFO-training batch loss: 0.0293; avg_loss: 0.0729
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9796
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 40, Global step 333:
20-03-23 00:19-INFO-training batch loss: 0.0777; avg_loss: 0.0731
20-03-23 00:19-INFO-training batch acc: 0.9766; avg_acc: 0.9795
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 41, Global step 334:
20-03-23 00:19-INFO-training batch loss: 0.0452; avg_loss: 0.0724
20-03-23 00:19-INFO-training batch acc: 0.9844; avg_acc: 0.9796
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 42, Global step 335:
20-03-23 00:19-INFO-training batch loss: 0.0158; avg_loss: 0.0710
20-03-23 00:19-INFO-training batch acc: 1.0000; avg_acc: 0.9801
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 43, Global step 336:
20-03-23 00:19-INFO-training batch loss: 0.0697; avg_loss: 0.0710
20-03-23 00:19-INFO-training batch acc: 0.9688; avg_acc: 0.9798
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 44, Global step 337:
20-03-23 00:19-INFO-training batch loss: 0.0825; avg_loss: 0.0713
20-03-23 00:19-INFO-training batch acc: 0.9688; avg_acc: 0.9796
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 45, Global step 338:
20-03-23 00:19-INFO-training batch loss: 0.0575; avg_loss: 0.0710
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9799
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 46, Global step 339:
20-03-23 00:19-INFO-training batch loss: 0.0270; avg_loss: 0.0700
20-03-23 00:19-INFO-training batch acc: 1.0000; avg_acc: 0.9803
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 47, Global step 340:
20-03-23 00:19-INFO-training batch loss: 0.0366; avg_loss: 0.0693
20-03-23 00:19-INFO-training batch acc: 0.9922; avg_acc: 0.9806
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 48, Global step 341:
20-03-23 00:19-INFO-training batch loss: 0.0176; avg_loss: 0.0682
20-03-23 00:19-INFO-training batch acc: 1.0000; avg_acc: 0.9810
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 49, Global step 342:
20-03-23 00:19-INFO-training batch loss: 0.0474; avg_loss: 0.0678
20-03-23 00:19-INFO-training batch acc: 0.9844; avg_acc: 0.9810
20-03-23 00:19-INFO-
20-03-23 00:19-INFO-Epoch 1, Batch 50, Global step 343:
20-03-23 00:19-INFO-training batch loss: 0.0204; avg_loss: 0.0668
20-03-23 00:19-INFO-training batch acc: 1.0000; avg_acc: 0.9814
20-03-23 00:19-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 51, Global step 344:
20-03-23 00:20-INFO-training batch loss: 0.0578; avg_loss: 0.0667
20-03-23 00:20-INFO-training batch acc: 0.9766; avg_acc: 0.9813
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 52, Global step 345:
20-03-23 00:20-INFO-training batch loss: 0.0492; avg_loss: 0.0663
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9814
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 53, Global step 346:
20-03-23 00:20-INFO-training batch loss: 0.0434; avg_loss: 0.0659
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9814
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 54, Global step 347:
20-03-23 00:20-INFO-training batch loss: 0.0476; avg_loss: 0.0656
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9815
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 55, Global step 348:
20-03-23 00:20-INFO-training batch loss: 0.0948; avg_loss: 0.0661
20-03-23 00:20-INFO-training batch acc: 0.9766; avg_acc: 0.9814
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 56, Global step 349:
20-03-23 00:20-INFO-training batch loss: 0.0615; avg_loss: 0.0660
20-03-23 00:20-INFO-training batch acc: 0.9688; avg_acc: 0.9812
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 57, Global step 350:
20-03-23 00:20-INFO-training batch loss: 0.0656; avg_loss: 0.0660
20-03-23 00:20-INFO-training batch acc: 0.9766; avg_acc: 0.9811
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 58, Global step 351:
20-03-23 00:20-INFO-training batch loss: 0.0316; avg_loss: 0.0654
20-03-23 00:20-INFO-training batch acc: 0.9922; avg_acc: 0.9813
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 59, Global step 352:
20-03-23 00:20-INFO-training batch loss: 0.0898; avg_loss: 0.0658
20-03-23 00:20-INFO-training batch acc: 0.9766; avg_acc: 0.9812
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 60, Global step 353:
20-03-23 00:20-INFO-training batch loss: 0.0448; avg_loss: 0.0655
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9812
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 61, Global step 354:
20-03-23 00:20-INFO-training batch loss: 0.0180; avg_loss: 0.0647
20-03-23 00:20-INFO-training batch acc: 0.9922; avg_acc: 0.9814
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 62, Global step 355:
20-03-23 00:20-INFO-training batch loss: 0.1229; avg_loss: 0.0656
20-03-23 00:20-INFO-training batch acc: 0.9297; avg_acc: 0.9806
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 63, Global step 356:
20-03-23 00:20-INFO-training batch loss: 0.0253; avg_loss: 0.0650
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9807
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 64, Global step 357:
20-03-23 00:20-INFO-training batch loss: 0.0264; avg_loss: 0.0644
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9807
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 65, Global step 358:
20-03-23 00:20-INFO-training batch loss: 0.0180; avg_loss: 0.0637
20-03-23 00:20-INFO-training batch acc: 0.9922; avg_acc: 0.9809
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 66, Global step 359:
20-03-23 00:20-INFO-training batch loss: 0.1114; avg_loss: 0.0644
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9809
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 67, Global step 360:
20-03-23 00:20-INFO-training batch loss: 0.0622; avg_loss: 0.0644
20-03-23 00:20-INFO-training batch acc: 0.9922; avg_acc: 0.9811
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 68, Global step 361:
20-03-23 00:20-INFO-training batch loss: 0.0417; avg_loss: 0.0640
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9812
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 69, Global step 362:
20-03-23 00:20-INFO-training batch loss: 0.0872; avg_loss: 0.0644
20-03-23 00:20-INFO-training batch acc: 0.9609; avg_acc: 0.9809
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 70, Global step 363:
20-03-23 00:20-INFO-training batch loss: 0.0659; avg_loss: 0.0644
20-03-23 00:20-INFO-training batch acc: 0.9609; avg_acc: 0.9806
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 71, Global step 364:
20-03-23 00:20-INFO-training batch loss: 0.0365; avg_loss: 0.0640
20-03-23 00:20-INFO-training batch acc: 0.9922; avg_acc: 0.9807
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 72, Global step 365:
20-03-23 00:20-INFO-training batch loss: 0.0679; avg_loss: 0.0640
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9808
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 73, Global step 366:
20-03-23 00:20-INFO-training batch loss: 0.0740; avg_loss: 0.0642
20-03-23 00:20-INFO-training batch acc: 0.9766; avg_acc: 0.9807
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 74, Global step 367:
20-03-23 00:20-INFO-training batch loss: 0.0715; avg_loss: 0.0643
20-03-23 00:20-INFO-training batch acc: 0.9766; avg_acc: 0.9807
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 75, Global step 368:
20-03-23 00:20-INFO-training batch loss: 0.0594; avg_loss: 0.0642
20-03-23 00:20-INFO-training batch acc: 0.9844; avg_acc: 0.9807
20-03-23 00:20-INFO-
20-03-23 00:20-INFO-Epoch 1, Batch 76, Global step 369:
20-03-23 00:20-INFO-training batch loss: 0.0492; avg_loss: 0.0640
20-03-23 00:20-INFO-training batch acc: 0.9922; avg_acc: 0.9809
20-03-23 00:20-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 77, Global step 370:
20-03-23 00:21-INFO-training batch loss: 0.0551; avg_loss: 0.0639
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9809
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 78, Global step 371:
20-03-23 00:21-INFO-training batch loss: 0.0965; avg_loss: 0.0643
20-03-23 00:21-INFO-training batch acc: 0.9688; avg_acc: 0.9808
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 79, Global step 372:
20-03-23 00:21-INFO-training batch loss: 0.0533; avg_loss: 0.0642
20-03-23 00:21-INFO-training batch acc: 0.9922; avg_acc: 0.9809
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 80, Global step 373:
20-03-23 00:21-INFO-training batch loss: 0.0763; avg_loss: 0.0643
20-03-23 00:21-INFO-training batch acc: 0.9766; avg_acc: 0.9809
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 81, Global step 374:
20-03-23 00:21-INFO-training batch loss: 0.0680; avg_loss: 0.0644
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9809
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 82, Global step 375:
20-03-23 00:21-INFO-training batch loss: 0.0087; avg_loss: 0.0637
20-03-23 00:21-INFO-training batch acc: 1.0000; avg_acc: 0.9811
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 83, Global step 376:
20-03-23 00:21-INFO-training batch loss: 0.0135; avg_loss: 0.0631
20-03-23 00:21-INFO-training batch acc: 1.0000; avg_acc: 0.9814
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 84, Global step 377:
20-03-23 00:21-INFO-training batch loss: 0.0208; avg_loss: 0.0626
20-03-23 00:21-INFO-training batch acc: 0.9922; avg_acc: 0.9815
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 85, Global step 378:
20-03-23 00:21-INFO-training batch loss: 0.0732; avg_loss: 0.0627
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9815
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 86, Global step 379:
20-03-23 00:21-INFO-training batch loss: 0.0953; avg_loss: 0.0631
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9816
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 87, Global step 380:
20-03-23 00:21-INFO-training batch loss: 0.0557; avg_loss: 0.0630
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9816
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 88, Global step 381:
20-03-23 00:21-INFO-training batch loss: 0.0836; avg_loss: 0.0632
20-03-23 00:21-INFO-training batch acc: 0.9766; avg_acc: 0.9815
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 89, Global step 382:
20-03-23 00:21-INFO-training batch loss: 0.0387; avg_loss: 0.0630
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9816
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 90, Global step 383:
20-03-23 00:21-INFO-training batch loss: 0.0432; avg_loss: 0.0628
20-03-23 00:21-INFO-training batch acc: 0.9922; avg_acc: 0.9817
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 91, Global step 384:
20-03-23 00:21-INFO-training batch loss: 0.0487; avg_loss: 0.0626
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9817
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 92, Global step 385:
20-03-23 00:21-INFO-training batch loss: 0.0151; avg_loss: 0.0621
20-03-23 00:21-INFO-training batch acc: 1.0000; avg_acc: 0.9819
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 93, Global step 386:
20-03-23 00:21-INFO-training batch loss: 0.0604; avg_loss: 0.0621
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9819
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 94, Global step 387:
20-03-23 00:21-INFO-training batch loss: 0.0485; avg_loss: 0.0619
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9820
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 95, Global step 388:
20-03-23 00:21-INFO-training batch loss: 0.0544; avg_loss: 0.0618
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9820
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 96, Global step 389:
20-03-23 00:21-INFO-training batch loss: 0.1232; avg_loss: 0.0625
20-03-23 00:21-INFO-training batch acc: 0.9766; avg_acc: 0.9819
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 97, Global step 390:
20-03-23 00:21-INFO-training batch loss: 0.0733; avg_loss: 0.0626
20-03-23 00:21-INFO-training batch acc: 0.9766; avg_acc: 0.9819
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 98, Global step 391:
20-03-23 00:21-INFO-training batch loss: 0.1490; avg_loss: 0.0635
20-03-23 00:21-INFO-training batch acc: 0.9688; avg_acc: 0.9817
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 99, Global step 392:
20-03-23 00:21-INFO-training batch loss: 0.0270; avg_loss: 0.0631
20-03-23 00:21-INFO-training batch acc: 0.9922; avg_acc: 0.9818
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 100, Global step 393:
20-03-23 00:21-INFO-training batch loss: 0.0599; avg_loss: 0.0631
20-03-23 00:21-INFO-training batch acc: 0.9844; avg_acc: 0.9819
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 101, Global step 394:
20-03-23 00:21-INFO-training batch loss: 0.0232; avg_loss: 0.0627
20-03-23 00:21-INFO-training batch acc: 0.9922; avg_acc: 0.9820
20-03-23 00:21-INFO-
20-03-23 00:21-INFO-Epoch 1, Batch 102, Global step 395:
20-03-23 00:21-INFO-training batch loss: 0.0815; avg_loss: 0.0629
20-03-23 00:21-INFO-training batch acc: 0.9766; avg_acc: 0.9819
20-03-23 00:21-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 103, Global step 396:
20-03-23 00:22-INFO-training batch loss: 0.0397; avg_loss: 0.0626
20-03-23 00:22-INFO-training batch acc: 0.9844; avg_acc: 0.9819
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 104, Global step 397:
20-03-23 00:22-INFO-training batch loss: 0.0559; avg_loss: 0.0626
20-03-23 00:22-INFO-training batch acc: 0.9844; avg_acc: 0.9820
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 105, Global step 398:
20-03-23 00:22-INFO-training batch loss: 0.0560; avg_loss: 0.0625
20-03-23 00:22-INFO-training batch acc: 0.9766; avg_acc: 0.9819
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 106, Global step 399:
20-03-23 00:22-INFO-training batch loss: 0.1195; avg_loss: 0.0630
20-03-23 00:22-INFO-training batch acc: 0.9609; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 107, Global step 400:
20-03-23 00:22-INFO-training batch loss: 0.0286; avg_loss: 0.0627
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9818
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 108, Global step 401:
20-03-23 00:22-INFO-training batch loss: 0.0882; avg_loss: 0.0630
20-03-23 00:22-INFO-training batch acc: 0.9688; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 109, Global step 402:
20-03-23 00:22-INFO-training batch loss: 0.0434; avg_loss: 0.0628
20-03-23 00:22-INFO-training batch acc: 0.9844; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 110, Global step 403:
20-03-23 00:22-INFO-training batch loss: 0.0414; avg_loss: 0.0626
20-03-23 00:22-INFO-training batch acc: 0.9766; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 111, Global step 404:
20-03-23 00:22-INFO-training batch loss: 0.0454; avg_loss: 0.0624
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9818
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 112, Global step 405:
20-03-23 00:22-INFO-training batch loss: 0.0508; avg_loss: 0.0623
20-03-23 00:22-INFO-training batch acc: 0.9688; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 113, Global step 406:
20-03-23 00:22-INFO-training batch loss: 0.0393; avg_loss: 0.0621
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 114, Global step 407:
20-03-23 00:22-INFO-training batch loss: 0.0255; avg_loss: 0.0618
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9818
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 115, Global step 408:
20-03-23 00:22-INFO-training batch loss: 0.0493; avg_loss: 0.0617
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9819
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 116, Global step 409:
20-03-23 00:22-INFO-training batch loss: 0.0290; avg_loss: 0.0614
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9820
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 117, Global step 410:
20-03-23 00:22-INFO-training batch loss: 0.1085; avg_loss: 0.0618
20-03-23 00:22-INFO-training batch acc: 0.9531; avg_acc: 0.9818
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 118, Global step 411:
20-03-23 00:22-INFO-training batch loss: 0.0756; avg_loss: 0.0619
20-03-23 00:22-INFO-training batch acc: 0.9766; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 119, Global step 412:
20-03-23 00:22-INFO-training batch loss: 0.0870; avg_loss: 0.0621
20-03-23 00:22-INFO-training batch acc: 0.9766; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 120, Global step 413:
20-03-23 00:22-INFO-training batch loss: 0.0471; avg_loss: 0.0620
20-03-23 00:22-INFO-training batch acc: 0.9844; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 121, Global step 414:
20-03-23 00:22-INFO-training batch loss: 0.0831; avg_loss: 0.0622
20-03-23 00:22-INFO-training batch acc: 0.9844; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 122, Global step 415:
20-03-23 00:22-INFO-training batch loss: 0.0876; avg_loss: 0.0624
20-03-23 00:22-INFO-training batch acc: 0.9688; avg_acc: 0.9816
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 123, Global step 416:
20-03-23 00:22-INFO-training batch loss: 0.0243; avg_loss: 0.0621
20-03-23 00:22-INFO-training batch acc: 0.9922; avg_acc: 0.9817
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 124, Global step 417:
20-03-23 00:22-INFO-training batch loss: 0.0271; avg_loss: 0.0618
20-03-23 00:22-INFO-training batch acc: 1.0000; avg_acc: 0.9819
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 125, Global step 418:
20-03-23 00:22-INFO-training batch loss: 0.0780; avg_loss: 0.0619
20-03-23 00:22-INFO-training batch acc: 0.9688; avg_acc: 0.9818
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 126, Global step 419:
20-03-23 00:22-INFO-training batch loss: 0.1497; avg_loss: 0.0626
20-03-23 00:22-INFO-training batch acc: 0.9688; avg_acc: 0.9816
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 127, Global step 420:
20-03-23 00:22-INFO-training batch loss: 0.0643; avg_loss: 0.0626
20-03-23 00:22-INFO-training batch acc: 0.9766; avg_acc: 0.9816
20-03-23 00:22-INFO-
20-03-23 00:22-INFO-Epoch 1, Batch 128, Global step 421:
20-03-23 00:22-INFO-training batch loss: 0.1060; avg_loss: 0.0630
20-03-23 00:22-INFO-training batch acc: 0.9766; avg_acc: 0.9816
20-03-23 00:22-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 129, Global step 422:
20-03-23 00:23-INFO-training batch loss: 0.1008; avg_loss: 0.0633
20-03-23 00:23-INFO-training batch acc: 0.9688; avg_acc: 0.9815
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 130, Global step 423:
20-03-23 00:23-INFO-training batch loss: 0.0494; avg_loss: 0.0632
20-03-23 00:23-INFO-training batch acc: 0.9766; avg_acc: 0.9814
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 131, Global step 424:
20-03-23 00:23-INFO-training batch loss: 0.0343; avg_loss: 0.0629
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9815
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 132, Global step 425:
20-03-23 00:23-INFO-training batch loss: 0.0695; avg_loss: 0.0630
20-03-23 00:23-INFO-training batch acc: 0.9766; avg_acc: 0.9814
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 133, Global step 426:
20-03-23 00:23-INFO-training batch loss: 0.0135; avg_loss: 0.0626
20-03-23 00:23-INFO-training batch acc: 0.9922; avg_acc: 0.9815
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 134, Global step 427:
20-03-23 00:23-INFO-training batch loss: 0.0454; avg_loss: 0.0625
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9815
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 135, Global step 428:
20-03-23 00:23-INFO-training batch loss: 0.0274; avg_loss: 0.0622
20-03-23 00:23-INFO-training batch acc: 0.9922; avg_acc: 0.9816
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 136, Global step 429:
20-03-23 00:23-INFO-training batch loss: 0.0124; avg_loss: 0.0619
20-03-23 00:23-INFO-training batch acc: 1.0000; avg_acc: 0.9817
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 137, Global step 430:
20-03-23 00:23-INFO-training batch loss: 0.0498; avg_loss: 0.0618
20-03-23 00:23-INFO-training batch acc: 0.9922; avg_acc: 0.9818
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 138, Global step 431:
20-03-23 00:23-INFO-training batch loss: 0.0714; avg_loss: 0.0619
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9818
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 139, Global step 432:
20-03-23 00:23-INFO-training batch loss: 0.0165; avg_loss: 0.0615
20-03-23 00:23-INFO-training batch acc: 0.9922; avg_acc: 0.9819
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 140, Global step 433:
20-03-23 00:23-INFO-training batch loss: 0.0293; avg_loss: 0.0613
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9819
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 141, Global step 434:
20-03-23 00:23-INFO-training batch loss: 0.0075; avg_loss: 0.0609
20-03-23 00:23-INFO-training batch acc: 1.0000; avg_acc: 0.9820
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 142, Global step 435:
20-03-23 00:23-INFO-training batch loss: 0.0680; avg_loss: 0.0610
20-03-23 00:23-INFO-training batch acc: 0.9766; avg_acc: 0.9820
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 143, Global step 436:
20-03-23 00:23-INFO-training batch loss: 0.0079; avg_loss: 0.0606
20-03-23 00:23-INFO-training batch acc: 1.0000; avg_acc: 0.9821
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 144, Global step 437:
20-03-23 00:23-INFO-training batch loss: 0.0938; avg_loss: 0.0608
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9822
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 145, Global step 438:
20-03-23 00:23-INFO-training batch loss: 0.0461; avg_loss: 0.0607
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9822
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 146, Global step 439:
20-03-23 00:23-INFO-training batch loss: 0.0734; avg_loss: 0.0608
20-03-23 00:23-INFO-training batch acc: 0.9688; avg_acc: 0.9821
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 147, Global step 440:
20-03-23 00:23-INFO-training batch loss: 0.0492; avg_loss: 0.0607
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9821
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 148, Global step 441:
20-03-23 00:23-INFO-training batch loss: 0.0893; avg_loss: 0.0609
20-03-23 00:23-INFO-training batch acc: 0.9609; avg_acc: 0.9819
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 149, Global step 442:
20-03-23 00:23-INFO-training batch loss: 0.0148; avg_loss: 0.0606
20-03-23 00:23-INFO-training batch acc: 1.0000; avg_acc: 0.9821
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 150, Global step 443:
20-03-23 00:23-INFO-training batch loss: 0.0201; avg_loss: 0.0603
20-03-23 00:23-INFO-training batch acc: 1.0000; avg_acc: 0.9822
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 151, Global step 444:
20-03-23 00:23-INFO-training batch loss: 0.0310; avg_loss: 0.0601
20-03-23 00:23-INFO-training batch acc: 1.0000; avg_acc: 0.9823
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 152, Global step 445:
20-03-23 00:23-INFO-training batch loss: 0.0495; avg_loss: 0.0601
20-03-23 00:23-INFO-training batch acc: 0.9922; avg_acc: 0.9824
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 153, Global step 446:
20-03-23 00:23-INFO-training batch loss: 0.0450; avg_loss: 0.0600
20-03-23 00:23-INFO-training batch acc: 0.9922; avg_acc: 0.9824
20-03-23 00:23-INFO-
20-03-23 00:23-INFO-Epoch 1, Batch 154, Global step 447:
20-03-23 00:23-INFO-training batch loss: 0.0414; avg_loss: 0.0599
20-03-23 00:23-INFO-training batch acc: 0.9844; avg_acc: 0.9824
20-03-23 00:23-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 155, Global step 448:
20-03-23 00:24-INFO-training batch loss: 0.0188; avg_loss: 0.0596
20-03-23 00:24-INFO-training batch acc: 1.0000; avg_acc: 0.9826
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 156, Global step 449:
20-03-23 00:24-INFO-training batch loss: 0.0565; avg_loss: 0.0596
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9826
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 157, Global step 450:
20-03-23 00:24-INFO-training batch loss: 0.0321; avg_loss: 0.0594
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9826
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 158, Global step 451:
20-03-23 00:24-INFO-training batch loss: 0.0374; avg_loss: 0.0593
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9827
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 159, Global step 452:
20-03-23 00:24-INFO-training batch loss: 0.0617; avg_loss: 0.0593
20-03-23 00:24-INFO-training batch acc: 0.9688; avg_acc: 0.9826
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 160, Global step 453:
20-03-23 00:24-INFO-training batch loss: 0.0557; avg_loss: 0.0593
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9826
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 161, Global step 454:
20-03-23 00:24-INFO-training batch loss: 0.0232; avg_loss: 0.0590
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9827
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 162, Global step 455:
20-03-23 00:24-INFO-training batch loss: 0.0674; avg_loss: 0.0591
20-03-23 00:24-INFO-training batch acc: 0.9766; avg_acc: 0.9826
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 163, Global step 456:
20-03-23 00:24-INFO-training batch loss: 0.0552; avg_loss: 0.0591
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9827
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 164, Global step 457:
20-03-23 00:24-INFO-training batch loss: 0.0192; avg_loss: 0.0588
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 165, Global step 458:
20-03-23 00:24-INFO-training batch loss: 0.0285; avg_loss: 0.0586
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 166, Global step 459:
20-03-23 00:24-INFO-training batch loss: 0.0400; avg_loss: 0.0585
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 167, Global step 460:
20-03-23 00:24-INFO-training batch loss: 0.0797; avg_loss: 0.0586
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 168, Global step 461:
20-03-23 00:24-INFO-training batch loss: 0.0238; avg_loss: 0.0584
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 169, Global step 462:
20-03-23 00:24-INFO-training batch loss: 0.0308; avg_loss: 0.0583
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 170, Global step 463:
20-03-23 00:24-INFO-training batch loss: 0.0362; avg_loss: 0.0581
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9829
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 171, Global step 464:
20-03-23 00:24-INFO-training batch loss: 0.0981; avg_loss: 0.0584
20-03-23 00:24-INFO-training batch acc: 0.9531; avg_acc: 0.9827
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 172, Global step 465:
20-03-23 00:24-INFO-training batch loss: 0.0176; avg_loss: 0.0581
20-03-23 00:24-INFO-training batch acc: 1.0000; avg_acc: 0.9828
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 173, Global step 466:
20-03-23 00:24-INFO-training batch loss: 0.0064; avg_loss: 0.0578
20-03-23 00:24-INFO-training batch acc: 1.0000; avg_acc: 0.9829
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 174, Global step 467:
20-03-23 00:24-INFO-training batch loss: 0.0266; avg_loss: 0.0577
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9829
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 175, Global step 468:
20-03-23 00:24-INFO-training batch loss: 0.0223; avg_loss: 0.0575
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9829
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 176, Global step 469:
20-03-23 00:24-INFO-training batch loss: 0.0199; avg_loss: 0.0572
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9830
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 177, Global step 470:
20-03-23 00:24-INFO-training batch loss: 0.0114; avg_loss: 0.0570
20-03-23 00:24-INFO-training batch acc: 1.0000; avg_acc: 0.9831
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 178, Global step 471:
20-03-23 00:24-INFO-training batch loss: 0.0480; avg_loss: 0.0569
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9831
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 179, Global step 472:
20-03-23 00:24-INFO-training batch loss: 0.0669; avg_loss: 0.0570
20-03-23 00:24-INFO-training batch acc: 0.9844; avg_acc: 0.9831
20-03-23 00:24-INFO-
20-03-23 00:24-INFO-Epoch 1, Batch 180, Global step 473:
20-03-23 00:24-INFO-training batch loss: 0.0302; avg_loss: 0.0568
20-03-23 00:24-INFO-training batch acc: 0.9922; avg_acc: 0.9832
20-03-23 00:24-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 181, Global step 474:
20-03-23 00:25-INFO-training batch loss: 0.0158; avg_loss: 0.0566
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 182, Global step 475:
20-03-23 00:25-INFO-training batch loss: 0.1032; avg_loss: 0.0569
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 183, Global step 476:
20-03-23 00:25-INFO-training batch loss: 0.0349; avg_loss: 0.0568
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9833
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 184, Global step 477:
20-03-23 00:25-INFO-training batch loss: 0.0846; avg_loss: 0.0569
20-03-23 00:25-INFO-training batch acc: 0.9766; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 185, Global step 478:
20-03-23 00:25-INFO-training batch loss: 0.0797; avg_loss: 0.0570
20-03-23 00:25-INFO-training batch acc: 0.9766; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 186, Global step 479:
20-03-23 00:25-INFO-training batch loss: 0.0844; avg_loss: 0.0572
20-03-23 00:25-INFO-training batch acc: 0.9766; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 187, Global step 480:
20-03-23 00:25-INFO-training batch loss: 0.0283; avg_loss: 0.0570
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 188, Global step 481:
20-03-23 00:25-INFO-training batch loss: 0.0506; avg_loss: 0.0570
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 189, Global step 482:
20-03-23 00:25-INFO-training batch loss: 0.0298; avg_loss: 0.0568
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9832
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 190, Global step 483:
20-03-23 00:25-INFO-training batch loss: 0.0600; avg_loss: 0.0569
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9833
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 191, Global step 484:
20-03-23 00:25-INFO-training batch loss: 0.0204; avg_loss: 0.0567
20-03-23 00:25-INFO-training batch acc: 1.0000; avg_acc: 0.9834
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 192, Global step 485:
20-03-23 00:25-INFO-training batch loss: 0.0144; avg_loss: 0.0564
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9834
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 193, Global step 486:
20-03-23 00:25-INFO-training batch loss: 0.0290; avg_loss: 0.0563
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9834
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 194, Global step 487:
20-03-23 00:25-INFO-training batch loss: 0.0896; avg_loss: 0.0565
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9834
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 195, Global step 488:
20-03-23 00:25-INFO-training batch loss: 0.0519; avg_loss: 0.0565
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9834
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 196, Global step 489:
20-03-23 00:25-INFO-training batch loss: 0.0046; avg_loss: 0.0562
20-03-23 00:25-INFO-training batch acc: 1.0000; avg_acc: 0.9835
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 197, Global step 490:
20-03-23 00:25-INFO-training batch loss: 0.0083; avg_loss: 0.0559
20-03-23 00:25-INFO-training batch acc: 1.0000; avg_acc: 0.9836
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 198, Global step 491:
20-03-23 00:25-INFO-training batch loss: 0.0082; avg_loss: 0.0557
20-03-23 00:25-INFO-training batch acc: 1.0000; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 199, Global step 492:
20-03-23 00:25-INFO-training batch loss: 0.0329; avg_loss: 0.0556
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 200, Global step 493:
20-03-23 00:25-INFO-training batch loss: 0.0372; avg_loss: 0.0555
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 201, Global step 494:
20-03-23 00:25-INFO-training batch loss: 0.0217; avg_loss: 0.0553
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 202, Global step 495:
20-03-23 00:25-INFO-training batch loss: 0.0509; avg_loss: 0.0553
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 203, Global step 496:
20-03-23 00:25-INFO-training batch loss: 0.1019; avg_loss: 0.0555
20-03-23 00:25-INFO-training batch acc: 0.9844; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 204, Global step 497:
20-03-23 00:25-INFO-training batch loss: 0.0633; avg_loss: 0.0556
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9837
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 205, Global step 498:
20-03-23 00:25-INFO-training batch loss: 0.0612; avg_loss: 0.0556
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9838
20-03-23 00:25-INFO-
20-03-23 00:25-INFO-Epoch 1, Batch 206, Global step 499:
20-03-23 00:25-INFO-training batch loss: 0.0259; avg_loss: 0.0555
20-03-23 00:25-INFO-training batch acc: 0.9922; avg_acc: 0.9838
20-03-23 00:25-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 207, Global step 500:
20-03-23 00:26-INFO-training batch loss: 0.0147; avg_loss: 0.0553
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9839
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 208, Global step 501:
20-03-23 00:26-INFO-training batch loss: 0.0123; avg_loss: 0.0551
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9840
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 209, Global step 502:
20-03-23 00:26-INFO-training batch loss: 0.0122; avg_loss: 0.0549
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9840
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 210, Global step 503:
20-03-23 00:26-INFO-training batch loss: 0.0101; avg_loss: 0.0546
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9841
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 211, Global step 504:
20-03-23 00:26-INFO-training batch loss: 0.0100; avg_loss: 0.0544
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9842
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 212, Global step 505:
20-03-23 00:26-INFO-training batch loss: 0.0088; avg_loss: 0.0542
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9843
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 213, Global step 506:
20-03-23 00:26-INFO-training batch loss: 0.0119; avg_loss: 0.0540
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9843
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 214, Global step 507:
20-03-23 00:26-INFO-training batch loss: 0.0259; avg_loss: 0.0539
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9844
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 215, Global step 508:
20-03-23 00:26-INFO-training batch loss: 0.0304; avg_loss: 0.0538
20-03-23 00:26-INFO-training batch acc: 0.9844; avg_acc: 0.9844
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 216, Global step 509:
20-03-23 00:26-INFO-training batch loss: 0.0060; avg_loss: 0.0536
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9844
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 217, Global step 510:
20-03-23 00:26-INFO-training batch loss: 0.0176; avg_loss: 0.0534
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9845
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 218, Global step 511:
20-03-23 00:26-INFO-training batch loss: 0.0407; avg_loss: 0.0533
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9845
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 219, Global step 512:
20-03-23 00:26-INFO-training batch loss: 0.0449; avg_loss: 0.0533
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9846
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 220, Global step 513:
20-03-23 00:26-INFO-training batch loss: 0.0143; avg_loss: 0.0531
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9846
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 221, Global step 514:
20-03-23 00:26-INFO-training batch loss: 0.0101; avg_loss: 0.0529
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9847
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 222, Global step 515:
20-03-23 00:26-INFO-training batch loss: 0.0477; avg_loss: 0.0529
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9847
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 223, Global step 516:
20-03-23 00:26-INFO-training batch loss: 0.0084; avg_loss: 0.0527
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9848
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 224, Global step 517:
20-03-23 00:26-INFO-training batch loss: 0.0028; avg_loss: 0.0525
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9849
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 225, Global step 518:
20-03-23 00:26-INFO-training batch loss: 0.0145; avg_loss: 0.0523
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9849
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 226, Global step 519:
20-03-23 00:26-INFO-training batch loss: 0.0043; avg_loss: 0.0521
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9850
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 227, Global step 520:
20-03-23 00:26-INFO-training batch loss: 0.0032; avg_loss: 0.0519
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9850
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 228, Global step 521:
20-03-23 00:26-INFO-training batch loss: 0.0435; avg_loss: 0.0518
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9851
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 229, Global step 522:
20-03-23 00:26-INFO-training batch loss: 0.0020; avg_loss: 0.0516
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9851
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 230, Global step 523:
20-03-23 00:26-INFO-training batch loss: 0.0019; avg_loss: 0.0514
20-03-23 00:26-INFO-training batch acc: 1.0000; avg_acc: 0.9852
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 231, Global step 524:
20-03-23 00:26-INFO-training batch loss: 0.0146; avg_loss: 0.0512
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9852
20-03-23 00:26-INFO-
20-03-23 00:26-INFO-Epoch 1, Batch 232, Global step 525:
20-03-23 00:26-INFO-training batch loss: 0.0486; avg_loss: 0.0512
20-03-23 00:26-INFO-training batch acc: 0.9922; avg_acc: 0.9853
20-03-23 00:26-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 233, Global step 526:
20-03-23 00:27-INFO-training batch loss: 0.0437; avg_loss: 0.0512
20-03-23 00:27-INFO-training batch acc: 0.9922; avg_acc: 0.9853
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 234, Global step 527:
20-03-23 00:27-INFO-training batch loss: 0.0048; avg_loss: 0.0510
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9853
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 235, Global step 528:
20-03-23 00:27-INFO-training batch loss: 0.0137; avg_loss: 0.0508
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9854
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 236, Global step 529:
20-03-23 00:27-INFO-training batch loss: 0.0047; avg_loss: 0.0506
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9855
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 237, Global step 530:
20-03-23 00:27-INFO-training batch loss: 0.0065; avg_loss: 0.0505
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9855
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 238, Global step 531:
20-03-23 00:27-INFO-training batch loss: 0.0047; avg_loss: 0.0503
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9856
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 239, Global step 532:
20-03-23 00:27-INFO-training batch loss: 0.0084; avg_loss: 0.0501
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9856
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 240, Global step 533:
20-03-23 00:27-INFO-training batch loss: 0.0085; avg_loss: 0.0499
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9857
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 241, Global step 534:
20-03-23 00:27-INFO-training batch loss: 0.0048; avg_loss: 0.0497
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9858
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 242, Global step 535:
20-03-23 00:27-INFO-training batch loss: 0.0028; avg_loss: 0.0495
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9858
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 243, Global step 536:
20-03-23 00:27-INFO-training batch loss: 0.0361; avg_loss: 0.0495
20-03-23 00:27-INFO-training batch acc: 0.9922; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 244, Global step 537:
20-03-23 00:27-INFO-training batch loss: 0.0590; avg_loss: 0.0495
20-03-23 00:27-INFO-training batch acc: 0.9844; avg_acc: 0.9858
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 245, Global step 538:
20-03-23 00:27-INFO-training batch loss: 0.0127; avg_loss: 0.0494
20-03-23 00:27-INFO-training batch acc: 0.9922; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 246, Global step 539:
20-03-23 00:27-INFO-training batch loss: 0.0067; avg_loss: 0.0492
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 247, Global step 540:
20-03-23 00:27-INFO-training batch loss: 0.0360; avg_loss: 0.0491
20-03-23 00:27-INFO-training batch acc: 0.9922; avg_acc: 0.9860
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 248, Global step 541:
20-03-23 00:27-INFO-training batch loss: 0.0888; avg_loss: 0.0493
20-03-23 00:27-INFO-training batch acc: 0.9766; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 249, Global step 542:
20-03-23 00:27-INFO-training batch loss: 0.0581; avg_loss: 0.0493
20-03-23 00:27-INFO-training batch acc: 0.9844; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 250, Global step 543:
20-03-23 00:27-INFO-training batch loss: 0.0440; avg_loss: 0.0493
20-03-23 00:27-INFO-training batch acc: 0.9844; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 251, Global step 544:
20-03-23 00:27-INFO-training batch loss: 0.0165; avg_loss: 0.0492
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9860
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 252, Global step 545:
20-03-23 00:27-INFO-training batch loss: 0.0831; avg_loss: 0.0493
20-03-23 00:27-INFO-training batch acc: 0.9844; avg_acc: 0.9860
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 253, Global step 546:
20-03-23 00:27-INFO-training batch loss: 0.0838; avg_loss: 0.0495
20-03-23 00:27-INFO-training batch acc: 0.9688; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 254, Global step 547:
20-03-23 00:27-INFO-training batch loss: 0.0297; avg_loss: 0.0494
20-03-23 00:27-INFO-training batch acc: 0.9844; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 255, Global step 548:
20-03-23 00:27-INFO-training batch loss: 0.0110; avg_loss: 0.0492
20-03-23 00:27-INFO-training batch acc: 1.0000; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 256, Global step 549:
20-03-23 00:27-INFO-training batch loss: 0.1082; avg_loss: 0.0495
20-03-23 00:27-INFO-training batch acc: 0.9844; avg_acc: 0.9859
20-03-23 00:27-INFO-
20-03-23 00:27-INFO-Epoch 1, Batch 257, Global step 550:
20-03-23 00:27-INFO-training batch loss: 0.0213; avg_loss: 0.0494
20-03-23 00:27-INFO-training batch acc: 0.9922; avg_acc: 0.9860
20-03-23 00:27-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 258, Global step 551:
20-03-23 00:28-INFO-training batch loss: 0.0965; avg_loss: 0.0495
20-03-23 00:28-INFO-training batch acc: 0.9844; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 259, Global step 552:
20-03-23 00:28-INFO-training batch loss: 0.1465; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 260, Global step 553:
20-03-23 00:28-INFO-training batch loss: 0.0073; avg_loss: 0.0497
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 261, Global step 554:
20-03-23 00:28-INFO-training batch loss: 0.0846; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9844; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 262, Global step 555:
20-03-23 00:28-INFO-training batch loss: 0.0877; avg_loss: 0.0500
20-03-23 00:28-INFO-training batch acc: 0.9531; avg_acc: 0.9858
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 263, Global step 556:
20-03-23 00:28-INFO-training batch loss: 0.0288; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9922; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 264, Global step 557:
20-03-23 00:28-INFO-training batch loss: 0.0700; avg_loss: 0.0500
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9858
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 265, Global step 558:
20-03-23 00:28-INFO-training batch loss: 0.0274; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 266, Global step 559:
20-03-23 00:28-INFO-training batch loss: 0.0742; avg_loss: 0.0500
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9858
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 267, Global step 560:
20-03-23 00:28-INFO-training batch loss: 0.0716; avg_loss: 0.0501
20-03-23 00:28-INFO-training batch acc: 0.9844; avg_acc: 0.9858
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 268, Global step 561:
20-03-23 00:28-INFO-training batch loss: 0.0251; avg_loss: 0.0500
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 269, Global step 562:
20-03-23 00:28-INFO-training batch loss: 0.0346; avg_loss: 0.0500
20-03-23 00:28-INFO-training batch acc: 0.9922; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 270, Global step 563:
20-03-23 00:28-INFO-training batch loss: 0.0367; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 271, Global step 564:
20-03-23 00:28-INFO-training batch loss: 0.0178; avg_loss: 0.0498
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9859
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 272, Global step 565:
20-03-23 00:28-INFO-training batch loss: 0.0350; avg_loss: 0.0497
20-03-23 00:28-INFO-training batch acc: 0.9922; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 273, Global step 566:
20-03-23 00:28-INFO-training batch loss: 0.0103; avg_loss: 0.0496
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 274, Global step 567:
20-03-23 00:28-INFO-training batch loss: 0.0635; avg_loss: 0.0496
20-03-23 00:28-INFO-training batch acc: 0.9922; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 275, Global step 568:
20-03-23 00:28-INFO-training batch loss: 0.0680; avg_loss: 0.0497
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 276, Global step 569:
20-03-23 00:28-INFO-training batch loss: 0.0908; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 277, Global step 570:
20-03-23 00:28-INFO-training batch loss: 0.0798; avg_loss: 0.0500
20-03-23 00:28-INFO-training batch acc: 0.9844; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 278, Global step 571:
20-03-23 00:28-INFO-training batch loss: 0.0068; avg_loss: 0.0498
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 279, Global step 572:
20-03-23 00:28-INFO-training batch loss: 0.0437; avg_loss: 0.0498
20-03-23 00:28-INFO-training batch acc: 0.9922; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 280, Global step 573:
20-03-23 00:28-INFO-training batch loss: 0.0128; avg_loss: 0.0497
20-03-23 00:28-INFO-training batch acc: 1.0000; avg_acc: 0.9861
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 281, Global step 574:
20-03-23 00:28-INFO-training batch loss: 0.0646; avg_loss: 0.0497
20-03-23 00:28-INFO-training batch acc: 0.9766; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 282, Global step 575:
20-03-23 00:28-INFO-training batch loss: 0.0985; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9844; avg_acc: 0.9860
20-03-23 00:28-INFO-
20-03-23 00:28-INFO-Epoch 1, Batch 283, Global step 576:
20-03-23 00:28-INFO-training batch loss: 0.0472; avg_loss: 0.0499
20-03-23 00:28-INFO-training batch acc: 0.9922; avg_acc: 0.9861
20-03-23 00:28-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 284, Global step 577:
20-03-23 00:29-INFO-training batch loss: 0.0409; avg_loss: 0.0498
20-03-23 00:29-INFO-training batch acc: 0.9922; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 285, Global step 578:
20-03-23 00:29-INFO-training batch loss: 0.0324; avg_loss: 0.0498
20-03-23 00:29-INFO-training batch acc: 0.9922; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 286, Global step 579:
20-03-23 00:29-INFO-training batch loss: 0.0394; avg_loss: 0.0497
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 287, Global step 580:
20-03-23 00:29-INFO-training batch loss: 0.0276; avg_loss: 0.0497
20-03-23 00:29-INFO-training batch acc: 0.9922; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 288, Global step 581:
20-03-23 00:29-INFO-training batch loss: 0.0176; avg_loss: 0.0496
20-03-23 00:29-INFO-training batch acc: 1.0000; avg_acc: 0.9862
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 289, Global step 582:
20-03-23 00:29-INFO-training batch loss: 0.0212; avg_loss: 0.0495
20-03-23 00:29-INFO-training batch acc: 0.9922; avg_acc: 0.9862
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 290, Global step 583:
20-03-23 00:29-INFO-training batch loss: 0.0748; avg_loss: 0.0495
20-03-23 00:29-INFO-training batch acc: 0.9766; avg_acc: 0.9862
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 291, Global step 584:
20-03-23 00:29-INFO-training batch loss: 0.0450; avg_loss: 0.0495
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 292, Global step 585:
20-03-23 00:29-INFO-training batch loss: 0.0257; avg_loss: 0.0494
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, Batch 293, Global step 586:
20-03-23 00:29-INFO-training batch loss: 0.0038; avg_loss: 0.0493
20-03-23 00:29-INFO-training batch acc: 1.0000; avg_acc: 0.9862
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, training batch loss: 0.0038; avg_loss: 0.0493
20-03-23 00:29-INFO-Epoch 1, training batch accuracy: 1.0000; avg_accuracy: 0.9862
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 1, evaluating batch loss: 0.8106; avg_loss: 0.5813
20-03-23 00:29-INFO-Epoch 1, evaluating batch accuracy: 0.8571; avg_accuracy: 0.8920
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 1, Global step 587:
20-03-23 00:29-INFO-training batch loss: 0.0037; avg_loss: 0.0037
20-03-23 00:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 2, Global step 588:
20-03-23 00:29-INFO-training batch loss: 0.0606; avg_loss: 0.0321
20-03-23 00:29-INFO-training batch acc: 0.9922; avg_acc: 0.9961
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 3, Global step 589:
20-03-23 00:29-INFO-training batch loss: 0.0659; avg_loss: 0.0434
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 4, Global step 590:
20-03-23 00:29-INFO-training batch loss: 0.0151; avg_loss: 0.0363
20-03-23 00:29-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 5, Global step 591:
20-03-23 00:29-INFO-training batch loss: 0.0158; avg_loss: 0.0322
20-03-23 00:29-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 6, Global step 592:
20-03-23 00:29-INFO-training batch loss: 0.0770; avg_loss: 0.0397
20-03-23 00:29-INFO-training batch acc: 0.9766; avg_acc: 0.9909
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 7, Global step 593:
20-03-23 00:29-INFO-training batch loss: 0.0271; avg_loss: 0.0379
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9900
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 8, Global step 594:
20-03-23 00:29-INFO-training batch loss: 0.1075; avg_loss: 0.0466
20-03-23 00:29-INFO-training batch acc: 0.9688; avg_acc: 0.9873
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 9, Global step 595:
20-03-23 00:29-INFO-training batch loss: 0.0835; avg_loss: 0.0507
20-03-23 00:29-INFO-training batch acc: 0.9766; avg_acc: 0.9861
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 10, Global step 596:
20-03-23 00:29-INFO-training batch loss: 0.0323; avg_loss: 0.0488
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9859
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 11, Global step 597:
20-03-23 00:29-INFO-training batch loss: 0.0626; avg_loss: 0.0501
20-03-23 00:29-INFO-training batch acc: 0.9844; avg_acc: 0.9858
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 12, Global step 598:
20-03-23 00:29-INFO-training batch loss: 0.0140; avg_loss: 0.0471
20-03-23 00:29-INFO-training batch acc: 1.0000; avg_acc: 0.9870
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 13, Global step 599:
20-03-23 00:29-INFO-training batch loss: 0.0417; avg_loss: 0.0467
20-03-23 00:29-INFO-training batch acc: 0.9766; avg_acc: 0.9862
20-03-23 00:29-INFO-
20-03-23 00:29-INFO-Epoch 2, Batch 14, Global step 600:
20-03-23 00:29-INFO-training batch loss: 0.0180; avg_loss: 0.0446
20-03-23 00:29-INFO-training batch acc: 1.0000; avg_acc: 0.9872
20-03-23 00:29-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 15, Global step 601:
20-03-23 00:30-INFO-training batch loss: 0.0197; avg_loss: 0.0430
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9880
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 16, Global step 602:
20-03-23 00:30-INFO-training batch loss: 0.0211; avg_loss: 0.0416
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9888
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 17, Global step 603:
20-03-23 00:30-INFO-training batch loss: 0.0171; avg_loss: 0.0402
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9894
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 18, Global step 604:
20-03-23 00:30-INFO-training batch loss: 0.0180; avg_loss: 0.0389
20-03-23 00:30-INFO-training batch acc: 0.9922; avg_acc: 0.9896
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 19, Global step 605:
20-03-23 00:30-INFO-training batch loss: 0.0545; avg_loss: 0.0397
20-03-23 00:30-INFO-training batch acc: 0.9766; avg_acc: 0.9889
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 20, Global step 606:
20-03-23 00:30-INFO-training batch loss: 0.0176; avg_loss: 0.0386
20-03-23 00:30-INFO-training batch acc: 0.9922; avg_acc: 0.9891
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 21, Global step 607:
20-03-23 00:30-INFO-training batch loss: 0.0063; avg_loss: 0.0371
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9896
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 22, Global step 608:
20-03-23 00:30-INFO-training batch loss: 0.0495; avg_loss: 0.0377
20-03-23 00:30-INFO-training batch acc: 0.9844; avg_acc: 0.9893
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 23, Global step 609:
20-03-23 00:30-INFO-training batch loss: 0.0195; avg_loss: 0.0369
20-03-23 00:30-INFO-training batch acc: 0.9922; avg_acc: 0.9895
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 24, Global step 610:
20-03-23 00:30-INFO-training batch loss: 0.0102; avg_loss: 0.0358
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9899
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 25, Global step 611:
20-03-23 00:30-INFO-training batch loss: 0.0401; avg_loss: 0.0359
20-03-23 00:30-INFO-training batch acc: 0.9844; avg_acc: 0.9897
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 26, Global step 612:
20-03-23 00:30-INFO-training batch loss: 0.0282; avg_loss: 0.0356
20-03-23 00:30-INFO-training batch acc: 0.9844; avg_acc: 0.9895
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 27, Global step 613:
20-03-23 00:30-INFO-training batch loss: 0.1014; avg_loss: 0.0381
20-03-23 00:30-INFO-training batch acc: 0.9766; avg_acc: 0.9890
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 28, Global step 614:
20-03-23 00:30-INFO-training batch loss: 0.0258; avg_loss: 0.0376
20-03-23 00:30-INFO-training batch acc: 0.9844; avg_acc: 0.9888
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 29, Global step 615:
20-03-23 00:30-INFO-training batch loss: 0.0081; avg_loss: 0.0366
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9892
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 30, Global step 616:
20-03-23 00:30-INFO-training batch loss: 0.0365; avg_loss: 0.0366
20-03-23 00:30-INFO-training batch acc: 0.9844; avg_acc: 0.9891
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 31, Global step 617:
20-03-23 00:30-INFO-training batch loss: 0.0083; avg_loss: 0.0357
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9894
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 32, Global step 618:
20-03-23 00:30-INFO-training batch loss: 0.0363; avg_loss: 0.0357
20-03-23 00:30-INFO-training batch acc: 0.9844; avg_acc: 0.9893
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 33, Global step 619:
20-03-23 00:30-INFO-training batch loss: 0.0142; avg_loss: 0.0351
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9896
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 34, Global step 620:
20-03-23 00:30-INFO-training batch loss: 0.0071; avg_loss: 0.0342
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9899
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 35, Global step 621:
20-03-23 00:30-INFO-training batch loss: 0.0085; avg_loss: 0.0335
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9902
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 36, Global step 622:
20-03-23 00:30-INFO-training batch loss: 0.0861; avg_loss: 0.0350
20-03-23 00:30-INFO-training batch acc: 0.9766; avg_acc: 0.9898
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 37, Global step 623:
20-03-23 00:30-INFO-training batch loss: 0.0396; avg_loss: 0.0351
20-03-23 00:30-INFO-training batch acc: 0.9922; avg_acc: 0.9899
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 38, Global step 624:
20-03-23 00:30-INFO-training batch loss: 0.0056; avg_loss: 0.0343
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9901
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 39, Global step 625:
20-03-23 00:30-INFO-training batch loss: 0.0068; avg_loss: 0.0336
20-03-23 00:30-INFO-training batch acc: 1.0000; avg_acc: 0.9904
20-03-23 00:30-INFO-
20-03-23 00:30-INFO-Epoch 2, Batch 40, Global step 626:
20-03-23 00:30-INFO-training batch loss: 0.0742; avg_loss: 0.0346
20-03-23 00:30-INFO-training batch acc: 0.9766; avg_acc: 0.9900
20-03-23 00:30-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 41, Global step 627:
20-03-23 00:31-INFO-training batch loss: 0.0045; avg_loss: 0.0339
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9903
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 42, Global step 628:
20-03-23 00:31-INFO-training batch loss: 0.0026; avg_loss: 0.0331
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9905
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 43, Global step 629:
20-03-23 00:31-INFO-training batch loss: 0.0261; avg_loss: 0.0330
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9906
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 44, Global step 630:
20-03-23 00:31-INFO-training batch loss: 0.0489; avg_loss: 0.0333
20-03-23 00:31-INFO-training batch acc: 0.9844; avg_acc: 0.9904
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 45, Global step 631:
20-03-23 00:31-INFO-training batch loss: 0.0159; avg_loss: 0.0330
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9905
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 46, Global step 632:
20-03-23 00:31-INFO-training batch loss: 0.0092; avg_loss: 0.0324
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9907
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 47, Global step 633:
20-03-23 00:31-INFO-training batch loss: 0.0133; avg_loss: 0.0320
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9907
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 48, Global step 634:
20-03-23 00:31-INFO-training batch loss: 0.0037; avg_loss: 0.0314
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9909
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 49, Global step 635:
20-03-23 00:31-INFO-training batch loss: 0.0299; avg_loss: 0.0314
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9909
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 50, Global step 636:
20-03-23 00:31-INFO-training batch loss: 0.0078; avg_loss: 0.0309
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9911
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 51, Global step 637:
20-03-23 00:31-INFO-training batch loss: 0.0621; avg_loss: 0.0315
20-03-23 00:31-INFO-training batch acc: 0.9844; avg_acc: 0.9910
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 52, Global step 638:
20-03-23 00:31-INFO-training batch loss: 0.0080; avg_loss: 0.0311
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9911
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 53, Global step 639:
20-03-23 00:31-INFO-training batch loss: 0.0202; avg_loss: 0.0309
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9912
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 54, Global step 640:
20-03-23 00:31-INFO-training batch loss: 0.0058; avg_loss: 0.0304
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9913
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 55, Global step 641:
20-03-23 00:31-INFO-training batch loss: 0.0487; avg_loss: 0.0308
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9913
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 56, Global step 642:
20-03-23 00:31-INFO-training batch loss: 0.0215; avg_loss: 0.0306
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9914
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 57, Global step 643:
20-03-23 00:31-INFO-training batch loss: 0.0095; avg_loss: 0.0302
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 58, Global step 644:
20-03-23 00:31-INFO-training batch loss: 0.0454; avg_loss: 0.0305
20-03-23 00:31-INFO-training batch acc: 0.9844; avg_acc: 0.9914
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 59, Global step 645:
20-03-23 00:31-INFO-training batch loss: 0.0062; avg_loss: 0.0301
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 60, Global step 646:
20-03-23 00:31-INFO-training batch loss: 0.0405; avg_loss: 0.0302
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9915
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 61, Global step 647:
20-03-23 00:31-INFO-training batch loss: 0.0036; avg_loss: 0.0298
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 62, Global step 648:
20-03-23 00:31-INFO-training batch loss: 0.0065; avg_loss: 0.0294
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 63, Global step 649:
20-03-23 00:31-INFO-training batch loss: 0.0040; avg_loss: 0.0290
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 64, Global step 650:
20-03-23 00:31-INFO-training batch loss: 0.0027; avg_loss: 0.0286
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 65, Global step 651:
20-03-23 00:31-INFO-training batch loss: 0.0016; avg_loss: 0.0282
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 66, Global step 652:
20-03-23 00:31-INFO-training batch loss: 0.0014; avg_loss: 0.0278
20-03-23 00:31-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:31-INFO-
20-03-23 00:31-INFO-Epoch 2, Batch 67, Global step 653:
20-03-23 00:31-INFO-training batch loss: 0.0321; avg_loss: 0.0279
20-03-23 00:31-INFO-training batch acc: 0.9922; avg_acc: 0.9923
20-03-23 00:31-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 68, Global step 654:
20-03-23 00:32-INFO-training batch loss: 0.0322; avg_loss: 0.0279
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 69, Global step 655:
20-03-23 00:32-INFO-training batch loss: 0.0535; avg_loss: 0.0283
20-03-23 00:32-INFO-training batch acc: 0.9766; avg_acc: 0.9920
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 70, Global step 656:
20-03-23 00:32-INFO-training batch loss: 0.0053; avg_loss: 0.0280
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 71, Global step 657:
20-03-23 00:32-INFO-training batch loss: 0.0491; avg_loss: 0.0283
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 72, Global step 658:
20-03-23 00:32-INFO-training batch loss: 0.0375; avg_loss: 0.0284
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 73, Global step 659:
20-03-23 00:32-INFO-training batch loss: 0.0238; avg_loss: 0.0283
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 74, Global step 660:
20-03-23 00:32-INFO-training batch loss: 0.0143; avg_loss: 0.0281
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 75, Global step 661:
20-03-23 00:32-INFO-training batch loss: 0.0281; avg_loss: 0.0281
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 76, Global step 662:
20-03-23 00:32-INFO-training batch loss: 0.0391; avg_loss: 0.0283
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 77, Global step 663:
20-03-23 00:32-INFO-training batch loss: 0.0036; avg_loss: 0.0280
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 78, Global step 664:
20-03-23 00:32-INFO-training batch loss: 0.0166; avg_loss: 0.0278
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 79, Global step 665:
20-03-23 00:32-INFO-training batch loss: 0.0036; avg_loss: 0.0275
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 80, Global step 666:
20-03-23 00:32-INFO-training batch loss: 0.0206; avg_loss: 0.0274
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9921
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 81, Global step 667:
20-03-23 00:32-INFO-training batch loss: 0.0392; avg_loss: 0.0276
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 82, Global step 668:
20-03-23 00:32-INFO-training batch loss: 0.0029; avg_loss: 0.0273
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 83, Global step 669:
20-03-23 00:32-INFO-training batch loss: 0.0424; avg_loss: 0.0275
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9921
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 84, Global step 670:
20-03-23 00:32-INFO-training batch loss: 0.0056; avg_loss: 0.0272
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 85, Global step 671:
20-03-23 00:32-INFO-training batch loss: 0.0566; avg_loss: 0.0275
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9921
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 86, Global step 672:
20-03-23 00:32-INFO-training batch loss: 0.0062; avg_loss: 0.0273
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 87, Global step 673:
20-03-23 00:32-INFO-training batch loss: 0.0206; avg_loss: 0.0272
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 88, Global step 674:
20-03-23 00:32-INFO-training batch loss: 0.0165; avg_loss: 0.0271
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 89, Global step 675:
20-03-23 00:32-INFO-training batch loss: 0.0405; avg_loss: 0.0272
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9923
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 90, Global step 676:
20-03-23 00:32-INFO-training batch loss: 0.0524; avg_loss: 0.0275
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 91, Global step 677:
20-03-23 00:32-INFO-training batch loss: 0.0072; avg_loss: 0.0273
20-03-23 00:32-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 92, Global step 678:
20-03-23 00:32-INFO-training batch loss: 0.0223; avg_loss: 0.0272
20-03-23 00:32-INFO-training batch acc: 0.9922; avg_acc: 0.9923
20-03-23 00:32-INFO-
20-03-23 00:32-INFO-Epoch 2, Batch 93, Global step 679:
20-03-23 00:32-INFO-training batch loss: 0.0343; avg_loss: 0.0273
20-03-23 00:32-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:32-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 94, Global step 680:
20-03-23 00:33-INFO-training batch loss: 0.0127; avg_loss: 0.0272
20-03-23 00:33-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 95, Global step 681:
20-03-23 00:33-INFO-training batch loss: 0.0629; avg_loss: 0.0275
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 96, Global step 682:
20-03-23 00:33-INFO-training batch loss: 0.0280; avg_loss: 0.0275
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 97, Global step 683:
20-03-23 00:33-INFO-training batch loss: 0.0323; avg_loss: 0.0276
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 98, Global step 684:
20-03-23 00:33-INFO-training batch loss: 0.0302; avg_loss: 0.0276
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 99, Global step 685:
20-03-23 00:33-INFO-training batch loss: 0.0368; avg_loss: 0.0277
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9921
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 100, Global step 686:
20-03-23 00:33-INFO-training batch loss: 0.0276; avg_loss: 0.0277
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9921
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 101, Global step 687:
20-03-23 00:33-INFO-training batch loss: 0.0512; avg_loss: 0.0279
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 102, Global step 688:
20-03-23 00:33-INFO-training batch loss: 0.0330; avg_loss: 0.0280
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 103, Global step 689:
20-03-23 00:33-INFO-training batch loss: 0.0261; avg_loss: 0.0280
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 104, Global step 690:
20-03-23 00:33-INFO-training batch loss: 0.0433; avg_loss: 0.0281
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 105, Global step 691:
20-03-23 00:33-INFO-training batch loss: 0.0150; avg_loss: 0.0280
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 106, Global step 692:
20-03-23 00:33-INFO-training batch loss: 0.0345; avg_loss: 0.0281
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 107, Global step 693:
20-03-23 00:33-INFO-training batch loss: 0.0439; avg_loss: 0.0282
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 108, Global step 694:
20-03-23 00:33-INFO-training batch loss: 0.0302; avg_loss: 0.0282
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 109, Global step 695:
20-03-23 00:33-INFO-training batch loss: 0.0412; avg_loss: 0.0283
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 110, Global step 696:
20-03-23 00:33-INFO-training batch loss: 0.0087; avg_loss: 0.0282
20-03-23 00:33-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 111, Global step 697:
20-03-23 00:33-INFO-training batch loss: 0.0097; avg_loss: 0.0280
20-03-23 00:33-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 112, Global step 698:
20-03-23 00:33-INFO-training batch loss: 0.0350; avg_loss: 0.0281
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 113, Global step 699:
20-03-23 00:33-INFO-training batch loss: 0.0166; avg_loss: 0.0280
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 114, Global step 700:
20-03-23 00:33-INFO-training batch loss: 0.0359; avg_loss: 0.0280
20-03-23 00:33-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 115, Global step 701:
20-03-23 00:33-INFO-training batch loss: 0.0108; avg_loss: 0.0279
20-03-23 00:33-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 116, Global step 702:
20-03-23 00:33-INFO-training batch loss: 0.0062; avg_loss: 0.0277
20-03-23 00:33-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 117, Global step 703:
20-03-23 00:33-INFO-training batch loss: 0.0742; avg_loss: 0.0281
20-03-23 00:33-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 118, Global step 704:
20-03-23 00:33-INFO-training batch loss: 0.0059; avg_loss: 0.0279
20-03-23 00:33-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:33-INFO-
20-03-23 00:33-INFO-Epoch 2, Batch 119, Global step 705:
20-03-23 00:33-INFO-training batch loss: 0.0708; avg_loss: 0.0283
20-03-23 00:33-INFO-training batch acc: 0.9766; avg_acc: 0.9919
20-03-23 00:33-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 120, Global step 706:
20-03-23 00:34-INFO-training batch loss: 0.0045; avg_loss: 0.0281
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 121, Global step 707:
20-03-23 00:34-INFO-training batch loss: 0.0156; avg_loss: 0.0280
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 122, Global step 708:
20-03-23 00:34-INFO-training batch loss: 0.0462; avg_loss: 0.0281
20-03-23 00:34-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 123, Global step 709:
20-03-23 00:34-INFO-training batch loss: 0.0236; avg_loss: 0.0281
20-03-23 00:34-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 124, Global step 710:
20-03-23 00:34-INFO-training batch loss: 0.0077; avg_loss: 0.0279
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 125, Global step 711:
20-03-23 00:34-INFO-training batch loss: 0.0579; avg_loss: 0.0282
20-03-23 00:34-INFO-training batch acc: 0.9766; avg_acc: 0.9918
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 126, Global step 712:
20-03-23 00:34-INFO-training batch loss: 0.1509; avg_loss: 0.0291
20-03-23 00:34-INFO-training batch acc: 0.9688; avg_acc: 0.9916
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 127, Global step 713:
20-03-23 00:34-INFO-training batch loss: 0.0503; avg_loss: 0.0293
20-03-23 00:34-INFO-training batch acc: 0.9844; avg_acc: 0.9915
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 128, Global step 714:
20-03-23 00:34-INFO-training batch loss: 0.0298; avg_loss: 0.0293
20-03-23 00:34-INFO-training batch acc: 0.9766; avg_acc: 0.9914
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 129, Global step 715:
20-03-23 00:34-INFO-training batch loss: 0.0483; avg_loss: 0.0294
20-03-23 00:34-INFO-training batch acc: 0.9844; avg_acc: 0.9913
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 130, Global step 716:
20-03-23 00:34-INFO-training batch loss: 0.0104; avg_loss: 0.0293
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9914
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 131, Global step 717:
20-03-23 00:34-INFO-training batch loss: 0.0086; avg_loss: 0.0291
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 132, Global step 718:
20-03-23 00:34-INFO-training batch loss: 0.0371; avg_loss: 0.0292
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9915
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 133, Global step 719:
20-03-23 00:34-INFO-training batch loss: 0.0210; avg_loss: 0.0291
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9915
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 134, Global step 720:
20-03-23 00:34-INFO-training batch loss: 0.0108; avg_loss: 0.0290
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 135, Global step 721:
20-03-23 00:34-INFO-training batch loss: 0.0122; avg_loss: 0.0289
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 136, Global step 722:
20-03-23 00:34-INFO-training batch loss: 0.0082; avg_loss: 0.0287
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 137, Global step 723:
20-03-23 00:34-INFO-training batch loss: 0.0201; avg_loss: 0.0287
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9917
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 138, Global step 724:
20-03-23 00:34-INFO-training batch loss: 0.0275; avg_loss: 0.0287
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9917
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 139, Global step 725:
20-03-23 00:34-INFO-training batch loss: 0.0028; avg_loss: 0.0285
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 140, Global step 726:
20-03-23 00:34-INFO-training batch loss: 0.0095; avg_loss: 0.0283
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 141, Global step 727:
20-03-23 00:34-INFO-training batch loss: 0.0021; avg_loss: 0.0281
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 142, Global step 728:
20-03-23 00:34-INFO-training batch loss: 0.0442; avg_loss: 0.0283
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 143, Global step 729:
20-03-23 00:34-INFO-training batch loss: 0.0084; avg_loss: 0.0281
20-03-23 00:34-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 144, Global step 730:
20-03-23 00:34-INFO-training batch loss: 0.0368; avg_loss: 0.0282
20-03-23 00:34-INFO-training batch acc: 0.9766; avg_acc: 0.9918
20-03-23 00:34-INFO-
20-03-23 00:34-INFO-Epoch 2, Batch 145, Global step 731:
20-03-23 00:34-INFO-training batch loss: 0.0482; avg_loss: 0.0283
20-03-23 00:34-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:34-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 146, Global step 732:
20-03-23 00:35-INFO-training batch loss: 0.0438; avg_loss: 0.0284
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 147, Global step 733:
20-03-23 00:35-INFO-training batch loss: 0.0531; avg_loss: 0.0286
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 148, Global step 734:
20-03-23 00:35-INFO-training batch loss: 0.0269; avg_loss: 0.0286
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 149, Global step 735:
20-03-23 00:35-INFO-training batch loss: 0.0094; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 150, Global step 736:
20-03-23 00:35-INFO-training batch loss: 0.0104; avg_loss: 0.0283
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 151, Global step 737:
20-03-23 00:35-INFO-training batch loss: 0.0163; avg_loss: 0.0283
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 152, Global step 738:
20-03-23 00:35-INFO-training batch loss: 0.0549; avg_loss: 0.0284
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 153, Global step 739:
20-03-23 00:35-INFO-training batch loss: 0.0461; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 154, Global step 740:
20-03-23 00:35-INFO-training batch loss: 0.0537; avg_loss: 0.0287
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 155, Global step 741:
20-03-23 00:35-INFO-training batch loss: 0.0225; avg_loss: 0.0287
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 156, Global step 742:
20-03-23 00:35-INFO-training batch loss: 0.0448; avg_loss: 0.0288
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9917
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 157, Global step 743:
20-03-23 00:35-INFO-training batch loss: 0.0128; avg_loss: 0.0287
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9917
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 158, Global step 744:
20-03-23 00:35-INFO-training batch loss: 0.0096; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 159, Global step 745:
20-03-23 00:35-INFO-training batch loss: 0.0211; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9917
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 160, Global step 746:
20-03-23 00:35-INFO-training batch loss: 0.0333; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9917
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 161, Global step 747:
20-03-23 00:35-INFO-training batch loss: 0.0125; avg_loss: 0.0284
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 162, Global step 748:
20-03-23 00:35-INFO-training batch loss: 0.0404; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 163, Global step 749:
20-03-23 00:35-INFO-training batch loss: 0.0282; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 164, Global step 750:
20-03-23 00:35-INFO-training batch loss: 0.0227; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 165, Global step 751:
20-03-23 00:35-INFO-training batch loss: 0.0098; avg_loss: 0.0284
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 166, Global step 752:
20-03-23 00:35-INFO-training batch loss: 0.0622; avg_loss: 0.0286
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 167, Global step 753:
20-03-23 00:35-INFO-training batch loss: 0.0357; avg_loss: 0.0286
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 168, Global step 754:
20-03-23 00:35-INFO-training batch loss: 0.0408; avg_loss: 0.0287
20-03-23 00:35-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 169, Global step 755:
20-03-23 00:35-INFO-training batch loss: 0.0080; avg_loss: 0.0286
20-03-23 00:35-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 170, Global step 756:
20-03-23 00:35-INFO-training batch loss: 0.0125; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 00:35-INFO-
20-03-23 00:35-INFO-Epoch 2, Batch 171, Global step 757:
20-03-23 00:35-INFO-training batch loss: 0.0350; avg_loss: 0.0285
20-03-23 00:35-INFO-training batch acc: 0.9766; avg_acc: 0.9917
20-03-23 00:35-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 172, Global step 758:
20-03-23 00:36-INFO-training batch loss: 0.0070; avg_loss: 0.0284
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 173, Global step 759:
20-03-23 00:36-INFO-training batch loss: 0.0049; avg_loss: 0.0282
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 174, Global step 760:
20-03-23 00:36-INFO-training batch loss: 0.0111; avg_loss: 0.0281
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 175, Global step 761:
20-03-23 00:36-INFO-training batch loss: 0.0054; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 176, Global step 762:
20-03-23 00:36-INFO-training batch loss: 0.0271; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 177, Global step 763:
20-03-23 00:36-INFO-training batch loss: 0.0065; avg_loss: 0.0279
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 178, Global step 764:
20-03-23 00:36-INFO-training batch loss: 0.0328; avg_loss: 0.0279
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 179, Global step 765:
20-03-23 00:36-INFO-training batch loss: 0.0404; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 180, Global step 766:
20-03-23 00:36-INFO-training batch loss: 0.0087; avg_loss: 0.0279
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 181, Global step 767:
20-03-23 00:36-INFO-training batch loss: 0.0111; avg_loss: 0.0278
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 182, Global step 768:
20-03-23 00:36-INFO-training batch loss: 0.0701; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 183, Global step 769:
20-03-23 00:36-INFO-training batch loss: 0.0209; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 184, Global step 770:
20-03-23 00:36-INFO-training batch loss: 0.0132; avg_loss: 0.0279
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 185, Global step 771:
20-03-23 00:36-INFO-training batch loss: 0.0311; avg_loss: 0.0279
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 186, Global step 772:
20-03-23 00:36-INFO-training batch loss: 0.0491; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 187, Global step 773:
20-03-23 00:36-INFO-training batch loss: 0.0214; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 188, Global step 774:
20-03-23 00:36-INFO-training batch loss: 0.0444; avg_loss: 0.0281
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 189, Global step 775:
20-03-23 00:36-INFO-training batch loss: 0.0088; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 190, Global step 776:
20-03-23 00:36-INFO-training batch loss: 0.0353; avg_loss: 0.0280
20-03-23 00:36-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 191, Global step 777:
20-03-23 00:36-INFO-training batch loss: 0.0074; avg_loss: 0.0279
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 192, Global step 778:
20-03-23 00:36-INFO-training batch loss: 0.0078; avg_loss: 0.0278
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 193, Global step 779:
20-03-23 00:36-INFO-training batch loss: 0.0058; avg_loss: 0.0277
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 194, Global step 780:
20-03-23 00:36-INFO-training batch loss: 0.0256; avg_loss: 0.0277
20-03-23 00:36-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 195, Global step 781:
20-03-23 00:36-INFO-training batch loss: 0.0347; avg_loss: 0.0277
20-03-23 00:36-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 196, Global step 782:
20-03-23 00:36-INFO-training batch loss: 0.0065; avg_loss: 0.0276
20-03-23 00:36-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:36-INFO-Epoch 2, Batch 197, Global step 783:
20-03-23 00:36-INFO-training batch loss: 0.0113; avg_loss: 0.0275
20-03-23 00:36-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:36-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 198, Global step 784:
20-03-23 00:37-INFO-training batch loss: 0.0132; avg_loss: 0.0274
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 199, Global step 785:
20-03-23 00:37-INFO-training batch loss: 0.0469; avg_loss: 0.0275
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 200, Global step 786:
20-03-23 00:37-INFO-training batch loss: 0.0320; avg_loss: 0.0276
20-03-23 00:37-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 201, Global step 787:
20-03-23 00:37-INFO-training batch loss: 0.0084; avg_loss: 0.0275
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 202, Global step 788:
20-03-23 00:37-INFO-training batch loss: 0.0175; avg_loss: 0.0274
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 203, Global step 789:
20-03-23 00:37-INFO-training batch loss: 0.0944; avg_loss: 0.0278
20-03-23 00:37-INFO-training batch acc: 0.9766; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 204, Global step 790:
20-03-23 00:37-INFO-training batch loss: 0.0338; avg_loss: 0.0278
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 205, Global step 791:
20-03-23 00:37-INFO-training batch loss: 0.0236; avg_loss: 0.0278
20-03-23 00:37-INFO-training batch acc: 0.9844; avg_acc: 0.9919
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 206, Global step 792:
20-03-23 00:37-INFO-training batch loss: 0.0138; avg_loss: 0.0277
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 207, Global step 793:
20-03-23 00:37-INFO-training batch loss: 0.0299; avg_loss: 0.0277
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 208, Global step 794:
20-03-23 00:37-INFO-training batch loss: 0.0151; avg_loss: 0.0276
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 209, Global step 795:
20-03-23 00:37-INFO-training batch loss: 0.0117; avg_loss: 0.0276
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 210, Global step 796:
20-03-23 00:37-INFO-training batch loss: 0.0421; avg_loss: 0.0276
20-03-23 00:37-INFO-training batch acc: 0.9844; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 211, Global step 797:
20-03-23 00:37-INFO-training batch loss: 0.0103; avg_loss: 0.0276
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 212, Global step 798:
20-03-23 00:37-INFO-training batch loss: 0.0066; avg_loss: 0.0275
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 213, Global step 799:
20-03-23 00:37-INFO-training batch loss: 0.0100; avg_loss: 0.0274
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 214, Global step 800:
20-03-23 00:37-INFO-training batch loss: 0.0100; avg_loss: 0.0273
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 215, Global step 801:
20-03-23 00:37-INFO-training batch loss: 0.0403; avg_loss: 0.0274
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 216, Global step 802:
20-03-23 00:37-INFO-training batch loss: 0.0064; avg_loss: 0.0273
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 217, Global step 803:
20-03-23 00:37-INFO-training batch loss: 0.0081; avg_loss: 0.0272
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 218, Global step 804:
20-03-23 00:37-INFO-training batch loss: 0.0161; avg_loss: 0.0271
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 219, Global step 805:
20-03-23 00:37-INFO-training batch loss: 0.0382; avg_loss: 0.0272
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9923
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 220, Global step 806:
20-03-23 00:37-INFO-training batch loss: 0.0040; avg_loss: 0.0271
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 221, Global step 807:
20-03-23 00:37-INFO-training batch loss: 0.0047; avg_loss: 0.0270
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 222, Global step 808:
20-03-23 00:37-INFO-training batch loss: 0.0201; avg_loss: 0.0269
20-03-23 00:37-INFO-training batch acc: 0.9922; avg_acc: 0.9923
20-03-23 00:37-INFO-
20-03-23 00:37-INFO-Epoch 2, Batch 223, Global step 809:
20-03-23 00:37-INFO-training batch loss: 0.0028; avg_loss: 0.0268
20-03-23 00:37-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 00:37-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 224, Global step 810:
20-03-23 00:38-INFO-training batch loss: 0.0022; avg_loss: 0.0267
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 225, Global step 811:
20-03-23 00:38-INFO-training batch loss: 0.0030; avg_loss: 0.0266
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 226, Global step 812:
20-03-23 00:38-INFO-training batch loss: 0.0096; avg_loss: 0.0265
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 227, Global step 813:
20-03-23 00:38-INFO-training batch loss: 0.0040; avg_loss: 0.0264
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 228, Global step 814:
20-03-23 00:38-INFO-training batch loss: 0.0300; avg_loss: 0.0264
20-03-23 00:38-INFO-training batch acc: 0.9844; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 229, Global step 815:
20-03-23 00:38-INFO-training batch loss: 0.0045; avg_loss: 0.0264
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 230, Global step 816:
20-03-23 00:38-INFO-training batch loss: 0.0015; avg_loss: 0.0262
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 231, Global step 817:
20-03-23 00:38-INFO-training batch loss: 0.0199; avg_loss: 0.0262
20-03-23 00:38-INFO-training batch acc: 0.9844; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 232, Global step 818:
20-03-23 00:38-INFO-training batch loss: 0.0226; avg_loss: 0.0262
20-03-23 00:38-INFO-training batch acc: 0.9922; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 233, Global step 819:
20-03-23 00:38-INFO-training batch loss: 0.0136; avg_loss: 0.0261
20-03-23 00:38-INFO-training batch acc: 0.9922; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 234, Global step 820:
20-03-23 00:38-INFO-training batch loss: 0.0061; avg_loss: 0.0261
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 235, Global step 821:
20-03-23 00:38-INFO-training batch loss: 0.0056; avg_loss: 0.0260
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 236, Global step 822:
20-03-23 00:38-INFO-training batch loss: 0.0081; avg_loss: 0.0259
20-03-23 00:38-INFO-training batch acc: 0.9922; avg_acc: 0.9926
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 237, Global step 823:
20-03-23 00:38-INFO-training batch loss: 0.0020; avg_loss: 0.0258
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 238, Global step 824:
20-03-23 00:38-INFO-training batch loss: 0.0019; avg_loss: 0.0257
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 239, Global step 825:
20-03-23 00:38-INFO-training batch loss: 0.0027; avg_loss: 0.0256
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 240, Global step 826:
20-03-23 00:38-INFO-training batch loss: 0.0032; avg_loss: 0.0255
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 241, Global step 827:
20-03-23 00:38-INFO-training batch loss: 0.0017; avg_loss: 0.0254
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 242, Global step 828:
20-03-23 00:38-INFO-training batch loss: 0.0020; avg_loss: 0.0253
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 243, Global step 829:
20-03-23 00:38-INFO-training batch loss: 0.0359; avg_loss: 0.0254
20-03-23 00:38-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 244, Global step 830:
20-03-23 00:38-INFO-training batch loss: 0.0720; avg_loss: 0.0255
20-03-23 00:38-INFO-training batch acc: 0.9844; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 245, Global step 831:
20-03-23 00:38-INFO-training batch loss: 0.0029; avg_loss: 0.0255
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 246, Global step 832:
20-03-23 00:38-INFO-training batch loss: 0.0040; avg_loss: 0.0254
20-03-23 00:38-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 247, Global step 833:
20-03-23 00:38-INFO-training batch loss: 0.0394; avg_loss: 0.0254
20-03-23 00:38-INFO-training batch acc: 0.9922; avg_acc: 0.9928
20-03-23 00:38-INFO-
20-03-23 00:38-INFO-Epoch 2, Batch 248, Global step 834:
20-03-23 00:38-INFO-training batch loss: 0.0828; avg_loss: 0.0257
20-03-23 00:38-INFO-training batch acc: 0.9766; avg_acc: 0.9927
20-03-23 00:38-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 249, Global step 835:
20-03-23 00:39-INFO-training batch loss: 0.0297; avg_loss: 0.0257
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 250, Global step 836:
20-03-23 00:39-INFO-training batch loss: 0.0052; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 251, Global step 837:
20-03-23 00:39-INFO-training batch loss: 0.0022; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 252, Global step 838:
20-03-23 00:39-INFO-training batch loss: 0.0243; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 253, Global step 839:
20-03-23 00:39-INFO-training batch loss: 0.0254; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 254, Global step 840:
20-03-23 00:39-INFO-training batch loss: 0.0383; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 255, Global step 841:
20-03-23 00:39-INFO-training batch loss: 0.0094; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 256, Global step 842:
20-03-23 00:39-INFO-training batch loss: 0.0105; avg_loss: 0.0254
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 257, Global step 843:
20-03-23 00:39-INFO-training batch loss: 0.0276; avg_loss: 0.0254
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 258, Global step 844:
20-03-23 00:39-INFO-training batch loss: 0.0224; avg_loss: 0.0254
20-03-23 00:39-INFO-training batch acc: 0.9844; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 259, Global step 845:
20-03-23 00:39-INFO-training batch loss: 0.0051; avg_loss: 0.0253
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 260, Global step 846:
20-03-23 00:39-INFO-training batch loss: 0.0209; avg_loss: 0.0253
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 261, Global step 847:
20-03-23 00:39-INFO-training batch loss: 0.0498; avg_loss: 0.0254
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 262, Global step 848:
20-03-23 00:39-INFO-training batch loss: 0.0267; avg_loss: 0.0254
20-03-23 00:39-INFO-training batch acc: 0.9844; avg_acc: 0.9928
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 263, Global step 849:
20-03-23 00:39-INFO-training batch loss: 0.0621; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 0.9844; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 264, Global step 850:
20-03-23 00:39-INFO-training batch loss: 0.0202; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 265, Global step 851:
20-03-23 00:39-INFO-training batch loss: 0.0064; avg_loss: 0.0255
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 266, Global step 852:
20-03-23 00:39-INFO-training batch loss: 0.0660; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 0.9844; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 267, Global step 853:
20-03-23 00:39-INFO-training batch loss: 0.0383; avg_loss: 0.0257
20-03-23 00:39-INFO-training batch acc: 0.9844; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 268, Global step 854:
20-03-23 00:39-INFO-training batch loss: 0.0150; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 269, Global step 855:
20-03-23 00:39-INFO-training batch loss: 0.0176; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 270, Global step 856:
20-03-23 00:39-INFO-training batch loss: 0.0622; avg_loss: 0.0257
20-03-23 00:39-INFO-training batch acc: 0.9844; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 271, Global step 857:
20-03-23 00:39-INFO-training batch loss: 0.0068; avg_loss: 0.0257
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 272, Global step 858:
20-03-23 00:39-INFO-training batch loss: 0.0359; avg_loss: 0.0257
20-03-23 00:39-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 273, Global step 859:
20-03-23 00:39-INFO-training batch loss: 0.0098; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:39-INFO-Epoch 2, Batch 274, Global step 860:
20-03-23 00:39-INFO-training batch loss: 0.0096; avg_loss: 0.0256
20-03-23 00:39-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:39-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 275, Global step 861:
20-03-23 00:40-INFO-training batch loss: 0.0307; avg_loss: 0.0256
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 276, Global step 862:
20-03-23 00:40-INFO-training batch loss: 0.0504; avg_loss: 0.0257
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 277, Global step 863:
20-03-23 00:40-INFO-training batch loss: 0.0120; avg_loss: 0.0256
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 278, Global step 864:
20-03-23 00:40-INFO-training batch loss: 0.0178; avg_loss: 0.0256
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 279, Global step 865:
20-03-23 00:40-INFO-training batch loss: 0.0377; avg_loss: 0.0257
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 280, Global step 866:
20-03-23 00:40-INFO-training batch loss: 0.0092; avg_loss: 0.0256
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 281, Global step 867:
20-03-23 00:40-INFO-training batch loss: 0.0450; avg_loss: 0.0257
20-03-23 00:40-INFO-training batch acc: 0.9844; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 282, Global step 868:
20-03-23 00:40-INFO-training batch loss: 0.0874; avg_loss: 0.0259
20-03-23 00:40-INFO-training batch acc: 0.9766; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 283, Global step 869:
20-03-23 00:40-INFO-training batch loss: 0.0853; avg_loss: 0.0261
20-03-23 00:40-INFO-training batch acc: 0.9766; avg_acc: 0.9926
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 284, Global step 870:
20-03-23 00:40-INFO-training batch loss: 0.0132; avg_loss: 0.0261
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 285, Global step 871:
20-03-23 00:40-INFO-training batch loss: 0.0037; avg_loss: 0.0260
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 286, Global step 872:
20-03-23 00:40-INFO-training batch loss: 0.0147; avg_loss: 0.0259
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 287, Global step 873:
20-03-23 00:40-INFO-training batch loss: 0.0088; avg_loss: 0.0259
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 288, Global step 874:
20-03-23 00:40-INFO-training batch loss: 0.0130; avg_loss: 0.0258
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 289, Global step 875:
20-03-23 00:40-INFO-training batch loss: 0.0084; avg_loss: 0.0258
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 290, Global step 876:
20-03-23 00:40-INFO-training batch loss: 0.0344; avg_loss: 0.0258
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 291, Global step 877:
20-03-23 00:40-INFO-training batch loss: 0.0389; avg_loss: 0.0258
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 292, Global step 878:
20-03-23 00:40-INFO-training batch loss: 0.0071; avg_loss: 0.0258
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, Batch 293, Global step 879:
20-03-23 00:40-INFO-training batch loss: 0.0045; avg_loss: 0.0257
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, training batch loss: 0.0045; avg_loss: 0.0257
20-03-23 00:40-INFO-Epoch 2, training batch accuracy: 1.0000; avg_accuracy: 0.9928
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 2, evaluating batch loss: 0.8680; avg_loss: 0.5022
20-03-23 00:40-INFO-Epoch 2, evaluating batch accuracy: 0.8857; avg_accuracy: 0.8933
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 3, Batch 1, Global step 880:
20-03-23 00:40-INFO-training batch loss: 0.0079; avg_loss: 0.0079
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 3, Batch 2, Global step 881:
20-03-23 00:40-INFO-training batch loss: 0.0232; avg_loss: 0.0156
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9961
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 3, Batch 3, Global step 882:
20-03-23 00:40-INFO-training batch loss: 0.0286; avg_loss: 0.0199
20-03-23 00:40-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:40-INFO-
20-03-23 00:40-INFO-Epoch 3, Batch 4, Global step 883:
20-03-23 00:40-INFO-training batch loss: 0.0080; avg_loss: 0.0169
20-03-23 00:40-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 00:40-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 5, Global step 884:
20-03-23 00:41-INFO-training batch loss: 0.0040; avg_loss: 0.0144
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 6, Global step 885:
20-03-23 00:41-INFO-training batch loss: 0.1097; avg_loss: 0.0302
20-03-23 00:41-INFO-training batch acc: 0.9688; avg_acc: 0.9922
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 7, Global step 886:
20-03-23 00:41-INFO-training batch loss: 0.0057; avg_loss: 0.0267
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9933
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 8, Global step 887:
20-03-23 00:41-INFO-training batch loss: 0.0382; avg_loss: 0.0282
20-03-23 00:41-INFO-training batch acc: 0.9922; avg_acc: 0.9932
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 9, Global step 888:
20-03-23 00:41-INFO-training batch loss: 0.0969; avg_loss: 0.0358
20-03-23 00:41-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 10, Global step 889:
20-03-23 00:41-INFO-training batch loss: 0.0115; avg_loss: 0.0334
20-03-23 00:41-INFO-training batch acc: 0.9922; avg_acc: 0.9922
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 11, Global step 890:
20-03-23 00:41-INFO-training batch loss: 0.0409; avg_loss: 0.0341
20-03-23 00:41-INFO-training batch acc: 0.9844; avg_acc: 0.9915
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 12, Global step 891:
20-03-23 00:41-INFO-training batch loss: 0.0054; avg_loss: 0.0317
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 13, Global step 892:
20-03-23 00:41-INFO-training batch loss: 0.0477; avg_loss: 0.0329
20-03-23 00:41-INFO-training batch acc: 0.9844; avg_acc: 0.9916
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 14, Global step 893:
20-03-23 00:41-INFO-training batch loss: 0.0070; avg_loss: 0.0311
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 15, Global step 894:
20-03-23 00:41-INFO-training batch loss: 0.0045; avg_loss: 0.0293
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 16, Global step 895:
20-03-23 00:41-INFO-training batch loss: 0.0061; avg_loss: 0.0278
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9932
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 17, Global step 896:
20-03-23 00:41-INFO-training batch loss: 0.0096; avg_loss: 0.0268
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9936
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 18, Global step 897:
20-03-23 00:41-INFO-training batch loss: 0.0079; avg_loss: 0.0257
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 19, Global step 898:
20-03-23 00:41-INFO-training batch loss: 0.0129; avg_loss: 0.0250
20-03-23 00:41-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 20, Global step 899:
20-03-23 00:41-INFO-training batch loss: 0.0071; avg_loss: 0.0241
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 21, Global step 900:
20-03-23 00:41-INFO-training batch loss: 0.0151; avg_loss: 0.0237
20-03-23 00:41-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 22, Global step 901:
20-03-23 00:41-INFO-training batch loss: 0.0357; avg_loss: 0.0243
20-03-23 00:41-INFO-training batch acc: 0.9844; avg_acc: 0.9936
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 23, Global step 902:
20-03-23 00:41-INFO-training batch loss: 0.0023; avg_loss: 0.0233
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 24, Global step 903:
20-03-23 00:41-INFO-training batch loss: 0.0046; avg_loss: 0.0225
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 25, Global step 904:
20-03-23 00:41-INFO-training batch loss: 0.0303; avg_loss: 0.0228
20-03-23 00:41-INFO-training batch acc: 0.9844; avg_acc: 0.9938
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 26, Global step 905:
20-03-23 00:41-INFO-training batch loss: 0.0057; avg_loss: 0.0222
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 27, Global step 906:
20-03-23 00:41-INFO-training batch loss: 0.0142; avg_loss: 0.0219
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 28, Global step 907:
20-03-23 00:41-INFO-training batch loss: 0.0322; avg_loss: 0.0222
20-03-23 00:41-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 29, Global step 908:
20-03-23 00:41-INFO-training batch loss: 0.0303; avg_loss: 0.0225
20-03-23 00:41-INFO-training batch acc: 0.9844; avg_acc: 0.9938
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 30, Global step 909:
20-03-23 00:41-INFO-training batch loss: 0.0236; avg_loss: 0.0226
20-03-23 00:41-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:41-INFO-
20-03-23 00:41-INFO-Epoch 3, Batch 31, Global step 910:
20-03-23 00:41-INFO-training batch loss: 0.0044; avg_loss: 0.0220
20-03-23 00:41-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:41-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 32, Global step 911:
20-03-23 00:42-INFO-training batch loss: 0.0346; avg_loss: 0.0224
20-03-23 00:42-INFO-training batch acc: 0.9844; avg_acc: 0.9937
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 33, Global step 912:
20-03-23 00:42-INFO-training batch loss: 0.0063; avg_loss: 0.0219
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 34, Global step 913:
20-03-23 00:42-INFO-training batch loss: 0.0075; avg_loss: 0.0215
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 35, Global step 914:
20-03-23 00:42-INFO-training batch loss: 0.0052; avg_loss: 0.0210
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 36, Global step 915:
20-03-23 00:42-INFO-training batch loss: 0.0563; avg_loss: 0.0220
20-03-23 00:42-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 37, Global step 916:
20-03-23 00:42-INFO-training batch loss: 0.0234; avg_loss: 0.0220
20-03-23 00:42-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 38, Global step 917:
20-03-23 00:42-INFO-training batch loss: 0.0062; avg_loss: 0.0216
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 39, Global step 918:
20-03-23 00:42-INFO-training batch loss: 0.0056; avg_loss: 0.0212
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 40, Global step 919:
20-03-23 00:42-INFO-training batch loss: 0.0295; avg_loss: 0.0214
20-03-23 00:42-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 41, Global step 920:
20-03-23 00:42-INFO-training batch loss: 0.0448; avg_loss: 0.0220
20-03-23 00:42-INFO-training batch acc: 0.9844; avg_acc: 0.9941
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 42, Global step 921:
20-03-23 00:42-INFO-training batch loss: 0.0035; avg_loss: 0.0215
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 43, Global step 922:
20-03-23 00:42-INFO-training batch loss: 0.0060; avg_loss: 0.0212
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 44, Global step 923:
20-03-23 00:42-INFO-training batch loss: 0.0433; avg_loss: 0.0217
20-03-23 00:42-INFO-training batch acc: 0.9844; avg_acc: 0.9941
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 45, Global step 924:
20-03-23 00:42-INFO-training batch loss: 0.0036; avg_loss: 0.0213
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 46, Global step 925:
20-03-23 00:42-INFO-training batch loss: 0.0033; avg_loss: 0.0209
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 47, Global step 926:
20-03-23 00:42-INFO-training batch loss: 0.0039; avg_loss: 0.0205
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 48, Global step 927:
20-03-23 00:42-INFO-training batch loss: 0.0032; avg_loss: 0.0202
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 49, Global step 928:
20-03-23 00:42-INFO-training batch loss: 0.0067; avg_loss: 0.0199
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 50, Global step 929:
20-03-23 00:42-INFO-training batch loss: 0.0080; avg_loss: 0.0196
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 51, Global step 930:
20-03-23 00:42-INFO-training batch loss: 0.0523; avg_loss: 0.0203
20-03-23 00:42-INFO-training batch acc: 0.9766; avg_acc: 0.9945
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 52, Global step 931:
20-03-23 00:42-INFO-training batch loss: 0.0075; avg_loss: 0.0200
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 53, Global step 932:
20-03-23 00:42-INFO-training batch loss: 0.0164; avg_loss: 0.0200
20-03-23 00:42-INFO-training batch acc: 0.9844; avg_acc: 0.9944
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 54, Global step 933:
20-03-23 00:42-INFO-training batch loss: 0.0126; avg_loss: 0.0198
20-03-23 00:42-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 55, Global step 934:
20-03-23 00:42-INFO-training batch loss: 0.0142; avg_loss: 0.0197
20-03-23 00:42-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 56, Global step 935:
20-03-23 00:42-INFO-training batch loss: 0.0407; avg_loss: 0.0201
20-03-23 00:42-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:42-INFO-
20-03-23 00:42-INFO-Epoch 3, Batch 57, Global step 936:
20-03-23 00:42-INFO-training batch loss: 0.0027; avg_loss: 0.0198
20-03-23 00:42-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:42-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 58, Global step 937:
20-03-23 00:43-INFO-training batch loss: 0.0225; avg_loss: 0.0198
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 59, Global step 938:
20-03-23 00:43-INFO-training batch loss: 0.0038; avg_loss: 0.0196
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 60, Global step 939:
20-03-23 00:43-INFO-training batch loss: 0.0181; avg_loss: 0.0195
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 61, Global step 940:
20-03-23 00:43-INFO-training batch loss: 0.0031; avg_loss: 0.0193
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 62, Global step 941:
20-03-23 00:43-INFO-training batch loss: 0.0027; avg_loss: 0.0190
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 63, Global step 942:
20-03-23 00:43-INFO-training batch loss: 0.0052; avg_loss: 0.0188
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 64, Global step 943:
20-03-23 00:43-INFO-training batch loss: 0.0013; avg_loss: 0.0185
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 65, Global step 944:
20-03-23 00:43-INFO-training batch loss: 0.0023; avg_loss: 0.0183
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 66, Global step 945:
20-03-23 00:43-INFO-training batch loss: 0.0033; avg_loss: 0.0180
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 67, Global step 946:
20-03-23 00:43-INFO-training batch loss: 0.0283; avg_loss: 0.0182
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 68, Global step 947:
20-03-23 00:43-INFO-training batch loss: 0.0274; avg_loss: 0.0183
20-03-23 00:43-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 69, Global step 948:
20-03-23 00:43-INFO-training batch loss: 0.0677; avg_loss: 0.0190
20-03-23 00:43-INFO-training batch acc: 0.9766; avg_acc: 0.9945
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 70, Global step 949:
20-03-23 00:43-INFO-training batch loss: 0.0183; avg_loss: 0.0190
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 71, Global step 950:
20-03-23 00:43-INFO-training batch loss: 0.0604; avg_loss: 0.0196
20-03-23 00:43-INFO-training batch acc: 0.9844; avg_acc: 0.9943
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 72, Global step 951:
20-03-23 00:43-INFO-training batch loss: 0.0088; avg_loss: 0.0195
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 73, Global step 952:
20-03-23 00:43-INFO-training batch loss: 0.0159; avg_loss: 0.0194
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 74, Global step 953:
20-03-23 00:43-INFO-training batch loss: 0.0383; avg_loss: 0.0197
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 75, Global step 954:
20-03-23 00:43-INFO-training batch loss: 0.0119; avg_loss: 0.0196
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 76, Global step 955:
20-03-23 00:43-INFO-training batch loss: 0.0091; avg_loss: 0.0194
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 77, Global step 956:
20-03-23 00:43-INFO-training batch loss: 0.0038; avg_loss: 0.0192
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 78, Global step 957:
20-03-23 00:43-INFO-training batch loss: 0.0150; avg_loss: 0.0192
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 79, Global step 958:
20-03-23 00:43-INFO-training batch loss: 0.0064; avg_loss: 0.0190
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 80, Global step 959:
20-03-23 00:43-INFO-training batch loss: 0.0239; avg_loss: 0.0191
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 81, Global step 960:
20-03-23 00:43-INFO-training batch loss: 0.0298; avg_loss: 0.0192
20-03-23 00:43-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 82, Global step 961:
20-03-23 00:43-INFO-training batch loss: 0.0022; avg_loss: 0.0190
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:43-INFO-
20-03-23 00:43-INFO-Epoch 3, Batch 83, Global step 962:
20-03-23 00:43-INFO-training batch loss: 0.0046; avg_loss: 0.0188
20-03-23 00:43-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:43-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 84, Global step 963:
20-03-23 00:44-INFO-training batch loss: 0.0040; avg_loss: 0.0186
20-03-23 00:44-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 85, Global step 964:
20-03-23 00:44-INFO-training batch loss: 0.0303; avg_loss: 0.0188
20-03-23 00:44-INFO-training batch acc: 0.9844; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 86, Global step 965:
20-03-23 00:44-INFO-training batch loss: 0.0066; avg_loss: 0.0186
20-03-23 00:44-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 87, Global step 966:
20-03-23 00:44-INFO-training batch loss: 0.0214; avg_loss: 0.0187
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 88, Global step 967:
20-03-23 00:44-INFO-training batch loss: 0.0035; avg_loss: 0.0185
20-03-23 00:44-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 89, Global step 968:
20-03-23 00:44-INFO-training batch loss: 0.0051; avg_loss: 0.0184
20-03-23 00:44-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 90, Global step 969:
20-03-23 00:44-INFO-training batch loss: 0.0218; avg_loss: 0.0184
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 91, Global step 970:
20-03-23 00:44-INFO-training batch loss: 0.0164; avg_loss: 0.0184
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 92, Global step 971:
20-03-23 00:44-INFO-training batch loss: 0.0192; avg_loss: 0.0184
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 93, Global step 972:
20-03-23 00:44-INFO-training batch loss: 0.0131; avg_loss: 0.0183
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 94, Global step 973:
20-03-23 00:44-INFO-training batch loss: 0.0053; avg_loss: 0.0182
20-03-23 00:44-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 95, Global step 974:
20-03-23 00:44-INFO-training batch loss: 0.0198; avg_loss: 0.0182
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 96, Global step 975:
20-03-23 00:44-INFO-training batch loss: 0.0183; avg_loss: 0.0182
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 97, Global step 976:
20-03-23 00:44-INFO-training batch loss: 0.0103; avg_loss: 0.0181
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 98, Global step 977:
20-03-23 00:44-INFO-training batch loss: 0.0250; avg_loss: 0.0182
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 99, Global step 978:
20-03-23 00:44-INFO-training batch loss: 0.0114; avg_loss: 0.0181
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 100, Global step 979:
20-03-23 00:44-INFO-training batch loss: 0.0158; avg_loss: 0.0181
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 101, Global step 980:
20-03-23 00:44-INFO-training batch loss: 0.0453; avg_loss: 0.0184
20-03-23 00:44-INFO-training batch acc: 0.9844; avg_acc: 0.9944
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 102, Global step 981:
20-03-23 00:44-INFO-training batch loss: 0.0295; avg_loss: 0.0185
20-03-23 00:44-INFO-training batch acc: 0.9844; avg_acc: 0.9943
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 103, Global step 982:
20-03-23 00:44-INFO-training batch loss: 0.0541; avg_loss: 0.0188
20-03-23 00:44-INFO-training batch acc: 0.9844; avg_acc: 0.9942
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 104, Global step 983:
20-03-23 00:44-INFO-training batch loss: 0.0535; avg_loss: 0.0192
20-03-23 00:44-INFO-training batch acc: 0.9844; avg_acc: 0.9941
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 105, Global step 984:
20-03-23 00:44-INFO-training batch loss: 0.0236; avg_loss: 0.0192
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 106, Global step 985:
20-03-23 00:44-INFO-training batch loss: 0.0182; avg_loss: 0.0192
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 107, Global step 986:
20-03-23 00:44-INFO-training batch loss: 0.0040; avg_loss: 0.0190
20-03-23 00:44-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 108, Global step 987:
20-03-23 00:44-INFO-training batch loss: 0.0307; avg_loss: 0.0192
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 109, Global step 988:
20-03-23 00:44-INFO-training batch loss: 0.0453; avg_loss: 0.0194
20-03-23 00:44-INFO-training batch acc: 0.9844; avg_acc: 0.9940
20-03-23 00:44-INFO-
20-03-23 00:44-INFO-Epoch 3, Batch 110, Global step 989:
20-03-23 00:44-INFO-training batch loss: 0.0083; avg_loss: 0.0193
20-03-23 00:44-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:44-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 111, Global step 990:
20-03-23 00:45-INFO-training batch loss: 0.0241; avg_loss: 0.0193
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 112, Global step 991:
20-03-23 00:45-INFO-training batch loss: 0.0054; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 113, Global step 992:
20-03-23 00:45-INFO-training batch loss: 0.0127; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 114, Global step 993:
20-03-23 00:45-INFO-training batch loss: 0.0096; avg_loss: 0.0191
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 115, Global step 994:
20-03-23 00:45-INFO-training batch loss: 0.0081; avg_loss: 0.0190
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 116, Global step 995:
20-03-23 00:45-INFO-training batch loss: 0.0138; avg_loss: 0.0189
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 117, Global step 996:
20-03-23 00:45-INFO-training batch loss: 0.0405; avg_loss: 0.0191
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 118, Global step 997:
20-03-23 00:45-INFO-training batch loss: 0.0089; avg_loss: 0.0190
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 119, Global step 998:
20-03-23 00:45-INFO-training batch loss: 0.0576; avg_loss: 0.0194
20-03-23 00:45-INFO-training batch acc: 0.9766; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 120, Global step 999:
20-03-23 00:45-INFO-training batch loss: 0.0094; avg_loss: 0.0193
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 121, Global step 1000:
20-03-23 00:45-INFO-training batch loss: 0.0059; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 122, Global step 1001:
20-03-23 00:45-INFO-training batch loss: 0.0403; avg_loss: 0.0193
20-03-23 00:45-INFO-training batch acc: 0.9766; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 123, Global step 1002:
20-03-23 00:45-INFO-training batch loss: 0.0032; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 124, Global step 1003:
20-03-23 00:45-INFO-training batch loss: 0.0156; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 125, Global step 1004:
20-03-23 00:45-INFO-training batch loss: 0.0103; avg_loss: 0.0191
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 126, Global step 1005:
20-03-23 00:45-INFO-training batch loss: 0.0357; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 0.9844; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 127, Global step 1006:
20-03-23 00:45-INFO-training batch loss: 0.0170; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 128, Global step 1007:
20-03-23 00:45-INFO-training batch loss: 0.0288; avg_loss: 0.0193
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 129, Global step 1008:
20-03-23 00:45-INFO-training batch loss: 0.0231; avg_loss: 0.0193
20-03-23 00:45-INFO-training batch acc: 0.9844; avg_acc: 0.9937
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 130, Global step 1009:
20-03-23 00:45-INFO-training batch loss: 0.0042; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 131, Global step 1010:
20-03-23 00:45-INFO-training batch loss: 0.0027; avg_loss: 0.0191
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 132, Global step 1011:
20-03-23 00:45-INFO-training batch loss: 0.0362; avg_loss: 0.0192
20-03-23 00:45-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 133, Global step 1012:
20-03-23 00:45-INFO-training batch loss: 0.0031; avg_loss: 0.0191
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 134, Global step 1013:
20-03-23 00:45-INFO-training batch loss: 0.0045; avg_loss: 0.0190
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 135, Global step 1014:
20-03-23 00:45-INFO-training batch loss: 0.0052; avg_loss: 0.0189
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:45-INFO-
20-03-23 00:45-INFO-Epoch 3, Batch 136, Global step 1015:
20-03-23 00:45-INFO-training batch loss: 0.0022; avg_loss: 0.0188
20-03-23 00:45-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:45-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 137, Global step 1016:
20-03-23 00:46-INFO-training batch loss: 0.0047; avg_loss: 0.0187
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 138, Global step 1017:
20-03-23 00:46-INFO-training batch loss: 0.0317; avg_loss: 0.0187
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 139, Global step 1018:
20-03-23 00:46-INFO-training batch loss: 0.0068; avg_loss: 0.0187
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 140, Global step 1019:
20-03-23 00:46-INFO-training batch loss: 0.0088; avg_loss: 0.0186
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 141, Global step 1020:
20-03-23 00:46-INFO-training batch loss: 0.0025; avg_loss: 0.0185
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 142, Global step 1021:
20-03-23 00:46-INFO-training batch loss: 0.0080; avg_loss: 0.0184
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 143, Global step 1022:
20-03-23 00:46-INFO-training batch loss: 0.0164; avg_loss: 0.0184
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 144, Global step 1023:
20-03-23 00:46-INFO-training batch loss: 0.0447; avg_loss: 0.0186
20-03-23 00:46-INFO-training batch acc: 0.9844; avg_acc: 0.9941
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 145, Global step 1024:
20-03-23 00:46-INFO-training batch loss: 0.0064; avg_loss: 0.0185
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 146, Global step 1025:
20-03-23 00:46-INFO-training batch loss: 0.0203; avg_loss: 0.0185
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 147, Global step 1026:
20-03-23 00:46-INFO-training batch loss: 0.0073; avg_loss: 0.0184
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 148, Global step 1027:
20-03-23 00:46-INFO-training batch loss: 0.0170; avg_loss: 0.0184
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 149, Global step 1028:
20-03-23 00:46-INFO-training batch loss: 0.0074; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 150, Global step 1029:
20-03-23 00:46-INFO-training batch loss: 0.0169; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 151, Global step 1030:
20-03-23 00:46-INFO-training batch loss: 0.0036; avg_loss: 0.0182
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 152, Global step 1031:
20-03-23 00:46-INFO-training batch loss: 0.0360; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 153, Global step 1032:
20-03-23 00:46-INFO-training batch loss: 0.0060; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 154, Global step 1033:
20-03-23 00:46-INFO-training batch loss: 0.0114; avg_loss: 0.0182
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 155, Global step 1034:
20-03-23 00:46-INFO-training batch loss: 0.0295; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 156, Global step 1035:
20-03-23 00:46-INFO-training batch loss: 0.0233; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 0.9922; avg_acc: 0.9942
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 157, Global step 1036:
20-03-23 00:46-INFO-training batch loss: 0.0073; avg_loss: 0.0183
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 158, Global step 1037:
20-03-23 00:46-INFO-training batch loss: 0.0082; avg_loss: 0.0182
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 159, Global step 1038:
20-03-23 00:46-INFO-training batch loss: 0.0083; avg_loss: 0.0181
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 160, Global step 1039:
20-03-23 00:46-INFO-training batch loss: 0.0076; avg_loss: 0.0181
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:46-INFO-
20-03-23 00:46-INFO-Epoch 3, Batch 161, Global step 1040:
20-03-23 00:46-INFO-training batch loss: 0.0065; avg_loss: 0.0180
20-03-23 00:46-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:46-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 162, Global step 1041:
20-03-23 00:47-INFO-training batch loss: 0.0195; avg_loss: 0.0180
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 163, Global step 1042:
20-03-23 00:47-INFO-training batch loss: 0.0076; avg_loss: 0.0179
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 164, Global step 1043:
20-03-23 00:47-INFO-training batch loss: 0.0043; avg_loss: 0.0179
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 165, Global step 1044:
20-03-23 00:47-INFO-training batch loss: 0.0062; avg_loss: 0.0178
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 166, Global step 1045:
20-03-23 00:47-INFO-training batch loss: 0.0279; avg_loss: 0.0178
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 167, Global step 1046:
20-03-23 00:47-INFO-training batch loss: 0.0340; avg_loss: 0.0179
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 168, Global step 1047:
20-03-23 00:47-INFO-training batch loss: 0.0143; avg_loss: 0.0179
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 169, Global step 1048:
20-03-23 00:47-INFO-training batch loss: 0.0026; avg_loss: 0.0178
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 170, Global step 1049:
20-03-23 00:47-INFO-training batch loss: 0.0022; avg_loss: 0.0177
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 171, Global step 1050:
20-03-23 00:47-INFO-training batch loss: 0.0105; avg_loss: 0.0177
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 172, Global step 1051:
20-03-23 00:47-INFO-training batch loss: 0.0022; avg_loss: 0.0176
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 173, Global step 1052:
20-03-23 00:47-INFO-training batch loss: 0.0009; avg_loss: 0.0175
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 174, Global step 1053:
20-03-23 00:47-INFO-training batch loss: 0.0090; avg_loss: 0.0175
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 175, Global step 1054:
20-03-23 00:47-INFO-training batch loss: 0.0030; avg_loss: 0.0174
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 176, Global step 1055:
20-03-23 00:47-INFO-training batch loss: 0.0058; avg_loss: 0.0173
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 177, Global step 1056:
20-03-23 00:47-INFO-training batch loss: 0.0020; avg_loss: 0.0172
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 178, Global step 1057:
20-03-23 00:47-INFO-training batch loss: 0.0416; avg_loss: 0.0174
20-03-23 00:47-INFO-training batch acc: 0.9844; avg_acc: 0.9946
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 179, Global step 1058:
20-03-23 00:47-INFO-training batch loss: 0.0076; avg_loss: 0.0173
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 180, Global step 1059:
20-03-23 00:47-INFO-training batch loss: 0.0006; avg_loss: 0.0172
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 181, Global step 1060:
20-03-23 00:47-INFO-training batch loss: 0.0017; avg_loss: 0.0171
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 182, Global step 1061:
20-03-23 00:47-INFO-training batch loss: 0.0091; avg_loss: 0.0171
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 183, Global step 1062:
20-03-23 00:47-INFO-training batch loss: 0.0019; avg_loss: 0.0170
20-03-23 00:47-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 184, Global step 1063:
20-03-23 00:47-INFO-training batch loss: 0.0260; avg_loss: 0.0171
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 185, Global step 1064:
20-03-23 00:47-INFO-training batch loss: 0.0192; avg_loss: 0.0171
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 186, Global step 1065:
20-03-23 00:47-INFO-training batch loss: 0.0247; avg_loss: 0.0171
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:47-INFO-Epoch 3, Batch 187, Global step 1066:
20-03-23 00:47-INFO-training batch loss: 0.0425; avg_loss: 0.0172
20-03-23 00:47-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:47-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 188, Global step 1067:
20-03-23 00:48-INFO-training batch loss: 0.0048; avg_loss: 0.0172
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 189, Global step 1068:
20-03-23 00:48-INFO-training batch loss: 0.0019; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 190, Global step 1069:
20-03-23 00:48-INFO-training batch loss: 0.0120; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 191, Global step 1070:
20-03-23 00:48-INFO-training batch loss: 0.0239; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 192, Global step 1071:
20-03-23 00:48-INFO-training batch loss: 0.0035; avg_loss: 0.0170
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 193, Global step 1072:
20-03-23 00:48-INFO-training batch loss: 0.0063; avg_loss: 0.0170
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 194, Global step 1073:
20-03-23 00:48-INFO-training batch loss: 0.0035; avg_loss: 0.0169
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 195, Global step 1074:
20-03-23 00:48-INFO-training batch loss: 0.0104; avg_loss: 0.0169
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 196, Global step 1075:
20-03-23 00:48-INFO-training batch loss: 0.0214; avg_loss: 0.0169
20-03-23 00:48-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 197, Global step 1076:
20-03-23 00:48-INFO-training batch loss: 0.0048; avg_loss: 0.0168
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 198, Global step 1077:
20-03-23 00:48-INFO-training batch loss: 0.0035; avg_loss: 0.0168
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 199, Global step 1078:
20-03-23 00:48-INFO-training batch loss: 0.0142; avg_loss: 0.0168
20-03-23 00:48-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 200, Global step 1079:
20-03-23 00:48-INFO-training batch loss: 0.0115; avg_loss: 0.0167
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 201, Global step 1080:
20-03-23 00:48-INFO-training batch loss: 0.0123; avg_loss: 0.0167
20-03-23 00:48-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 202, Global step 1081:
20-03-23 00:48-INFO-training batch loss: 0.0288; avg_loss: 0.0168
20-03-23 00:48-INFO-training batch acc: 0.9844; avg_acc: 0.9948
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 203, Global step 1082:
20-03-23 00:48-INFO-training batch loss: 0.0303; avg_loss: 0.0168
20-03-23 00:48-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 204, Global step 1083:
20-03-23 00:48-INFO-training batch loss: 0.0528; avg_loss: 0.0170
20-03-23 00:48-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 205, Global step 1084:
20-03-23 00:48-INFO-training batch loss: 0.0318; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 0.9844; avg_acc: 0.9946
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 206, Global step 1085:
20-03-23 00:48-INFO-training batch loss: 0.0174; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 207, Global step 1086:
20-03-23 00:48-INFO-training batch loss: 0.0107; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 208, Global step 1087:
20-03-23 00:48-INFO-training batch loss: 0.0340; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 0.9844; avg_acc: 0.9946
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 209, Global step 1088:
20-03-23 00:48-INFO-training batch loss: 0.0044; avg_loss: 0.0171
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 210, Global step 1089:
20-03-23 00:48-INFO-training batch loss: 0.0076; avg_loss: 0.0170
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 211, Global step 1090:
20-03-23 00:48-INFO-training batch loss: 0.0082; avg_loss: 0.0170
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:48-INFO-Epoch 3, Batch 212, Global step 1091:
20-03-23 00:48-INFO-training batch loss: 0.0027; avg_loss: 0.0169
20-03-23 00:48-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:48-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 213, Global step 1092:
20-03-23 00:49-INFO-training batch loss: 0.0023; avg_loss: 0.0169
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 214, Global step 1093:
20-03-23 00:49-INFO-training batch loss: 0.0142; avg_loss: 0.0168
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 215, Global step 1094:
20-03-23 00:49-INFO-training batch loss: 0.0081; avg_loss: 0.0168
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 216, Global step 1095:
20-03-23 00:49-INFO-training batch loss: 0.0050; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 217, Global step 1096:
20-03-23 00:49-INFO-training batch loss: 0.0139; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 218, Global step 1097:
20-03-23 00:49-INFO-training batch loss: 0.0236; avg_loss: 0.0168
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 219, Global step 1098:
20-03-23 00:49-INFO-training batch loss: 0.0380; avg_loss: 0.0169
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 220, Global step 1099:
20-03-23 00:49-INFO-training batch loss: 0.0126; avg_loss: 0.0168
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 221, Global step 1100:
20-03-23 00:49-INFO-training batch loss: 0.0145; avg_loss: 0.0168
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 222, Global step 1101:
20-03-23 00:49-INFO-training batch loss: 0.0409; avg_loss: 0.0169
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 223, Global step 1102:
20-03-23 00:49-INFO-training batch loss: 0.0032; avg_loss: 0.0169
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 224, Global step 1103:
20-03-23 00:49-INFO-training batch loss: 0.0019; avg_loss: 0.0168
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 225, Global step 1104:
20-03-23 00:49-INFO-training batch loss: 0.0034; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 226, Global step 1105:
20-03-23 00:49-INFO-training batch loss: 0.0070; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 227, Global step 1106:
20-03-23 00:49-INFO-training batch loss: 0.0046; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 228, Global step 1107:
20-03-23 00:49-INFO-training batch loss: 0.0206; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 229, Global step 1108:
20-03-23 00:49-INFO-training batch loss: 0.0033; avg_loss: 0.0166
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 230, Global step 1109:
20-03-23 00:49-INFO-training batch loss: 0.0035; avg_loss: 0.0166
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 231, Global step 1110:
20-03-23 00:49-INFO-training batch loss: 0.0148; avg_loss: 0.0165
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 232, Global step 1111:
20-03-23 00:49-INFO-training batch loss: 0.0126; avg_loss: 0.0165
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 233, Global step 1112:
20-03-23 00:49-INFO-training batch loss: 0.0115; avg_loss: 0.0165
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 234, Global step 1113:
20-03-23 00:49-INFO-training batch loss: 0.0030; avg_loss: 0.0165
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 235, Global step 1114:
20-03-23 00:49-INFO-training batch loss: 0.0759; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 0.9844; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 236, Global step 1115:
20-03-23 00:49-INFO-training batch loss: 0.0114; avg_loss: 0.0167
20-03-23 00:49-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 237, Global step 1116:
20-03-23 00:49-INFO-training batch loss: 0.0037; avg_loss: 0.0166
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:49-INFO-Epoch 3, Batch 238, Global step 1117:
20-03-23 00:49-INFO-training batch loss: 0.0013; avg_loss: 0.0166
20-03-23 00:49-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:49-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 239, Global step 1118:
20-03-23 00:50-INFO-training batch loss: 0.0027; avg_loss: 0.0165
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 240, Global step 1119:
20-03-23 00:50-INFO-training batch loss: 0.0024; avg_loss: 0.0164
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 241, Global step 1120:
20-03-23 00:50-INFO-training batch loss: 0.0035; avg_loss: 0.0164
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 242, Global step 1121:
20-03-23 00:50-INFO-training batch loss: 0.0030; avg_loss: 0.0163
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9950
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 243, Global step 1122:
20-03-23 00:50-INFO-training batch loss: 0.0499; avg_loss: 0.0165
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9950
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 244, Global step 1123:
20-03-23 00:50-INFO-training batch loss: 0.0371; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9844; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 245, Global step 1124:
20-03-23 00:50-INFO-training batch loss: 0.0038; avg_loss: 0.0165
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 246, Global step 1125:
20-03-23 00:50-INFO-training batch loss: 0.0024; avg_loss: 0.0164
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9950
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 247, Global step 1126:
20-03-23 00:50-INFO-training batch loss: 0.0445; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 248, Global step 1127:
20-03-23 00:50-INFO-training batch loss: 0.0425; avg_loss: 0.0167
20-03-23 00:50-INFO-training batch acc: 0.9766; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 249, Global step 1128:
20-03-23 00:50-INFO-training batch loss: 0.0249; avg_loss: 0.0167
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 250, Global step 1129:
20-03-23 00:50-INFO-training batch loss: 0.0013; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 251, Global step 1130:
20-03-23 00:50-INFO-training batch loss: 0.0012; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 252, Global step 1131:
20-03-23 00:50-INFO-training batch loss: 0.0055; avg_loss: 0.0165
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 253, Global step 1132:
20-03-23 00:50-INFO-training batch loss: 0.0396; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9844; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 254, Global step 1133:
20-03-23 00:50-INFO-training batch loss: 0.0013; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 255, Global step 1134:
20-03-23 00:50-INFO-training batch loss: 0.0128; avg_loss: 0.0165
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 256, Global step 1135:
20-03-23 00:50-INFO-training batch loss: 0.0230; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 257, Global step 1136:
20-03-23 00:50-INFO-training batch loss: 0.0207; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 258, Global step 1137:
20-03-23 00:50-INFO-training batch loss: 0.0196; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 259, Global step 1138:
20-03-23 00:50-INFO-training batch loss: 0.0162; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 260, Global step 1139:
20-03-23 00:50-INFO-training batch loss: 0.0013; avg_loss: 0.0165
20-03-23 00:50-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 261, Global step 1140:
20-03-23 00:50-INFO-training batch loss: 0.0433; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9844; avg_acc: 0.9948
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 262, Global step 1141:
20-03-23 00:50-INFO-training batch loss: 0.0111; avg_loss: 0.0166
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 263, Global step 1142:
20-03-23 00:50-INFO-training batch loss: 0.0608; avg_loss: 0.0168
20-03-23 00:50-INFO-training batch acc: 0.9844; avg_acc: 0.9948
20-03-23 00:50-INFO-
20-03-23 00:50-INFO-Epoch 3, Batch 264, Global step 1143:
20-03-23 00:50-INFO-training batch loss: 0.0245; avg_loss: 0.0168
20-03-23 00:50-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:50-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 265, Global step 1144:
20-03-23 00:51-INFO-training batch loss: 0.0074; avg_loss: 0.0168
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 266, Global step 1145:
20-03-23 00:51-INFO-training batch loss: 0.0377; avg_loss: 0.0169
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 267, Global step 1146:
20-03-23 00:51-INFO-training batch loss: 0.0790; avg_loss: 0.0171
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 268, Global step 1147:
20-03-23 00:51-INFO-training batch loss: 0.0077; avg_loss: 0.0171
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 269, Global step 1148:
20-03-23 00:51-INFO-training batch loss: 0.0197; avg_loss: 0.0171
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 270, Global step 1149:
20-03-23 00:51-INFO-training batch loss: 0.0563; avg_loss: 0.0172
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 271, Global step 1150:
20-03-23 00:51-INFO-training batch loss: 0.0020; avg_loss: 0.0172
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 272, Global step 1151:
20-03-23 00:51-INFO-training batch loss: 0.0297; avg_loss: 0.0172
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 273, Global step 1152:
20-03-23 00:51-INFO-training batch loss: 0.0039; avg_loss: 0.0172
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 274, Global step 1153:
20-03-23 00:51-INFO-training batch loss: 0.0090; avg_loss: 0.0171
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 275, Global step 1154:
20-03-23 00:51-INFO-training batch loss: 0.0320; avg_loss: 0.0172
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 276, Global step 1155:
20-03-23 00:51-INFO-training batch loss: 0.0406; avg_loss: 0.0173
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 277, Global step 1156:
20-03-23 00:51-INFO-training batch loss: 0.0160; avg_loss: 0.0173
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 278, Global step 1157:
20-03-23 00:51-INFO-training batch loss: 0.0117; avg_loss: 0.0172
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 279, Global step 1158:
20-03-23 00:51-INFO-training batch loss: 0.0450; avg_loss: 0.0173
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 280, Global step 1159:
20-03-23 00:51-INFO-training batch loss: 0.0042; avg_loss: 0.0173
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 281, Global step 1160:
20-03-23 00:51-INFO-training batch loss: 0.0255; avg_loss: 0.0173
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 282, Global step 1161:
20-03-23 00:51-INFO-training batch loss: 0.0444; avg_loss: 0.0174
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 283, Global step 1162:
20-03-23 00:51-INFO-training batch loss: 0.0508; avg_loss: 0.0175
20-03-23 00:51-INFO-training batch acc: 0.9844; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 284, Global step 1163:
20-03-23 00:51-INFO-training batch loss: 0.0084; avg_loss: 0.0175
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 285, Global step 1164:
20-03-23 00:51-INFO-training batch loss: 0.0019; avg_loss: 0.0175
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 286, Global step 1165:
20-03-23 00:51-INFO-training batch loss: 0.0069; avg_loss: 0.0174
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 287, Global step 1166:
20-03-23 00:51-INFO-training batch loss: 0.0113; avg_loss: 0.0174
20-03-23 00:51-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 288, Global step 1167:
20-03-23 00:51-INFO-training batch loss: 0.0053; avg_loss: 0.0174
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:51-INFO-Epoch 3, Batch 289, Global step 1168:
20-03-23 00:51-INFO-training batch loss: 0.0087; avg_loss: 0.0173
20-03-23 00:51-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:51-INFO-
20-03-23 00:52-INFO-Epoch 3, Batch 290, Global step 1169:
20-03-23 00:52-INFO-training batch loss: 0.0494; avg_loss: 0.0174
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 3, Batch 291, Global step 1170:
20-03-23 00:52-INFO-training batch loss: 0.0421; avg_loss: 0.0175
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9946
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 3, Batch 292, Global step 1171:
20-03-23 00:52-INFO-training batch loss: 0.0028; avg_loss: 0.0175
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 3, Batch 293, Global step 1172:
20-03-23 00:52-INFO-training batch loss: 0.0036; avg_loss: 0.0174
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 3, training batch loss: 0.0036; avg_loss: 0.0174
20-03-23 00:52-INFO-Epoch 3, training batch accuracy: 1.0000; avg_accuracy: 0.9946
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 3, evaluating batch loss: 0.6248; avg_loss: 0.4756
20-03-23 00:52-INFO-Epoch 3, evaluating batch accuracy: 0.8571; avg_accuracy: 0.8881
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 1, Global step 1173:
20-03-23 00:52-INFO-training batch loss: 0.0085; avg_loss: 0.0085
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 2, Global step 1174:
20-03-23 00:52-INFO-training batch loss: 0.0323; avg_loss: 0.0204
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9961
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 3, Global step 1175:
20-03-23 00:52-INFO-training batch loss: 0.0321; avg_loss: 0.0243
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9948
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 4, Global step 1176:
20-03-23 00:52-INFO-training batch loss: 0.0273; avg_loss: 0.0251
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 5, Global step 1177:
20-03-23 00:52-INFO-training batch loss: 0.0234; avg_loss: 0.0247
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 6, Global step 1178:
20-03-23 00:52-INFO-training batch loss: 0.0238; avg_loss: 0.0246
20-03-23 00:52-INFO-training batch acc: 0.9766; avg_acc: 0.9909
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 7, Global step 1179:
20-03-23 00:52-INFO-training batch loss: 0.0032; avg_loss: 0.0215
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 8, Global step 1180:
20-03-23 00:52-INFO-training batch loss: 0.0721; avg_loss: 0.0278
20-03-23 00:52-INFO-training batch acc: 0.9844; avg_acc: 0.9912
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 9, Global step 1181:
20-03-23 00:52-INFO-training batch loss: 0.0400; avg_loss: 0.0292
20-03-23 00:52-INFO-training batch acc: 0.9766; avg_acc: 0.9896
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 10, Global step 1182:
20-03-23 00:52-INFO-training batch loss: 0.0127; avg_loss: 0.0275
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9898
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 11, Global step 1183:
20-03-23 00:52-INFO-training batch loss: 0.0722; avg_loss: 0.0316
20-03-23 00:52-INFO-training batch acc: 0.9766; avg_acc: 0.9886
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 12, Global step 1184:
20-03-23 00:52-INFO-training batch loss: 0.0100; avg_loss: 0.0298
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9896
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 13, Global step 1185:
20-03-23 00:52-INFO-training batch loss: 0.0292; avg_loss: 0.0297
20-03-23 00:52-INFO-training batch acc: 0.9844; avg_acc: 0.9892
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 14, Global step 1186:
20-03-23 00:52-INFO-training batch loss: 0.0827; avg_loss: 0.0335
20-03-23 00:52-INFO-training batch acc: 0.9844; avg_acc: 0.9888
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 15, Global step 1187:
20-03-23 00:52-INFO-training batch loss: 0.0151; avg_loss: 0.0323
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9891
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 16, Global step 1188:
20-03-23 00:52-INFO-training batch loss: 0.0074; avg_loss: 0.0307
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9897
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 17, Global step 1189:
20-03-23 00:52-INFO-training batch loss: 0.0562; avg_loss: 0.0322
20-03-23 00:52-INFO-training batch acc: 0.9922; avg_acc: 0.9899
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 18, Global step 1190:
20-03-23 00:52-INFO-training batch loss: 0.0116; avg_loss: 0.0311
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9905
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 19, Global step 1191:
20-03-23 00:52-INFO-training batch loss: 0.0420; avg_loss: 0.0317
20-03-23 00:52-INFO-training batch acc: 0.9766; avg_acc: 0.9897
20-03-23 00:52-INFO-
20-03-23 00:52-INFO-Epoch 4, Batch 20, Global step 1192:
20-03-23 00:52-INFO-training batch loss: 0.0043; avg_loss: 0.0303
20-03-23 00:52-INFO-training batch acc: 1.0000; avg_acc: 0.9902
20-03-23 00:52-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 21, Global step 1193:
20-03-23 00:53-INFO-training batch loss: 0.0035; avg_loss: 0.0290
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9907
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 22, Global step 1194:
20-03-23 00:53-INFO-training batch loss: 0.0621; avg_loss: 0.0305
20-03-23 00:53-INFO-training batch acc: 0.9844; avg_acc: 0.9904
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 23, Global step 1195:
20-03-23 00:53-INFO-training batch loss: 0.0465; avg_loss: 0.0312
20-03-23 00:53-INFO-training batch acc: 0.9922; avg_acc: 0.9905
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 24, Global step 1196:
20-03-23 00:53-INFO-training batch loss: 0.0040; avg_loss: 0.0301
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9909
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 25, Global step 1197:
20-03-23 00:53-INFO-training batch loss: 0.0166; avg_loss: 0.0295
20-03-23 00:53-INFO-training batch acc: 0.9922; avg_acc: 0.9909
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 26, Global step 1198:
20-03-23 00:53-INFO-training batch loss: 0.0159; avg_loss: 0.0290
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9913
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 27, Global step 1199:
20-03-23 00:53-INFO-training batch loss: 0.0670; avg_loss: 0.0304
20-03-23 00:53-INFO-training batch acc: 0.9766; avg_acc: 0.9907
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 28, Global step 1200:
20-03-23 00:53-INFO-training batch loss: 0.0184; avg_loss: 0.0300
20-03-23 00:53-INFO-training batch acc: 0.9922; avg_acc: 0.9908
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 29, Global step 1201:
20-03-23 00:53-INFO-training batch loss: 0.0139; avg_loss: 0.0294
20-03-23 00:53-INFO-training batch acc: 0.9922; avg_acc: 0.9908
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 30, Global step 1202:
20-03-23 00:53-INFO-training batch loss: 0.0142; avg_loss: 0.0289
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9911
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 31, Global step 1203:
20-03-23 00:53-INFO-training batch loss: 0.0645; avg_loss: 0.0301
20-03-23 00:53-INFO-training batch acc: 0.9922; avg_acc: 0.9912
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 32, Global step 1204:
20-03-23 00:53-INFO-training batch loss: 0.0080; avg_loss: 0.0294
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 33, Global step 1205:
20-03-23 00:53-INFO-training batch loss: 0.0038; avg_loss: 0.0286
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 34, Global step 1206:
20-03-23 00:53-INFO-training batch loss: 0.0043; avg_loss: 0.0279
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 35, Global step 1207:
20-03-23 00:53-INFO-training batch loss: 0.0033; avg_loss: 0.0272
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 36, Global step 1208:
20-03-23 00:53-INFO-training batch loss: 0.0944; avg_loss: 0.0291
20-03-23 00:53-INFO-training batch acc: 0.9688; avg_acc: 0.9915
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 37, Global step 1209:
20-03-23 00:53-INFO-training batch loss: 0.0610; avg_loss: 0.0299
20-03-23 00:53-INFO-training batch acc: 0.9844; avg_acc: 0.9913
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 38, Global step 1210:
20-03-23 00:53-INFO-training batch loss: 0.0034; avg_loss: 0.0292
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 39, Global step 1211:
20-03-23 00:53-INFO-training batch loss: 0.0018; avg_loss: 0.0285
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 40, Global step 1212:
20-03-23 00:53-INFO-training batch loss: 0.0042; avg_loss: 0.0279
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 41, Global step 1213:
20-03-23 00:53-INFO-training batch loss: 0.0143; avg_loss: 0.0276
20-03-23 00:53-INFO-training batch acc: 0.9922; avg_acc: 0.9920
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 42, Global step 1214:
20-03-23 00:53-INFO-training batch loss: 0.0031; avg_loss: 0.0270
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 43, Global step 1215:
20-03-23 00:53-INFO-training batch loss: 0.0083; avg_loss: 0.0266
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 44, Global step 1216:
20-03-23 00:53-INFO-training batch loss: 0.0199; avg_loss: 0.0264
20-03-23 00:53-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 45, Global step 1217:
20-03-23 00:53-INFO-training batch loss: 0.0038; avg_loss: 0.0259
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 00:53-INFO-
20-03-23 00:53-INFO-Epoch 4, Batch 46, Global step 1218:
20-03-23 00:53-INFO-training batch loss: 0.0029; avg_loss: 0.0254
20-03-23 00:53-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 00:53-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 47, Global step 1219:
20-03-23 00:54-INFO-training batch loss: 0.0044; avg_loss: 0.0250
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 48, Global step 1220:
20-03-23 00:54-INFO-training batch loss: 0.0037; avg_loss: 0.0245
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 49, Global step 1221:
20-03-23 00:54-INFO-training batch loss: 0.0054; avg_loss: 0.0241
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9930
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 50, Global step 1222:
20-03-23 00:54-INFO-training batch loss: 0.0058; avg_loss: 0.0238
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9931
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 51, Global step 1223:
20-03-23 00:54-INFO-training batch loss: 0.0134; avg_loss: 0.0236
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9933
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 52, Global step 1224:
20-03-23 00:54-INFO-training batch loss: 0.0117; avg_loss: 0.0233
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9932
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 53, Global step 1225:
20-03-23 00:54-INFO-training batch loss: 0.0128; avg_loss: 0.0231
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9932
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 54, Global step 1226:
20-03-23 00:54-INFO-training batch loss: 0.0040; avg_loss: 0.0228
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9933
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 55, Global step 1227:
20-03-23 00:54-INFO-training batch loss: 0.0112; avg_loss: 0.0226
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9935
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 56, Global step 1228:
20-03-23 00:54-INFO-training batch loss: 0.0244; avg_loss: 0.0226
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9934
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 57, Global step 1229:
20-03-23 00:54-INFO-training batch loss: 0.0051; avg_loss: 0.0223
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9936
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 58, Global step 1230:
20-03-23 00:54-INFO-training batch loss: 0.0053; avg_loss: 0.0220
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9937
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 59, Global step 1231:
20-03-23 00:54-INFO-training batch loss: 0.0035; avg_loss: 0.0217
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 60, Global step 1232:
20-03-23 00:54-INFO-training batch loss: 0.0145; avg_loss: 0.0216
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9938
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 61, Global step 1233:
20-03-23 00:54-INFO-training batch loss: 0.0038; avg_loss: 0.0213
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 62, Global step 1234:
20-03-23 00:54-INFO-training batch loss: 0.0018; avg_loss: 0.0210
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 63, Global step 1235:
20-03-23 00:54-INFO-training batch loss: 0.0027; avg_loss: 0.0207
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 64, Global step 1236:
20-03-23 00:54-INFO-training batch loss: 0.0075; avg_loss: 0.0205
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 65, Global step 1237:
20-03-23 00:54-INFO-training batch loss: 0.0487; avg_loss: 0.0209
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 66, Global step 1238:
20-03-23 00:54-INFO-training batch loss: 0.0069; avg_loss: 0.0207
20-03-23 00:54-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 67, Global step 1239:
20-03-23 00:54-INFO-training batch loss: 0.0175; avg_loss: 0.0206
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9942
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 68, Global step 1240:
20-03-23 00:54-INFO-training batch loss: 0.0147; avg_loss: 0.0206
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9941
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 69, Global step 1241:
20-03-23 00:54-INFO-training batch loss: 0.0395; avg_loss: 0.0208
20-03-23 00:54-INFO-training batch acc: 0.9844; avg_acc: 0.9940
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 70, Global step 1242:
20-03-23 00:54-INFO-training batch loss: 0.0132; avg_loss: 0.0207
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9940
20-03-23 00:54-INFO-
20-03-23 00:54-INFO-Epoch 4, Batch 71, Global step 1243:
20-03-23 00:54-INFO-training batch loss: 0.0321; avg_loss: 0.0209
20-03-23 00:54-INFO-training batch acc: 0.9922; avg_acc: 0.9939
20-03-23 00:54-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 72, Global step 1244:
20-03-23 00:55-INFO-training batch loss: 0.0026; avg_loss: 0.0206
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 73, Global step 1245:
20-03-23 00:55-INFO-training batch loss: 0.0089; avg_loss: 0.0205
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 74, Global step 1246:
20-03-23 00:55-INFO-training batch loss: 0.0059; avg_loss: 0.0203
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 75, Global step 1247:
20-03-23 00:55-INFO-training batch loss: 0.0342; avg_loss: 0.0205
20-03-23 00:55-INFO-training batch acc: 0.9922; avg_acc: 0.9942
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 76, Global step 1248:
20-03-23 00:55-INFO-training batch loss: 0.0058; avg_loss: 0.0203
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 77, Global step 1249:
20-03-23 00:55-INFO-training batch loss: 0.0034; avg_loss: 0.0200
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 78, Global step 1250:
20-03-23 00:55-INFO-training batch loss: 0.0126; avg_loss: 0.0199
20-03-23 00:55-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 79, Global step 1251:
20-03-23 00:55-INFO-training batch loss: 0.0018; avg_loss: 0.0197
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 80, Global step 1252:
20-03-23 00:55-INFO-training batch loss: 0.0171; avg_loss: 0.0197
20-03-23 00:55-INFO-training batch acc: 0.9922; avg_acc: 0.9943
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 81, Global step 1253:
20-03-23 00:55-INFO-training batch loss: 0.0035; avg_loss: 0.0195
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 82, Global step 1254:
20-03-23 00:55-INFO-training batch loss: 0.0111; avg_loss: 0.0194
20-03-23 00:55-INFO-training batch acc: 0.9922; avg_acc: 0.9944
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 83, Global step 1255:
20-03-23 00:55-INFO-training batch loss: 0.0015; avg_loss: 0.0192
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 84, Global step 1256:
20-03-23 00:55-INFO-training batch loss: 0.0012; avg_loss: 0.0190
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 85, Global step 1257:
20-03-23 00:55-INFO-training batch loss: 0.0033; avg_loss: 0.0188
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 86, Global step 1258:
20-03-23 00:55-INFO-training batch loss: 0.0026; avg_loss: 0.0186
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 87, Global step 1259:
20-03-23 00:55-INFO-training batch loss: 0.0036; avg_loss: 0.0184
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 88, Global step 1260:
20-03-23 00:55-INFO-training batch loss: 0.0221; avg_loss: 0.0185
20-03-23 00:55-INFO-training batch acc: 0.9922; avg_acc: 0.9947
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 89, Global step 1261:
20-03-23 00:55-INFO-training batch loss: 0.0058; avg_loss: 0.0183
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 90, Global step 1262:
20-03-23 00:55-INFO-training batch loss: 0.0030; avg_loss: 0.0181
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 91, Global step 1263:
20-03-23 00:55-INFO-training batch loss: 0.0064; avg_loss: 0.0180
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9948
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 92, Global step 1264:
20-03-23 00:55-INFO-training batch loss: 0.0057; avg_loss: 0.0179
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9949
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 93, Global step 1265:
20-03-23 00:55-INFO-training batch loss: 0.0017; avg_loss: 0.0177
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9950
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 94, Global step 1266:
20-03-23 00:55-INFO-training batch loss: 0.0018; avg_loss: 0.0175
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9950
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 95, Global step 1267:
20-03-23 00:55-INFO-training batch loss: 0.0030; avg_loss: 0.0174
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9951
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 96, Global step 1268:
20-03-23 00:55-INFO-training batch loss: 0.0077; avg_loss: 0.0173
20-03-23 00:55-INFO-training batch acc: 0.9922; avg_acc: 0.9950
20-03-23 00:55-INFO-
20-03-23 00:55-INFO-Epoch 4, Batch 97, Global step 1269:
20-03-23 00:55-INFO-training batch loss: 0.0064; avg_loss: 0.0172
20-03-23 00:55-INFO-training batch acc: 1.0000; avg_acc: 0.9951
20-03-23 00:55-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 98, Global step 1270:
20-03-23 00:56-INFO-training batch loss: 0.0068; avg_loss: 0.0171
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9951
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 99, Global step 1271:
20-03-23 00:56-INFO-training batch loss: 0.0042; avg_loss: 0.0169
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 100, Global step 1272:
20-03-23 00:56-INFO-training batch loss: 0.0014; avg_loss: 0.0168
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 101, Global step 1273:
20-03-23 00:56-INFO-training batch loss: 0.0349; avg_loss: 0.0170
20-03-23 00:56-INFO-training batch acc: 0.9844; avg_acc: 0.9951
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 102, Global step 1274:
20-03-23 00:56-INFO-training batch loss: 0.0024; avg_loss: 0.0168
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 103, Global step 1275:
20-03-23 00:56-INFO-training batch loss: 0.0077; avg_loss: 0.0167
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 104, Global step 1276:
20-03-23 00:56-INFO-training batch loss: 0.0100; avg_loss: 0.0167
20-03-23 00:56-INFO-training batch acc: 0.9922; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 105, Global step 1277:
20-03-23 00:56-INFO-training batch loss: 0.0046; avg_loss: 0.0165
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 106, Global step 1278:
20-03-23 00:56-INFO-training batch loss: 0.0047; avg_loss: 0.0164
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 107, Global step 1279:
20-03-23 00:56-INFO-training batch loss: 0.0025; avg_loss: 0.0163
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 108, Global step 1280:
20-03-23 00:56-INFO-training batch loss: 0.0059; avg_loss: 0.0162
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 109, Global step 1281:
20-03-23 00:56-INFO-training batch loss: 0.0094; avg_loss: 0.0161
20-03-23 00:56-INFO-training batch acc: 0.9922; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 110, Global step 1282:
20-03-23 00:56-INFO-training batch loss: 0.0318; avg_loss: 0.0163
20-03-23 00:56-INFO-training batch acc: 0.9844; avg_acc: 0.9952
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 111, Global step 1283:
20-03-23 00:56-INFO-training batch loss: 0.0024; avg_loss: 0.0162
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 112, Global step 1284:
20-03-23 00:56-INFO-training batch loss: 0.0015; avg_loss: 0.0160
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 113, Global step 1285:
20-03-23 00:56-INFO-training batch loss: 0.0032; avg_loss: 0.0159
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 114, Global step 1286:
20-03-23 00:56-INFO-training batch loss: 0.0151; avg_loss: 0.0159
20-03-23 00:56-INFO-training batch acc: 0.9922; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 115, Global step 1287:
20-03-23 00:56-INFO-training batch loss: 0.0029; avg_loss: 0.0158
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 116, Global step 1288:
20-03-23 00:56-INFO-training batch loss: 0.0039; avg_loss: 0.0157
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 117, Global step 1289:
20-03-23 00:56-INFO-training batch loss: 0.0244; avg_loss: 0.0158
20-03-23 00:56-INFO-training batch acc: 0.9844; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 118, Global step 1290:
20-03-23 00:56-INFO-training batch loss: 0.0015; avg_loss: 0.0156
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 119, Global step 1291:
20-03-23 00:56-INFO-training batch loss: 0.0465; avg_loss: 0.0159
20-03-23 00:56-INFO-training batch acc: 0.9922; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 120, Global step 1292:
20-03-23 00:56-INFO-training batch loss: 0.0021; avg_loss: 0.0158
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 121, Global step 1293:
20-03-23 00:56-INFO-training batch loss: 0.0090; avg_loss: 0.0157
20-03-23 00:56-INFO-training batch acc: 0.9922; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 122, Global step 1294:
20-03-23 00:56-INFO-training batch loss: 0.0505; avg_loss: 0.0160
20-03-23 00:56-INFO-training batch acc: 0.9922; avg_acc: 0.9953
20-03-23 00:56-INFO-
20-03-23 00:56-INFO-Epoch 4, Batch 123, Global step 1295:
20-03-23 00:56-INFO-training batch loss: 0.0023; avg_loss: 0.0159
20-03-23 00:56-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:56-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 124, Global step 1296:
20-03-23 00:57-INFO-training batch loss: 0.0016; avg_loss: 0.0158
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 125, Global step 1297:
20-03-23 00:57-INFO-training batch loss: 0.0085; avg_loss: 0.0157
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 126, Global step 1298:
20-03-23 00:57-INFO-training batch loss: 0.0140; avg_loss: 0.0157
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 127, Global step 1299:
20-03-23 00:57-INFO-training batch loss: 0.0076; avg_loss: 0.0157
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 128, Global step 1300:
20-03-23 00:57-INFO-training batch loss: 0.0126; avg_loss: 0.0156
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 129, Global step 1301:
20-03-23 00:57-INFO-training batch loss: 0.0184; avg_loss: 0.0157
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9953
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 130, Global step 1302:
20-03-23 00:57-INFO-training batch loss: 0.0017; avg_loss: 0.0155
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 131, Global step 1303:
20-03-23 00:57-INFO-training batch loss: 0.0009; avg_loss: 0.0154
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 132, Global step 1304:
20-03-23 00:57-INFO-training batch loss: 0.0011; avg_loss: 0.0153
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9954
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 133, Global step 1305:
20-03-23 00:57-INFO-training batch loss: 0.0035; avg_loss: 0.0152
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9955
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 134, Global step 1306:
20-03-23 00:57-INFO-training batch loss: 0.0062; avg_loss: 0.0152
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9955
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 135, Global step 1307:
20-03-23 00:57-INFO-training batch loss: 0.0020; avg_loss: 0.0151
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9955
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 136, Global step 1308:
20-03-23 00:57-INFO-training batch loss: 0.0010; avg_loss: 0.0150
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 137, Global step 1309:
20-03-23 00:57-INFO-training batch loss: 0.0028; avg_loss: 0.0149
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 138, Global step 1310:
20-03-23 00:57-INFO-training batch loss: 0.0466; avg_loss: 0.0151
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 139, Global step 1311:
20-03-23 00:57-INFO-training batch loss: 0.0013; avg_loss: 0.0150
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 140, Global step 1312:
20-03-23 00:57-INFO-training batch loss: 0.0141; avg_loss: 0.0150
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 141, Global step 1313:
20-03-23 00:57-INFO-training batch loss: 0.0019; avg_loss: 0.0149
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 142, Global step 1314:
20-03-23 00:57-INFO-training batch loss: 0.0107; avg_loss: 0.0149
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 143, Global step 1315:
20-03-23 00:57-INFO-training batch loss: 0.0016; avg_loss: 0.0148
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 144, Global step 1316:
20-03-23 00:57-INFO-training batch loss: 0.0204; avg_loss: 0.0148
20-03-23 00:57-INFO-training batch acc: 0.9844; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 145, Global step 1317:
20-03-23 00:57-INFO-training batch loss: 0.0099; avg_loss: 0.0148
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9955
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 146, Global step 1318:
20-03-23 00:57-INFO-training batch loss: 0.0055; avg_loss: 0.0147
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 147, Global step 1319:
20-03-23 00:57-INFO-training batch loss: 0.0326; avg_loss: 0.0149
20-03-23 00:57-INFO-training batch acc: 0.9922; avg_acc: 0.9955
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 148, Global step 1320:
20-03-23 00:57-INFO-training batch loss: 0.0051; avg_loss: 0.0148
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:57-INFO-Epoch 4, Batch 149, Global step 1321:
20-03-23 00:57-INFO-training batch loss: 0.0025; avg_loss: 0.0147
20-03-23 00:57-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:57-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 150, Global step 1322:
20-03-23 00:58-INFO-training batch loss: 0.0042; avg_loss: 0.0146
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 151, Global step 1323:
20-03-23 00:58-INFO-training batch loss: 0.0031; avg_loss: 0.0146
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 152, Global step 1324:
20-03-23 00:58-INFO-training batch loss: 0.0203; avg_loss: 0.0146
20-03-23 00:58-INFO-training batch acc: 0.9844; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 153, Global step 1325:
20-03-23 00:58-INFO-training batch loss: 0.0058; avg_loss: 0.0145
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 154, Global step 1326:
20-03-23 00:58-INFO-training batch loss: 0.0064; avg_loss: 0.0145
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 155, Global step 1327:
20-03-23 00:58-INFO-training batch loss: 0.0194; avg_loss: 0.0145
20-03-23 00:58-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 156, Global step 1328:
20-03-23 00:58-INFO-training batch loss: 0.0199; avg_loss: 0.0145
20-03-23 00:58-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 157, Global step 1329:
20-03-23 00:58-INFO-training batch loss: 0.0027; avg_loss: 0.0145
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 158, Global step 1330:
20-03-23 00:58-INFO-training batch loss: 0.0048; avg_loss: 0.0144
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 159, Global step 1331:
20-03-23 00:58-INFO-training batch loss: 0.0042; avg_loss: 0.0143
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 160, Global step 1332:
20-03-23 00:58-INFO-training batch loss: 0.0085; avg_loss: 0.0143
20-03-23 00:58-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 161, Global step 1333:
20-03-23 00:58-INFO-training batch loss: 0.0057; avg_loss: 0.0143
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 162, Global step 1334:
20-03-23 00:58-INFO-training batch loss: 0.0333; avg_loss: 0.0144
20-03-23 00:58-INFO-training batch acc: 0.9922; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 163, Global step 1335:
20-03-23 00:58-INFO-training batch loss: 0.0123; avg_loss: 0.0144
20-03-23 00:58-INFO-training batch acc: 0.9922; avg_acc: 0.9956
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 164, Global step 1336:
20-03-23 00:58-INFO-training batch loss: 0.0099; avg_loss: 0.0143
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 165, Global step 1337:
20-03-23 00:58-INFO-training batch loss: 0.0036; avg_loss: 0.0143
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 166, Global step 1338:
20-03-23 00:58-INFO-training batch loss: 0.0097; avg_loss: 0.0142
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 167, Global step 1339:
20-03-23 00:58-INFO-training batch loss: 0.0056; avg_loss: 0.0142
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9957
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 168, Global step 1340:
20-03-23 00:58-INFO-training batch loss: 0.0021; avg_loss: 0.0141
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 169, Global step 1341:
20-03-23 00:58-INFO-training batch loss: 0.0009; avg_loss: 0.0140
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 170, Global step 1342:
20-03-23 00:58-INFO-training batch loss: 0.0011; avg_loss: 0.0140
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 171, Global step 1343:
20-03-23 00:58-INFO-training batch loss: 0.0188; avg_loss: 0.0140
20-03-23 00:58-INFO-training batch acc: 0.9922; avg_acc: 0.9958
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 172, Global step 1344:
20-03-23 00:58-INFO-training batch loss: 0.0006; avg_loss: 0.0139
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 173, Global step 1345:
20-03-23 00:58-INFO-training batch loss: 0.0009; avg_loss: 0.0138
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9958
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 174, Global step 1346:
20-03-23 00:58-INFO-training batch loss: 0.0015; avg_loss: 0.0138
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:58-INFO-
20-03-23 00:58-INFO-Epoch 4, Batch 175, Global step 1347:
20-03-23 00:58-INFO-training batch loss: 0.0052; avg_loss: 0.0137
20-03-23 00:58-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:58-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 176, Global step 1348:
20-03-23 00:59-INFO-training batch loss: 0.0010; avg_loss: 0.0136
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 177, Global step 1349:
20-03-23 00:59-INFO-training batch loss: 0.0024; avg_loss: 0.0136
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 178, Global step 1350:
20-03-23 00:59-INFO-training batch loss: 0.0292; avg_loss: 0.0137
20-03-23 00:59-INFO-training batch acc: 0.9844; avg_acc: 0.9959
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 179, Global step 1351:
20-03-23 00:59-INFO-training batch loss: 0.0066; avg_loss: 0.0136
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 180, Global step 1352:
20-03-23 00:59-INFO-training batch loss: 0.0008; avg_loss: 0.0136
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 181, Global step 1353:
20-03-23 00:59-INFO-training batch loss: 0.0034; avg_loss: 0.0135
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9959
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 182, Global step 1354:
20-03-23 00:59-INFO-training batch loss: 0.0021; avg_loss: 0.0134
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 183, Global step 1355:
20-03-23 00:59-INFO-training batch loss: 0.0051; avg_loss: 0.0134
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 184, Global step 1356:
20-03-23 00:59-INFO-training batch loss: 0.0025; avg_loss: 0.0133
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 185, Global step 1357:
20-03-23 00:59-INFO-training batch loss: 0.0032; avg_loss: 0.0133
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9960
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 186, Global step 1358:
20-03-23 00:59-INFO-training batch loss: 0.0016; avg_loss: 0.0132
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 187, Global step 1359:
20-03-23 00:59-INFO-training batch loss: 0.0012; avg_loss: 0.0132
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 188, Global step 1360:
20-03-23 00:59-INFO-training batch loss: 0.0011; avg_loss: 0.0131
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 189, Global step 1361:
20-03-23 00:59-INFO-training batch loss: 0.0010; avg_loss: 0.0130
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 190, Global step 1362:
20-03-23 00:59-INFO-training batch loss: 0.0022; avg_loss: 0.0130
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9961
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 191, Global step 1363:
20-03-23 00:59-INFO-training batch loss: 0.0015; avg_loss: 0.0129
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 192, Global step 1364:
20-03-23 00:59-INFO-training batch loss: 0.0017; avg_loss: 0.0129
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 193, Global step 1365:
20-03-23 00:59-INFO-training batch loss: 0.0009; avg_loss: 0.0128
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 194, Global step 1366:
20-03-23 00:59-INFO-training batch loss: 0.0058; avg_loss: 0.0128
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 195, Global step 1367:
20-03-23 00:59-INFO-training batch loss: 0.0017; avg_loss: 0.0127
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 196, Global step 1368:
20-03-23 00:59-INFO-training batch loss: 0.0018; avg_loss: 0.0126
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 197, Global step 1369:
20-03-23 00:59-INFO-training batch loss: 0.0088; avg_loss: 0.0126
20-03-23 00:59-INFO-training batch acc: 0.9922; avg_acc: 0.9962
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 198, Global step 1370:
20-03-23 00:59-INFO-training batch loss: 0.0017; avg_loss: 0.0126
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 199, Global step 1371:
20-03-23 00:59-INFO-training batch loss: 0.0086; avg_loss: 0.0125
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 200, Global step 1372:
20-03-23 00:59-INFO-training batch loss: 0.0017; avg_loss: 0.0125
20-03-23 00:59-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 00:59-INFO-
20-03-23 00:59-INFO-Epoch 4, Batch 201, Global step 1373:
20-03-23 00:59-INFO-training batch loss: 0.0127; avg_loss: 0.0125
20-03-23 00:59-INFO-training batch acc: 0.9922; avg_acc: 0.9963
20-03-23 00:59-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 202, Global step 1374:
20-03-23 01:00-INFO-training batch loss: 0.0015; avg_loss: 0.0124
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 203, Global step 1375:
20-03-23 01:00-INFO-training batch loss: 0.0110; avg_loss: 0.0124
20-03-23 01:00-INFO-training batch acc: 0.9922; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 204, Global step 1376:
20-03-23 01:00-INFO-training batch loss: 0.0164; avg_loss: 0.0125
20-03-23 01:00-INFO-training batch acc: 0.9922; avg_acc: 0.9962
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 205, Global step 1377:
20-03-23 01:00-INFO-training batch loss: 0.0085; avg_loss: 0.0124
20-03-23 01:00-INFO-training batch acc: 0.9922; avg_acc: 0.9962
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 206, Global step 1378:
20-03-23 01:00-INFO-training batch loss: 0.0034; avg_loss: 0.0124
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9962
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 207, Global step 1379:
20-03-23 01:00-INFO-training batch loss: 0.0016; avg_loss: 0.0123
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 208, Global step 1380:
20-03-23 01:00-INFO-training batch loss: 0.0050; avg_loss: 0.0123
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 209, Global step 1381:
20-03-23 01:00-INFO-training batch loss: 0.0006; avg_loss: 0.0122
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 210, Global step 1382:
20-03-23 01:00-INFO-training batch loss: 0.0009; avg_loss: 0.0122
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 211, Global step 1383:
20-03-23 01:00-INFO-training batch loss: 0.0008; avg_loss: 0.0121
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9963
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 212, Global step 1384:
20-03-23 01:00-INFO-training batch loss: 0.0006; avg_loss: 0.0121
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 213, Global step 1385:
20-03-23 01:00-INFO-training batch loss: 0.0018; avg_loss: 0.0120
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 214, Global step 1386:
20-03-23 01:00-INFO-training batch loss: 0.0046; avg_loss: 0.0120
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 215, Global step 1387:
20-03-23 01:00-INFO-training batch loss: 0.0007; avg_loss: 0.0119
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 216, Global step 1388:
20-03-23 01:00-INFO-training batch loss: 0.0006; avg_loss: 0.0119
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 217, Global step 1389:
20-03-23 01:00-INFO-training batch loss: 0.0014; avg_loss: 0.0118
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9964
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 218, Global step 1390:
20-03-23 01:00-INFO-training batch loss: 0.0035; avg_loss: 0.0118
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 219, Global step 1391:
20-03-23 01:00-INFO-training batch loss: 0.0040; avg_loss: 0.0118
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 220, Global step 1392:
20-03-23 01:00-INFO-training batch loss: 0.0016; avg_loss: 0.0117
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 221, Global step 1393:
20-03-23 01:00-INFO-training batch loss: 0.0010; avg_loss: 0.0117
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 222, Global step 1394:
20-03-23 01:00-INFO-training batch loss: 0.0075; avg_loss: 0.0117
20-03-23 01:00-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 223, Global step 1395:
20-03-23 01:00-INFO-training batch loss: 0.0101; avg_loss: 0.0117
20-03-23 01:00-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 224, Global step 1396:
20-03-23 01:00-INFO-training batch loss: 0.0009; avg_loss: 0.0116
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 225, Global step 1397:
20-03-23 01:00-INFO-training batch loss: 0.0009; avg_loss: 0.0116
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:00-INFO-Epoch 4, Batch 226, Global step 1398:
20-03-23 01:00-INFO-training batch loss: 0.0019; avg_loss: 0.0115
20-03-23 01:00-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:00-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 227, Global step 1399:
20-03-23 01:01-INFO-training batch loss: 0.0012; avg_loss: 0.0115
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 228, Global step 1400:
20-03-23 01:01-INFO-training batch loss: 0.0050; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 229, Global step 1401:
20-03-23 01:01-INFO-training batch loss: 0.0013; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 230, Global step 1402:
20-03-23 01:01-INFO-training batch loss: 0.0017; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 231, Global step 1403:
20-03-23 01:01-INFO-training batch loss: 0.0230; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 0.9844; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 232, Global step 1404:
20-03-23 01:01-INFO-training batch loss: 0.0029; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 233, Global step 1405:
20-03-23 01:01-INFO-training batch loss: 0.0010; avg_loss: 0.0113
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 234, Global step 1406:
20-03-23 01:01-INFO-training batch loss: 0.0306; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 0.9844; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 235, Global step 1407:
20-03-23 01:01-INFO-training batch loss: 0.0021; avg_loss: 0.0114
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 236, Global step 1408:
20-03-23 01:01-INFO-training batch loss: 0.0007; avg_loss: 0.0113
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 237, Global step 1409:
20-03-23 01:01-INFO-training batch loss: 0.0093; avg_loss: 0.0113
20-03-23 01:01-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 238, Global step 1410:
20-03-23 01:01-INFO-training batch loss: 0.0006; avg_loss: 0.0113
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 239, Global step 1411:
20-03-23 01:01-INFO-training batch loss: 0.0011; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 240, Global step 1412:
20-03-23 01:01-INFO-training batch loss: 0.0008; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 241, Global step 1413:
20-03-23 01:01-INFO-training batch loss: 0.0055; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 242, Global step 1414:
20-03-23 01:01-INFO-training batch loss: 0.0029; avg_loss: 0.0111
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 243, Global step 1415:
20-03-23 01:01-INFO-training batch loss: 0.0416; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 0.9844; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 244, Global step 1416:
20-03-23 01:01-INFO-training batch loss: 0.0089; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 245, Global step 1417:
20-03-23 01:01-INFO-training batch loss: 0.0017; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 246, Global step 1418:
20-03-23 01:01-INFO-training batch loss: 0.0015; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 247, Global step 1419:
20-03-23 01:01-INFO-training batch loss: 0.0051; avg_loss: 0.0111
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 248, Global step 1420:
20-03-23 01:01-INFO-training batch loss: 0.0155; avg_loss: 0.0112
20-03-23 01:01-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 249, Global step 1421:
20-03-23 01:01-INFO-training batch loss: 0.0022; avg_loss: 0.0111
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 250, Global step 1422:
20-03-23 01:01-INFO-training batch loss: 0.0014; avg_loss: 0.0111
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 251, Global step 1423:
20-03-23 01:01-INFO-training batch loss: 0.0013; avg_loss: 0.0110
20-03-23 01:01-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:01-INFO-Epoch 4, Batch 252, Global step 1424:
20-03-23 01:01-INFO-training batch loss: 0.0086; avg_loss: 0.0110
20-03-23 01:01-INFO-training batch acc: 0.9922; avg_acc: 0.9966
20-03-23 01:01-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 253, Global step 1425:
20-03-23 01:02-INFO-training batch loss: 0.0356; avg_loss: 0.0111
20-03-23 01:02-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 254, Global step 1426:
20-03-23 01:02-INFO-training batch loss: 0.0039; avg_loss: 0.0111
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 255, Global step 1427:
20-03-23 01:02-INFO-training batch loss: 0.0018; avg_loss: 0.0111
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 256, Global step 1428:
20-03-23 01:02-INFO-training batch loss: 0.0153; avg_loss: 0.0111
20-03-23 01:02-INFO-training batch acc: 0.9922; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 257, Global step 1429:
20-03-23 01:02-INFO-training batch loss: 0.0135; avg_loss: 0.0111
20-03-23 01:02-INFO-training batch acc: 0.9922; avg_acc: 0.9965
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 258, Global step 1430:
20-03-23 01:02-INFO-training batch loss: 0.0018; avg_loss: 0.0111
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9965
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 259, Global step 1431:
20-03-23 01:02-INFO-training batch loss: 0.0034; avg_loss: 0.0110
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 260, Global step 1432:
20-03-23 01:02-INFO-training batch loss: 0.0034; avg_loss: 0.0110
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 261, Global step 1433:
20-03-23 01:02-INFO-training batch loss: 0.0020; avg_loss: 0.0110
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 262, Global step 1434:
20-03-23 01:02-INFO-training batch loss: 0.0020; avg_loss: 0.0109
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 263, Global step 1435:
20-03-23 01:02-INFO-training batch loss: 0.0033; avg_loss: 0.0109
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 264, Global step 1436:
20-03-23 01:02-INFO-training batch loss: 0.0137; avg_loss: 0.0109
20-03-23 01:02-INFO-training batch acc: 0.9922; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 265, Global step 1437:
20-03-23 01:02-INFO-training batch loss: 0.0026; avg_loss: 0.0109
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 266, Global step 1438:
20-03-23 01:02-INFO-training batch loss: 0.0032; avg_loss: 0.0108
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 267, Global step 1439:
20-03-23 01:02-INFO-training batch loss: 0.0020; avg_loss: 0.0108
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 268, Global step 1440:
20-03-23 01:02-INFO-training batch loss: 0.0014; avg_loss: 0.0108
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 269, Global step 1441:
20-03-23 01:02-INFO-training batch loss: 0.0130; avg_loss: 0.0108
20-03-23 01:02-INFO-training batch acc: 0.9922; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 270, Global step 1442:
20-03-23 01:02-INFO-training batch loss: 0.0013; avg_loss: 0.0108
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9966
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 271, Global step 1443:
20-03-23 01:02-INFO-training batch loss: 0.0024; avg_loss: 0.0107
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 272, Global step 1444:
20-03-23 01:02-INFO-training batch loss: 0.0016; avg_loss: 0.0107
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 273, Global step 1445:
20-03-23 01:02-INFO-training batch loss: 0.0027; avg_loss: 0.0107
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 274, Global step 1446:
20-03-23 01:02-INFO-training batch loss: 0.0009; avg_loss: 0.0106
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 275, Global step 1447:
20-03-23 01:02-INFO-training batch loss: 0.0015; avg_loss: 0.0106
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 276, Global step 1448:
20-03-23 01:02-INFO-training batch loss: 0.0071; avg_loss: 0.0106
20-03-23 01:02-INFO-training batch acc: 0.9922; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 277, Global step 1449:
20-03-23 01:02-INFO-training batch loss: 0.0013; avg_loss: 0.0105
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:02-INFO-Epoch 4, Batch 278, Global step 1450:
20-03-23 01:02-INFO-training batch loss: 0.0030; avg_loss: 0.0105
20-03-23 01:02-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:02-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 279, Global step 1451:
20-03-23 01:03-INFO-training batch loss: 0.0025; avg_loss: 0.0105
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 280, Global step 1452:
20-03-23 01:03-INFO-training batch loss: 0.0041; avg_loss: 0.0105
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 281, Global step 1453:
20-03-23 01:03-INFO-training batch loss: 0.0027; avg_loss: 0.0104
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9967
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 282, Global step 1454:
20-03-23 01:03-INFO-training batch loss: 0.0025; avg_loss: 0.0104
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 283, Global step 1455:
20-03-23 01:03-INFO-training batch loss: 0.0027; avg_loss: 0.0104
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 284, Global step 1456:
20-03-23 01:03-INFO-training batch loss: 0.0040; avg_loss: 0.0104
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 285, Global step 1457:
20-03-23 01:03-INFO-training batch loss: 0.0008; avg_loss: 0.0103
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 286, Global step 1458:
20-03-23 01:03-INFO-training batch loss: 0.0008; avg_loss: 0.0103
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 287, Global step 1459:
20-03-23 01:03-INFO-training batch loss: 0.0016; avg_loss: 0.0103
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 288, Global step 1460:
20-03-23 01:03-INFO-training batch loss: 0.0009; avg_loss: 0.0102
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 289, Global step 1461:
20-03-23 01:03-INFO-training batch loss: 0.0260; avg_loss: 0.0103
20-03-23 01:03-INFO-training batch acc: 0.9922; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 290, Global step 1462:
20-03-23 01:03-INFO-training batch loss: 0.0043; avg_loss: 0.0103
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 291, Global step 1463:
20-03-23 01:03-INFO-training batch loss: 0.0012; avg_loss: 0.0102
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 292, Global step 1464:
20-03-23 01:03-INFO-training batch loss: 0.0010; avg_loss: 0.0102
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9968
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, Batch 293, Global step 1465:
20-03-23 01:03-INFO-training batch loss: 0.0010; avg_loss: 0.0102
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 0.9969
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, training batch loss: 0.0010; avg_loss: 0.0102
20-03-23 01:03-INFO-Epoch 4, training batch accuracy: 1.0000; avg_accuracy: 0.9969
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 4, evaluating batch loss: 0.9951; avg_loss: 0.6800
20-03-23 01:03-INFO-Epoch 4, evaluating batch accuracy: 0.9143; avg_accuracy: 0.9239
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 1, Global step 1466:
20-03-23 01:03-INFO-training batch loss: 0.0018; avg_loss: 0.0018
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 2, Global step 1467:
20-03-23 01:03-INFO-training batch loss: 0.0008; avg_loss: 0.0013
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 3, Global step 1468:
20-03-23 01:03-INFO-training batch loss: 0.0017; avg_loss: 0.0014
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 4, Global step 1469:
20-03-23 01:03-INFO-training batch loss: 0.0010; avg_loss: 0.0013
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 5, Global step 1470:
20-03-23 01:03-INFO-training batch loss: 0.0003; avg_loss: 0.0011
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 6, Global step 1471:
20-03-23 01:03-INFO-training batch loss: 0.0014; avg_loss: 0.0012
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 7, Global step 1472:
20-03-23 01:03-INFO-training batch loss: 0.0010; avg_loss: 0.0011
20-03-23 01:03-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 01:03-INFO-
20-03-23 01:03-INFO-Epoch 5, Batch 8, Global step 1473:
20-03-23 01:03-INFO-training batch loss: 0.0162; avg_loss: 0.0030
20-03-23 01:03-INFO-training batch acc: 0.9922; avg_acc: 0.9990
20-03-23 01:03-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 9, Global step 1474:
20-03-23 01:04-INFO-training batch loss: 0.0023; avg_loss: 0.0030
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 10, Global step 1475:
20-03-23 01:04-INFO-training batch loss: 0.0017; avg_loss: 0.0028
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 11, Global step 1476:
20-03-23 01:04-INFO-training batch loss: 0.0082; avg_loss: 0.0033
20-03-23 01:04-INFO-training batch acc: 0.9922; avg_acc: 0.9986
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 12, Global step 1477:
20-03-23 01:04-INFO-training batch loss: 0.0004; avg_loss: 0.0031
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 13, Global step 1478:
20-03-23 01:04-INFO-training batch loss: 0.0009; avg_loss: 0.0029
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 14, Global step 1479:
20-03-23 01:04-INFO-training batch loss: 0.0011; avg_loss: 0.0028
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 15, Global step 1480:
20-03-23 01:04-INFO-training batch loss: 0.0006; avg_loss: 0.0026
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 16, Global step 1481:
20-03-23 01:04-INFO-training batch loss: 0.0011; avg_loss: 0.0025
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 17, Global step 1482:
20-03-23 01:04-INFO-training batch loss: 0.0006; avg_loss: 0.0024
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 18, Global step 1483:
20-03-23 01:04-INFO-training batch loss: 0.0006; avg_loss: 0.0023
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 19, Global step 1484:
20-03-23 01:04-INFO-training batch loss: 0.0049; avg_loss: 0.0025
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 20, Global step 1485:
20-03-23 01:04-INFO-training batch loss: 0.0037; avg_loss: 0.0025
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 21, Global step 1486:
20-03-23 01:04-INFO-training batch loss: 0.0008; avg_loss: 0.0024
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 22, Global step 1487:
20-03-23 01:04-INFO-training batch loss: 0.0015; avg_loss: 0.0024
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 23, Global step 1488:
20-03-23 01:04-INFO-training batch loss: 0.0028; avg_loss: 0.0024
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 24, Global step 1489:
20-03-23 01:04-INFO-training batch loss: 0.0004; avg_loss: 0.0023
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 25, Global step 1490:
20-03-23 01:04-INFO-training batch loss: 0.0015; avg_loss: 0.0023
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 26, Global step 1491:
20-03-23 01:04-INFO-training batch loss: 0.0009; avg_loss: 0.0022
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 27, Global step 1492:
20-03-23 01:04-INFO-training batch loss: 0.0030; avg_loss: 0.0023
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 28, Global step 1493:
20-03-23 01:04-INFO-training batch loss: 0.0012; avg_loss: 0.0022
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 29, Global step 1494:
20-03-23 01:04-INFO-training batch loss: 0.0011; avg_loss: 0.0022
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 30, Global step 1495:
20-03-23 01:04-INFO-training batch loss: 0.0014; avg_loss: 0.0022
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 31, Global step 1496:
20-03-23 01:04-INFO-training batch loss: 0.0025; avg_loss: 0.0022
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 32, Global step 1497:
20-03-23 01:04-INFO-training batch loss: 0.0004; avg_loss: 0.0021
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 33, Global step 1498:
20-03-23 01:04-INFO-training batch loss: 0.0005; avg_loss: 0.0021
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 34, Global step 1499:
20-03-23 01:04-INFO-training batch loss: 0.0004; avg_loss: 0.0020
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:04-INFO-
20-03-23 01:04-INFO-Epoch 5, Batch 35, Global step 1500:
20-03-23 01:04-INFO-training batch loss: 0.0007; avg_loss: 0.0020
20-03-23 01:04-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 01:04-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 36, Global step 1501:
20-03-23 01:05-INFO-training batch loss: 0.0362; avg_loss: 0.0029
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 37, Global step 1502:
20-03-23 01:05-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 38, Global step 1503:
20-03-23 01:05-INFO-training batch loss: 0.0005; avg_loss: 0.0028
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 39, Global step 1504:
20-03-23 01:05-INFO-training batch loss: 0.0006; avg_loss: 0.0028
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 40, Global step 1505:
20-03-23 01:05-INFO-training batch loss: 0.0027; avg_loss: 0.0028
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 41, Global step 1506:
20-03-23 01:05-INFO-training batch loss: 0.0026; avg_loss: 0.0028
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 42, Global step 1507:
20-03-23 01:05-INFO-training batch loss: 0.0011; avg_loss: 0.0027
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 43, Global step 1508:
20-03-23 01:05-INFO-training batch loss: 0.0050; avg_loss: 0.0028
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 44, Global step 1509:
20-03-23 01:05-INFO-training batch loss: 0.0132; avg_loss: 0.0030
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 45, Global step 1510:
20-03-23 01:05-INFO-training batch loss: 0.0065; avg_loss: 0.0031
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 46, Global step 1511:
20-03-23 01:05-INFO-training batch loss: 0.0009; avg_loss: 0.0031
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 47, Global step 1512:
20-03-23 01:05-INFO-training batch loss: 0.0010; avg_loss: 0.0030
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 48, Global step 1513:
20-03-23 01:05-INFO-training batch loss: 0.0014; avg_loss: 0.0030
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 49, Global step 1514:
20-03-23 01:05-INFO-training batch loss: 0.0014; avg_loss: 0.0029
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 50, Global step 1515:
20-03-23 01:05-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 51, Global step 1516:
20-03-23 01:05-INFO-training batch loss: 0.0523; avg_loss: 0.0039
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9992
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 52, Global step 1517:
20-03-23 01:05-INFO-training batch loss: 0.0027; avg_loss: 0.0039
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 53, Global step 1518:
20-03-23 01:05-INFO-training batch loss: 0.0018; avg_loss: 0.0038
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 54, Global step 1519:
20-03-23 01:05-INFO-training batch loss: 0.0081; avg_loss: 0.0039
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9991
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 55, Global step 1520:
20-03-23 01:05-INFO-training batch loss: 0.0101; avg_loss: 0.0040
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9990
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 56, Global step 1521:
20-03-23 01:05-INFO-training batch loss: 0.0404; avg_loss: 0.0047
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9989
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 57, Global step 1522:
20-03-23 01:05-INFO-training batch loss: 0.0019; avg_loss: 0.0046
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 58, Global step 1523:
20-03-23 01:05-INFO-training batch loss: 0.0366; avg_loss: 0.0052
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9988
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 59, Global step 1524:
20-03-23 01:05-INFO-training batch loss: 0.0038; avg_loss: 0.0051
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 60, Global step 1525:
20-03-23 01:05-INFO-training batch loss: 0.0446; avg_loss: 0.0058
20-03-23 01:05-INFO-training batch acc: 0.9922; avg_acc: 0.9987
20-03-23 01:05-INFO-
20-03-23 01:05-INFO-Epoch 5, Batch 61, Global step 1526:
20-03-23 01:05-INFO-training batch loss: 0.0017; avg_loss: 0.0057
20-03-23 01:05-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 01:05-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 62, Global step 1527:
20-03-23 01:06-INFO-training batch loss: 0.0025; avg_loss: 0.0057
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 63, Global step 1528:
20-03-23 01:06-INFO-training batch loss: 0.0022; avg_loss: 0.0056
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 64, Global step 1529:
20-03-23 01:06-INFO-training batch loss: 0.0011; avg_loss: 0.0056
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 65, Global step 1530:
20-03-23 01:06-INFO-training batch loss: 0.0012; avg_loss: 0.0055
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 66, Global step 1531:
20-03-23 01:06-INFO-training batch loss: 0.0018; avg_loss: 0.0054
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 67, Global step 1532:
20-03-23 01:06-INFO-training batch loss: 0.0019; avg_loss: 0.0054
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 68, Global step 1533:
20-03-23 01:06-INFO-training batch loss: 0.0583; avg_loss: 0.0062
20-03-23 01:06-INFO-training batch acc: 0.9844; avg_acc: 0.9986
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 69, Global step 1534:
20-03-23 01:06-INFO-training batch loss: 0.0393; avg_loss: 0.0066
20-03-23 01:06-INFO-training batch acc: 0.9766; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 70, Global step 1535:
20-03-23 01:06-INFO-training batch loss: 0.0015; avg_loss: 0.0066
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 71, Global step 1536:
20-03-23 01:06-INFO-training batch loss: 0.0175; avg_loss: 0.0067
20-03-23 01:06-INFO-training batch acc: 0.9922; avg_acc: 0.9982
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 72, Global step 1537:
20-03-23 01:06-INFO-training batch loss: 0.0025; avg_loss: 0.0067
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 73, Global step 1538:
20-03-23 01:06-INFO-training batch loss: 0.0020; avg_loss: 0.0066
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 74, Global step 1539:
20-03-23 01:06-INFO-training batch loss: 0.0035; avg_loss: 0.0066
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 75, Global step 1540:
20-03-23 01:06-INFO-training batch loss: 0.0252; avg_loss: 0.0068
20-03-23 01:06-INFO-training batch acc: 0.9922; avg_acc: 0.9982
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 76, Global step 1541:
20-03-23 01:06-INFO-training batch loss: 0.0028; avg_loss: 0.0068
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 77, Global step 1542:
20-03-23 01:06-INFO-training batch loss: 0.0059; avg_loss: 0.0067
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 78, Global step 1543:
20-03-23 01:06-INFO-training batch loss: 0.0024; avg_loss: 0.0067
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 79, Global step 1544:
20-03-23 01:06-INFO-training batch loss: 0.0017; avg_loss: 0.0066
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 80, Global step 1545:
20-03-23 01:06-INFO-training batch loss: 0.0492; avg_loss: 0.0072
20-03-23 01:06-INFO-training batch acc: 0.9922; avg_acc: 0.9982
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 81, Global step 1546:
20-03-23 01:06-INFO-training batch loss: 0.0033; avg_loss: 0.0071
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 82, Global step 1547:
20-03-23 01:06-INFO-training batch loss: 0.0742; avg_loss: 0.0079
20-03-23 01:06-INFO-training batch acc: 0.9844; avg_acc: 0.9981
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 83, Global step 1548:
20-03-23 01:06-INFO-training batch loss: 0.0328; avg_loss: 0.0082
20-03-23 01:06-INFO-training batch acc: 0.9922; avg_acc: 0.9980
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 84, Global step 1549:
20-03-23 01:06-INFO-training batch loss: 0.0050; avg_loss: 0.0082
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 85, Global step 1550:
20-03-23 01:06-INFO-training batch loss: 0.0025; avg_loss: 0.0081
20-03-23 01:06-INFO-training batch acc: 1.0000; avg_acc: 0.9981
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 86, Global step 1551:
20-03-23 01:06-INFO-training batch loss: 0.0264; avg_loss: 0.0083
20-03-23 01:06-INFO-training batch acc: 0.9922; avg_acc: 0.9980
20-03-23 01:06-INFO-
20-03-23 01:06-INFO-Epoch 5, Batch 87, Global step 1552:
20-03-23 01:06-INFO-training batch loss: 0.0220; avg_loss: 0.0085
20-03-23 01:06-INFO-training batch acc: 0.9922; avg_acc: 0.9979
20-03-23 01:06-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 88, Global step 1553:
20-03-23 01:07-INFO-training batch loss: 0.0051; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 89, Global step 1554:
20-03-23 01:07-INFO-training batch loss: 0.0027; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 90, Global step 1555:
20-03-23 01:07-INFO-training batch loss: 0.0054; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 91, Global step 1556:
20-03-23 01:07-INFO-training batch loss: 0.0194; avg_loss: 0.0085
20-03-23 01:07-INFO-training batch acc: 0.9922; avg_acc: 0.9979
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 92, Global step 1557:
20-03-23 01:07-INFO-training batch loss: 0.0040; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 93, Global step 1558:
20-03-23 01:07-INFO-training batch loss: 0.0059; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 94, Global step 1559:
20-03-23 01:07-INFO-training batch loss: 0.0038; avg_loss: 0.0083
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 95, Global step 1560:
20-03-23 01:07-INFO-training batch loss: 0.0177; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 0.9922; avg_acc: 0.9979
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 96, Global step 1561:
20-03-23 01:07-INFO-training batch loss: 0.0043; avg_loss: 0.0084
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 97, Global step 1562:
20-03-23 01:07-INFO-training batch loss: 0.0277; avg_loss: 0.0086
20-03-23 01:07-INFO-training batch acc: 0.9922; avg_acc: 0.9979
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 98, Global step 1563:
20-03-23 01:07-INFO-training batch loss: 0.0232; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 0.9844; avg_acc: 0.9978
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 99, Global step 1564:
20-03-23 01:07-INFO-training batch loss: 0.0027; avg_loss: 0.0087
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9978
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 100, Global step 1565:
20-03-23 01:07-INFO-training batch loss: 0.0014; avg_loss: 0.0086
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9978
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 101, Global step 1566:
20-03-23 01:07-INFO-training batch loss: 0.0305; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 0.9844; avg_acc: 0.9977
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 102, Global step 1567:
20-03-23 01:07-INFO-training batch loss: 0.0076; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 0.9922; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 103, Global step 1568:
20-03-23 01:07-INFO-training batch loss: 0.0080; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 104, Global step 1569:
20-03-23 01:07-INFO-training batch loss: 0.0029; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9977
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 105, Global step 1570:
20-03-23 01:07-INFO-training batch loss: 0.0289; avg_loss: 0.0089
20-03-23 01:07-INFO-training batch acc: 0.9844; avg_acc: 0.9975
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 106, Global step 1571:
20-03-23 01:07-INFO-training batch loss: 0.0089; avg_loss: 0.0089
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 107, Global step 1572:
20-03-23 01:07-INFO-training batch loss: 0.0040; avg_loss: 0.0089
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 108, Global step 1573:
20-03-23 01:07-INFO-training batch loss: 0.0031; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 109, Global step 1574:
20-03-23 01:07-INFO-training batch loss: 0.0129; avg_loss: 0.0089
20-03-23 01:07-INFO-training batch acc: 0.9922; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 110, Global step 1575:
20-03-23 01:07-INFO-training batch loss: 0.0011; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 111, Global step 1576:
20-03-23 01:07-INFO-training batch loss: 0.0213; avg_loss: 0.0089
20-03-23 01:07-INFO-training batch acc: 0.9922; avg_acc: 0.9975
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 112, Global step 1577:
20-03-23 01:07-INFO-training batch loss: 0.0027; avg_loss: 0.0089
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:07-INFO-Epoch 5, Batch 113, Global step 1578:
20-03-23 01:07-INFO-training batch loss: 0.0017; avg_loss: 0.0088
20-03-23 01:07-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:07-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 114, Global step 1579:
20-03-23 01:08-INFO-training batch loss: 0.0026; avg_loss: 0.0088
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 115, Global step 1580:
20-03-23 01:08-INFO-training batch loss: 0.0187; avg_loss: 0.0088
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9976
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 116, Global step 1581:
20-03-23 01:08-INFO-training batch loss: 0.0017; avg_loss: 0.0088
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 117, Global step 1582:
20-03-23 01:08-INFO-training batch loss: 0.0229; avg_loss: 0.0089
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 118, Global step 1583:
20-03-23 01:08-INFO-training batch loss: 0.0028; avg_loss: 0.0088
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9976
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 119, Global step 1584:
20-03-23 01:08-INFO-training batch loss: 0.0512; avg_loss: 0.0092
20-03-23 01:08-INFO-training batch acc: 0.9844; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 120, Global step 1585:
20-03-23 01:08-INFO-training batch loss: 0.0027; avg_loss: 0.0091
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 121, Global step 1586:
20-03-23 01:08-INFO-training batch loss: 0.0027; avg_loss: 0.0091
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 122, Global step 1587:
20-03-23 01:08-INFO-training batch loss: 0.0050; avg_loss: 0.0091
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 123, Global step 1588:
20-03-23 01:08-INFO-training batch loss: 0.0026; avg_loss: 0.0090
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 124, Global step 1589:
20-03-23 01:08-INFO-training batch loss: 0.0035; avg_loss: 0.0090
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 125, Global step 1590:
20-03-23 01:08-INFO-training batch loss: 0.0235; avg_loss: 0.0091
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 126, Global step 1591:
20-03-23 01:08-INFO-training batch loss: 0.0397; avg_loss: 0.0093
20-03-23 01:08-INFO-training batch acc: 0.9844; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 127, Global step 1592:
20-03-23 01:08-INFO-training batch loss: 0.0014; avg_loss: 0.0093
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 128, Global step 1593:
20-03-23 01:08-INFO-training batch loss: 0.0187; avg_loss: 0.0093
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 129, Global step 1594:
20-03-23 01:08-INFO-training batch loss: 0.0102; avg_loss: 0.0093
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 130, Global step 1595:
20-03-23 01:08-INFO-training batch loss: 0.0218; avg_loss: 0.0094
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 131, Global step 1596:
20-03-23 01:08-INFO-training batch loss: 0.0005; avg_loss: 0.0094
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 132, Global step 1597:
20-03-23 01:08-INFO-training batch loss: 0.0020; avg_loss: 0.0093
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 133, Global step 1598:
20-03-23 01:08-INFO-training batch loss: 0.0018; avg_loss: 0.0093
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 134, Global step 1599:
20-03-23 01:08-INFO-training batch loss: 0.0080; avg_loss: 0.0092
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 135, Global step 1600:
20-03-23 01:08-INFO-training batch loss: 0.0036; avg_loss: 0.0092
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 136, Global step 1601:
20-03-23 01:08-INFO-training batch loss: 0.0008; avg_loss: 0.0091
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9975
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 137, Global step 1602:
20-03-23 01:08-INFO-training batch loss: 0.0066; avg_loss: 0.0091
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 138, Global step 1603:
20-03-23 01:08-INFO-training batch loss: 0.0552; avg_loss: 0.0095
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 139, Global step 1604:
20-03-23 01:08-INFO-training batch loss: 0.0011; avg_loss: 0.0094
20-03-23 01:08-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:08-INFO-Epoch 5, Batch 140, Global step 1605:
20-03-23 01:08-INFO-training batch loss: 0.0143; avg_loss: 0.0094
20-03-23 01:08-INFO-training batch acc: 0.9922; avg_acc: 0.9974
20-03-23 01:08-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 141, Global step 1606:
20-03-23 01:09-INFO-training batch loss: 0.0015; avg_loss: 0.0094
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 142, Global step 1607:
20-03-23 01:09-INFO-training batch loss: 0.0183; avg_loss: 0.0094
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9974
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 143, Global step 1608:
20-03-23 01:09-INFO-training batch loss: 0.0124; avg_loss: 0.0095
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9973
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 144, Global step 1609:
20-03-23 01:09-INFO-training batch loss: 0.0315; avg_loss: 0.0096
20-03-23 01:09-INFO-training batch acc: 0.9766; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 145, Global step 1610:
20-03-23 01:09-INFO-training batch loss: 0.0281; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 146, Global step 1611:
20-03-23 01:09-INFO-training batch loss: 0.0049; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 147, Global step 1612:
20-03-23 01:09-INFO-training batch loss: 0.0084; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 148, Global step 1613:
20-03-23 01:09-INFO-training batch loss: 0.0027; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 149, Global step 1614:
20-03-23 01:09-INFO-training batch loss: 0.0044; avg_loss: 0.0096
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 150, Global step 1615:
20-03-23 01:09-INFO-training batch loss: 0.0055; avg_loss: 0.0096
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 151, Global step 1616:
20-03-23 01:09-INFO-training batch loss: 0.0036; avg_loss: 0.0096
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 152, Global step 1617:
20-03-23 01:09-INFO-training batch loss: 0.0019; avg_loss: 0.0095
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 153, Global step 1618:
20-03-23 01:09-INFO-training batch loss: 0.0076; avg_loss: 0.0095
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 154, Global step 1619:
20-03-23 01:09-INFO-training batch loss: 0.0286; avg_loss: 0.0096
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9973
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 155, Global step 1620:
20-03-23 01:09-INFO-training batch loss: 0.0315; avg_loss: 0.0098
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 156, Global step 1621:
20-03-23 01:09-INFO-training batch loss: 0.0212; avg_loss: 0.0098
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 157, Global step 1622:
20-03-23 01:09-INFO-training batch loss: 0.0015; avg_loss: 0.0098
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 158, Global step 1623:
20-03-23 01:09-INFO-training batch loss: 0.0021; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 159, Global step 1624:
20-03-23 01:09-INFO-training batch loss: 0.0080; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 160, Global step 1625:
20-03-23 01:09-INFO-training batch loss: 0.0028; avg_loss: 0.0097
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9973
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 161, Global step 1626:
20-03-23 01:09-INFO-training batch loss: 0.0467; avg_loss: 0.0099
20-03-23 01:09-INFO-training batch acc: 0.9766; avg_acc: 0.9971
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 162, Global step 1627:
20-03-23 01:09-INFO-training batch loss: 0.0036; avg_loss: 0.0099
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 163, Global step 1628:
20-03-23 01:09-INFO-training batch loss: 0.0029; avg_loss: 0.0098
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 164, Global step 1629:
20-03-23 01:09-INFO-training batch loss: 0.0119; avg_loss: 0.0098
20-03-23 01:09-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:09-INFO-
20-03-23 01:09-INFO-Epoch 5, Batch 165, Global step 1630:
20-03-23 01:09-INFO-training batch loss: 0.0068; avg_loss: 0.0098
20-03-23 01:09-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:09-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 166, Global step 1631:
20-03-23 01:10-INFO-training batch loss: 0.0021; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 167, Global step 1632:
20-03-23 01:10-INFO-training batch loss: 0.0289; avg_loss: 0.0099
20-03-23 01:10-INFO-training batch acc: 0.9844; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 168, Global step 1633:
20-03-23 01:10-INFO-training batch loss: 0.0094; avg_loss: 0.0099
20-03-23 01:10-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 169, Global step 1634:
20-03-23 01:10-INFO-training batch loss: 0.0028; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 170, Global step 1635:
20-03-23 01:10-INFO-training batch loss: 0.0060; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 171, Global step 1636:
20-03-23 01:10-INFO-training batch loss: 0.0147; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 172, Global step 1637:
20-03-23 01:10-INFO-training batch loss: 0.0106; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 173, Global step 1638:
20-03-23 01:10-INFO-training batch loss: 0.0038; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 174, Global step 1639:
20-03-23 01:10-INFO-training batch loss: 0.0043; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 175, Global step 1640:
20-03-23 01:10-INFO-training batch loss: 0.0097; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 176, Global step 1641:
20-03-23 01:10-INFO-training batch loss: 0.0049; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 177, Global step 1642:
20-03-23 01:10-INFO-training batch loss: 0.0019; avg_loss: 0.0097
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 178, Global step 1643:
20-03-23 01:10-INFO-training batch loss: 0.0094; avg_loss: 0.0097
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 179, Global step 1644:
20-03-23 01:10-INFO-training batch loss: 0.0250; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 0.9844; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 180, Global step 1645:
20-03-23 01:10-INFO-training batch loss: 0.0029; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 181, Global step 1646:
20-03-23 01:10-INFO-training batch loss: 0.0181; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 0.9844; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 182, Global step 1647:
20-03-23 01:10-INFO-training batch loss: 0.0036; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 183, Global step 1648:
20-03-23 01:10-INFO-training batch loss: 0.0023; avg_loss: 0.0097
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 184, Global step 1649:
20-03-23 01:10-INFO-training batch loss: 0.0330; avg_loss: 0.0099
20-03-23 01:10-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 185, Global step 1650:
20-03-23 01:10-INFO-training batch loss: 0.0292; avg_loss: 0.0100
20-03-23 01:10-INFO-training batch acc: 0.9844; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 186, Global step 1651:
20-03-23 01:10-INFO-training batch loss: 0.0023; avg_loss: 0.0099
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 187, Global step 1652:
20-03-23 01:10-INFO-training batch loss: 0.0093; avg_loss: 0.0099
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 188, Global step 1653:
20-03-23 01:10-INFO-training batch loss: 0.0046; avg_loss: 0.0099
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 189, Global step 1654:
20-03-23 01:10-INFO-training batch loss: 0.0027; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 190, Global step 1655:
20-03-23 01:10-INFO-training batch loss: 0.0043; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:10-INFO-
20-03-23 01:10-INFO-Epoch 5, Batch 191, Global step 1656:
20-03-23 01:10-INFO-training batch loss: 0.0031; avg_loss: 0.0098
20-03-23 01:10-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:10-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 192, Global step 1657:
20-03-23 01:11-INFO-training batch loss: 0.0094; avg_loss: 0.0098
20-03-23 01:11-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 193, Global step 1658:
20-03-23 01:11-INFO-training batch loss: 0.0014; avg_loss: 0.0097
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 194, Global step 1659:
20-03-23 01:11-INFO-training batch loss: 0.0022; avg_loss: 0.0097
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 195, Global step 1660:
20-03-23 01:11-INFO-training batch loss: 0.0011; avg_loss: 0.0097
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 196, Global step 1661:
20-03-23 01:11-INFO-training batch loss: 0.0011; avg_loss: 0.0096
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 197, Global step 1662:
20-03-23 01:11-INFO-training batch loss: 0.0027; avg_loss: 0.0096
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 198, Global step 1663:
20-03-23 01:11-INFO-training batch loss: 0.0017; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 199, Global step 1664:
20-03-23 01:11-INFO-training batch loss: 0.0028; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 200, Global step 1665:
20-03-23 01:11-INFO-training batch loss: 0.0036; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 201, Global step 1666:
20-03-23 01:11-INFO-training batch loss: 0.0018; avg_loss: 0.0094
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 202, Global step 1667:
20-03-23 01:11-INFO-training batch loss: 0.0019; avg_loss: 0.0094
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 203, Global step 1668:
20-03-23 01:11-INFO-training batch loss: 0.0233; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 204, Global step 1669:
20-03-23 01:11-INFO-training batch loss: 0.0013; avg_loss: 0.0094
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 205, Global step 1670:
20-03-23 01:11-INFO-training batch loss: 0.0214; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 206, Global step 1671:
20-03-23 01:11-INFO-training batch loss: 0.0040; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 207, Global step 1672:
20-03-23 01:11-INFO-training batch loss: 0.0009; avg_loss: 0.0094
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 208, Global step 1673:
20-03-23 01:11-INFO-training batch loss: 0.0011; avg_loss: 0.0094
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 209, Global step 1674:
20-03-23 01:11-INFO-training batch loss: 0.0029; avg_loss: 0.0093
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 210, Global step 1675:
20-03-23 01:11-INFO-training batch loss: 0.0519; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 211, Global step 1676:
20-03-23 01:11-INFO-training batch loss: 0.0012; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 212, Global step 1677:
20-03-23 01:11-INFO-training batch loss: 0.0018; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 213, Global step 1678:
20-03-23 01:11-INFO-training batch loss: 0.0030; avg_loss: 0.0094
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 214, Global step 1679:
20-03-23 01:11-INFO-training batch loss: 0.0119; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 215, Global step 1680:
20-03-23 01:11-INFO-training batch loss: 0.0099; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 216, Global step 1681:
20-03-23 01:11-INFO-training batch loss: 0.0280; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:11-INFO-Epoch 5, Batch 217, Global step 1682:
20-03-23 01:11-INFO-training batch loss: 0.0041; avg_loss: 0.0095
20-03-23 01:11-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:11-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 218, Global step 1683:
20-03-23 01:12-INFO-training batch loss: 0.0548; avg_loss: 0.0097
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 219, Global step 1684:
20-03-23 01:12-INFO-training batch loss: 0.0219; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 220, Global step 1685:
20-03-23 01:12-INFO-training batch loss: 0.0287; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 221, Global step 1686:
20-03-23 01:12-INFO-training batch loss: 0.0023; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 222, Global step 1687:
20-03-23 01:12-INFO-training batch loss: 0.0088; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 223, Global step 1688:
20-03-23 01:12-INFO-training batch loss: 0.0017; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 224, Global step 1689:
20-03-23 01:12-INFO-training batch loss: 0.0095; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 225, Global step 1690:
20-03-23 01:12-INFO-training batch loss: 0.0039; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 226, Global step 1691:
20-03-23 01:12-INFO-training batch loss: 0.0009; avg_loss: 0.0097
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 227, Global step 1692:
20-03-23 01:12-INFO-training batch loss: 0.0426; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 0.9844; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 228, Global step 1693:
20-03-23 01:12-INFO-training batch loss: 0.0060; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 229, Global step 1694:
20-03-23 01:12-INFO-training batch loss: 0.0012; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 230, Global step 1695:
20-03-23 01:12-INFO-training batch loss: 0.0004; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 231, Global step 1696:
20-03-23 01:12-INFO-training batch loss: 0.0272; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 232, Global step 1697:
20-03-23 01:12-INFO-training batch loss: 0.0459; avg_loss: 0.0100
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 233, Global step 1698:
20-03-23 01:12-INFO-training batch loss: 0.0136; avg_loss: 0.0100
20-03-23 01:12-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 234, Global step 1699:
20-03-23 01:12-INFO-training batch loss: 0.0018; avg_loss: 0.0100
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 235, Global step 1700:
20-03-23 01:12-INFO-training batch loss: 0.0050; avg_loss: 0.0100
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 236, Global step 1701:
20-03-23 01:12-INFO-training batch loss: 0.0015; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 237, Global step 1702:
20-03-23 01:12-INFO-training batch loss: 0.0225; avg_loss: 0.0100
20-03-23 01:12-INFO-training batch acc: 0.9844; avg_acc: 0.9970
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 238, Global step 1703:
20-03-23 01:12-INFO-training batch loss: 0.0021; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 239, Global step 1704:
20-03-23 01:12-INFO-training batch loss: 0.0021; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 240, Global step 1705:
20-03-23 01:12-INFO-training batch loss: 0.0019; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 241, Global step 1706:
20-03-23 01:12-INFO-training batch loss: 0.0078; avg_loss: 0.0099
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 242, Global step 1707:
20-03-23 01:12-INFO-training batch loss: 0.0014; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:12-INFO-Epoch 5, Batch 243, Global step 1708:
20-03-23 01:12-INFO-training batch loss: 0.0024; avg_loss: 0.0098
20-03-23 01:12-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:12-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 244, Global step 1709:
20-03-23 01:13-INFO-training batch loss: 0.0049; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 245, Global step 1710:
20-03-23 01:13-INFO-training batch loss: 0.0411; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 246, Global step 1711:
20-03-23 01:13-INFO-training batch loss: 0.0123; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 247, Global step 1712:
20-03-23 01:13-INFO-training batch loss: 0.0106; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 248, Global step 1713:
20-03-23 01:13-INFO-training batch loss: 0.0032; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 249, Global step 1714:
20-03-23 01:13-INFO-training batch loss: 0.0309; avg_loss: 0.0100
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 250, Global step 1715:
20-03-23 01:13-INFO-training batch loss: 0.0026; avg_loss: 0.0100
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 251, Global step 1716:
20-03-23 01:13-INFO-training batch loss: 0.0015; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 252, Global step 1717:
20-03-23 01:13-INFO-training batch loss: 0.0165; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 253, Global step 1718:
20-03-23 01:13-INFO-training batch loss: 0.0036; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 254, Global step 1719:
20-03-23 01:13-INFO-training batch loss: 0.0221; avg_loss: 0.0100
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 255, Global step 1720:
20-03-23 01:13-INFO-training batch loss: 0.0056; avg_loss: 0.0100
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 256, Global step 1721:
20-03-23 01:13-INFO-training batch loss: 0.0081; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 257, Global step 1722:
20-03-23 01:13-INFO-training batch loss: 0.0014; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 258, Global step 1723:
20-03-23 01:13-INFO-training batch loss: 0.0030; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 259, Global step 1724:
20-03-23 01:13-INFO-training batch loss: 0.0013; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 260, Global step 1725:
20-03-23 01:13-INFO-training batch loss: 0.0013; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 261, Global step 1726:
20-03-23 01:13-INFO-training batch loss: 0.0113; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 262, Global step 1727:
20-03-23 01:13-INFO-training batch loss: 0.0179; avg_loss: 0.0099
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 263, Global step 1728:
20-03-23 01:13-INFO-training batch loss: 0.0088; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9970
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 264, Global step 1729:
20-03-23 01:13-INFO-training batch loss: 0.0078; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9970
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 265, Global step 1730:
20-03-23 01:13-INFO-training batch loss: 0.0015; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 266, Global step 1731:
20-03-23 01:13-INFO-training batch loss: 0.0045; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 267, Global step 1732:
20-03-23 01:13-INFO-training batch loss: 0.0044; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 268, Global step 1733:
20-03-23 01:13-INFO-training batch loss: 0.0020; avg_loss: 0.0097
20-03-23 01:13-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:13-INFO-Epoch 5, Batch 269, Global step 1734:
20-03-23 01:13-INFO-training batch loss: 0.0207; avg_loss: 0.0098
20-03-23 01:13-INFO-training batch acc: 0.9922; avg_acc: 0.9971
20-03-23 01:13-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 270, Global step 1735:
20-03-23 01:14-INFO-training batch loss: 0.0050; avg_loss: 0.0098
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 271, Global step 1736:
20-03-23 01:14-INFO-training batch loss: 0.0016; avg_loss: 0.0097
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 272, Global step 1737:
20-03-23 01:14-INFO-training batch loss: 0.0024; avg_loss: 0.0097
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 273, Global step 1738:
20-03-23 01:14-INFO-training batch loss: 0.0011; avg_loss: 0.0097
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 274, Global step 1739:
20-03-23 01:14-INFO-training batch loss: 0.0008; avg_loss: 0.0096
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 275, Global step 1740:
20-03-23 01:14-INFO-training batch loss: 0.0033; avg_loss: 0.0096
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 276, Global step 1741:
20-03-23 01:14-INFO-training batch loss: 0.0013; avg_loss: 0.0096
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 277, Global step 1742:
20-03-23 01:14-INFO-training batch loss: 0.0007; avg_loss: 0.0096
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 278, Global step 1743:
20-03-23 01:14-INFO-training batch loss: 0.0015; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 279, Global step 1744:
20-03-23 01:14-INFO-training batch loss: 0.0011; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 280, Global step 1745:
20-03-23 01:14-INFO-training batch loss: 0.0014; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 281, Global step 1746:
20-03-23 01:14-INFO-training batch loss: 0.0097; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 282, Global step 1747:
20-03-23 01:14-INFO-training batch loss: 0.0172; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 283, Global step 1748:
20-03-23 01:14-INFO-training batch loss: 0.0025; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 284, Global step 1749:
20-03-23 01:14-INFO-training batch loss: 0.0186; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 0.9844; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 285, Global step 1750:
20-03-23 01:14-INFO-training batch loss: 0.0021; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9971
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 286, Global step 1751:
20-03-23 01:14-INFO-training batch loss: 0.0014; avg_loss: 0.0095
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 287, Global step 1752:
20-03-23 01:14-INFO-training batch loss: 0.0017; avg_loss: 0.0094
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 288, Global step 1753:
20-03-23 01:14-INFO-training batch loss: 0.0018; avg_loss: 0.0094
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 289, Global step 1754:
20-03-23 01:14-INFO-training batch loss: 0.0061; avg_loss: 0.0094
20-03-23 01:14-INFO-training batch acc: 0.9922; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 290, Global step 1755:
20-03-23 01:14-INFO-training batch loss: 0.0044; avg_loss: 0.0094
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 291, Global step 1756:
20-03-23 01:14-INFO-training batch loss: 0.0016; avg_loss: 0.0093
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 292, Global step 1757:
20-03-23 01:14-INFO-training batch loss: 0.0010; avg_loss: 0.0093
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, Batch 293, Global step 1758:
20-03-23 01:14-INFO-training batch loss: 0.0004; avg_loss: 0.0093
20-03-23 01:14-INFO-training batch acc: 1.0000; avg_acc: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:14-INFO-Epoch 5, training batch loss: 0.0004; avg_loss: 0.0093
20-03-23 01:14-INFO-Epoch 5, training batch accuracy: 1.0000; avg_accuracy: 0.9972
20-03-23 01:14-INFO-
20-03-23 01:15-INFO-Epoch 5, evaluating batch loss: 1.1826; avg_loss: 0.7552
20-03-23 01:15-INFO-Epoch 5, evaluating batch accuracy: 0.8857; avg_accuracy: 0.9109
20-03-23 01:15-INFO-
20-03-23 01:15-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
