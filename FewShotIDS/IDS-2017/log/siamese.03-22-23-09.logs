20-03-22 23:09-INFO-{'session_length': 24, 'height': 32, 'width': 32, 'num_labels': 8, 'learning_rate': 0.005, 'filter_sizes': [3, 4, 5, 6], 'num_filters': 64, 'filter_sizes_hierarchical': [3, 4, 5], 'num_fitlers_hierarchical': 64, 'is_train': True, 'early_stop': True, 'is_tuning': False}
20-03-22 23:09-WARNING-From ../utils.py:127: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

20-03-22 23:09-WARNING-From ../model/train.py:105: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

20-03-22 23:09-WARNING-From ../model/siamese_network.py:33: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

20-03-22 23:09-WARNING-From ../model/siamese_network.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

20-03-22 23:09-WARNING-From ../model/siamese_network.py:41: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

20-03-22 23:09-WARNING-From ../model/utils/utils.py:26: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151ee85890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151ee85890>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-From ../model/utils/utils.py:45: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling1D instead.
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151edf4410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151edf4410>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151ee854d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151ee854d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee85790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee85790>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151ee856d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151ee856d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee85790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee85790>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e2763d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e2763d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e276450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e276450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-From ../model/utils/modules.py:205: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
20-03-22 23:09-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f151e21ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f151e21ca90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1e94d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1e94d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1abf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1abf50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1abfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1abfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee49450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee49450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e16c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e16c590>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee49450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee49450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-From ../model/utils/modules.py:240: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
20-03-22 23:09-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151e19b450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151e19b450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-From ../model/utils/modules.py:242: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
20-03-22 23:09-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f151e16ccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f151e16ccd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-From ../model/utils/modules.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e2615d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e2615d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ede5410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ede5410>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e16cd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e16cd90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1e9c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1e9c10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1e9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1e9050>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1e9e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1e9e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1fa310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e1fa310>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1e9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e1e9490>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f152b865610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f152b865610>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e109fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e109fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e059f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151e059f90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e0768d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e0768d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee67a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151ee67a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e076750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f151e076750>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151edf0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7f151edf0690>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151e109a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151e109a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f151e216f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f151e216f50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151df87410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151df87410>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151e109910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f151e109910>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 23:09-WARNING-From ../model/base_model.py:132: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

20-03-22 23:09-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20-03-22 23:09-WARNING-From ../model/train.py:113: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

20-03-22 23:09-INFO-Epoch 0, Batch 1, Global step 1:
20-03-22 23:09-INFO-training batch loss: 4.2051; avg_loss: 4.2051
20-03-22 23:09-INFO-training batch acc: 0.5078; avg_acc: 0.5078
20-03-22 23:09-INFO-
20-03-22 23:09-INFO-Epoch 0, Batch 2, Global step 2:
20-03-22 23:09-INFO-training batch loss: 19.7923; avg_loss: 11.9987
20-03-22 23:09-INFO-training batch acc: 0.5938; avg_acc: 0.5508
20-03-22 23:09-INFO-
20-03-22 23:09-INFO-Epoch 0, Batch 3, Global step 3:
20-03-22 23:09-INFO-training batch loss: 9.3284; avg_loss: 11.1086
20-03-22 23:09-INFO-training batch acc: 0.5547; avg_acc: 0.5521
20-03-22 23:09-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 4, Global step 4:
20-03-22 23:10-INFO-training batch loss: 4.0881; avg_loss: 9.3535
20-03-22 23:10-INFO-training batch acc: 0.3984; avg_acc: 0.5137
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 5, Global step 5:
20-03-22 23:10-INFO-training batch loss: 2.3225; avg_loss: 7.9473
20-03-22 23:10-INFO-training batch acc: 0.4766; avg_acc: 0.5062
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 6, Global step 6:
20-03-22 23:10-INFO-training batch loss: 1.8313; avg_loss: 6.9280
20-03-22 23:10-INFO-training batch acc: 0.5859; avg_acc: 0.5195
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 7, Global step 7:
20-03-22 23:10-INFO-training batch loss: 1.1836; avg_loss: 6.1073
20-03-22 23:10-INFO-training batch acc: 0.6406; avg_acc: 0.5368
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 8, Global step 8:
20-03-22 23:10-INFO-training batch loss: 1.0083; avg_loss: 5.4700
20-03-22 23:10-INFO-training batch acc: 0.5078; avg_acc: 0.5332
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 9, Global step 9:
20-03-22 23:10-INFO-training batch loss: 0.8666; avg_loss: 4.9585
20-03-22 23:10-INFO-training batch acc: 0.5000; avg_acc: 0.5295
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 10, Global step 10:
20-03-22 23:10-INFO-training batch loss: 0.9333; avg_loss: 4.5560
20-03-22 23:10-INFO-training batch acc: 0.5469; avg_acc: 0.5312
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 11, Global step 11:
20-03-22 23:10-INFO-training batch loss: 0.7628; avg_loss: 4.2111
20-03-22 23:10-INFO-training batch acc: 0.6094; avg_acc: 0.5384
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 12, Global step 12:
20-03-22 23:10-INFO-training batch loss: 0.8104; avg_loss: 3.9277
20-03-22 23:10-INFO-training batch acc: 0.5312; avg_acc: 0.5378
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 13, Global step 13:
20-03-22 23:10-INFO-training batch loss: 0.7281; avg_loss: 3.6816
20-03-22 23:10-INFO-training batch acc: 0.5703; avg_acc: 0.5403
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 14, Global step 14:
20-03-22 23:10-INFO-training batch loss: 0.6652; avg_loss: 3.4661
20-03-22 23:10-INFO-training batch acc: 0.6406; avg_acc: 0.5474
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 15, Global step 15:
20-03-22 23:10-INFO-training batch loss: 0.7143; avg_loss: 3.2827
20-03-22 23:10-INFO-training batch acc: 0.5859; avg_acc: 0.5500
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 16, Global step 16:
20-03-22 23:10-INFO-training batch loss: 0.6752; avg_loss: 3.1197
20-03-22 23:10-INFO-training batch acc: 0.5703; avg_acc: 0.5513
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 17, Global step 17:
20-03-22 23:10-INFO-training batch loss: 0.7489; avg_loss: 2.9803
20-03-22 23:10-INFO-training batch acc: 0.5703; avg_acc: 0.5524
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 18, Global step 18:
20-03-22 23:10-INFO-training batch loss: 0.7727; avg_loss: 2.8576
20-03-22 23:10-INFO-training batch acc: 0.5000; avg_acc: 0.5495
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 19, Global step 19:
20-03-22 23:10-INFO-training batch loss: 0.7212; avg_loss: 2.7452
20-03-22 23:10-INFO-training batch acc: 0.4922; avg_acc: 0.5465
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 20, Global step 20:
20-03-22 23:10-INFO-training batch loss: 0.6502; avg_loss: 2.6404
20-03-22 23:10-INFO-training batch acc: 0.6094; avg_acc: 0.5496
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 21, Global step 21:
20-03-22 23:10-INFO-training batch loss: 0.6727; avg_loss: 2.5467
20-03-22 23:10-INFO-training batch acc: 0.5859; avg_acc: 0.5513
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 22, Global step 22:
20-03-22 23:10-INFO-training batch loss: 0.6793; avg_loss: 2.4618
20-03-22 23:10-INFO-training batch acc: 0.6250; avg_acc: 0.5547
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 23, Global step 23:
20-03-22 23:10-INFO-training batch loss: 0.6861; avg_loss: 2.3846
20-03-22 23:10-INFO-training batch acc: 0.5625; avg_acc: 0.5550
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 24, Global step 24:
20-03-22 23:10-INFO-training batch loss: 0.6704; avg_loss: 2.3132
20-03-22 23:10-INFO-training batch acc: 0.6172; avg_acc: 0.5576
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 25, Global step 25:
20-03-22 23:10-INFO-training batch loss: 0.6712; avg_loss: 2.2475
20-03-22 23:10-INFO-training batch acc: 0.5703; avg_acc: 0.5581
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 26, Global step 26:
20-03-22 23:10-INFO-training batch loss: 0.6568; avg_loss: 2.1863
20-03-22 23:10-INFO-training batch acc: 0.6094; avg_acc: 0.5601
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 27, Global step 27:
20-03-22 23:10-INFO-training batch loss: 0.6551; avg_loss: 2.1296
20-03-22 23:10-INFO-training batch acc: 0.6328; avg_acc: 0.5628
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 28, Global step 28:
20-03-22 23:10-INFO-training batch loss: 0.6425; avg_loss: 2.0765
20-03-22 23:10-INFO-training batch acc: 0.6562; avg_acc: 0.5661
20-03-22 23:10-INFO-
20-03-22 23:10-INFO-Epoch 0, Batch 29, Global step 29:
20-03-22 23:10-INFO-training batch loss: 0.7020; avg_loss: 2.0291
20-03-22 23:10-INFO-training batch acc: 0.5625; avg_acc: 0.5660
20-03-22 23:10-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 30, Global step 30:
20-03-22 23:11-INFO-training batch loss: 0.6807; avg_loss: 1.9842
20-03-22 23:11-INFO-training batch acc: 0.5391; avg_acc: 0.5651
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 31, Global step 31:
20-03-22 23:11-INFO-training batch loss: 0.6591; avg_loss: 1.9414
20-03-22 23:11-INFO-training batch acc: 0.5703; avg_acc: 0.5653
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 32, Global step 32:
20-03-22 23:11-INFO-training batch loss: 0.6607; avg_loss: 1.9014
20-03-22 23:11-INFO-training batch acc: 0.5938; avg_acc: 0.5662
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 33, Global step 33:
20-03-22 23:11-INFO-training batch loss: 0.6610; avg_loss: 1.8638
20-03-22 23:11-INFO-training batch acc: 0.5938; avg_acc: 0.5670
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 34, Global step 34:
20-03-22 23:11-INFO-training batch loss: 0.6629; avg_loss: 1.8285
20-03-22 23:11-INFO-training batch acc: 0.6016; avg_acc: 0.5680
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 35, Global step 35:
20-03-22 23:11-INFO-training batch loss: 0.6777; avg_loss: 1.7956
20-03-22 23:11-INFO-training batch acc: 0.5859; avg_acc: 0.5685
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 36, Global step 36:
20-03-22 23:11-INFO-training batch loss: 0.7016; avg_loss: 1.7652
20-03-22 23:11-INFO-training batch acc: 0.5625; avg_acc: 0.5684
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 37, Global step 37:
20-03-22 23:11-INFO-training batch loss: 0.6734; avg_loss: 1.7357
20-03-22 23:11-INFO-training batch acc: 0.5938; avg_acc: 0.5690
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 38, Global step 38:
20-03-22 23:11-INFO-training batch loss: 0.6682; avg_loss: 1.7076
20-03-22 23:11-INFO-training batch acc: 0.6484; avg_acc: 0.5711
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 39, Global step 39:
20-03-22 23:11-INFO-training batch loss: 0.6437; avg_loss: 1.6803
20-03-22 23:11-INFO-training batch acc: 0.5938; avg_acc: 0.5717
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 40, Global step 40:
20-03-22 23:11-INFO-training batch loss: 0.7038; avg_loss: 1.6559
20-03-22 23:11-INFO-training batch acc: 0.5234; avg_acc: 0.5705
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 41, Global step 41:
20-03-22 23:11-INFO-training batch loss: 0.6636; avg_loss: 1.6317
20-03-22 23:11-INFO-training batch acc: 0.6094; avg_acc: 0.5715
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 42, Global step 42:
20-03-22 23:11-INFO-training batch loss: 0.6918; avg_loss: 1.6094
20-03-22 23:11-INFO-training batch acc: 0.6094; avg_acc: 0.5724
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 43, Global step 43:
20-03-22 23:11-INFO-training batch loss: 0.6731; avg_loss: 1.5876
20-03-22 23:11-INFO-training batch acc: 0.5703; avg_acc: 0.5723
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 44, Global step 44:
20-03-22 23:11-INFO-training batch loss: 0.6600; avg_loss: 1.5665
20-03-22 23:11-INFO-training batch acc: 0.6172; avg_acc: 0.5733
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 45, Global step 45:
20-03-22 23:11-INFO-training batch loss: 0.6949; avg_loss: 1.5471
20-03-22 23:11-INFO-training batch acc: 0.5391; avg_acc: 0.5726
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 46, Global step 46:
20-03-22 23:11-INFO-training batch loss: 0.6702; avg_loss: 1.5281
20-03-22 23:11-INFO-training batch acc: 0.5859; avg_acc: 0.5729
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 47, Global step 47:
20-03-22 23:11-INFO-training batch loss: 0.6626; avg_loss: 1.5096
20-03-22 23:11-INFO-training batch acc: 0.6016; avg_acc: 0.5735
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 48, Global step 48:
20-03-22 23:11-INFO-training batch loss: 0.6434; avg_loss: 1.4916
20-03-22 23:11-INFO-training batch acc: 0.6953; avg_acc: 0.5760
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 49, Global step 49:
20-03-22 23:11-INFO-training batch loss: 0.6573; avg_loss: 1.4746
20-03-22 23:11-INFO-training batch acc: 0.6016; avg_acc: 0.5765
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 50, Global step 50:
20-03-22 23:11-INFO-training batch loss: 0.6911; avg_loss: 1.4589
20-03-22 23:11-INFO-training batch acc: 0.5391; avg_acc: 0.5758
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 51, Global step 51:
20-03-22 23:11-INFO-training batch loss: 0.6828; avg_loss: 1.4437
20-03-22 23:11-INFO-training batch acc: 0.5547; avg_acc: 0.5754
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 52, Global step 52:
20-03-22 23:11-INFO-training batch loss: 0.6912; avg_loss: 1.4292
20-03-22 23:11-INFO-training batch acc: 0.5703; avg_acc: 0.5753
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 53, Global step 53:
20-03-22 23:11-INFO-training batch loss: 0.6871; avg_loss: 1.4152
20-03-22 23:11-INFO-training batch acc: 0.6172; avg_acc: 0.5761
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 54, Global step 54:
20-03-22 23:11-INFO-training batch loss: 0.6628; avg_loss: 1.4013
20-03-22 23:11-INFO-training batch acc: 0.5781; avg_acc: 0.5761
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 55, Global step 55:
20-03-22 23:11-INFO-training batch loss: 0.6543; avg_loss: 1.3877
20-03-22 23:11-INFO-training batch acc: 0.6016; avg_acc: 0.5766
20-03-22 23:11-INFO-
20-03-22 23:11-INFO-Epoch 0, Batch 56, Global step 56:
20-03-22 23:11-INFO-training batch loss: 0.6361; avg_loss: 1.3743
20-03-22 23:11-INFO-training batch acc: 0.6250; avg_acc: 0.5774
20-03-22 23:11-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 57, Global step 57:
20-03-22 23:12-INFO-training batch loss: 0.6538; avg_loss: 1.3616
20-03-22 23:12-INFO-training batch acc: 0.5938; avg_acc: 0.5777
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 58, Global step 58:
20-03-22 23:12-INFO-training batch loss: 0.6421; avg_loss: 1.3492
20-03-22 23:12-INFO-training batch acc: 0.6875; avg_acc: 0.5796
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 59, Global step 59:
20-03-22 23:12-INFO-training batch loss: 0.6533; avg_loss: 1.3374
20-03-22 23:12-INFO-training batch acc: 0.5859; avg_acc: 0.5797
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 60, Global step 60:
20-03-22 23:12-INFO-training batch loss: 0.6446; avg_loss: 1.3259
20-03-22 23:12-INFO-training batch acc: 0.5078; avg_acc: 0.5785
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 61, Global step 61:
20-03-22 23:12-INFO-training batch loss: 0.6455; avg_loss: 1.3147
20-03-22 23:12-INFO-training batch acc: 0.6172; avg_acc: 0.5791
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 62, Global step 62:
20-03-22 23:12-INFO-training batch loss: 0.7309; avg_loss: 1.3053
20-03-22 23:12-INFO-training batch acc: 0.5312; avg_acc: 0.5784
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 63, Global step 63:
20-03-22 23:12-INFO-training batch loss: 0.6526; avg_loss: 1.2950
20-03-22 23:12-INFO-training batch acc: 0.6016; avg_acc: 0.5787
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 64, Global step 64:
20-03-22 23:12-INFO-training batch loss: 0.7165; avg_loss: 1.2859
20-03-22 23:12-INFO-training batch acc: 0.5234; avg_acc: 0.5779
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 65, Global step 65:
20-03-22 23:12-INFO-training batch loss: 0.6690; avg_loss: 1.2764
20-03-22 23:12-INFO-training batch acc: 0.5625; avg_acc: 0.5776
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 66, Global step 66:
20-03-22 23:12-INFO-training batch loss: 0.6445; avg_loss: 1.2669
20-03-22 23:12-INFO-training batch acc: 0.5781; avg_acc: 0.5777
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 67, Global step 67:
20-03-22 23:12-INFO-training batch loss: 0.6578; avg_loss: 1.2578
20-03-22 23:12-INFO-training batch acc: 0.5625; avg_acc: 0.5774
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 68, Global step 68:
20-03-22 23:12-INFO-training batch loss: 0.6569; avg_loss: 1.2489
20-03-22 23:12-INFO-training batch acc: 0.6016; avg_acc: 0.5778
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 69, Global step 69:
20-03-22 23:12-INFO-training batch loss: 0.6512; avg_loss: 1.2403
20-03-22 23:12-INFO-training batch acc: 0.6016; avg_acc: 0.5781
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 70, Global step 70:
20-03-22 23:12-INFO-training batch loss: 0.6552; avg_loss: 1.2319
20-03-22 23:12-INFO-training batch acc: 0.6094; avg_acc: 0.5786
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 71, Global step 71:
20-03-22 23:12-INFO-training batch loss: 0.7091; avg_loss: 1.2245
20-03-22 23:12-INFO-training batch acc: 0.5078; avg_acc: 0.5776
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 72, Global step 72:
20-03-22 23:12-INFO-training batch loss: 0.6674; avg_loss: 1.2168
20-03-22 23:12-INFO-training batch acc: 0.5469; avg_acc: 0.5771
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 73, Global step 73:
20-03-22 23:12-INFO-training batch loss: 0.6808; avg_loss: 1.2095
20-03-22 23:12-INFO-training batch acc: 0.5703; avg_acc: 0.5771
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 74, Global step 74:
20-03-22 23:12-INFO-training batch loss: 0.6690; avg_loss: 1.2022
20-03-22 23:12-INFO-training batch acc: 0.5781; avg_acc: 0.5771
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 75, Global step 75:
20-03-22 23:12-INFO-training batch loss: 0.6888; avg_loss: 1.1953
20-03-22 23:12-INFO-training batch acc: 0.5703; avg_acc: 0.5770
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 76, Global step 76:
20-03-22 23:12-INFO-training batch loss: 0.6268; avg_loss: 1.1878
20-03-22 23:12-INFO-training batch acc: 0.6406; avg_acc: 0.5778
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 77, Global step 77:
20-03-22 23:12-INFO-training batch loss: 0.6961; avg_loss: 1.1814
20-03-22 23:12-INFO-training batch acc: 0.5391; avg_acc: 0.5773
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 78, Global step 78:
20-03-22 23:12-INFO-training batch loss: 0.6527; avg_loss: 1.1747
20-03-22 23:12-INFO-training batch acc: 0.6172; avg_acc: 0.5778
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 79, Global step 79:
20-03-22 23:12-INFO-training batch loss: 0.6827; avg_loss: 1.1684
20-03-22 23:12-INFO-training batch acc: 0.5547; avg_acc: 0.5775
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 80, Global step 80:
20-03-22 23:12-INFO-training batch loss: 0.6459; avg_loss: 1.1619
20-03-22 23:12-INFO-training batch acc: 0.6562; avg_acc: 0.5785
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 81, Global step 81:
20-03-22 23:12-INFO-training batch loss: 0.6364; avg_loss: 1.1554
20-03-22 23:12-INFO-training batch acc: 0.6562; avg_acc: 0.5795
20-03-22 23:12-INFO-
20-03-22 23:12-INFO-Epoch 0, Batch 82, Global step 82:
20-03-22 23:12-INFO-training batch loss: 0.6630; avg_loss: 1.1494
20-03-22 23:12-INFO-training batch acc: 0.5781; avg_acc: 0.5795
20-03-22 23:12-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 83, Global step 83:
20-03-22 23:13-INFO-training batch loss: 0.6654; avg_loss: 1.1436
20-03-22 23:13-INFO-training batch acc: 0.6562; avg_acc: 0.5804
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 84, Global step 84:
20-03-22 23:13-INFO-training batch loss: 0.6510; avg_loss: 1.1377
20-03-22 23:13-INFO-training batch acc: 0.5469; avg_acc: 0.5800
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 85, Global step 85:
20-03-22 23:13-INFO-training batch loss: 0.6659; avg_loss: 1.1322
20-03-22 23:13-INFO-training batch acc: 0.5938; avg_acc: 0.5801
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 86, Global step 86:
20-03-22 23:13-INFO-training batch loss: 0.6456; avg_loss: 1.1265
20-03-22 23:13-INFO-training batch acc: 0.6250; avg_acc: 0.5807
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 87, Global step 87:
20-03-22 23:13-INFO-training batch loss: 0.6884; avg_loss: 1.1215
20-03-22 23:13-INFO-training batch acc: 0.5469; avg_acc: 0.5803
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 88, Global step 88:
20-03-22 23:13-INFO-training batch loss: 0.6523; avg_loss: 1.1161
20-03-22 23:13-INFO-training batch acc: 0.5859; avg_acc: 0.5803
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 89, Global step 89:
20-03-22 23:13-INFO-training batch loss: 0.6560; avg_loss: 1.1110
20-03-22 23:13-INFO-training batch acc: 0.5938; avg_acc: 0.5805
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 90, Global step 90:
20-03-22 23:13-INFO-training batch loss: 0.6887; avg_loss: 1.1063
20-03-22 23:13-INFO-training batch acc: 0.5547; avg_acc: 0.5802
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 91, Global step 91:
20-03-22 23:13-INFO-training batch loss: 0.6806; avg_loss: 1.1016
20-03-22 23:13-INFO-training batch acc: 0.5625; avg_acc: 0.5800
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 92, Global step 92:
20-03-22 23:13-INFO-training batch loss: 0.6359; avg_loss: 1.0965
20-03-22 23:13-INFO-training batch acc: 0.6797; avg_acc: 0.5811
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 93, Global step 93:
20-03-22 23:13-INFO-training batch loss: 0.6698; avg_loss: 1.0920
20-03-22 23:13-INFO-training batch acc: 0.5703; avg_acc: 0.5810
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 94, Global step 94:
20-03-22 23:13-INFO-training batch loss: 0.6434; avg_loss: 1.0872
20-03-22 23:13-INFO-training batch acc: 0.6641; avg_acc: 0.5819
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 95, Global step 95:
20-03-22 23:13-INFO-training batch loss: 0.6834; avg_loss: 1.0829
20-03-22 23:13-INFO-training batch acc: 0.5469; avg_acc: 0.5815
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 96, Global step 96:
20-03-22 23:13-INFO-training batch loss: 0.6677; avg_loss: 1.0786
20-03-22 23:13-INFO-training batch acc: 0.5859; avg_acc: 0.5815
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 97, Global step 97:
20-03-22 23:13-INFO-training batch loss: 0.6577; avg_loss: 1.0743
20-03-22 23:13-INFO-training batch acc: 0.6094; avg_acc: 0.5818
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 98, Global step 98:
20-03-22 23:13-INFO-training batch loss: 0.6687; avg_loss: 1.0701
20-03-22 23:13-INFO-training batch acc: 0.5547; avg_acc: 0.5816
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 99, Global step 99:
20-03-22 23:13-INFO-training batch loss: 0.6818; avg_loss: 1.0662
20-03-22 23:13-INFO-training batch acc: 0.5625; avg_acc: 0.5814
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 100, Global step 100:
20-03-22 23:13-INFO-training batch loss: 0.6651; avg_loss: 1.0622
20-03-22 23:13-INFO-training batch acc: 0.6016; avg_acc: 0.5816
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 101, Global step 101:
20-03-22 23:13-INFO-training batch loss: 0.6774; avg_loss: 1.0584
20-03-22 23:13-INFO-training batch acc: 0.5703; avg_acc: 0.5815
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 102, Global step 102:
20-03-22 23:13-INFO-training batch loss: 0.6564; avg_loss: 1.0544
20-03-22 23:13-INFO-training batch acc: 0.5781; avg_acc: 0.5814
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 103, Global step 103:
20-03-22 23:13-INFO-training batch loss: 0.6526; avg_loss: 1.0505
20-03-22 23:13-INFO-training batch acc: 0.6250; avg_acc: 0.5818
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 104, Global step 104:
20-03-22 23:13-INFO-training batch loss: 0.6260; avg_loss: 1.0465
20-03-22 23:13-INFO-training batch acc: 0.6562; avg_acc: 0.5826
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 105, Global step 105:
20-03-22 23:13-INFO-training batch loss: 0.6728; avg_loss: 1.0429
20-03-22 23:13-INFO-training batch acc: 0.5625; avg_acc: 0.5824
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 106, Global step 106:
20-03-22 23:13-INFO-training batch loss: 0.6969; avg_loss: 1.0396
20-03-22 23:13-INFO-training batch acc: 0.5234; avg_acc: 0.5818
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 107, Global step 107:
20-03-22 23:13-INFO-training batch loss: 0.6772; avg_loss: 1.0363
20-03-22 23:13-INFO-training batch acc: 0.6016; avg_acc: 0.5820
20-03-22 23:13-INFO-
20-03-22 23:13-INFO-Epoch 0, Batch 108, Global step 108:
20-03-22 23:13-INFO-training batch loss: 0.6422; avg_loss: 1.0326
20-03-22 23:13-INFO-training batch acc: 0.6406; avg_acc: 0.5825
20-03-22 23:13-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 109, Global step 109:
20-03-22 23:14-INFO-training batch loss: 0.6834; avg_loss: 1.0294
20-03-22 23:14-INFO-training batch acc: 0.5312; avg_acc: 0.5821
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 110, Global step 110:
20-03-22 23:14-INFO-training batch loss: 0.6928; avg_loss: 1.0263
20-03-22 23:14-INFO-training batch acc: 0.6172; avg_acc: 0.5824
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 111, Global step 111:
20-03-22 23:14-INFO-training batch loss: 0.6856; avg_loss: 1.0233
20-03-22 23:14-INFO-training batch acc: 0.5859; avg_acc: 0.5824
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 112, Global step 112:
20-03-22 23:14-INFO-training batch loss: 0.6538; avg_loss: 1.0200
20-03-22 23:14-INFO-training batch acc: 0.5938; avg_acc: 0.5825
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 113, Global step 113:
20-03-22 23:14-INFO-training batch loss: 0.6755; avg_loss: 1.0169
20-03-22 23:14-INFO-training batch acc: 0.6016; avg_acc: 0.5827
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 114, Global step 114:
20-03-22 23:14-INFO-training batch loss: 0.6762; avg_loss: 1.0139
20-03-22 23:14-INFO-training batch acc: 0.5781; avg_acc: 0.5826
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 115, Global step 115:
20-03-22 23:14-INFO-training batch loss: 0.6799; avg_loss: 1.0110
20-03-22 23:14-INFO-training batch acc: 0.5938; avg_acc: 0.5827
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 116, Global step 116:
20-03-22 23:14-INFO-training batch loss: 0.6441; avg_loss: 1.0079
20-03-22 23:14-INFO-training batch acc: 0.6562; avg_acc: 0.5834
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 117, Global step 117:
20-03-22 23:14-INFO-training batch loss: 0.6754; avg_loss: 1.0050
20-03-22 23:14-INFO-training batch acc: 0.5469; avg_acc: 0.5831
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 118, Global step 118:
20-03-22 23:14-INFO-training batch loss: 0.6669; avg_loss: 1.0022
20-03-22 23:14-INFO-training batch acc: 0.5859; avg_acc: 0.5831
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 119, Global step 119:
20-03-22 23:14-INFO-training batch loss: 0.6611; avg_loss: 0.9993
20-03-22 23:14-INFO-training batch acc: 0.5859; avg_acc: 0.5831
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 120, Global step 120:
20-03-22 23:14-INFO-training batch loss: 0.6421; avg_loss: 0.9963
20-03-22 23:14-INFO-training batch acc: 0.6406; avg_acc: 0.5836
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 121, Global step 121:
20-03-22 23:14-INFO-training batch loss: 0.6890; avg_loss: 0.9938
20-03-22 23:14-INFO-training batch acc: 0.5469; avg_acc: 0.5833
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 122, Global step 122:
20-03-22 23:14-INFO-training batch loss: 0.6804; avg_loss: 0.9912
20-03-22 23:14-INFO-training batch acc: 0.5391; avg_acc: 0.5829
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 123, Global step 123:
20-03-22 23:14-INFO-training batch loss: 0.6151; avg_loss: 0.9882
20-03-22 23:14-INFO-training batch acc: 0.7266; avg_acc: 0.5841
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 124, Global step 124:
20-03-22 23:14-INFO-training batch loss: 0.6697; avg_loss: 0.9856
20-03-22 23:14-INFO-training batch acc: 0.5938; avg_acc: 0.5842
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 125, Global step 125:
20-03-22 23:14-INFO-training batch loss: 0.6775; avg_loss: 0.9831
20-03-22 23:14-INFO-training batch acc: 0.6016; avg_acc: 0.5843
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 126, Global step 126:
20-03-22 23:14-INFO-training batch loss: 0.6583; avg_loss: 0.9805
20-03-22 23:14-INFO-training batch acc: 0.6172; avg_acc: 0.5846
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 127, Global step 127:
20-03-22 23:14-INFO-training batch loss: 0.6414; avg_loss: 0.9779
20-03-22 23:14-INFO-training batch acc: 0.6328; avg_acc: 0.5850
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 128, Global step 128:
20-03-22 23:14-INFO-training batch loss: 0.6430; avg_loss: 0.9753
20-03-22 23:14-INFO-training batch acc: 0.6484; avg_acc: 0.5854
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 129, Global step 129:
20-03-22 23:14-INFO-training batch loss: 0.6626; avg_loss: 0.9728
20-03-22 23:14-INFO-training batch acc: 0.5859; avg_acc: 0.5855
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 130, Global step 130:
20-03-22 23:14-INFO-training batch loss: 0.6733; avg_loss: 0.9705
20-03-22 23:14-INFO-training batch acc: 0.5703; avg_acc: 0.5853
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 131, Global step 131:
20-03-22 23:14-INFO-training batch loss: 0.6817; avg_loss: 0.9683
20-03-22 23:14-INFO-training batch acc: 0.5703; avg_acc: 0.5852
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 132, Global step 132:
20-03-22 23:14-INFO-training batch loss: 0.6524; avg_loss: 0.9659
20-03-22 23:14-INFO-training batch acc: 0.5859; avg_acc: 0.5852
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 133, Global step 133:
20-03-22 23:14-INFO-training batch loss: 0.6506; avg_loss: 0.9636
20-03-22 23:14-INFO-training batch acc: 0.6172; avg_acc: 0.5855
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 134, Global step 134:
20-03-22 23:14-INFO-training batch loss: 0.6771; avg_loss: 0.9614
20-03-22 23:14-INFO-training batch acc: 0.5312; avg_acc: 0.5851
20-03-22 23:14-INFO-
20-03-22 23:14-INFO-Epoch 0, Batch 135, Global step 135:
20-03-22 23:14-INFO-training batch loss: 0.6516; avg_loss: 0.9591
20-03-22 23:14-INFO-training batch acc: 0.6016; avg_acc: 0.5852
20-03-22 23:14-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 136, Global step 136:
20-03-22 23:15-INFO-training batch loss: 0.6649; avg_loss: 0.9570
20-03-22 23:15-INFO-training batch acc: 0.5781; avg_acc: 0.5851
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 137, Global step 137:
20-03-22 23:15-INFO-training batch loss: 0.6653; avg_loss: 0.9548
20-03-22 23:15-INFO-training batch acc: 0.6328; avg_acc: 0.5855
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 138, Global step 138:
20-03-22 23:15-INFO-training batch loss: 0.7075; avg_loss: 0.9530
20-03-22 23:15-INFO-training batch acc: 0.5234; avg_acc: 0.5850
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 139, Global step 139:
20-03-22 23:15-INFO-training batch loss: 0.6448; avg_loss: 0.9508
20-03-22 23:15-INFO-training batch acc: 0.5859; avg_acc: 0.5850
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 140, Global step 140:
20-03-22 23:15-INFO-training batch loss: 0.6530; avg_loss: 0.9487
20-03-22 23:15-INFO-training batch acc: 0.5859; avg_acc: 0.5850
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 141, Global step 141:
20-03-22 23:15-INFO-training batch loss: 0.6333; avg_loss: 0.9465
20-03-22 23:15-INFO-training batch acc: 0.5859; avg_acc: 0.5851
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 142, Global step 142:
20-03-22 23:15-INFO-training batch loss: 0.6508; avg_loss: 0.9444
20-03-22 23:15-INFO-training batch acc: 0.6016; avg_acc: 0.5852
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 143, Global step 143:
20-03-22 23:15-INFO-training batch loss: 0.6780; avg_loss: 0.9425
20-03-22 23:15-INFO-training batch acc: 0.5859; avg_acc: 0.5852
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 144, Global step 144:
20-03-22 23:15-INFO-training batch loss: 0.6977; avg_loss: 0.9408
20-03-22 23:15-INFO-training batch acc: 0.5469; avg_acc: 0.5849
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 145, Global step 145:
20-03-22 23:15-INFO-training batch loss: 0.6639; avg_loss: 0.9389
20-03-22 23:15-INFO-training batch acc: 0.5938; avg_acc: 0.5850
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 146, Global step 146:
20-03-22 23:15-INFO-training batch loss: 0.6575; avg_loss: 0.9370
20-03-22 23:15-INFO-training batch acc: 0.6094; avg_acc: 0.5851
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 147, Global step 147:
20-03-22 23:15-INFO-training batch loss: 0.6726; avg_loss: 0.9352
20-03-22 23:15-INFO-training batch acc: 0.5859; avg_acc: 0.5851
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 148, Global step 148:
20-03-22 23:15-INFO-training batch loss: 0.6384; avg_loss: 0.9332
20-03-22 23:15-INFO-training batch acc: 0.6719; avg_acc: 0.5857
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 149, Global step 149:
20-03-22 23:15-INFO-training batch loss: 0.6465; avg_loss: 0.9312
20-03-22 23:15-INFO-training batch acc: 0.6016; avg_acc: 0.5858
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 150, Global step 150:
20-03-22 23:15-INFO-training batch loss: 0.6910; avg_loss: 0.9296
20-03-22 23:15-INFO-training batch acc: 0.5312; avg_acc: 0.5855
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 151, Global step 151:
20-03-22 23:15-INFO-training batch loss: 0.6268; avg_loss: 0.9276
20-03-22 23:15-INFO-training batch acc: 0.6250; avg_acc: 0.5857
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 152, Global step 152:
20-03-22 23:15-INFO-training batch loss: 0.6954; avg_loss: 0.9261
20-03-22 23:15-INFO-training batch acc: 0.5000; avg_acc: 0.5852
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 153, Global step 153:
20-03-22 23:15-INFO-training batch loss: 0.6622; avg_loss: 0.9244
20-03-22 23:15-INFO-training batch acc: 0.5859; avg_acc: 0.5852
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 154, Global step 154:
20-03-22 23:15-INFO-training batch loss: 0.6491; avg_loss: 0.9226
20-03-22 23:15-INFO-training batch acc: 0.6094; avg_acc: 0.5853
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 155, Global step 155:
20-03-22 23:15-INFO-training batch loss: 0.6295; avg_loss: 0.9207
20-03-22 23:15-INFO-training batch acc: 0.6172; avg_acc: 0.5855
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 156, Global step 156:
20-03-22 23:15-INFO-training batch loss: 0.6200; avg_loss: 0.9188
20-03-22 23:15-INFO-training batch acc: 0.6016; avg_acc: 0.5856
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 157, Global step 157:
20-03-22 23:15-INFO-training batch loss: 0.6094; avg_loss: 0.9168
20-03-22 23:15-INFO-training batch acc: 0.6328; avg_acc: 0.5859
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 158, Global step 158:
20-03-22 23:15-INFO-training batch loss: 0.7021; avg_loss: 0.9155
20-03-22 23:15-INFO-training batch acc: 0.6094; avg_acc: 0.5861
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 159, Global step 159:
20-03-22 23:15-INFO-training batch loss: 0.6362; avg_loss: 0.9137
20-03-22 23:15-INFO-training batch acc: 0.6172; avg_acc: 0.5863
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 160, Global step 160:
20-03-22 23:15-INFO-training batch loss: 0.6408; avg_loss: 0.9120
20-03-22 23:15-INFO-training batch acc: 0.6094; avg_acc: 0.5864
20-03-22 23:15-INFO-
20-03-22 23:15-INFO-Epoch 0, Batch 161, Global step 161:
20-03-22 23:15-INFO-training batch loss: 0.5875; avg_loss: 0.9100
20-03-22 23:15-INFO-training batch acc: 0.6797; avg_acc: 0.5870
20-03-22 23:15-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 162, Global step 162:
20-03-22 23:16-INFO-training batch loss: 0.6992; avg_loss: 0.9087
20-03-22 23:16-INFO-training batch acc: 0.5703; avg_acc: 0.5869
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 163, Global step 163:
20-03-22 23:16-INFO-training batch loss: 0.7279; avg_loss: 0.9076
20-03-22 23:16-INFO-training batch acc: 0.5938; avg_acc: 0.5869
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 164, Global step 164:
20-03-22 23:16-INFO-training batch loss: 0.6376; avg_loss: 0.9059
20-03-22 23:16-INFO-training batch acc: 0.5938; avg_acc: 0.5870
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 165, Global step 165:
20-03-22 23:16-INFO-training batch loss: 0.6348; avg_loss: 0.9043
20-03-22 23:16-INFO-training batch acc: 0.6406; avg_acc: 0.5873
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 166, Global step 166:
20-03-22 23:16-INFO-training batch loss: 0.6643; avg_loss: 0.9028
20-03-22 23:16-INFO-training batch acc: 0.5703; avg_acc: 0.5872
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 167, Global step 167:
20-03-22 23:16-INFO-training batch loss: 0.7129; avg_loss: 0.9017
20-03-22 23:16-INFO-training batch acc: 0.4844; avg_acc: 0.5866
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 168, Global step 168:
20-03-22 23:16-INFO-training batch loss: 0.6330; avg_loss: 0.9001
20-03-22 23:16-INFO-training batch acc: 0.6797; avg_acc: 0.5871
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 169, Global step 169:
20-03-22 23:16-INFO-training batch loss: 0.6874; avg_loss: 0.8988
20-03-22 23:16-INFO-training batch acc: 0.5469; avg_acc: 0.5869
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 170, Global step 170:
20-03-22 23:16-INFO-training batch loss: 0.6688; avg_loss: 0.8975
20-03-22 23:16-INFO-training batch acc: 0.5781; avg_acc: 0.5869
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 171, Global step 171:
20-03-22 23:16-INFO-training batch loss: 0.6549; avg_loss: 0.8961
20-03-22 23:16-INFO-training batch acc: 0.6172; avg_acc: 0.5870
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 172, Global step 172:
20-03-22 23:16-INFO-training batch loss: 0.6843; avg_loss: 0.8948
20-03-22 23:16-INFO-training batch acc: 0.5625; avg_acc: 0.5869
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 173, Global step 173:
20-03-22 23:16-INFO-training batch loss: 0.6472; avg_loss: 0.8934
20-03-22 23:16-INFO-training batch acc: 0.5703; avg_acc: 0.5868
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 174, Global step 174:
20-03-22 23:16-INFO-training batch loss: 0.6557; avg_loss: 0.8920
20-03-22 23:16-INFO-training batch acc: 0.6172; avg_acc: 0.5870
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 175, Global step 175:
20-03-22 23:16-INFO-training batch loss: 0.6317; avg_loss: 0.8905
20-03-22 23:16-INFO-training batch acc: 0.6172; avg_acc: 0.5871
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 176, Global step 176:
20-03-22 23:16-INFO-training batch loss: 0.6585; avg_loss: 0.8892
20-03-22 23:16-INFO-training batch acc: 0.6172; avg_acc: 0.5873
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 177, Global step 177:
20-03-22 23:16-INFO-training batch loss: 0.6050; avg_loss: 0.8876
20-03-22 23:16-INFO-training batch acc: 0.6719; avg_acc: 0.5878
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 178, Global step 178:
20-03-22 23:16-INFO-training batch loss: 0.6670; avg_loss: 0.8864
20-03-22 23:16-INFO-training batch acc: 0.5703; avg_acc: 0.5877
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 179, Global step 179:
20-03-22 23:16-INFO-training batch loss: 0.6591; avg_loss: 0.8851
20-03-22 23:16-INFO-training batch acc: 0.5547; avg_acc: 0.5875
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 180, Global step 180:
20-03-22 23:16-INFO-training batch loss: 0.6513; avg_loss: 0.8838
20-03-22 23:16-INFO-training batch acc: 0.5703; avg_acc: 0.5874
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 181, Global step 181:
20-03-22 23:16-INFO-training batch loss: 0.6677; avg_loss: 0.8826
20-03-22 23:16-INFO-training batch acc: 0.5234; avg_acc: 0.5871
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 182, Global step 182:
20-03-22 23:16-INFO-training batch loss: 0.6246; avg_loss: 0.8812
20-03-22 23:16-INFO-training batch acc: 0.6562; avg_acc: 0.5874
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 183, Global step 183:
20-03-22 23:16-INFO-training batch loss: 0.6510; avg_loss: 0.8799
20-03-22 23:16-INFO-training batch acc: 0.6016; avg_acc: 0.5875
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 184, Global step 184:
20-03-22 23:16-INFO-training batch loss: 0.6364; avg_loss: 0.8786
20-03-22 23:16-INFO-training batch acc: 0.6328; avg_acc: 0.5878
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 185, Global step 185:
20-03-22 23:16-INFO-training batch loss: 0.6543; avg_loss: 0.8774
20-03-22 23:16-INFO-training batch acc: 0.6172; avg_acc: 0.5879
20-03-22 23:16-INFO-
20-03-22 23:16-INFO-Epoch 0, Batch 186, Global step 186:
20-03-22 23:16-INFO-training batch loss: 0.6365; avg_loss: 0.8761
20-03-22 23:16-INFO-training batch acc: 0.6016; avg_acc: 0.5880
20-03-22 23:16-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 187, Global step 187:
20-03-22 23:17-INFO-training batch loss: 0.6493; avg_loss: 0.8749
20-03-22 23:17-INFO-training batch acc: 0.6172; avg_acc: 0.5882
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 188, Global step 188:
20-03-22 23:17-INFO-training batch loss: 0.6891; avg_loss: 0.8739
20-03-22 23:17-INFO-training batch acc: 0.5703; avg_acc: 0.5881
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 189, Global step 189:
20-03-22 23:17-INFO-training batch loss: 0.6312; avg_loss: 0.8726
20-03-22 23:17-INFO-training batch acc: 0.6328; avg_acc: 0.5883
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 190, Global step 190:
20-03-22 23:17-INFO-training batch loss: 0.6688; avg_loss: 0.8716
20-03-22 23:17-INFO-training batch acc: 0.5859; avg_acc: 0.5883
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 191, Global step 191:
20-03-22 23:17-INFO-training batch loss: 0.6611; avg_loss: 0.8705
20-03-22 23:17-INFO-training batch acc: 0.6406; avg_acc: 0.5886
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 192, Global step 192:
20-03-22 23:17-INFO-training batch loss: 0.6522; avg_loss: 0.8693
20-03-22 23:17-INFO-training batch acc: 0.6172; avg_acc: 0.5887
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 193, Global step 193:
20-03-22 23:17-INFO-training batch loss: 0.6603; avg_loss: 0.8682
20-03-22 23:17-INFO-training batch acc: 0.5781; avg_acc: 0.5886
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 194, Global step 194:
20-03-22 23:17-INFO-training batch loss: 0.6569; avg_loss: 0.8671
20-03-22 23:17-INFO-training batch acc: 0.6016; avg_acc: 0.5887
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 195, Global step 195:
20-03-22 23:17-INFO-training batch loss: 0.6565; avg_loss: 0.8661
20-03-22 23:17-INFO-training batch acc: 0.5703; avg_acc: 0.5886
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 196, Global step 196:
20-03-22 23:17-INFO-training batch loss: 0.6399; avg_loss: 0.8649
20-03-22 23:17-INFO-training batch acc: 0.6406; avg_acc: 0.5889
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 197, Global step 197:
20-03-22 23:17-INFO-training batch loss: 0.6834; avg_loss: 0.8640
20-03-22 23:17-INFO-training batch acc: 0.5859; avg_acc: 0.5889
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 198, Global step 198:
20-03-22 23:17-INFO-training batch loss: 0.6278; avg_loss: 0.8628
20-03-22 23:17-INFO-training batch acc: 0.5938; avg_acc: 0.5889
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 199, Global step 199:
20-03-22 23:17-INFO-training batch loss: 0.6547; avg_loss: 0.8618
20-03-22 23:17-INFO-training batch acc: 0.5938; avg_acc: 0.5889
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 200, Global step 200:
20-03-22 23:17-INFO-training batch loss: 0.6386; avg_loss: 0.8606
20-03-22 23:17-INFO-training batch acc: 0.6562; avg_acc: 0.5893
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 201, Global step 201:
20-03-22 23:17-INFO-training batch loss: 0.5983; avg_loss: 0.8593
20-03-22 23:17-INFO-training batch acc: 0.6406; avg_acc: 0.5895
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 202, Global step 202:
20-03-22 23:17-INFO-training batch loss: 0.6349; avg_loss: 0.8582
20-03-22 23:17-INFO-training batch acc: 0.6016; avg_acc: 0.5896
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 203, Global step 203:
20-03-22 23:17-INFO-training batch loss: 0.6757; avg_loss: 0.8573
20-03-22 23:17-INFO-training batch acc: 0.6016; avg_acc: 0.5896
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 204, Global step 204:
20-03-22 23:17-INFO-training batch loss: 0.6098; avg_loss: 0.8561
20-03-22 23:17-INFO-training batch acc: 0.6328; avg_acc: 0.5898
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 205, Global step 205:
20-03-22 23:17-INFO-training batch loss: 0.6879; avg_loss: 0.8553
20-03-22 23:17-INFO-training batch acc: 0.5703; avg_acc: 0.5897
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 206, Global step 206:
20-03-22 23:17-INFO-training batch loss: 0.6530; avg_loss: 0.8543
20-03-22 23:17-INFO-training batch acc: 0.5938; avg_acc: 0.5898
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 207, Global step 207:
20-03-22 23:17-INFO-training batch loss: 0.6457; avg_loss: 0.8533
20-03-22 23:17-INFO-training batch acc: 0.6328; avg_acc: 0.5900
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 208, Global step 208:
20-03-22 23:17-INFO-training batch loss: 0.6555; avg_loss: 0.8523
20-03-22 23:17-INFO-training batch acc: 0.6016; avg_acc: 0.5900
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 209, Global step 209:
20-03-22 23:17-INFO-training batch loss: 0.6465; avg_loss: 0.8514
20-03-22 23:17-INFO-training batch acc: 0.6250; avg_acc: 0.5902
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 210, Global step 210:
20-03-22 23:17-INFO-training batch loss: 0.6316; avg_loss: 0.8503
20-03-22 23:17-INFO-training batch acc: 0.6250; avg_acc: 0.5904
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 211, Global step 211:
20-03-22 23:17-INFO-training batch loss: 0.6519; avg_loss: 0.8494
20-03-22 23:17-INFO-training batch acc: 0.5859; avg_acc: 0.5903
20-03-22 23:17-INFO-
20-03-22 23:17-INFO-Epoch 0, Batch 212, Global step 212:
20-03-22 23:17-INFO-training batch loss: 0.6359; avg_loss: 0.8484
20-03-22 23:17-INFO-training batch acc: 0.6406; avg_acc: 0.5906
20-03-22 23:17-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 213, Global step 213:
20-03-22 23:18-INFO-training batch loss: 0.7088; avg_loss: 0.8477
20-03-22 23:18-INFO-training batch acc: 0.5312; avg_acc: 0.5903
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 214, Global step 214:
20-03-22 23:18-INFO-training batch loss: 0.6821; avg_loss: 0.8469
20-03-22 23:18-INFO-training batch acc: 0.5703; avg_acc: 0.5902
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 215, Global step 215:
20-03-22 23:18-INFO-training batch loss: 0.6201; avg_loss: 0.8459
20-03-22 23:18-INFO-training batch acc: 0.6328; avg_acc: 0.5904
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 216, Global step 216:
20-03-22 23:18-INFO-training batch loss: 0.6932; avg_loss: 0.8452
20-03-22 23:18-INFO-training batch acc: 0.4844; avg_acc: 0.5899
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 217, Global step 217:
20-03-22 23:18-INFO-training batch loss: 0.6540; avg_loss: 0.8443
20-03-22 23:18-INFO-training batch acc: 0.5781; avg_acc: 0.5899
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 218, Global step 218:
20-03-22 23:18-INFO-training batch loss: 0.6686; avg_loss: 0.8435
20-03-22 23:18-INFO-training batch acc: 0.5625; avg_acc: 0.5897
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 219, Global step 219:
20-03-22 23:18-INFO-training batch loss: 0.6490; avg_loss: 0.8426
20-03-22 23:18-INFO-training batch acc: 0.5781; avg_acc: 0.5897
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 220, Global step 220:
20-03-22 23:18-INFO-training batch loss: 0.6438; avg_loss: 0.8417
20-03-22 23:18-INFO-training batch acc: 0.6250; avg_acc: 0.5898
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 221, Global step 221:
20-03-22 23:18-INFO-training batch loss: 0.6556; avg_loss: 0.8409
20-03-22 23:18-INFO-training batch acc: 0.6328; avg_acc: 0.5900
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 222, Global step 222:
20-03-22 23:18-INFO-training batch loss: 0.6434; avg_loss: 0.8400
20-03-22 23:18-INFO-training batch acc: 0.6328; avg_acc: 0.5902
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 223, Global step 223:
20-03-22 23:18-INFO-training batch loss: 0.6679; avg_loss: 0.8392
20-03-22 23:18-INFO-training batch acc: 0.5469; avg_acc: 0.5900
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 224, Global step 224:
20-03-22 23:18-INFO-training batch loss: 0.5982; avg_loss: 0.8381
20-03-22 23:18-INFO-training batch acc: 0.6406; avg_acc: 0.5903
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 225, Global step 225:
20-03-22 23:18-INFO-training batch loss: 0.5776; avg_loss: 0.8370
20-03-22 23:18-INFO-training batch acc: 0.6406; avg_acc: 0.5905
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 226, Global step 226:
20-03-22 23:18-INFO-training batch loss: 0.7096; avg_loss: 0.8364
20-03-22 23:18-INFO-training batch acc: 0.5312; avg_acc: 0.5902
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 227, Global step 227:
20-03-22 23:18-INFO-training batch loss: 0.6134; avg_loss: 0.8354
20-03-22 23:18-INFO-training batch acc: 0.6406; avg_acc: 0.5904
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 228, Global step 228:
20-03-22 23:18-INFO-training batch loss: 0.6313; avg_loss: 0.8345
20-03-22 23:18-INFO-training batch acc: 0.6250; avg_acc: 0.5906
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 229, Global step 229:
20-03-22 23:18-INFO-training batch loss: 0.6366; avg_loss: 0.8337
20-03-22 23:18-INFO-training batch acc: 0.5781; avg_acc: 0.5905
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 230, Global step 230:
20-03-22 23:18-INFO-training batch loss: 0.6161; avg_loss: 0.8327
20-03-22 23:18-INFO-training batch acc: 0.6250; avg_acc: 0.5907
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 231, Global step 231:
20-03-22 23:18-INFO-training batch loss: 0.5867; avg_loss: 0.8316
20-03-22 23:18-INFO-training batch acc: 0.6562; avg_acc: 0.5910
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 232, Global step 232:
20-03-22 23:18-INFO-training batch loss: 0.6774; avg_loss: 0.8310
20-03-22 23:18-INFO-training batch acc: 0.5625; avg_acc: 0.5909
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 233, Global step 233:
20-03-22 23:18-INFO-training batch loss: 0.5697; avg_loss: 0.8299
20-03-22 23:18-INFO-training batch acc: 0.6875; avg_acc: 0.5913
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 234, Global step 234:
20-03-22 23:18-INFO-training batch loss: 0.6666; avg_loss: 0.8292
20-03-22 23:18-INFO-training batch acc: 0.5391; avg_acc: 0.5910
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 235, Global step 235:
20-03-22 23:18-INFO-training batch loss: 0.6266; avg_loss: 0.8283
20-03-22 23:18-INFO-training batch acc: 0.5859; avg_acc: 0.5910
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 236, Global step 236:
20-03-22 23:18-INFO-training batch loss: 0.6203; avg_loss: 0.8274
20-03-22 23:18-INFO-training batch acc: 0.5938; avg_acc: 0.5910
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 237, Global step 237:
20-03-22 23:18-INFO-training batch loss: 0.6366; avg_loss: 0.8266
20-03-22 23:18-INFO-training batch acc: 0.5938; avg_acc: 0.5910
20-03-22 23:18-INFO-
20-03-22 23:18-INFO-Epoch 0, Batch 238, Global step 238:
20-03-22 23:18-INFO-training batch loss: 0.6006; avg_loss: 0.8257
20-03-22 23:18-INFO-training batch acc: 0.6484; avg_acc: 0.5913
20-03-22 23:18-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 239, Global step 239:
20-03-22 23:19-INFO-training batch loss: 0.6381; avg_loss: 0.8249
20-03-22 23:19-INFO-training batch acc: 0.5703; avg_acc: 0.5912
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 240, Global step 240:
20-03-22 23:19-INFO-training batch loss: 0.6269; avg_loss: 0.8241
20-03-22 23:19-INFO-training batch acc: 0.6094; avg_acc: 0.5913
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 241, Global step 241:
20-03-22 23:19-INFO-training batch loss: 0.6011; avg_loss: 0.8231
20-03-22 23:19-INFO-training batch acc: 0.5938; avg_acc: 0.5913
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 242, Global step 242:
20-03-22 23:19-INFO-training batch loss: 0.5723; avg_loss: 0.8221
20-03-22 23:19-INFO-training batch acc: 0.6719; avg_acc: 0.5916
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 243, Global step 243:
20-03-22 23:19-INFO-training batch loss: 0.5789; avg_loss: 0.8211
20-03-22 23:19-INFO-training batch acc: 0.6484; avg_acc: 0.5919
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 244, Global step 244:
20-03-22 23:19-INFO-training batch loss: 0.6465; avg_loss: 0.8204
20-03-22 23:19-INFO-training batch acc: 0.5312; avg_acc: 0.5916
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 245, Global step 245:
20-03-22 23:19-INFO-training batch loss: 0.6027; avg_loss: 0.8195
20-03-22 23:19-INFO-training batch acc: 0.5703; avg_acc: 0.5915
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 246, Global step 246:
20-03-22 23:19-INFO-training batch loss: 0.5698; avg_loss: 0.8185
20-03-22 23:19-INFO-training batch acc: 0.6641; avg_acc: 0.5918
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 247, Global step 247:
20-03-22 23:19-INFO-training batch loss: 0.5996; avg_loss: 0.8176
20-03-22 23:19-INFO-training batch acc: 0.5547; avg_acc: 0.5917
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 248, Global step 248:
20-03-22 23:19-INFO-training batch loss: 0.6099; avg_loss: 0.8167
20-03-22 23:19-INFO-training batch acc: 0.5781; avg_acc: 0.5916
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 249, Global step 249:
20-03-22 23:19-INFO-training batch loss: 0.6135; avg_loss: 0.8159
20-03-22 23:19-INFO-training batch acc: 0.6172; avg_acc: 0.5917
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 250, Global step 250:
20-03-22 23:19-INFO-training batch loss: 0.5783; avg_loss: 0.8150
20-03-22 23:19-INFO-training batch acc: 0.6172; avg_acc: 0.5918
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 251, Global step 251:
20-03-22 23:19-INFO-training batch loss: 0.6646; avg_loss: 0.8144
20-03-22 23:19-INFO-training batch acc: 0.5547; avg_acc: 0.5917
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 252, Global step 252:
20-03-22 23:19-INFO-training batch loss: 0.6092; avg_loss: 0.8136
20-03-22 23:19-INFO-training batch acc: 0.6172; avg_acc: 0.5918
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 253, Global step 253:
20-03-22 23:19-INFO-training batch loss: 0.6123; avg_loss: 0.8128
20-03-22 23:19-INFO-training batch acc: 0.6016; avg_acc: 0.5918
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 254, Global step 254:
20-03-22 23:19-INFO-training batch loss: 0.6283; avg_loss: 0.8120
20-03-22 23:19-INFO-training batch acc: 0.6094; avg_acc: 0.5919
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 255, Global step 255:
20-03-22 23:19-INFO-training batch loss: 0.6366; avg_loss: 0.8114
20-03-22 23:19-INFO-training batch acc: 0.5469; avg_acc: 0.5917
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 256, Global step 256:
20-03-22 23:19-INFO-training batch loss: 0.6010; avg_loss: 0.8105
20-03-22 23:19-INFO-training batch acc: 0.5781; avg_acc: 0.5916
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 257, Global step 257:
20-03-22 23:19-INFO-training batch loss: 0.5462; avg_loss: 0.8095
20-03-22 23:19-INFO-training batch acc: 0.6719; avg_acc: 0.5920
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 258, Global step 258:
20-03-22 23:19-INFO-training batch loss: 0.5390; avg_loss: 0.8085
20-03-22 23:19-INFO-training batch acc: 0.6484; avg_acc: 0.5922
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 259, Global step 259:
20-03-22 23:19-INFO-training batch loss: 0.5193; avg_loss: 0.8073
20-03-22 23:19-INFO-training batch acc: 0.7031; avg_acc: 0.5926
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 260, Global step 260:
20-03-22 23:19-INFO-training batch loss: 0.5181; avg_loss: 0.8062
20-03-22 23:19-INFO-training batch acc: 0.7344; avg_acc: 0.5931
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 261, Global step 261:
20-03-22 23:19-INFO-training batch loss: 0.5118; avg_loss: 0.8051
20-03-22 23:19-INFO-training batch acc: 0.7188; avg_acc: 0.5936
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 262, Global step 262:
20-03-22 23:19-INFO-training batch loss: 0.4450; avg_loss: 0.8037
20-03-22 23:19-INFO-training batch acc: 0.7812; avg_acc: 0.5943
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 263, Global step 263:
20-03-22 23:19-INFO-training batch loss: 0.4608; avg_loss: 0.8024
20-03-22 23:19-INFO-training batch acc: 0.7969; avg_acc: 0.5951
20-03-22 23:19-INFO-
20-03-22 23:19-INFO-Epoch 0, Batch 264, Global step 264:
20-03-22 23:19-INFO-training batch loss: 0.4472; avg_loss: 0.8011
20-03-22 23:19-INFO-training batch acc: 0.7891; avg_acc: 0.5959
20-03-22 23:19-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 265, Global step 265:
20-03-22 23:20-INFO-training batch loss: 0.4714; avg_loss: 0.7998
20-03-22 23:20-INFO-training batch acc: 0.7734; avg_acc: 0.5965
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 266, Global step 266:
20-03-22 23:20-INFO-training batch loss: 0.4551; avg_loss: 0.7985
20-03-22 23:20-INFO-training batch acc: 0.7578; avg_acc: 0.5971
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 267, Global step 267:
20-03-22 23:20-INFO-training batch loss: 0.3888; avg_loss: 0.7970
20-03-22 23:20-INFO-training batch acc: 0.8359; avg_acc: 0.5980
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 268, Global step 268:
20-03-22 23:20-INFO-training batch loss: 0.3746; avg_loss: 0.7954
20-03-22 23:20-INFO-training batch acc: 0.8203; avg_acc: 0.5989
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 269, Global step 269:
20-03-22 23:20-INFO-training batch loss: 0.3683; avg_loss: 0.7938
20-03-22 23:20-INFO-training batch acc: 0.8359; avg_acc: 0.5997
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 270, Global step 270:
20-03-22 23:20-INFO-training batch loss: 0.3956; avg_loss: 0.7924
20-03-22 23:20-INFO-training batch acc: 0.7969; avg_acc: 0.6005
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 271, Global step 271:
20-03-22 23:20-INFO-training batch loss: 0.3737; avg_loss: 0.7908
20-03-22 23:20-INFO-training batch acc: 0.8047; avg_acc: 0.6012
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 272, Global step 272:
20-03-22 23:20-INFO-training batch loss: 0.3752; avg_loss: 0.7893
20-03-22 23:20-INFO-training batch acc: 0.8516; avg_acc: 0.6021
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 273, Global step 273:
20-03-22 23:20-INFO-training batch loss: 0.3559; avg_loss: 0.7877
20-03-22 23:20-INFO-training batch acc: 0.8203; avg_acc: 0.6029
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 274, Global step 274:
20-03-22 23:20-INFO-training batch loss: 0.4037; avg_loss: 0.7863
20-03-22 23:20-INFO-training batch acc: 0.8047; avg_acc: 0.6037
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 275, Global step 275:
20-03-22 23:20-INFO-training batch loss: 0.2917; avg_loss: 0.7845
20-03-22 23:20-INFO-training batch acc: 0.8828; avg_acc: 0.6047
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 276, Global step 276:
20-03-22 23:20-INFO-training batch loss: 0.2939; avg_loss: 0.7827
20-03-22 23:20-INFO-training batch acc: 0.8672; avg_acc: 0.6056
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 277, Global step 277:
20-03-22 23:20-INFO-training batch loss: 0.4102; avg_loss: 0.7814
20-03-22 23:20-INFO-training batch acc: 0.7734; avg_acc: 0.6062
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 278, Global step 278:
20-03-22 23:20-INFO-training batch loss: 0.3536; avg_loss: 0.7798
20-03-22 23:20-INFO-training batch acc: 0.8438; avg_acc: 0.6071
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 279, Global step 279:
20-03-22 23:20-INFO-training batch loss: 0.4082; avg_loss: 0.7785
20-03-22 23:20-INFO-training batch acc: 0.7891; avg_acc: 0.6078
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 280, Global step 280:
20-03-22 23:20-INFO-training batch loss: 0.3743; avg_loss: 0.7771
20-03-22 23:20-INFO-training batch acc: 0.8203; avg_acc: 0.6085
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 281, Global step 281:
20-03-22 23:20-INFO-training batch loss: 0.3727; avg_loss: 0.7756
20-03-22 23:20-INFO-training batch acc: 0.8359; avg_acc: 0.6093
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 282, Global step 282:
20-03-22 23:20-INFO-training batch loss: 0.2570; avg_loss: 0.7738
20-03-22 23:20-INFO-training batch acc: 0.9219; avg_acc: 0.6104
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 283, Global step 283:
20-03-22 23:20-INFO-training batch loss: 0.3537; avg_loss: 0.7723
20-03-22 23:20-INFO-training batch acc: 0.8281; avg_acc: 0.6112
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, Batch 284, Global step 284:
20-03-22 23:20-INFO-training batch loss: 0.2448; avg_loss: 0.7704
20-03-22 23:20-INFO-training batch acc: 0.9474; avg_acc: 0.6124
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, training batch loss: 0.2448; avg_loss: 0.7704
20-03-22 23:20-INFO-Epoch 0, training batch accuracy: 0.9474; avg_accuracy: 0.6124
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 0, evaluating batch loss: 0.8340; avg_loss: 0.4498
20-03-22 23:20-INFO-Epoch 0, evaluating batch accuracy: 0.7727; avg_accuracy: 0.8436
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 1, Batch 1, Global step 285:
20-03-22 23:20-INFO-training batch loss: 0.3106; avg_loss: 0.3106
20-03-22 23:20-INFO-training batch acc: 0.8750; avg_acc: 0.8750
20-03-22 23:20-INFO-
20-03-22 23:20-INFO-Epoch 1, Batch 2, Global step 286:
20-03-22 23:20-INFO-training batch loss: 0.2996; avg_loss: 0.3051
20-03-22 23:20-INFO-training batch acc: 0.8750; avg_acc: 0.8750
20-03-22 23:20-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 3, Global step 287:
20-03-22 23:21-INFO-training batch loss: 0.2872; avg_loss: 0.2991
20-03-22 23:21-INFO-training batch acc: 0.8750; avg_acc: 0.8750
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 4, Global step 288:
20-03-22 23:21-INFO-training batch loss: 0.2684; avg_loss: 0.2914
20-03-22 23:21-INFO-training batch acc: 0.9375; avg_acc: 0.8906
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 5, Global step 289:
20-03-22 23:21-INFO-training batch loss: 0.2287; avg_loss: 0.2789
20-03-22 23:21-INFO-training batch acc: 0.9297; avg_acc: 0.8984
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 6, Global step 290:
20-03-22 23:21-INFO-training batch loss: 0.2444; avg_loss: 0.2731
20-03-22 23:21-INFO-training batch acc: 0.8828; avg_acc: 0.8958
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 7, Global step 291:
20-03-22 23:21-INFO-training batch loss: 0.3259; avg_loss: 0.2807
20-03-22 23:21-INFO-training batch acc: 0.8750; avg_acc: 0.8929
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 8, Global step 292:
20-03-22 23:21-INFO-training batch loss: 0.2379; avg_loss: 0.2753
20-03-22 23:21-INFO-training batch acc: 0.8672; avg_acc: 0.8896
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 9, Global step 293:
20-03-22 23:21-INFO-training batch loss: 0.1979; avg_loss: 0.2667
20-03-22 23:21-INFO-training batch acc: 0.9219; avg_acc: 0.8932
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 10, Global step 294:
20-03-22 23:21-INFO-training batch loss: 0.1426; avg_loss: 0.2543
20-03-22 23:21-INFO-training batch acc: 0.9609; avg_acc: 0.9000
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 11, Global step 295:
20-03-22 23:21-INFO-training batch loss: 0.3785; avg_loss: 0.2656
20-03-22 23:21-INFO-training batch acc: 0.7969; avg_acc: 0.8906
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 12, Global step 296:
20-03-22 23:21-INFO-training batch loss: 0.2946; avg_loss: 0.2680
20-03-22 23:21-INFO-training batch acc: 0.8906; avg_acc: 0.8906
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 13, Global step 297:
20-03-22 23:21-INFO-training batch loss: 0.2374; avg_loss: 0.2657
20-03-22 23:21-INFO-training batch acc: 0.9062; avg_acc: 0.8918
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 14, Global step 298:
20-03-22 23:21-INFO-training batch loss: 0.3195; avg_loss: 0.2695
20-03-22 23:21-INFO-training batch acc: 0.8672; avg_acc: 0.8901
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 15, Global step 299:
20-03-22 23:21-INFO-training batch loss: 0.3078; avg_loss: 0.2721
20-03-22 23:21-INFO-training batch acc: 0.8828; avg_acc: 0.8896
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 16, Global step 300:
20-03-22 23:21-INFO-training batch loss: 0.2511; avg_loss: 0.2707
20-03-22 23:21-INFO-training batch acc: 0.9141; avg_acc: 0.8911
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 17, Global step 301:
20-03-22 23:21-INFO-training batch loss: 0.3351; avg_loss: 0.2745
20-03-22 23:21-INFO-training batch acc: 0.8672; avg_acc: 0.8897
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 18, Global step 302:
20-03-22 23:21-INFO-training batch loss: 0.1579; avg_loss: 0.2680
20-03-22 23:21-INFO-training batch acc: 0.9453; avg_acc: 0.8928
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 19, Global step 303:
20-03-22 23:21-INFO-training batch loss: 0.1811; avg_loss: 0.2635
20-03-22 23:21-INFO-training batch acc: 0.9453; avg_acc: 0.8956
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 20, Global step 304:
20-03-22 23:21-INFO-training batch loss: 0.2299; avg_loss: 0.2618
20-03-22 23:21-INFO-training batch acc: 0.9141; avg_acc: 0.8965
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 21, Global step 305:
20-03-22 23:21-INFO-training batch loss: 0.1922; avg_loss: 0.2585
20-03-22 23:21-INFO-training batch acc: 0.9531; avg_acc: 0.8992
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 22, Global step 306:
20-03-22 23:21-INFO-training batch loss: 0.0985; avg_loss: 0.2512
20-03-22 23:21-INFO-training batch acc: 0.9922; avg_acc: 0.9034
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 23, Global step 307:
20-03-22 23:21-INFO-training batch loss: 0.2293; avg_loss: 0.2503
20-03-22 23:21-INFO-training batch acc: 0.9219; avg_acc: 0.9042
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 24, Global step 308:
20-03-22 23:21-INFO-training batch loss: 0.1629; avg_loss: 0.2466
20-03-22 23:21-INFO-training batch acc: 0.9453; avg_acc: 0.9059
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 25, Global step 309:
20-03-22 23:21-INFO-training batch loss: 0.1924; avg_loss: 0.2445
20-03-22 23:21-INFO-training batch acc: 0.9219; avg_acc: 0.9066
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 26, Global step 310:
20-03-22 23:21-INFO-training batch loss: 0.1913; avg_loss: 0.2424
20-03-22 23:21-INFO-training batch acc: 0.9375; avg_acc: 0.9078
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 27, Global step 311:
20-03-22 23:21-INFO-training batch loss: 0.1338; avg_loss: 0.2384
20-03-22 23:21-INFO-training batch acc: 0.9531; avg_acc: 0.9094
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 28, Global step 312:
20-03-22 23:21-INFO-training batch loss: 0.1585; avg_loss: 0.2355
20-03-22 23:21-INFO-training batch acc: 0.9531; avg_acc: 0.9110
20-03-22 23:21-INFO-
20-03-22 23:21-INFO-Epoch 1, Batch 29, Global step 313:
20-03-22 23:21-INFO-training batch loss: 0.1069; avg_loss: 0.2311
20-03-22 23:21-INFO-training batch acc: 0.9922; avg_acc: 0.9138
20-03-22 23:21-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 30, Global step 314:
20-03-22 23:22-INFO-training batch loss: 0.1114; avg_loss: 0.2271
20-03-22 23:22-INFO-training batch acc: 0.9844; avg_acc: 0.9161
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 31, Global step 315:
20-03-22 23:22-INFO-training batch loss: 0.1148; avg_loss: 0.2235
20-03-22 23:22-INFO-training batch acc: 0.9766; avg_acc: 0.9181
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 32, Global step 316:
20-03-22 23:22-INFO-training batch loss: 0.0892; avg_loss: 0.2193
20-03-22 23:22-INFO-training batch acc: 0.9844; avg_acc: 0.9202
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 33, Global step 317:
20-03-22 23:22-INFO-training batch loss: 0.0985; avg_loss: 0.2156
20-03-22 23:22-INFO-training batch acc: 0.9844; avg_acc: 0.9221
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 34, Global step 318:
20-03-22 23:22-INFO-training batch loss: 0.0960; avg_loss: 0.2121
20-03-22 23:22-INFO-training batch acc: 0.9609; avg_acc: 0.9233
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 35, Global step 319:
20-03-22 23:22-INFO-training batch loss: 0.1024; avg_loss: 0.2090
20-03-22 23:22-INFO-training batch acc: 0.9609; avg_acc: 0.9243
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 36, Global step 320:
20-03-22 23:22-INFO-training batch loss: 0.1555; avg_loss: 0.2075
20-03-22 23:22-INFO-training batch acc: 0.9219; avg_acc: 0.9243
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 37, Global step 321:
20-03-22 23:22-INFO-training batch loss: 0.1696; avg_loss: 0.2065
20-03-22 23:22-INFO-training batch acc: 0.9219; avg_acc: 0.9242
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 38, Global step 322:
20-03-22 23:22-INFO-training batch loss: 0.0992; avg_loss: 0.2036
20-03-22 23:22-INFO-training batch acc: 0.9766; avg_acc: 0.9256
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 39, Global step 323:
20-03-22 23:22-INFO-training batch loss: 0.3869; avg_loss: 0.2083
20-03-22 23:22-INFO-training batch acc: 0.8359; avg_acc: 0.9233
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 40, Global step 324:
20-03-22 23:22-INFO-training batch loss: 0.0880; avg_loss: 0.2053
20-03-22 23:22-INFO-training batch acc: 0.9531; avg_acc: 0.9240
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 41, Global step 325:
20-03-22 23:22-INFO-training batch loss: 0.1478; avg_loss: 0.2039
20-03-22 23:22-INFO-training batch acc: 0.9219; avg_acc: 0.9240
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 42, Global step 326:
20-03-22 23:22-INFO-training batch loss: 0.1608; avg_loss: 0.2029
20-03-22 23:22-INFO-training batch acc: 0.9375; avg_acc: 0.9243
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 43, Global step 327:
20-03-22 23:22-INFO-training batch loss: 0.1730; avg_loss: 0.2022
20-03-22 23:22-INFO-training batch acc: 0.9141; avg_acc: 0.9241
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 44, Global step 328:
20-03-22 23:22-INFO-training batch loss: 0.1471; avg_loss: 0.2010
20-03-22 23:22-INFO-training batch acc: 0.9297; avg_acc: 0.9242
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 45, Global step 329:
20-03-22 23:22-INFO-training batch loss: 0.2016; avg_loss: 0.2010
20-03-22 23:22-INFO-training batch acc: 0.9219; avg_acc: 0.9241
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 46, Global step 330:
20-03-22 23:22-INFO-training batch loss: 0.0802; avg_loss: 0.1983
20-03-22 23:22-INFO-training batch acc: 0.9766; avg_acc: 0.9253
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 47, Global step 331:
20-03-22 23:22-INFO-training batch loss: 0.1457; avg_loss: 0.1972
20-03-22 23:22-INFO-training batch acc: 0.9609; avg_acc: 0.9260
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 48, Global step 332:
20-03-22 23:22-INFO-training batch loss: 0.0693; avg_loss: 0.1946
20-03-22 23:22-INFO-training batch acc: 0.9922; avg_acc: 0.9274
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 49, Global step 333:
20-03-22 23:22-INFO-training batch loss: 0.1262; avg_loss: 0.1932
20-03-22 23:22-INFO-training batch acc: 0.9531; avg_acc: 0.9279
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 50, Global step 334:
20-03-22 23:22-INFO-training batch loss: 0.0746; avg_loss: 0.1908
20-03-22 23:22-INFO-training batch acc: 0.9766; avg_acc: 0.9289
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 51, Global step 335:
20-03-22 23:22-INFO-training batch loss: 0.0660; avg_loss: 0.1883
20-03-22 23:22-INFO-training batch acc: 0.9844; avg_acc: 0.9300
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 52, Global step 336:
20-03-22 23:22-INFO-training batch loss: 0.1406; avg_loss: 0.1874
20-03-22 23:22-INFO-training batch acc: 0.9688; avg_acc: 0.9307
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 53, Global step 337:
20-03-22 23:22-INFO-training batch loss: 0.0718; avg_loss: 0.1852
20-03-22 23:22-INFO-training batch acc: 0.9844; avg_acc: 0.9318
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 54, Global step 338:
20-03-22 23:22-INFO-training batch loss: 0.0679; avg_loss: 0.1831
20-03-22 23:22-INFO-training batch acc: 0.9844; avg_acc: 0.9327
20-03-22 23:22-INFO-
20-03-22 23:22-INFO-Epoch 1, Batch 55, Global step 339:
20-03-22 23:22-INFO-training batch loss: 0.0755; avg_loss: 0.1811
20-03-22 23:22-INFO-training batch acc: 0.9766; avg_acc: 0.9335
20-03-22 23:22-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 56, Global step 340:
20-03-22 23:23-INFO-training batch loss: 0.0398; avg_loss: 0.1786
20-03-22 23:23-INFO-training batch acc: 0.9922; avg_acc: 0.9346
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 57, Global step 341:
20-03-22 23:23-INFO-training batch loss: 0.0885; avg_loss: 0.1770
20-03-22 23:23-INFO-training batch acc: 0.9766; avg_acc: 0.9353
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 58, Global step 342:
20-03-22 23:23-INFO-training batch loss: 0.0917; avg_loss: 0.1755
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9362
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 59, Global step 343:
20-03-22 23:23-INFO-training batch loss: 0.1233; avg_loss: 0.1747
20-03-22 23:23-INFO-training batch acc: 0.9609; avg_acc: 0.9366
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 60, Global step 344:
20-03-22 23:23-INFO-training batch loss: 0.0758; avg_loss: 0.1730
20-03-22 23:23-INFO-training batch acc: 0.9766; avg_acc: 0.9372
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 61, Global step 345:
20-03-22 23:23-INFO-training batch loss: 0.0981; avg_loss: 0.1718
20-03-22 23:23-INFO-training batch acc: 0.9688; avg_acc: 0.9378
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 62, Global step 346:
20-03-22 23:23-INFO-training batch loss: 0.1151; avg_loss: 0.1709
20-03-22 23:23-INFO-training batch acc: 0.9453; avg_acc: 0.9379
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 63, Global step 347:
20-03-22 23:23-INFO-training batch loss: 0.0784; avg_loss: 0.1694
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9386
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 64, Global step 348:
20-03-22 23:23-INFO-training batch loss: 0.0466; avg_loss: 0.1675
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9393
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 65, Global step 349:
20-03-22 23:23-INFO-training batch loss: 0.0839; avg_loss: 0.1662
20-03-22 23:23-INFO-training batch acc: 0.9766; avg_acc: 0.9399
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 66, Global step 350:
20-03-22 23:23-INFO-training batch loss: 0.0870; avg_loss: 0.1650
20-03-22 23:23-INFO-training batch acc: 0.9688; avg_acc: 0.9403
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 67, Global step 351:
20-03-22 23:23-INFO-training batch loss: 0.0644; avg_loss: 0.1635
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9410
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 68, Global step 352:
20-03-22 23:23-INFO-training batch loss: 0.0478; avg_loss: 0.1618
20-03-22 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9419
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 69, Global step 353:
20-03-22 23:23-INFO-training batch loss: 0.0655; avg_loss: 0.1604
20-03-22 23:23-INFO-training batch acc: 0.9766; avg_acc: 0.9424
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 70, Global step 354:
20-03-22 23:23-INFO-training batch loss: 0.0552; avg_loss: 0.1589
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9430
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 71, Global step 355:
20-03-22 23:23-INFO-training batch loss: 0.0378; avg_loss: 0.1572
20-03-22 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9438
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 72, Global step 356:
20-03-22 23:23-INFO-training batch loss: 0.0952; avg_loss: 0.1563
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9443
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 73, Global step 357:
20-03-22 23:23-INFO-training batch loss: 0.0913; avg_loss: 0.1554
20-03-22 23:23-INFO-training batch acc: 0.9688; avg_acc: 0.9447
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 74, Global step 358:
20-03-22 23:23-INFO-training batch loss: 0.1066; avg_loss: 0.1548
20-03-22 23:23-INFO-training batch acc: 0.9688; avg_acc: 0.9450
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 75, Global step 359:
20-03-22 23:23-INFO-training batch loss: 0.0260; avg_loss: 0.1531
20-03-22 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9457
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 76, Global step 360:
20-03-22 23:23-INFO-training batch loss: 0.0532; avg_loss: 0.1517
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9462
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 77, Global step 361:
20-03-22 23:23-INFO-training batch loss: 0.0885; avg_loss: 0.1509
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9467
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 78, Global step 362:
20-03-22 23:23-INFO-training batch loss: 0.0579; avg_loss: 0.1497
20-03-22 23:23-INFO-training batch acc: 0.9922; avg_acc: 0.9473
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 79, Global step 363:
20-03-22 23:23-INFO-training batch loss: 0.0825; avg_loss: 0.1489
20-03-22 23:23-INFO-training batch acc: 0.9688; avg_acc: 0.9476
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 80, Global step 364:
20-03-22 23:23-INFO-training batch loss: 0.0562; avg_loss: 0.1477
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9480
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 81, Global step 365:
20-03-22 23:23-INFO-training batch loss: 0.0606; avg_loss: 0.1466
20-03-22 23:23-INFO-training batch acc: 0.9922; avg_acc: 0.9486
20-03-22 23:23-INFO-
20-03-22 23:23-INFO-Epoch 1, Batch 82, Global step 366:
20-03-22 23:23-INFO-training batch loss: 0.0397; avg_loss: 0.1453
20-03-22 23:23-INFO-training batch acc: 0.9844; avg_acc: 0.9490
20-03-22 23:23-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 83, Global step 367:
20-03-22 23:24-INFO-training batch loss: 0.0884; avg_loss: 0.1447
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9495
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 84, Global step 368:
20-03-22 23:24-INFO-training batch loss: 0.1195; avg_loss: 0.1444
20-03-22 23:24-INFO-training batch acc: 0.9688; avg_acc: 0.9497
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 85, Global step 369:
20-03-22 23:24-INFO-training batch loss: 0.0604; avg_loss: 0.1434
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9501
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 86, Global step 370:
20-03-22 23:24-INFO-training batch loss: 0.0608; avg_loss: 0.1424
20-03-22 23:24-INFO-training batch acc: 0.9766; avg_acc: 0.9504
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 87, Global step 371:
20-03-22 23:24-INFO-training batch loss: 0.0473; avg_loss: 0.1413
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9510
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 88, Global step 372:
20-03-22 23:24-INFO-training batch loss: 0.0412; avg_loss: 0.1402
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9514
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 89, Global step 373:
20-03-22 23:24-INFO-training batch loss: 0.0390; avg_loss: 0.1390
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9518
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 90, Global step 374:
20-03-22 23:24-INFO-training batch loss: 0.0493; avg_loss: 0.1380
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9523
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 91, Global step 375:
20-03-22 23:24-INFO-training batch loss: 0.0787; avg_loss: 0.1374
20-03-22 23:24-INFO-training batch acc: 0.9766; avg_acc: 0.9525
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 92, Global step 376:
20-03-22 23:24-INFO-training batch loss: 0.0444; avg_loss: 0.1364
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9529
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 93, Global step 377:
20-03-22 23:24-INFO-training batch loss: 0.0326; avg_loss: 0.1353
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9534
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 94, Global step 378:
20-03-22 23:24-INFO-training batch loss: 0.0157; avg_loss: 0.1340
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9539
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 95, Global step 379:
20-03-22 23:24-INFO-training batch loss: 0.0504; avg_loss: 0.1331
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9543
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 96, Global step 380:
20-03-22 23:24-INFO-training batch loss: 0.0462; avg_loss: 0.1322
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9546
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 97, Global step 381:
20-03-22 23:24-INFO-training batch loss: 0.0212; avg_loss: 0.1311
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9551
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 98, Global step 382:
20-03-22 23:24-INFO-training batch loss: 0.0653; avg_loss: 0.1304
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9554
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 99, Global step 383:
20-03-22 23:24-INFO-training batch loss: 0.0198; avg_loss: 0.1293
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9558
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 100, Global step 384:
20-03-22 23:24-INFO-training batch loss: 0.0309; avg_loss: 0.1283
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9562
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 101, Global step 385:
20-03-22 23:24-INFO-training batch loss: 0.0205; avg_loss: 0.1272
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9566
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 102, Global step 386:
20-03-22 23:24-INFO-training batch loss: 0.0358; avg_loss: 0.1263
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9570
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 103, Global step 387:
20-03-22 23:24-INFO-training batch loss: 0.0135; avg_loss: 0.1252
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9574
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 104, Global step 388:
20-03-22 23:24-INFO-training batch loss: 0.0691; avg_loss: 0.1247
20-03-22 23:24-INFO-training batch acc: 0.9844; avg_acc: 0.9576
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 105, Global step 389:
20-03-22 23:24-INFO-training batch loss: 0.0260; avg_loss: 0.1237
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9580
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 106, Global step 390:
20-03-22 23:24-INFO-training batch loss: 0.0250; avg_loss: 0.1228
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9583
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 107, Global step 391:
20-03-22 23:24-INFO-training batch loss: 0.0285; avg_loss: 0.1219
20-03-22 23:24-INFO-training batch acc: 1.0000; avg_acc: 0.9587
20-03-22 23:24-INFO-
20-03-22 23:24-INFO-Epoch 1, Batch 108, Global step 392:
20-03-22 23:24-INFO-training batch loss: 0.0307; avg_loss: 0.1211
20-03-22 23:24-INFO-training batch acc: 0.9922; avg_acc: 0.9590
20-03-22 23:24-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 109, Global step 393:
20-03-22 23:25-INFO-training batch loss: 0.0279; avg_loss: 0.1202
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9594
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 110, Global step 394:
20-03-22 23:25-INFO-training batch loss: 0.0157; avg_loss: 0.1193
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9597
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 111, Global step 395:
20-03-22 23:25-INFO-training batch loss: 0.0220; avg_loss: 0.1184
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9600
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 112, Global step 396:
20-03-22 23:25-INFO-training batch loss: 0.0206; avg_loss: 0.1175
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9603
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 113, Global step 397:
20-03-22 23:25-INFO-training batch loss: 0.0279; avg_loss: 0.1167
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9606
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 114, Global step 398:
20-03-22 23:25-INFO-training batch loss: 0.0283; avg_loss: 0.1160
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9609
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 115, Global step 399:
20-03-22 23:25-INFO-training batch loss: 0.0185; avg_loss: 0.1151
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9612
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 116, Global step 400:
20-03-22 23:25-INFO-training batch loss: 0.0397; avg_loss: 0.1145
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9615
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 117, Global step 401:
20-03-22 23:25-INFO-training batch loss: 0.0255; avg_loss: 0.1137
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9618
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 118, Global step 402:
20-03-22 23:25-INFO-training batch loss: 0.0194; avg_loss: 0.1129
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9621
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 119, Global step 403:
20-03-22 23:25-INFO-training batch loss: 0.0204; avg_loss: 0.1121
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9624
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 120, Global step 404:
20-03-22 23:25-INFO-training batch loss: 0.0101; avg_loss: 0.1113
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9628
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 121, Global step 405:
20-03-22 23:25-INFO-training batch loss: 0.0208; avg_loss: 0.1105
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9631
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 122, Global step 406:
20-03-22 23:25-INFO-training batch loss: 0.0129; avg_loss: 0.1097
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9634
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 123, Global step 407:
20-03-22 23:25-INFO-training batch loss: 0.0109; avg_loss: 0.1089
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9637
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 124, Global step 408:
20-03-22 23:25-INFO-training batch loss: 0.0188; avg_loss: 0.1082
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9639
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 125, Global step 409:
20-03-22 23:25-INFO-training batch loss: 0.0337; avg_loss: 0.1076
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9641
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 126, Global step 410:
20-03-22 23:25-INFO-training batch loss: 0.0097; avg_loss: 0.1068
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9644
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 127, Global step 411:
20-03-22 23:25-INFO-training batch loss: 0.0123; avg_loss: 0.1061
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9647
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 128, Global step 412:
20-03-22 23:25-INFO-training batch loss: 0.0169; avg_loss: 0.1054
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9650
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 129, Global step 413:
20-03-22 23:25-INFO-training batch loss: 0.0128; avg_loss: 0.1047
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9652
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 130, Global step 414:
20-03-22 23:25-INFO-training batch loss: 0.0100; avg_loss: 0.1039
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9655
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 131, Global step 415:
20-03-22 23:25-INFO-training batch loss: 0.0715; avg_loss: 0.1037
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9657
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 132, Global step 416:
20-03-22 23:25-INFO-training batch loss: 0.0144; avg_loss: 0.1030
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9660
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 133, Global step 417:
20-03-22 23:25-INFO-training batch loss: 0.0102; avg_loss: 0.1023
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9662
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 134, Global step 418:
20-03-22 23:25-INFO-training batch loss: 0.0092; avg_loss: 0.1016
20-03-22 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9665
20-03-22 23:25-INFO-
20-03-22 23:25-INFO-Epoch 1, Batch 135, Global step 419:
20-03-22 23:25-INFO-training batch loss: 0.0179; avg_loss: 0.1010
20-03-22 23:25-INFO-training batch acc: 0.9922; avg_acc: 0.9667
20-03-22 23:25-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 136, Global step 420:
20-03-22 23:26-INFO-training batch loss: 0.0119; avg_loss: 0.1004
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9669
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 137, Global step 421:
20-03-22 23:26-INFO-training batch loss: 0.0198; avg_loss: 0.0998
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9672
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 138, Global step 422:
20-03-22 23:26-INFO-training batch loss: 0.0183; avg_loss: 0.0992
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9674
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 139, Global step 423:
20-03-22 23:26-INFO-training batch loss: 0.0153; avg_loss: 0.0986
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9676
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 140, Global step 424:
20-03-22 23:26-INFO-training batch loss: 0.0127; avg_loss: 0.0980
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9679
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 141, Global step 425:
20-03-22 23:26-INFO-training batch loss: 0.0151; avg_loss: 0.0974
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9681
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 142, Global step 426:
20-03-22 23:26-INFO-training batch loss: 0.0113; avg_loss: 0.0968
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9683
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 143, Global step 427:
20-03-22 23:26-INFO-training batch loss: 0.0214; avg_loss: 0.0962
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9685
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 144, Global step 428:
20-03-22 23:26-INFO-training batch loss: 0.0297; avg_loss: 0.0958
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9686
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 145, Global step 429:
20-03-22 23:26-INFO-training batch loss: 0.0236; avg_loss: 0.0953
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9689
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 146, Global step 430:
20-03-22 23:26-INFO-training batch loss: 0.0164; avg_loss: 0.0947
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9690
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 147, Global step 431:
20-03-22 23:26-INFO-training batch loss: 0.0141; avg_loss: 0.0942
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9692
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 148, Global step 432:
20-03-22 23:26-INFO-training batch loss: 0.0226; avg_loss: 0.0937
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9694
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 149, Global step 433:
20-03-22 23:26-INFO-training batch loss: 0.0095; avg_loss: 0.0931
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9696
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 150, Global step 434:
20-03-22 23:26-INFO-training batch loss: 0.0112; avg_loss: 0.0926
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9698
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 151, Global step 435:
20-03-22 23:26-INFO-training batch loss: 0.0132; avg_loss: 0.0921
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9700
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 152, Global step 436:
20-03-22 23:26-INFO-training batch loss: 0.0286; avg_loss: 0.0916
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9701
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 153, Global step 437:
20-03-22 23:26-INFO-training batch loss: 0.0151; avg_loss: 0.0911
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9703
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 154, Global step 438:
20-03-22 23:26-INFO-training batch loss: 0.0103; avg_loss: 0.0906
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9705
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 155, Global step 439:
20-03-22 23:26-INFO-training batch loss: 0.0098; avg_loss: 0.0901
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9707
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 156, Global step 440:
20-03-22 23:26-INFO-training batch loss: 0.0128; avg_loss: 0.0896
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9709
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 157, Global step 441:
20-03-22 23:26-INFO-training batch loss: 0.0579; avg_loss: 0.0894
20-03-22 23:26-INFO-training batch acc: 0.9766; avg_acc: 0.9709
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 158, Global step 442:
20-03-22 23:26-INFO-training batch loss: 0.0069; avg_loss: 0.0889
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9711
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 159, Global step 443:
20-03-22 23:26-INFO-training batch loss: 0.0063; avg_loss: 0.0884
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9713
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 160, Global step 444:
20-03-22 23:26-INFO-training batch loss: 0.0261; avg_loss: 0.0880
20-03-22 23:26-INFO-training batch acc: 0.9922; avg_acc: 0.9714
20-03-22 23:26-INFO-
20-03-22 23:26-INFO-Epoch 1, Batch 161, Global step 445:
20-03-22 23:26-INFO-training batch loss: 0.0085; avg_loss: 0.0875
20-03-22 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9716
20-03-22 23:26-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 162, Global step 446:
20-03-22 23:27-INFO-training batch loss: 0.0154; avg_loss: 0.0870
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9717
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 163, Global step 447:
20-03-22 23:27-INFO-training batch loss: 0.0178; avg_loss: 0.0866
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9719
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 164, Global step 448:
20-03-22 23:27-INFO-training batch loss: 0.0317; avg_loss: 0.0863
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9720
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 165, Global step 449:
20-03-22 23:27-INFO-training batch loss: 0.0118; avg_loss: 0.0858
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9722
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 166, Global step 450:
20-03-22 23:27-INFO-training batch loss: 0.0311; avg_loss: 0.0855
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9723
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 167, Global step 451:
20-03-22 23:27-INFO-training batch loss: 0.0129; avg_loss: 0.0851
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9724
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 168, Global step 452:
20-03-22 23:27-INFO-training batch loss: 0.0102; avg_loss: 0.0846
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9726
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 169, Global step 453:
20-03-22 23:27-INFO-training batch loss: 0.0114; avg_loss: 0.0842
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9728
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 170, Global step 454:
20-03-22 23:27-INFO-training batch loss: 0.0128; avg_loss: 0.0838
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9729
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 171, Global step 455:
20-03-22 23:27-INFO-training batch loss: 0.0260; avg_loss: 0.0834
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9730
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 172, Global step 456:
20-03-22 23:27-INFO-training batch loss: 0.0184; avg_loss: 0.0830
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9732
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 173, Global step 457:
20-03-22 23:27-INFO-training batch loss: 0.0126; avg_loss: 0.0826
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9733
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 174, Global step 458:
20-03-22 23:27-INFO-training batch loss: 0.0086; avg_loss: 0.0822
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9735
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 175, Global step 459:
20-03-22 23:27-INFO-training batch loss: 0.0103; avg_loss: 0.0818
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9736
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 176, Global step 460:
20-03-22 23:27-INFO-training batch loss: 0.0194; avg_loss: 0.0814
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9737
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 177, Global step 461:
20-03-22 23:27-INFO-training batch loss: 0.0297; avg_loss: 0.0812
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9738
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 178, Global step 462:
20-03-22 23:27-INFO-training batch loss: 0.0113; avg_loss: 0.0808
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9740
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 179, Global step 463:
20-03-22 23:27-INFO-training batch loss: 0.0344; avg_loss: 0.0805
20-03-22 23:27-INFO-training batch acc: 0.9844; avg_acc: 0.9740
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 180, Global step 464:
20-03-22 23:27-INFO-training batch loss: 0.0183; avg_loss: 0.0802
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9741
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 181, Global step 465:
20-03-22 23:27-INFO-training batch loss: 0.0504; avg_loss: 0.0800
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9742
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 182, Global step 466:
20-03-22 23:27-INFO-training batch loss: 0.0502; avg_loss: 0.0798
20-03-22 23:27-INFO-training batch acc: 0.9766; avg_acc: 0.9742
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 183, Global step 467:
20-03-22 23:27-INFO-training batch loss: 0.0496; avg_loss: 0.0797
20-03-22 23:27-INFO-training batch acc: 0.9844; avg_acc: 0.9743
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 184, Global step 468:
20-03-22 23:27-INFO-training batch loss: 0.0193; avg_loss: 0.0793
20-03-22 23:27-INFO-training batch acc: 0.9922; avg_acc: 0.9744
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 185, Global step 469:
20-03-22 23:27-INFO-training batch loss: 0.0137; avg_loss: 0.0790
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9745
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 186, Global step 470:
20-03-22 23:27-INFO-training batch loss: 0.0156; avg_loss: 0.0786
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9747
20-03-22 23:27-INFO-
20-03-22 23:27-INFO-Epoch 1, Batch 187, Global step 471:
20-03-22 23:27-INFO-training batch loss: 0.0104; avg_loss: 0.0783
20-03-22 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9748
20-03-22 23:27-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 188, Global step 472:
20-03-22 23:28-INFO-training batch loss: 0.0356; avg_loss: 0.0780
20-03-22 23:28-INFO-training batch acc: 0.9922; avg_acc: 0.9749
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 189, Global step 473:
20-03-22 23:28-INFO-training batch loss: 0.0182; avg_loss: 0.0777
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9750
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 190, Global step 474:
20-03-22 23:28-INFO-training batch loss: 0.0195; avg_loss: 0.0774
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9752
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 191, Global step 475:
20-03-22 23:28-INFO-training batch loss: 0.0154; avg_loss: 0.0771
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9753
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 192, Global step 476:
20-03-22 23:28-INFO-training batch loss: 0.0162; avg_loss: 0.0768
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9754
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 193, Global step 477:
20-03-22 23:28-INFO-training batch loss: 0.0482; avg_loss: 0.0766
20-03-22 23:28-INFO-training batch acc: 0.9844; avg_acc: 0.9755
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 194, Global step 478:
20-03-22 23:28-INFO-training batch loss: 0.0264; avg_loss: 0.0764
20-03-22 23:28-INFO-training batch acc: 0.9844; avg_acc: 0.9755
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 195, Global step 479:
20-03-22 23:28-INFO-training batch loss: 0.0199; avg_loss: 0.0761
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9756
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 196, Global step 480:
20-03-22 23:28-INFO-training batch loss: 0.0190; avg_loss: 0.0758
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9758
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 197, Global step 481:
20-03-22 23:28-INFO-training batch loss: 0.0075; avg_loss: 0.0754
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9759
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 198, Global step 482:
20-03-22 23:28-INFO-training batch loss: 0.0355; avg_loss: 0.0752
20-03-22 23:28-INFO-training batch acc: 0.9922; avg_acc: 0.9760
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 199, Global step 483:
20-03-22 23:28-INFO-training batch loss: 0.0077; avg_loss: 0.0749
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9761
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 200, Global step 484:
20-03-22 23:28-INFO-training batch loss: 0.0680; avg_loss: 0.0749
20-03-22 23:28-INFO-training batch acc: 0.9922; avg_acc: 0.9762
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 201, Global step 485:
20-03-22 23:28-INFO-training batch loss: 0.0134; avg_loss: 0.0746
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9763
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 202, Global step 486:
20-03-22 23:28-INFO-training batch loss: 0.0222; avg_loss: 0.0743
20-03-22 23:28-INFO-training batch acc: 0.9922; avg_acc: 0.9764
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 203, Global step 487:
20-03-22 23:28-INFO-training batch loss: 0.0134; avg_loss: 0.0740
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9765
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 204, Global step 488:
20-03-22 23:28-INFO-training batch loss: 0.0099; avg_loss: 0.0737
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9766
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 205, Global step 489:
20-03-22 23:28-INFO-training batch loss: 0.0175; avg_loss: 0.0734
20-03-22 23:28-INFO-training batch acc: 0.9922; avg_acc: 0.9767
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 206, Global step 490:
20-03-22 23:28-INFO-training batch loss: 0.0112; avg_loss: 0.0731
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9768
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 207, Global step 491:
20-03-22 23:28-INFO-training batch loss: 0.0088; avg_loss: 0.0728
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9769
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 208, Global step 492:
20-03-22 23:28-INFO-training batch loss: 0.0081; avg_loss: 0.0725
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9770
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 209, Global step 493:
20-03-22 23:28-INFO-training batch loss: 0.0131; avg_loss: 0.0722
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9771
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 210, Global step 494:
20-03-22 23:28-INFO-training batch loss: 0.0139; avg_loss: 0.0719
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9772
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 211, Global step 495:
20-03-22 23:28-INFO-training batch loss: 0.0090; avg_loss: 0.0716
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9773
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 212, Global step 496:
20-03-22 23:28-INFO-training batch loss: 0.0106; avg_loss: 0.0713
20-03-22 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9774
20-03-22 23:28-INFO-
20-03-22 23:28-INFO-Epoch 1, Batch 213, Global step 497:
20-03-22 23:28-INFO-training batch loss: 0.0167; avg_loss: 0.0711
20-03-22 23:28-INFO-training batch acc: 0.9922; avg_acc: 0.9775
20-03-22 23:28-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 214, Global step 498:
20-03-22 23:29-INFO-training batch loss: 0.0184; avg_loss: 0.0708
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9776
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 215, Global step 499:
20-03-22 23:29-INFO-training batch loss: 0.0091; avg_loss: 0.0706
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9777
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 216, Global step 500:
20-03-22 23:29-INFO-training batch loss: 0.0102; avg_loss: 0.0703
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9778
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 217, Global step 501:
20-03-22 23:29-INFO-training batch loss: 0.0102; avg_loss: 0.0700
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9779
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 218, Global step 502:
20-03-22 23:29-INFO-training batch loss: 0.0074; avg_loss: 0.0697
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9780
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 219, Global step 503:
20-03-22 23:29-INFO-training batch loss: 0.0096; avg_loss: 0.0694
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9781
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 220, Global step 504:
20-03-22 23:29-INFO-training batch loss: 0.0066; avg_loss: 0.0692
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9782
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 221, Global step 505:
20-03-22 23:29-INFO-training batch loss: 0.0067; avg_loss: 0.0689
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9783
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 222, Global step 506:
20-03-22 23:29-INFO-training batch loss: 0.0078; avg_loss: 0.0686
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9784
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 223, Global step 507:
20-03-22 23:29-INFO-training batch loss: 0.0062; avg_loss: 0.0683
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9785
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 224, Global step 508:
20-03-22 23:29-INFO-training batch loss: 0.0060; avg_loss: 0.0680
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9786
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 225, Global step 509:
20-03-22 23:29-INFO-training batch loss: 0.0067; avg_loss: 0.0678
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9787
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 226, Global step 510:
20-03-22 23:29-INFO-training batch loss: 0.0241; avg_loss: 0.0676
20-03-22 23:29-INFO-training batch acc: 0.9922; avg_acc: 0.9788
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 227, Global step 511:
20-03-22 23:29-INFO-training batch loss: 0.0053; avg_loss: 0.0673
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9789
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 228, Global step 512:
20-03-22 23:29-INFO-training batch loss: 0.0058; avg_loss: 0.0670
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9790
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 229, Global step 513:
20-03-22 23:29-INFO-training batch loss: 0.0088; avg_loss: 0.0668
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9791
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 230, Global step 514:
20-03-22 23:29-INFO-training batch loss: 0.0075; avg_loss: 0.0665
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9791
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 231, Global step 515:
20-03-22 23:29-INFO-training batch loss: 0.0074; avg_loss: 0.0663
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9792
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 232, Global step 516:
20-03-22 23:29-INFO-training batch loss: 0.0058; avg_loss: 0.0660
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9793
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 233, Global step 517:
20-03-22 23:29-INFO-training batch loss: 0.0077; avg_loss: 0.0657
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9794
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 234, Global step 518:
20-03-22 23:29-INFO-training batch loss: 0.0107; avg_loss: 0.0655
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9795
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 235, Global step 519:
20-03-22 23:29-INFO-training batch loss: 0.0127; avg_loss: 0.0653
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9796
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 236, Global step 520:
20-03-22 23:29-INFO-training batch loss: 0.0091; avg_loss: 0.0651
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9797
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 237, Global step 521:
20-03-22 23:29-INFO-training batch loss: 0.0095; avg_loss: 0.0648
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9798
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 238, Global step 522:
20-03-22 23:29-INFO-training batch loss: 0.0075; avg_loss: 0.0646
20-03-22 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9798
20-03-22 23:29-INFO-
20-03-22 23:29-INFO-Epoch 1, Batch 239, Global step 523:
20-03-22 23:29-INFO-training batch loss: 0.0140; avg_loss: 0.0644
20-03-22 23:29-INFO-training batch acc: 0.9922; avg_acc: 0.9799
20-03-22 23:29-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 240, Global step 524:
20-03-22 23:30-INFO-training batch loss: 0.0227; avg_loss: 0.0642
20-03-22 23:30-INFO-training batch acc: 0.9922; avg_acc: 0.9799
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 241, Global step 525:
20-03-22 23:30-INFO-training batch loss: 0.0077; avg_loss: 0.0640
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9800
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 242, Global step 526:
20-03-22 23:30-INFO-training batch loss: 0.0059; avg_loss: 0.0637
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9801
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 243, Global step 527:
20-03-22 23:30-INFO-training batch loss: 0.0086; avg_loss: 0.0635
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9802
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 244, Global step 528:
20-03-22 23:30-INFO-training batch loss: 0.0118; avg_loss: 0.0633
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9803
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 245, Global step 529:
20-03-22 23:30-INFO-training batch loss: 0.0053; avg_loss: 0.0630
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9804
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 246, Global step 530:
20-03-22 23:30-INFO-training batch loss: 0.0051; avg_loss: 0.0628
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9804
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 247, Global step 531:
20-03-22 23:30-INFO-training batch loss: 0.0093; avg_loss: 0.0626
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9805
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 248, Global step 532:
20-03-22 23:30-INFO-training batch loss: 0.0118; avg_loss: 0.0624
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9806
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 249, Global step 533:
20-03-22 23:30-INFO-training batch loss: 0.0093; avg_loss: 0.0622
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9807
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 250, Global step 534:
20-03-22 23:30-INFO-training batch loss: 0.0069; avg_loss: 0.0620
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9808
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 251, Global step 535:
20-03-22 23:30-INFO-training batch loss: 0.0175; avg_loss: 0.0618
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9808
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 252, Global step 536:
20-03-22 23:30-INFO-training batch loss: 0.0063; avg_loss: 0.0616
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9809
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 253, Global step 537:
20-03-22 23:30-INFO-training batch loss: 0.0063; avg_loss: 0.0613
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9810
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 254, Global step 538:
20-03-22 23:30-INFO-training batch loss: 0.0139; avg_loss: 0.0611
20-03-22 23:30-INFO-training batch acc: 0.9922; avg_acc: 0.9810
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 255, Global step 539:
20-03-22 23:30-INFO-training batch loss: 0.0084; avg_loss: 0.0609
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9811
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 256, Global step 540:
20-03-22 23:30-INFO-training batch loss: 0.0056; avg_loss: 0.0607
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9812
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 257, Global step 541:
20-03-22 23:30-INFO-training batch loss: 0.0081; avg_loss: 0.0605
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9812
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 258, Global step 542:
20-03-22 23:30-INFO-training batch loss: 0.0049; avg_loss: 0.0603
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9813
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 259, Global step 543:
20-03-22 23:30-INFO-training batch loss: 0.0116; avg_loss: 0.0601
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9814
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 260, Global step 544:
20-03-22 23:30-INFO-training batch loss: 0.0082; avg_loss: 0.0599
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9815
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 261, Global step 545:
20-03-22 23:30-INFO-training batch loss: 0.0075; avg_loss: 0.0597
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9815
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 262, Global step 546:
20-03-22 23:30-INFO-training batch loss: 0.0074; avg_loss: 0.0595
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9816
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 263, Global step 547:
20-03-22 23:30-INFO-training batch loss: 0.0080; avg_loss: 0.0593
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9817
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 264, Global step 548:
20-03-22 23:30-INFO-training batch loss: 0.0048; avg_loss: 0.0591
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9817
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 265, Global step 549:
20-03-22 23:30-INFO-training batch loss: 0.0163; avg_loss: 0.0590
20-03-22 23:30-INFO-training batch acc: 0.9922; avg_acc: 0.9818
20-03-22 23:30-INFO-
20-03-22 23:30-INFO-Epoch 1, Batch 266, Global step 550:
20-03-22 23:30-INFO-training batch loss: 0.0083; avg_loss: 0.0588
20-03-22 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9818
20-03-22 23:30-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 267, Global step 551:
20-03-22 23:31-INFO-training batch loss: 0.0089; avg_loss: 0.0586
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9819
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 268, Global step 552:
20-03-22 23:31-INFO-training batch loss: 0.0099; avg_loss: 0.0584
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9820
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 269, Global step 553:
20-03-22 23:31-INFO-training batch loss: 0.0026; avg_loss: 0.0582
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9821
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 270, Global step 554:
20-03-22 23:31-INFO-training batch loss: 0.0046; avg_loss: 0.0580
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9821
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 271, Global step 555:
20-03-22 23:31-INFO-training batch loss: 0.0061; avg_loss: 0.0578
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9822
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 272, Global step 556:
20-03-22 23:31-INFO-training batch loss: 0.0047; avg_loss: 0.0576
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9822
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 273, Global step 557:
20-03-22 23:31-INFO-training batch loss: 0.0052; avg_loss: 0.0574
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9823
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 274, Global step 558:
20-03-22 23:31-INFO-training batch loss: 0.0053; avg_loss: 0.0572
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9824
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 275, Global step 559:
20-03-22 23:31-INFO-training batch loss: 0.0072; avg_loss: 0.0570
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9824
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 276, Global step 560:
20-03-22 23:31-INFO-training batch loss: 0.0050; avg_loss: 0.0568
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9825
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 277, Global step 561:
20-03-22 23:31-INFO-training batch loss: 0.0048; avg_loss: 0.0567
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9826
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 278, Global step 562:
20-03-22 23:31-INFO-training batch loss: 0.0039; avg_loss: 0.0565
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9826
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 279, Global step 563:
20-03-22 23:31-INFO-training batch loss: 0.0060; avg_loss: 0.0563
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9827
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 280, Global step 564:
20-03-22 23:31-INFO-training batch loss: 0.0035; avg_loss: 0.0561
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9828
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 281, Global step 565:
20-03-22 23:31-INFO-training batch loss: 0.0066; avg_loss: 0.0559
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9828
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 282, Global step 566:
20-03-22 23:31-INFO-training batch loss: 0.0050; avg_loss: 0.0557
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9829
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 283, Global step 567:
20-03-22 23:31-INFO-training batch loss: 0.0101; avg_loss: 0.0556
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9829
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, Batch 284, Global step 568:
20-03-22 23:31-INFO-training batch loss: 0.0048; avg_loss: 0.0554
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9830
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, training batch loss: 0.0048; avg_loss: 0.0554
20-03-22 23:31-INFO-Epoch 1, training batch accuracy: 1.0000; avg_accuracy: 0.9830
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 1, evaluating batch loss: 0.9701; avg_loss: 0.3409
20-03-22 23:31-INFO-Epoch 1, evaluating batch accuracy: 0.8636; avg_accuracy: 0.9540
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 2, Batch 1, Global step 569:
20-03-22 23:31-INFO-training batch loss: 0.0070; avg_loss: 0.0070
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 2, Batch 2, Global step 570:
20-03-22 23:31-INFO-training batch loss: 0.0252; avg_loss: 0.0161
20-03-22 23:31-INFO-training batch acc: 0.9922; avg_acc: 0.9961
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 2, Batch 3, Global step 571:
20-03-22 23:31-INFO-training batch loss: 0.0068; avg_loss: 0.0130
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-22 23:31-INFO-
20-03-22 23:31-INFO-Epoch 2, Batch 4, Global step 572:
20-03-22 23:31-INFO-training batch loss: 0.0046; avg_loss: 0.0109
20-03-22 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-22 23:31-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 5, Global step 573:
20-03-22 23:32-INFO-training batch loss: 0.0029; avg_loss: 0.0093
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9984
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 6, Global step 574:
20-03-22 23:32-INFO-training batch loss: 0.0030; avg_loss: 0.0083
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 7, Global step 575:
20-03-22 23:32-INFO-training batch loss: 0.0048; avg_loss: 0.0078
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 8, Global step 576:
20-03-22 23:32-INFO-training batch loss: 0.0063; avg_loss: 0.0076
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 9, Global step 577:
20-03-22 23:32-INFO-training batch loss: 0.0044; avg_loss: 0.0072
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 10, Global step 578:
20-03-22 23:32-INFO-training batch loss: 0.0044; avg_loss: 0.0069
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 11, Global step 579:
20-03-22 23:32-INFO-training batch loss: 0.0059; avg_loss: 0.0068
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 12, Global step 580:
20-03-22 23:32-INFO-training batch loss: 0.0257; avg_loss: 0.0084
20-03-22 23:32-INFO-training batch acc: 0.9922; avg_acc: 0.9987
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 13, Global step 581:
20-03-22 23:32-INFO-training batch loss: 0.0057; avg_loss: 0.0082
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 14, Global step 582:
20-03-22 23:32-INFO-training batch loss: 0.0068; avg_loss: 0.0081
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 15, Global step 583:
20-03-22 23:32-INFO-training batch loss: 0.0045; avg_loss: 0.0079
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 16, Global step 584:
20-03-22 23:32-INFO-training batch loss: 0.0058; avg_loss: 0.0077
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 17, Global step 585:
20-03-22 23:32-INFO-training batch loss: 0.0059; avg_loss: 0.0076
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 18, Global step 586:
20-03-22 23:32-INFO-training batch loss: 0.0042; avg_loss: 0.0074
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 19, Global step 587:
20-03-22 23:32-INFO-training batch loss: 0.0056; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 20, Global step 588:
20-03-22 23:32-INFO-training batch loss: 0.0146; avg_loss: 0.0077
20-03-22 23:32-INFO-training batch acc: 0.9922; avg_acc: 0.9988
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 21, Global step 589:
20-03-22 23:32-INFO-training batch loss: 0.0061; avg_loss: 0.0076
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 22, Global step 590:
20-03-22 23:32-INFO-training batch loss: 0.0045; avg_loss: 0.0075
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 23, Global step 591:
20-03-22 23:32-INFO-training batch loss: 0.0045; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 24, Global step 592:
20-03-22 23:32-INFO-training batch loss: 0.0089; avg_loss: 0.0074
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 25, Global step 593:
20-03-22 23:32-INFO-training batch loss: 0.0032; avg_loss: 0.0072
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 26, Global step 594:
20-03-22 23:32-INFO-training batch loss: 0.0091; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 27, Global step 595:
20-03-22 23:32-INFO-training batch loss: 0.0070; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 28, Global step 596:
20-03-22 23:32-INFO-training batch loss: 0.0084; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 29, Global step 597:
20-03-22 23:32-INFO-training batch loss: 0.0066; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 30, Global step 598:
20-03-22 23:32-INFO-training batch loss: 0.0071; avg_loss: 0.0073
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-22 23:32-INFO-
20-03-22 23:32-INFO-Epoch 2, Batch 31, Global step 599:
20-03-22 23:32-INFO-training batch loss: 0.0101; avg_loss: 0.0074
20-03-22 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-22 23:32-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 32, Global step 600:
20-03-22 23:33-INFO-training batch loss: 0.0030; avg_loss: 0.0073
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 33, Global step 601:
20-03-22 23:33-INFO-training batch loss: 0.0050; avg_loss: 0.0072
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 34, Global step 602:
20-03-22 23:33-INFO-training batch loss: 0.0036; avg_loss: 0.0071
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 35, Global step 603:
20-03-22 23:33-INFO-training batch loss: 0.0044; avg_loss: 0.0070
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 36, Global step 604:
20-03-22 23:33-INFO-training batch loss: 0.0034; avg_loss: 0.0069
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 37, Global step 605:
20-03-22 23:33-INFO-training batch loss: 0.0070; avg_loss: 0.0069
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 38, Global step 606:
20-03-22 23:33-INFO-training batch loss: 0.0052; avg_loss: 0.0069
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 39, Global step 607:
20-03-22 23:33-INFO-training batch loss: 0.0061; avg_loss: 0.0069
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 40, Global step 608:
20-03-22 23:33-INFO-training batch loss: 0.0041; avg_loss: 0.0068
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 41, Global step 609:
20-03-22 23:33-INFO-training batch loss: 0.0055; avg_loss: 0.0068
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 42, Global step 610:
20-03-22 23:33-INFO-training batch loss: 0.0038; avg_loss: 0.0067
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 43, Global step 611:
20-03-22 23:33-INFO-training batch loss: 0.0039; avg_loss: 0.0066
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 44, Global step 612:
20-03-22 23:33-INFO-training batch loss: 0.0038; avg_loss: 0.0066
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 45, Global step 613:
20-03-22 23:33-INFO-training batch loss: 0.0034; avg_loss: 0.0065
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 46, Global step 614:
20-03-22 23:33-INFO-training batch loss: 0.0044; avg_loss: 0.0064
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 47, Global step 615:
20-03-22 23:33-INFO-training batch loss: 0.0040; avg_loss: 0.0064
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 48, Global step 616:
20-03-22 23:33-INFO-training batch loss: 0.0065; avg_loss: 0.0064
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 49, Global step 617:
20-03-22 23:33-INFO-training batch loss: 0.0029; avg_loss: 0.0063
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 50, Global step 618:
20-03-22 23:33-INFO-training batch loss: 0.0045; avg_loss: 0.0063
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 51, Global step 619:
20-03-22 23:33-INFO-training batch loss: 0.0038; avg_loss: 0.0062
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 52, Global step 620:
20-03-22 23:33-INFO-training batch loss: 0.0072; avg_loss: 0.0062
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 53, Global step 621:
20-03-22 23:33-INFO-training batch loss: 0.0056; avg_loss: 0.0062
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 54, Global step 622:
20-03-22 23:33-INFO-training batch loss: 0.0012; avg_loss: 0.0061
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 55, Global step 623:
20-03-22 23:33-INFO-training batch loss: 0.0050; avg_loss: 0.0061
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 56, Global step 624:
20-03-22 23:33-INFO-training batch loss: 0.0026; avg_loss: 0.0061
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 57, Global step 625:
20-03-22 23:33-INFO-training batch loss: 0.0302; avg_loss: 0.0065
20-03-22 23:33-INFO-training batch acc: 0.9922; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:33-INFO-Epoch 2, Batch 58, Global step 626:
20-03-22 23:33-INFO-training batch loss: 0.0043; avg_loss: 0.0064
20-03-22 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:33-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 59, Global step 627:
20-03-22 23:34-INFO-training batch loss: 0.0065; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 60, Global step 628:
20-03-22 23:34-INFO-training batch loss: 0.0055; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 61, Global step 629:
20-03-22 23:34-INFO-training batch loss: 0.0098; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 62, Global step 630:
20-03-22 23:34-INFO-training batch loss: 0.0065; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 63, Global step 631:
20-03-22 23:34-INFO-training batch loss: 0.0062; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 64, Global step 632:
20-03-22 23:34-INFO-training batch loss: 0.0043; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 65, Global step 633:
20-03-22 23:34-INFO-training batch loss: 0.0101; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 66, Global step 634:
20-03-22 23:34-INFO-training batch loss: 0.0140; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 0.9922; avg_acc: 0.9994
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 67, Global step 635:
20-03-22 23:34-INFO-training batch loss: 0.0070; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 68, Global step 636:
20-03-22 23:34-INFO-training batch loss: 0.0049; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 69, Global step 637:
20-03-22 23:34-INFO-training batch loss: 0.0077; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 70, Global step 638:
20-03-22 23:34-INFO-training batch loss: 0.0050; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 71, Global step 639:
20-03-22 23:34-INFO-training batch loss: 0.0056; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 72, Global step 640:
20-03-22 23:34-INFO-training batch loss: 0.0067; avg_loss: 0.0066
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 73, Global step 641:
20-03-22 23:34-INFO-training batch loss: 0.0041; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 74, Global step 642:
20-03-22 23:34-INFO-training batch loss: 0.0037; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 75, Global step 643:
20-03-22 23:34-INFO-training batch loss: 0.0041; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 76, Global step 644:
20-03-22 23:34-INFO-training batch loss: 0.0051; avg_loss: 0.0065
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 77, Global step 645:
20-03-22 23:34-INFO-training batch loss: 0.0057; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 78, Global step 646:
20-03-22 23:34-INFO-training batch loss: 0.0030; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 79, Global step 647:
20-03-22 23:34-INFO-training batch loss: 0.0067; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 80, Global step 648:
20-03-22 23:34-INFO-training batch loss: 0.0028; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 81, Global step 649:
20-03-22 23:34-INFO-training batch loss: 0.0093; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 82, Global step 650:
20-03-22 23:34-INFO-training batch loss: 0.0043; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 83, Global step 651:
20-03-22 23:34-INFO-training batch loss: 0.0057; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:34-INFO-Epoch 2, Batch 84, Global step 652:
20-03-22 23:34-INFO-training batch loss: 0.0072; avg_loss: 0.0064
20-03-22 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:34-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 85, Global step 653:
20-03-22 23:35-INFO-training batch loss: 0.0043; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 86, Global step 654:
20-03-22 23:35-INFO-training batch loss: 0.0047; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 87, Global step 655:
20-03-22 23:35-INFO-training batch loss: 0.0086; avg_loss: 0.0064
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 88, Global step 656:
20-03-22 23:35-INFO-training batch loss: 0.0059; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 89, Global step 657:
20-03-22 23:35-INFO-training batch loss: 0.0032; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 90, Global step 658:
20-03-22 23:35-INFO-training batch loss: 0.0057; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 91, Global step 659:
20-03-22 23:35-INFO-training batch loss: 0.0082; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 92, Global step 660:
20-03-22 23:35-INFO-training batch loss: 0.0035; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 93, Global step 661:
20-03-22 23:35-INFO-training batch loss: 0.0032; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 94, Global step 662:
20-03-22 23:35-INFO-training batch loss: 0.0039; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 95, Global step 663:
20-03-22 23:35-INFO-training batch loss: 0.0062; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 96, Global step 664:
20-03-22 23:35-INFO-training batch loss: 0.0074; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 97, Global step 665:
20-03-22 23:35-INFO-training batch loss: 0.0092; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 0.9922; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 98, Global step 666:
20-03-22 23:35-INFO-training batch loss: 0.0034; avg_loss: 0.0063
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 99, Global step 667:
20-03-22 23:35-INFO-training batch loss: 0.0048; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 100, Global step 668:
20-03-22 23:35-INFO-training batch loss: 0.0049; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 101, Global step 669:
20-03-22 23:35-INFO-training batch loss: 0.0055; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 102, Global step 670:
20-03-22 23:35-INFO-training batch loss: 0.0027; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 103, Global step 671:
20-03-22 23:35-INFO-training batch loss: 0.0038; avg_loss: 0.0062
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 104, Global step 672:
20-03-22 23:35-INFO-training batch loss: 0.0025; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 105, Global step 673:
20-03-22 23:35-INFO-training batch loss: 0.0070; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 106, Global step 674:
20-03-22 23:35-INFO-training batch loss: 0.0032; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 107, Global step 675:
20-03-22 23:35-INFO-training batch loss: 0.0058; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 108, Global step 676:
20-03-22 23:35-INFO-training batch loss: 0.0019; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 109, Global step 677:
20-03-22 23:35-INFO-training batch loss: 0.0051; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:35-INFO-Epoch 2, Batch 110, Global step 678:
20-03-22 23:35-INFO-training batch loss: 0.0076; avg_loss: 0.0061
20-03-22 23:35-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:35-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 111, Global step 679:
20-03-22 23:36-INFO-training batch loss: 0.0047; avg_loss: 0.0061
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 112, Global step 680:
20-03-22 23:36-INFO-training batch loss: 0.0068; avg_loss: 0.0061
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 113, Global step 681:
20-03-22 23:36-INFO-training batch loss: 0.0056; avg_loss: 0.0061
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 114, Global step 682:
20-03-22 23:36-INFO-training batch loss: 0.0029; avg_loss: 0.0060
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 115, Global step 683:
20-03-22 23:36-INFO-training batch loss: 0.0041; avg_loss: 0.0060
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 116, Global step 684:
20-03-22 23:36-INFO-training batch loss: 0.0022; avg_loss: 0.0060
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 117, Global step 685:
20-03-22 23:36-INFO-training batch loss: 0.0047; avg_loss: 0.0060
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 118, Global step 686:
20-03-22 23:36-INFO-training batch loss: 0.0048; avg_loss: 0.0060
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 119, Global step 687:
20-03-22 23:36-INFO-training batch loss: 0.0042; avg_loss: 0.0059
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 120, Global step 688:
20-03-22 23:36-INFO-training batch loss: 0.0042; avg_loss: 0.0059
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 121, Global step 689:
20-03-22 23:36-INFO-training batch loss: 0.0047; avg_loss: 0.0059
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 122, Global step 690:
20-03-22 23:36-INFO-training batch loss: 0.0037; avg_loss: 0.0059
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 123, Global step 691:
20-03-22 23:36-INFO-training batch loss: 0.0024; avg_loss: 0.0059
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 124, Global step 692:
20-03-22 23:36-INFO-training batch loss: 0.0028; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 125, Global step 693:
20-03-22 23:36-INFO-training batch loss: 0.0022; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 126, Global step 694:
20-03-22 23:36-INFO-training batch loss: 0.0024; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 127, Global step 695:
20-03-22 23:36-INFO-training batch loss: 0.0029; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 128, Global step 696:
20-03-22 23:36-INFO-training batch loss: 0.0039; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 129, Global step 697:
20-03-22 23:36-INFO-training batch loss: 0.0113; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 130, Global step 698:
20-03-22 23:36-INFO-training batch loss: 0.0055; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 131, Global step 699:
20-03-22 23:36-INFO-training batch loss: 0.0084; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 132, Global step 700:
20-03-22 23:36-INFO-training batch loss: 0.0047; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 133, Global step 701:
20-03-22 23:36-INFO-training batch loss: 0.0082; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 134, Global step 702:
20-03-22 23:36-INFO-training batch loss: 0.0036; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 135, Global step 703:
20-03-22 23:36-INFO-training batch loss: 0.0050; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:36-INFO-Epoch 2, Batch 136, Global step 704:
20-03-22 23:36-INFO-training batch loss: 0.0040; avg_loss: 0.0058
20-03-22 23:36-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:36-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 137, Global step 705:
20-03-22 23:37-INFO-training batch loss: 0.0029; avg_loss: 0.0058
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 138, Global step 706:
20-03-22 23:37-INFO-training batch loss: 0.0039; avg_loss: 0.0058
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 139, Global step 707:
20-03-22 23:37-INFO-training batch loss: 0.0030; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 140, Global step 708:
20-03-22 23:37-INFO-training batch loss: 0.0034; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 141, Global step 709:
20-03-22 23:37-INFO-training batch loss: 0.0066; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 142, Global step 710:
20-03-22 23:37-INFO-training batch loss: 0.0061; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 143, Global step 711:
20-03-22 23:37-INFO-training batch loss: 0.0047; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 144, Global step 712:
20-03-22 23:37-INFO-training batch loss: 0.0044; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 145, Global step 713:
20-03-22 23:37-INFO-training batch loss: 0.0063; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 146, Global step 714:
20-03-22 23:37-INFO-training batch loss: 0.0050; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 147, Global step 715:
20-03-22 23:37-INFO-training batch loss: 0.0034; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 148, Global step 716:
20-03-22 23:37-INFO-training batch loss: 0.0036; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 149, Global step 717:
20-03-22 23:37-INFO-training batch loss: 0.0038; avg_loss: 0.0057
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 150, Global step 718:
20-03-22 23:37-INFO-training batch loss: 0.0024; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 151, Global step 719:
20-03-22 23:37-INFO-training batch loss: 0.0028; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 152, Global step 720:
20-03-22 23:37-INFO-training batch loss: 0.0082; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 153, Global step 721:
20-03-22 23:37-INFO-training batch loss: 0.0055; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 154, Global step 722:
20-03-22 23:37-INFO-training batch loss: 0.0038; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 155, Global step 723:
20-03-22 23:37-INFO-training batch loss: 0.0086; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 156, Global step 724:
20-03-22 23:37-INFO-training batch loss: 0.0019; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 157, Global step 725:
20-03-22 23:37-INFO-training batch loss: 0.0030; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 158, Global step 726:
20-03-22 23:37-INFO-training batch loss: 0.0026; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 159, Global step 727:
20-03-22 23:37-INFO-training batch loss: 0.0017; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 160, Global step 728:
20-03-22 23:37-INFO-training batch loss: 0.0035; avg_loss: 0.0056
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 161, Global step 729:
20-03-22 23:37-INFO-training batch loss: 0.0045; avg_loss: 0.0055
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 162, Global step 730:
20-03-22 23:37-INFO-training batch loss: 0.0036; avg_loss: 0.0055
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:37-INFO-Epoch 2, Batch 163, Global step 731:
20-03-22 23:37-INFO-training batch loss: 0.0035; avg_loss: 0.0055
20-03-22 23:37-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:37-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 164, Global step 732:
20-03-22 23:38-INFO-training batch loss: 0.0048; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 165, Global step 733:
20-03-22 23:38-INFO-training batch loss: 0.0030; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 166, Global step 734:
20-03-22 23:38-INFO-training batch loss: 0.0061; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 167, Global step 735:
20-03-22 23:38-INFO-training batch loss: 0.0030; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 168, Global step 736:
20-03-22 23:38-INFO-training batch loss: 0.0031; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 169, Global step 737:
20-03-22 23:38-INFO-training batch loss: 0.0046; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 170, Global step 738:
20-03-22 23:38-INFO-training batch loss: 0.0043; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 171, Global step 739:
20-03-22 23:38-INFO-training batch loss: 0.0033; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 172, Global step 740:
20-03-22 23:38-INFO-training batch loss: 0.0056; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 173, Global step 741:
20-03-22 23:38-INFO-training batch loss: 0.0187; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 174, Global step 742:
20-03-22 23:38-INFO-training batch loss: 0.0025; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 175, Global step 743:
20-03-22 23:38-INFO-training batch loss: 0.0022; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 176, Global step 744:
20-03-22 23:38-INFO-training batch loss: 0.0038; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 177, Global step 745:
20-03-22 23:38-INFO-training batch loss: 0.0017; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 178, Global step 746:
20-03-22 23:38-INFO-training batch loss: 0.0039; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 179, Global step 747:
20-03-22 23:38-INFO-training batch loss: 0.0033; avg_loss: 0.0054
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 180, Global step 748:
20-03-22 23:38-INFO-training batch loss: 0.0050; avg_loss: 0.0054
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 181, Global step 749:
20-03-22 23:38-INFO-training batch loss: 0.0045; avg_loss: 0.0054
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 182, Global step 750:
20-03-22 23:38-INFO-training batch loss: 0.0103; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 183, Global step 751:
20-03-22 23:38-INFO-training batch loss: 0.0035; avg_loss: 0.0054
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 184, Global step 752:
20-03-22 23:38-INFO-training batch loss: 0.0169; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 185, Global step 753:
20-03-22 23:38-INFO-training batch loss: 0.0044; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 186, Global step 754:
20-03-22 23:38-INFO-training batch loss: 0.0076; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 187, Global step 755:
20-03-22 23:38-INFO-training batch loss: 0.0087; avg_loss: 0.0055
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 188, Global step 756:
20-03-22 23:38-INFO-training batch loss: 0.0138; avg_loss: 0.0056
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:38-INFO-Epoch 2, Batch 189, Global step 757:
20-03-22 23:38-INFO-training batch loss: 0.0062; avg_loss: 0.0056
20-03-22 23:38-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:38-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 190, Global step 758:
20-03-22 23:39-INFO-training batch loss: 0.0089; avg_loss: 0.0056
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 191, Global step 759:
20-03-22 23:39-INFO-training batch loss: 0.0100; avg_loss: 0.0056
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 192, Global step 760:
20-03-22 23:39-INFO-training batch loss: 0.0038; avg_loss: 0.0056
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 193, Global step 761:
20-03-22 23:39-INFO-training batch loss: 0.0054; avg_loss: 0.0056
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 194, Global step 762:
20-03-22 23:39-INFO-training batch loss: 0.0064; avg_loss: 0.0056
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 195, Global step 763:
20-03-22 23:39-INFO-training batch loss: 0.0091; avg_loss: 0.0056
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 196, Global step 764:
20-03-22 23:39-INFO-training batch loss: 0.0182; avg_loss: 0.0057
20-03-22 23:39-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 197, Global step 765:
20-03-22 23:39-INFO-training batch loss: 0.0076; avg_loss: 0.0057
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 198, Global step 766:
20-03-22 23:39-INFO-training batch loss: 0.0105; avg_loss: 0.0057
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 199, Global step 767:
20-03-22 23:39-INFO-training batch loss: 0.0069; avg_loss: 0.0057
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 200, Global step 768:
20-03-22 23:39-INFO-training batch loss: 0.0128; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 201, Global step 769:
20-03-22 23:39-INFO-training batch loss: 0.0031; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 202, Global step 770:
20-03-22 23:39-INFO-training batch loss: 0.0067; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 203, Global step 771:
20-03-22 23:39-INFO-training batch loss: 0.0086; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 204, Global step 772:
20-03-22 23:39-INFO-training batch loss: 0.0065; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 205, Global step 773:
20-03-22 23:39-INFO-training batch loss: 0.0037; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 206, Global step 774:
20-03-22 23:39-INFO-training batch loss: 0.0048; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 207, Global step 775:
20-03-22 23:39-INFO-training batch loss: 0.0060; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 208, Global step 776:
20-03-22 23:39-INFO-training batch loss: 0.0065; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 209, Global step 777:
20-03-22 23:39-INFO-training batch loss: 0.0198; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 210, Global step 778:
20-03-22 23:39-INFO-training batch loss: 0.0018; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 211, Global step 779:
20-03-22 23:39-INFO-training batch loss: 0.0032; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 212, Global step 780:
20-03-22 23:39-INFO-training batch loss: 0.0059; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 213, Global step 781:
20-03-22 23:39-INFO-training batch loss: 0.0094; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 214, Global step 782:
20-03-22 23:39-INFO-training batch loss: 0.0043; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 215, Global step 783:
20-03-22 23:39-INFO-training batch loss: 0.0063; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:39-INFO-Epoch 2, Batch 216, Global step 784:
20-03-22 23:39-INFO-training batch loss: 0.0061; avg_loss: 0.0058
20-03-22 23:39-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:39-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 217, Global step 785:
20-03-22 23:40-INFO-training batch loss: 0.0024; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 218, Global step 786:
20-03-22 23:40-INFO-training batch loss: 0.0083; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 219, Global step 787:
20-03-22 23:40-INFO-training batch loss: 0.0051; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 220, Global step 788:
20-03-22 23:40-INFO-training batch loss: 0.0027; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 221, Global step 789:
20-03-22 23:40-INFO-training batch loss: 0.0071; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 222, Global step 790:
20-03-22 23:40-INFO-training batch loss: 0.0039; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 223, Global step 791:
20-03-22 23:40-INFO-training batch loss: 0.0027; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 224, Global step 792:
20-03-22 23:40-INFO-training batch loss: 0.0041; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 225, Global step 793:
20-03-22 23:40-INFO-training batch loss: 0.0036; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 226, Global step 794:
20-03-22 23:40-INFO-training batch loss: 0.0062; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 227, Global step 795:
20-03-22 23:40-INFO-training batch loss: 0.0039; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 228, Global step 796:
20-03-22 23:40-INFO-training batch loss: 0.0047; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 229, Global step 797:
20-03-22 23:40-INFO-training batch loss: 0.0049; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 230, Global step 798:
20-03-22 23:40-INFO-training batch loss: 0.0043; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 231, Global step 799:
20-03-22 23:40-INFO-training batch loss: 0.0085; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 232, Global step 800:
20-03-22 23:40-INFO-training batch loss: 0.0081; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 233, Global step 801:
20-03-22 23:40-INFO-training batch loss: 0.0031; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 234, Global step 802:
20-03-22 23:40-INFO-training batch loss: 0.0078; avg_loss: 0.0058
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 235, Global step 803:
20-03-22 23:40-INFO-training batch loss: 0.0029; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 236, Global step 804:
20-03-22 23:40-INFO-training batch loss: 0.0040; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 237, Global step 805:
20-03-22 23:40-INFO-training batch loss: 0.0030; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 238, Global step 806:
20-03-22 23:40-INFO-training batch loss: 0.0015; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 239, Global step 807:
20-03-22 23:40-INFO-training batch loss: 0.0028; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 240, Global step 808:
20-03-22 23:40-INFO-training batch loss: 0.0072; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 241, Global step 809:
20-03-22 23:40-INFO-training batch loss: 0.0019; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:40-INFO-Epoch 2, Batch 242, Global step 810:
20-03-22 23:40-INFO-training batch loss: 0.0032; avg_loss: 0.0057
20-03-22 23:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:40-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 243, Global step 811:
20-03-22 23:41-INFO-training batch loss: 0.0019; avg_loss: 0.0057
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 244, Global step 812:
20-03-22 23:41-INFO-training batch loss: 0.0033; avg_loss: 0.0057
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 245, Global step 813:
20-03-22 23:41-INFO-training batch loss: 0.0035; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 246, Global step 814:
20-03-22 23:41-INFO-training batch loss: 0.0040; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 247, Global step 815:
20-03-22 23:41-INFO-training batch loss: 0.0047; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 248, Global step 816:
20-03-22 23:41-INFO-training batch loss: 0.0043; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 249, Global step 817:
20-03-22 23:41-INFO-training batch loss: 0.0064; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 250, Global step 818:
20-03-22 23:41-INFO-training batch loss: 0.0046; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 251, Global step 819:
20-03-22 23:41-INFO-training batch loss: 0.0069; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 252, Global step 820:
20-03-22 23:41-INFO-training batch loss: 0.0041; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 253, Global step 821:
20-03-22 23:41-INFO-training batch loss: 0.0037; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 254, Global step 822:
20-03-22 23:41-INFO-training batch loss: 0.0021; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 255, Global step 823:
20-03-22 23:41-INFO-training batch loss: 0.0018; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 256, Global step 824:
20-03-22 23:41-INFO-training batch loss: 0.0039; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 257, Global step 825:
20-03-22 23:41-INFO-training batch loss: 0.0037; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 258, Global step 826:
20-03-22 23:41-INFO-training batch loss: 0.0019; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 259, Global step 827:
20-03-22 23:41-INFO-training batch loss: 0.0024; avg_loss: 0.0056
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 260, Global step 828:
20-03-22 23:41-INFO-training batch loss: 0.0028; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 261, Global step 829:
20-03-22 23:41-INFO-training batch loss: 0.0050; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 262, Global step 830:
20-03-22 23:41-INFO-training batch loss: 0.0035; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 263, Global step 831:
20-03-22 23:41-INFO-training batch loss: 0.0024; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 264, Global step 832:
20-03-22 23:41-INFO-training batch loss: 0.0018; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 265, Global step 833:
20-03-22 23:41-INFO-training batch loss: 0.0026; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 266, Global step 834:
20-03-22 23:41-INFO-training batch loss: 0.0038; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 267, Global step 835:
20-03-22 23:41-INFO-training batch loss: 0.0021; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 268, Global step 836:
20-03-22 23:41-INFO-training batch loss: 0.0024; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:41-INFO-
20-03-22 23:41-INFO-Epoch 2, Batch 269, Global step 837:
20-03-22 23:41-INFO-training batch loss: 0.0024; avg_loss: 0.0055
20-03-22 23:41-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:41-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 270, Global step 838:
20-03-22 23:42-INFO-training batch loss: 0.0024; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 271, Global step 839:
20-03-22 23:42-INFO-training batch loss: 0.0032; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 272, Global step 840:
20-03-22 23:42-INFO-training batch loss: 0.0038; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 273, Global step 841:
20-03-22 23:42-INFO-training batch loss: 0.0032; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 274, Global step 842:
20-03-22 23:42-INFO-training batch loss: 0.0050; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 275, Global step 843:
20-03-22 23:42-INFO-training batch loss: 0.0037; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 276, Global step 844:
20-03-22 23:42-INFO-training batch loss: 0.0021; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 277, Global step 845:
20-03-22 23:42-INFO-training batch loss: 0.0022; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 278, Global step 846:
20-03-22 23:42-INFO-training batch loss: 0.0030; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 279, Global step 847:
20-03-22 23:42-INFO-training batch loss: 0.0012; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 280, Global step 848:
20-03-22 23:42-INFO-training batch loss: 0.0029; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 281, Global step 849:
20-03-22 23:42-INFO-training batch loss: 0.0043; avg_loss: 0.0054
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 282, Global step 850:
20-03-22 23:42-INFO-training batch loss: 0.0031; avg_loss: 0.0053
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 283, Global step 851:
20-03-22 23:42-INFO-training batch loss: 0.0048; avg_loss: 0.0053
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, Batch 284, Global step 852:
20-03-22 23:42-INFO-training batch loss: 0.0010; avg_loss: 0.0053
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, training batch loss: 0.0010; avg_loss: 0.0053
20-03-22 23:42-INFO-Epoch 2, training batch accuracy: 1.0000; avg_accuracy: 0.9997
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 2, evaluating batch loss: 1.4684; avg_loss: 0.4925
20-03-22 23:42-INFO-Epoch 2, evaluating batch accuracy: 0.8409; avg_accuracy: 0.9369
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 1, Global step 853:
20-03-22 23:42-INFO-training batch loss: 0.0027; avg_loss: 0.0027
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 2, Global step 854:
20-03-22 23:42-INFO-training batch loss: 0.0033; avg_loss: 0.0030
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 3, Global step 855:
20-03-22 23:42-INFO-training batch loss: 0.0026; avg_loss: 0.0029
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 4, Global step 856:
20-03-22 23:42-INFO-training batch loss: 0.0087; avg_loss: 0.0043
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 5, Global step 857:
20-03-22 23:42-INFO-training batch loss: 0.0033; avg_loss: 0.0041
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 6, Global step 858:
20-03-22 23:42-INFO-training batch loss: 0.0078; avg_loss: 0.0048
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:42-INFO-Epoch 3, Batch 7, Global step 859:
20-03-22 23:42-INFO-training batch loss: 0.0024; avg_loss: 0.0044
20-03-22 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:42-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 8, Global step 860:
20-03-22 23:43-INFO-training batch loss: 0.0085; avg_loss: 0.0049
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 9, Global step 861:
20-03-22 23:43-INFO-training batch loss: 0.0027; avg_loss: 0.0047
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 10, Global step 862:
20-03-22 23:43-INFO-training batch loss: 0.0029; avg_loss: 0.0045
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 11, Global step 863:
20-03-22 23:43-INFO-training batch loss: 0.0047; avg_loss: 0.0045
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 12, Global step 864:
20-03-22 23:43-INFO-training batch loss: 0.0047; avg_loss: 0.0045
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 13, Global step 865:
20-03-22 23:43-INFO-training batch loss: 0.0109; avg_loss: 0.0050
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 14, Global step 866:
20-03-22 23:43-INFO-training batch loss: 0.0083; avg_loss: 0.0053
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 15, Global step 867:
20-03-22 23:43-INFO-training batch loss: 0.0072; avg_loss: 0.0054
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 16, Global step 868:
20-03-22 23:43-INFO-training batch loss: 0.0020; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 17, Global step 869:
20-03-22 23:43-INFO-training batch loss: 0.0028; avg_loss: 0.0050
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 18, Global step 870:
20-03-22 23:43-INFO-training batch loss: 0.0041; avg_loss: 0.0050
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 19, Global step 871:
20-03-22 23:43-INFO-training batch loss: 0.0046; avg_loss: 0.0050
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 20, Global step 872:
20-03-22 23:43-INFO-training batch loss: 0.0107; avg_loss: 0.0053
20-03-22 23:43-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 21, Global step 873:
20-03-22 23:43-INFO-training batch loss: 0.0036; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 22, Global step 874:
20-03-22 23:43-INFO-training batch loss: 0.0033; avg_loss: 0.0051
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 23, Global step 875:
20-03-22 23:43-INFO-training batch loss: 0.0038; avg_loss: 0.0050
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 24, Global step 876:
20-03-22 23:43-INFO-training batch loss: 0.0091; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 25, Global step 877:
20-03-22 23:43-INFO-training batch loss: 0.0050; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 26, Global step 878:
20-03-22 23:43-INFO-training batch loss: 0.0081; avg_loss: 0.0053
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 27, Global step 879:
20-03-22 23:43-INFO-training batch loss: 0.0036; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 28, Global step 880:
20-03-22 23:43-INFO-training batch loss: 0.0038; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 29, Global step 881:
20-03-22 23:43-INFO-training batch loss: 0.0053; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 30, Global step 882:
20-03-22 23:43-INFO-training batch loss: 0.0062; avg_loss: 0.0052
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 31, Global step 883:
20-03-22 23:43-INFO-training batch loss: 0.0020; avg_loss: 0.0051
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 32, Global step 884:
20-03-22 23:43-INFO-training batch loss: 0.0058; avg_loss: 0.0051
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 33, Global step 885:
20-03-22 23:43-INFO-training batch loss: 0.0038; avg_loss: 0.0051
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:43-INFO-
20-03-22 23:43-INFO-Epoch 3, Batch 34, Global step 886:
20-03-22 23:43-INFO-training batch loss: 0.0036; avg_loss: 0.0051
20-03-22 23:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:43-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 35, Global step 887:
20-03-22 23:44-INFO-training batch loss: 0.0052; avg_loss: 0.0051
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 36, Global step 888:
20-03-22 23:44-INFO-training batch loss: 0.0044; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 37, Global step 889:
20-03-22 23:44-INFO-training batch loss: 0.0056; avg_loss: 0.0051
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 38, Global step 890:
20-03-22 23:44-INFO-training batch loss: 0.0032; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 39, Global step 891:
20-03-22 23:44-INFO-training batch loss: 0.0035; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 40, Global step 892:
20-03-22 23:44-INFO-training batch loss: 0.0035; avg_loss: 0.0049
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 41, Global step 893:
20-03-22 23:44-INFO-training batch loss: 0.0032; avg_loss: 0.0049
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 42, Global step 894:
20-03-22 23:44-INFO-training batch loss: 0.0114; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 43, Global step 895:
20-03-22 23:44-INFO-training batch loss: 0.0032; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 44, Global step 896:
20-03-22 23:44-INFO-training batch loss: 0.0050; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 45, Global step 897:
20-03-22 23:44-INFO-training batch loss: 0.0043; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 46, Global step 898:
20-03-22 23:44-INFO-training batch loss: 0.0039; avg_loss: 0.0050
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 47, Global step 899:
20-03-22 23:44-INFO-training batch loss: 0.0041; avg_loss: 0.0049
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 48, Global step 900:
20-03-22 23:44-INFO-training batch loss: 0.0038; avg_loss: 0.0049
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 49, Global step 901:
20-03-22 23:44-INFO-training batch loss: 0.0017; avg_loss: 0.0049
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 50, Global step 902:
20-03-22 23:44-INFO-training batch loss: 0.0043; avg_loss: 0.0048
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 51, Global step 903:
20-03-22 23:44-INFO-training batch loss: 0.0021; avg_loss: 0.0048
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 52, Global step 904:
20-03-22 23:44-INFO-training batch loss: 0.0044; avg_loss: 0.0048
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 53, Global step 905:
20-03-22 23:44-INFO-training batch loss: 0.0023; avg_loss: 0.0047
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 54, Global step 906:
20-03-22 23:44-INFO-training batch loss: 0.0014; avg_loss: 0.0047
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 55, Global step 907:
20-03-22 23:44-INFO-training batch loss: 0.0023; avg_loss: 0.0046
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 56, Global step 908:
20-03-22 23:44-INFO-training batch loss: 0.0044; avg_loss: 0.0046
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 57, Global step 909:
20-03-22 23:44-INFO-training batch loss: 0.0057; avg_loss: 0.0046
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 58, Global step 910:
20-03-22 23:44-INFO-training batch loss: 0.0018; avg_loss: 0.0046
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 59, Global step 911:
20-03-22 23:44-INFO-training batch loss: 0.0012; avg_loss: 0.0045
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:44-INFO-Epoch 3, Batch 60, Global step 912:
20-03-22 23:44-INFO-training batch loss: 0.0016; avg_loss: 0.0045
20-03-22 23:44-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:44-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 61, Global step 913:
20-03-22 23:45-INFO-training batch loss: 0.0019; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 62, Global step 914:
20-03-22 23:45-INFO-training batch loss: 0.0094; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 63, Global step 915:
20-03-22 23:45-INFO-training batch loss: 0.0022; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 64, Global step 916:
20-03-22 23:45-INFO-training batch loss: 0.0050; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 65, Global step 917:
20-03-22 23:45-INFO-training batch loss: 0.0039; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 66, Global step 918:
20-03-22 23:45-INFO-training batch loss: 0.0034; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 67, Global step 919:
20-03-22 23:45-INFO-training batch loss: 0.0052; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 68, Global step 920:
20-03-22 23:45-INFO-training batch loss: 0.0028; avg_loss: 0.0045
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 69, Global step 921:
20-03-22 23:45-INFO-training batch loss: 0.0014; avg_loss: 0.0044
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 70, Global step 922:
20-03-22 23:45-INFO-training batch loss: 0.0033; avg_loss: 0.0044
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 71, Global step 923:
20-03-22 23:45-INFO-training batch loss: 0.0029; avg_loss: 0.0044
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 72, Global step 924:
20-03-22 23:45-INFO-training batch loss: 0.0057; avg_loss: 0.0044
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 73, Global step 925:
20-03-22 23:45-INFO-training batch loss: 0.0029; avg_loss: 0.0044
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 74, Global step 926:
20-03-22 23:45-INFO-training batch loss: 0.0028; avg_loss: 0.0044
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 75, Global step 927:
20-03-22 23:45-INFO-training batch loss: 0.0015; avg_loss: 0.0043
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 76, Global step 928:
20-03-22 23:45-INFO-training batch loss: 0.0012; avg_loss: 0.0043
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 77, Global step 929:
20-03-22 23:45-INFO-training batch loss: 0.0026; avg_loss: 0.0043
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 78, Global step 930:
20-03-22 23:45-INFO-training batch loss: 0.0034; avg_loss: 0.0042
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 79, Global step 931:
20-03-22 23:45-INFO-training batch loss: 0.0028; avg_loss: 0.0042
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 80, Global step 932:
20-03-22 23:45-INFO-training batch loss: 0.0023; avg_loss: 0.0042
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 81, Global step 933:
20-03-22 23:45-INFO-training batch loss: 0.0032; avg_loss: 0.0042
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 82, Global step 934:
20-03-22 23:45-INFO-training batch loss: 0.0026; avg_loss: 0.0042
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 83, Global step 935:
20-03-22 23:45-INFO-training batch loss: 0.0045; avg_loss: 0.0042
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 84, Global step 936:
20-03-22 23:45-INFO-training batch loss: 0.0018; avg_loss: 0.0041
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 85, Global step 937:
20-03-22 23:45-INFO-training batch loss: 0.0026; avg_loss: 0.0041
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:45-INFO-Epoch 3, Batch 86, Global step 938:
20-03-22 23:45-INFO-training batch loss: 0.0038; avg_loss: 0.0041
20-03-22 23:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:45-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 87, Global step 939:
20-03-22 23:46-INFO-training batch loss: 0.0034; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 88, Global step 940:
20-03-22 23:46-INFO-training batch loss: 0.0055; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 89, Global step 941:
20-03-22 23:46-INFO-training batch loss: 0.0066; avg_loss: 0.0042
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 90, Global step 942:
20-03-22 23:46-INFO-training batch loss: 0.0016; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 91, Global step 943:
20-03-22 23:46-INFO-training batch loss: 0.0100; avg_loss: 0.0042
20-03-22 23:46-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 92, Global step 944:
20-03-22 23:46-INFO-training batch loss: 0.0028; avg_loss: 0.0042
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 93, Global step 945:
20-03-22 23:46-INFO-training batch loss: 0.0019; avg_loss: 0.0042
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 94, Global step 946:
20-03-22 23:46-INFO-training batch loss: 0.0030; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 95, Global step 947:
20-03-22 23:46-INFO-training batch loss: 0.0029; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 96, Global step 948:
20-03-22 23:46-INFO-training batch loss: 0.0021; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 97, Global step 949:
20-03-22 23:46-INFO-training batch loss: 0.0063; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 98, Global step 950:
20-03-22 23:46-INFO-training batch loss: 0.0026; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 99, Global step 951:
20-03-22 23:46-INFO-training batch loss: 0.0020; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 100, Global step 952:
20-03-22 23:46-INFO-training batch loss: 0.0028; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 101, Global step 953:
20-03-22 23:46-INFO-training batch loss: 0.0018; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 102, Global step 954:
20-03-22 23:46-INFO-training batch loss: 0.0037; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 103, Global step 955:
20-03-22 23:46-INFO-training batch loss: 0.0036; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 104, Global step 956:
20-03-22 23:46-INFO-training batch loss: 0.0061; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 105, Global step 957:
20-03-22 23:46-INFO-training batch loss: 0.0021; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 106, Global step 958:
20-03-22 23:46-INFO-training batch loss: 0.0055; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 107, Global step 959:
20-03-22 23:46-INFO-training batch loss: 0.0061; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 108, Global step 960:
20-03-22 23:46-INFO-training batch loss: 0.0044; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 109, Global step 961:
20-03-22 23:46-INFO-training batch loss: 0.0041; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 110, Global step 962:
20-03-22 23:46-INFO-training batch loss: 0.0016; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 111, Global step 963:
20-03-22 23:46-INFO-training batch loss: 0.0021; avg_loss: 0.0040
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:46-INFO-Epoch 3, Batch 112, Global step 964:
20-03-22 23:46-INFO-training batch loss: 0.0057; avg_loss: 0.0041
20-03-22 23:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:46-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 113, Global step 965:
20-03-22 23:47-INFO-training batch loss: 0.0028; avg_loss: 0.0041
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 114, Global step 966:
20-03-22 23:47-INFO-training batch loss: 0.0020; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 115, Global step 967:
20-03-22 23:47-INFO-training batch loss: 0.0036; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 116, Global step 968:
20-03-22 23:47-INFO-training batch loss: 0.0039; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 117, Global step 969:
20-03-22 23:47-INFO-training batch loss: 0.0021; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 118, Global step 970:
20-03-22 23:47-INFO-training batch loss: 0.0034; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 119, Global step 971:
20-03-22 23:47-INFO-training batch loss: 0.0019; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 120, Global step 972:
20-03-22 23:47-INFO-training batch loss: 0.0020; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 121, Global step 973:
20-03-22 23:47-INFO-training batch loss: 0.0034; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 122, Global step 974:
20-03-22 23:47-INFO-training batch loss: 0.0028; avg_loss: 0.0040
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 123, Global step 975:
20-03-22 23:47-INFO-training batch loss: 0.0014; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 124, Global step 976:
20-03-22 23:47-INFO-training batch loss: 0.0041; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 125, Global step 977:
20-03-22 23:47-INFO-training batch loss: 0.0025; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 126, Global step 978:
20-03-22 23:47-INFO-training batch loss: 0.0024; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 127, Global step 979:
20-03-22 23:47-INFO-training batch loss: 0.0050; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 128, Global step 980:
20-03-22 23:47-INFO-training batch loss: 0.0025; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 129, Global step 981:
20-03-22 23:47-INFO-training batch loss: 0.0036; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 130, Global step 982:
20-03-22 23:47-INFO-training batch loss: 0.0020; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 131, Global step 983:
20-03-22 23:47-INFO-training batch loss: 0.0050; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 132, Global step 984:
20-03-22 23:47-INFO-training batch loss: 0.0027; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 133, Global step 985:
20-03-22 23:47-INFO-training batch loss: 0.0027; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 134, Global step 986:
20-03-22 23:47-INFO-training batch loss: 0.0058; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 135, Global step 987:
20-03-22 23:47-INFO-training batch loss: 0.0031; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 136, Global step 988:
20-03-22 23:47-INFO-training batch loss: 0.0016; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 137, Global step 989:
20-03-22 23:47-INFO-training batch loss: 0.0023; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:47-INFO-Epoch 3, Batch 138, Global step 990:
20-03-22 23:47-INFO-training batch loss: 0.0039; avg_loss: 0.0039
20-03-22 23:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:47-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 139, Global step 991:
20-03-22 23:48-INFO-training batch loss: 0.0016; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 140, Global step 992:
20-03-22 23:48-INFO-training batch loss: 0.0022; avg_loss: 0.0038
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 141, Global step 993:
20-03-22 23:48-INFO-training batch loss: 0.0028; avg_loss: 0.0038
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 142, Global step 994:
20-03-22 23:48-INFO-training batch loss: 0.0037; avg_loss: 0.0038
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 143, Global step 995:
20-03-22 23:48-INFO-training batch loss: 0.0025; avg_loss: 0.0038
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 144, Global step 996:
20-03-22 23:48-INFO-training batch loss: 0.0083; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 145, Global step 997:
20-03-22 23:48-INFO-training batch loss: 0.0052; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 146, Global step 998:
20-03-22 23:48-INFO-training batch loss: 0.0122; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 0.9922; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 147, Global step 999:
20-03-22 23:48-INFO-training batch loss: 0.0028; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 148, Global step 1000:
20-03-22 23:48-INFO-training batch loss: 0.0028; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 149, Global step 1001:
20-03-22 23:48-INFO-training batch loss: 0.0035; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 150, Global step 1002:
20-03-22 23:48-INFO-training batch loss: 0.0058; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 151, Global step 1003:
20-03-22 23:48-INFO-training batch loss: 0.0041; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 152, Global step 1004:
20-03-22 23:48-INFO-training batch loss: 0.0047; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 153, Global step 1005:
20-03-22 23:48-INFO-training batch loss: 0.0068; avg_loss: 0.0039
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 154, Global step 1006:
20-03-22 23:48-INFO-training batch loss: 0.0076; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 155, Global step 1007:
20-03-22 23:48-INFO-training batch loss: 0.0073; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 156, Global step 1008:
20-03-22 23:48-INFO-training batch loss: 0.0029; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 157, Global step 1009:
20-03-22 23:48-INFO-training batch loss: 0.0051; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 158, Global step 1010:
20-03-22 23:48-INFO-training batch loss: 0.0086; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 159, Global step 1011:
20-03-22 23:48-INFO-training batch loss: 0.0048; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 160, Global step 1012:
20-03-22 23:48-INFO-training batch loss: 0.0061; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 161, Global step 1013:
20-03-22 23:48-INFO-training batch loss: 0.0072; avg_loss: 0.0041
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 162, Global step 1014:
20-03-22 23:48-INFO-training batch loss: 0.0050; avg_loss: 0.0041
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 163, Global step 1015:
20-03-22 23:48-INFO-training batch loss: 0.0030; avg_loss: 0.0041
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 164, Global step 1016:
20-03-22 23:48-INFO-training batch loss: 0.0034; avg_loss: 0.0040
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:48-INFO-Epoch 3, Batch 165, Global step 1017:
20-03-22 23:48-INFO-training batch loss: 0.0054; avg_loss: 0.0041
20-03-22 23:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:48-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 166, Global step 1018:
20-03-22 23:49-INFO-training batch loss: 0.0046; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 167, Global step 1019:
20-03-22 23:49-INFO-training batch loss: 0.0038; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 168, Global step 1020:
20-03-22 23:49-INFO-training batch loss: 0.0028; avg_loss: 0.0040
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 169, Global step 1021:
20-03-22 23:49-INFO-training batch loss: 0.0084; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 170, Global step 1022:
20-03-22 23:49-INFO-training batch loss: 0.0098; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 171, Global step 1023:
20-03-22 23:49-INFO-training batch loss: 0.0023; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 172, Global step 1024:
20-03-22 23:49-INFO-training batch loss: 0.0034; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 173, Global step 1025:
20-03-22 23:49-INFO-training batch loss: 0.0024; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 174, Global step 1026:
20-03-22 23:49-INFO-training batch loss: 0.0037; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 175, Global step 1027:
20-03-22 23:49-INFO-training batch loss: 0.0045; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 176, Global step 1028:
20-03-22 23:49-INFO-training batch loss: 0.0106; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 177, Global step 1029:
20-03-22 23:49-INFO-training batch loss: 0.0013; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 178, Global step 1030:
20-03-22 23:49-INFO-training batch loss: 0.0034; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 179, Global step 1031:
20-03-22 23:49-INFO-training batch loss: 0.0033; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 180, Global step 1032:
20-03-22 23:49-INFO-training batch loss: 0.0045; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 181, Global step 1033:
20-03-22 23:49-INFO-training batch loss: 0.0087; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 0.9922; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 182, Global step 1034:
20-03-22 23:49-INFO-training batch loss: 0.0068; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 183, Global step 1035:
20-03-22 23:49-INFO-training batch loss: 0.0042; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 184, Global step 1036:
20-03-22 23:49-INFO-training batch loss: 0.0040; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 185, Global step 1037:
20-03-22 23:49-INFO-training batch loss: 0.0026; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 186, Global step 1038:
20-03-22 23:49-INFO-training batch loss: 0.0074; avg_loss: 0.0041
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 187, Global step 1039:
20-03-22 23:49-INFO-training batch loss: 0.0102; avg_loss: 0.0042
20-03-22 23:49-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 188, Global step 1040:
20-03-22 23:49-INFO-training batch loss: 0.0029; avg_loss: 0.0042
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 189, Global step 1041:
20-03-22 23:49-INFO-training batch loss: 0.0032; avg_loss: 0.0042
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 190, Global step 1042:
20-03-22 23:49-INFO-training batch loss: 0.0153; avg_loss: 0.0042
20-03-22 23:49-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-22 23:49-INFO-
20-03-22 23:49-INFO-Epoch 3, Batch 191, Global step 1043:
20-03-22 23:49-INFO-training batch loss: 0.0020; avg_loss: 0.0042
20-03-22 23:49-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:49-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 192, Global step 1044:
20-03-22 23:50-INFO-training batch loss: 0.0014; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 193, Global step 1045:
20-03-22 23:50-INFO-training batch loss: 0.0037; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 194, Global step 1046:
20-03-22 23:50-INFO-training batch loss: 0.0072; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 195, Global step 1047:
20-03-22 23:50-INFO-training batch loss: 0.0023; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 196, Global step 1048:
20-03-22 23:50-INFO-training batch loss: 0.0021; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 197, Global step 1049:
20-03-22 23:50-INFO-training batch loss: 0.0084; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 198, Global step 1050:
20-03-22 23:50-INFO-training batch loss: 0.0038; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 199, Global step 1051:
20-03-22 23:50-INFO-training batch loss: 0.0026; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 200, Global step 1052:
20-03-22 23:50-INFO-training batch loss: 0.0030; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 201, Global step 1053:
20-03-22 23:50-INFO-training batch loss: 0.0032; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 202, Global step 1054:
20-03-22 23:50-INFO-training batch loss: 0.0025; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 203, Global step 1055:
20-03-22 23:50-INFO-training batch loss: 0.0029; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 204, Global step 1056:
20-03-22 23:50-INFO-training batch loss: 0.0044; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 205, Global step 1057:
20-03-22 23:50-INFO-training batch loss: 0.0063; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 206, Global step 1058:
20-03-22 23:50-INFO-training batch loss: 0.0027; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 207, Global step 1059:
20-03-22 23:50-INFO-training batch loss: 0.0025; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 208, Global step 1060:
20-03-22 23:50-INFO-training batch loss: 0.0039; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 209, Global step 1061:
20-03-22 23:50-INFO-training batch loss: 0.0034; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 210, Global step 1062:
20-03-22 23:50-INFO-training batch loss: 0.0013; avg_loss: 0.0042
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 211, Global step 1063:
20-03-22 23:50-INFO-training batch loss: 0.0024; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 212, Global step 1064:
20-03-22 23:50-INFO-training batch loss: 0.0033; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 213, Global step 1065:
20-03-22 23:50-INFO-training batch loss: 0.0032; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 214, Global step 1066:
20-03-22 23:50-INFO-training batch loss: 0.0046; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 215, Global step 1067:
20-03-22 23:50-INFO-training batch loss: 0.0034; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 216, Global step 1068:
20-03-22 23:50-INFO-training batch loss: 0.0043; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 217, Global step 1069:
20-03-22 23:50-INFO-training batch loss: 0.0019; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:50-INFO-Epoch 3, Batch 218, Global step 1070:
20-03-22 23:50-INFO-training batch loss: 0.0035; avg_loss: 0.0041
20-03-22 23:50-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-22 23:50-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 219, Global step 1071:
20-03-22 23:51-INFO-training batch loss: 0.0045; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 220, Global step 1072:
20-03-22 23:51-INFO-training batch loss: 0.0016; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 221, Global step 1073:
20-03-22 23:51-INFO-training batch loss: 0.0016; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 222, Global step 1074:
20-03-22 23:51-INFO-training batch loss: 0.0033; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 223, Global step 1075:
20-03-22 23:51-INFO-training batch loss: 0.0018; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 224, Global step 1076:
20-03-22 23:51-INFO-training batch loss: 0.0053; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
20-03-22 23:51-INFO-Epoch 3, Batch 225, Global step 1077:
20-03-22 23:51-INFO-training batch loss: 0.0022; avg_loss: 0.0041
20-03-22 23:51-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-22 23:51-INFO-
