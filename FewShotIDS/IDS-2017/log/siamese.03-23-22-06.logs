20-03-23 22:06-INFO-{'session_length': 24, 'height': 32, 'width': 32, 'num_labels': 8, 'learning_rate': 0.005, 'filter_sizes': [3, 4, 5, 6], 'num_filters': 64, 'filter_sizes_hierarchical': [3, 4, 5], 'num_fitlers_hierarchical': 64, 'is_train': True, 'early_stop': False, 'is_tuning': False}
20-03-23 22:06-WARNING-From ../utils.py:129: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

20-03-23 22:06-WARNING-From ../model/train.py:105: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

20-03-23 22:06-WARNING-From ../model/siamese_network.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

20-03-23 22:06-WARNING-From ../model/siamese_network.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

20-03-23 22:06-WARNING-From ../model/siamese_network.py:69: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

20-03-23 22:06-WARNING-From ../model/utils/utils.py:26: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84d44cb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84d44cb90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-From ../model/utils/utils.py:45: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling1D instead.
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d44c290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d44c290>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84d44c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84d44c590>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d44cb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d44cb90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84d44ce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84d44ce90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d44c450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d44c450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84dd9aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84dd9aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84dd9aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84dd9aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-From ../model/utils/modules.py:205: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
20-03-23 22:06-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb84cc34190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb84cc34190>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84caff9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84caff9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cac42d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cac42d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cac46d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cac46d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb7e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb7e450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cac4f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cac4f50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cac4d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cac4d90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-From ../model/utils/modules.py:240: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
20-03-23 22:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84caff1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84caff1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-From ../model/utils/modules.py:242: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
20-03-23 22:06-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fb84d46b410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fb84d46b410>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-From ../model/utils/modules.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84ca78490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84ca78490>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84ca40b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84ca40b90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84caff390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84caff390>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb4d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb4d050>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cb47bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cb47bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb47890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb47890>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cb3ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cb3ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb3ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb3ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb84cac42d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb84cac42d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84c9a37d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84c9a37d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d455c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84d455c10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84c9edd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84c9edd90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb3ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb3ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cb7edd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fb84cb7edd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb814d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fb84cb814d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84c9a3510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84c9a3510>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fb84ca95150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fb84ca95150>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84c98aa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84c98aa10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84c9a3090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb84c9a3090>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 22:06-WARNING-From ../model/base_model.py:132: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

20-03-23 22:06-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20-03-23 22:06-WARNING-From ../model/train.py:113: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

20-03-23 22:06-INFO-Epoch 0, Batch 1, Global step 1:
20-03-23 22:06-INFO-training batch loss: 3.3458; avg_loss: 3.3458
20-03-23 22:06-INFO-training batch acc: 0.4844; avg_acc: 0.4844
20-03-23 22:06-INFO-
20-03-23 22:06-INFO-Epoch 0, Batch 2, Global step 2:
20-03-23 22:06-INFO-training batch loss: 3.5869; avg_loss: 3.4664
20-03-23 22:06-INFO-training batch acc: 0.5664; avg_acc: 0.5254
20-03-23 22:06-INFO-
20-03-23 22:06-INFO-Epoch 0, Batch 3, Global step 3:
20-03-23 22:06-INFO-training batch loss: 11.7201; avg_loss: 6.2176
20-03-23 22:06-INFO-training batch acc: 0.3867; avg_acc: 0.4792
20-03-23 22:06-INFO-
20-03-23 22:06-INFO-Epoch 0, Batch 4, Global step 4:
20-03-23 22:06-INFO-training batch loss: 4.1279; avg_loss: 5.6952
20-03-23 22:06-INFO-training batch acc: 0.4141; avg_acc: 0.4629
20-03-23 22:06-INFO-
20-03-23 22:06-INFO-Epoch 0, Batch 5, Global step 5:
20-03-23 22:06-INFO-training batch loss: 2.6860; avg_loss: 5.0933
20-03-23 22:06-INFO-training batch acc: 0.6094; avg_acc: 0.4922
20-03-23 22:06-INFO-
20-03-23 22:06-INFO-Epoch 0, Batch 6, Global step 6:
20-03-23 22:06-INFO-training batch loss: 1.3890; avg_loss: 4.4760
20-03-23 22:06-INFO-training batch acc: 0.6445; avg_acc: 0.5176
20-03-23 22:06-INFO-
20-03-23 22:06-INFO-Epoch 0, Batch 7, Global step 7:
20-03-23 22:06-INFO-training batch loss: 1.1660; avg_loss: 4.0031
20-03-23 22:06-INFO-training batch acc: 0.5312; avg_acc: 0.5195
20-03-23 22:06-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 8, Global step 8:
20-03-23 22:07-INFO-training batch loss: 0.9175; avg_loss: 3.6174
20-03-23 22:07-INFO-training batch acc: 0.5508; avg_acc: 0.5234
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 9, Global step 9:
20-03-23 22:07-INFO-training batch loss: 0.8020; avg_loss: 3.3046
20-03-23 22:07-INFO-training batch acc: 0.5703; avg_acc: 0.5286
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 10, Global step 10:
20-03-23 22:07-INFO-training batch loss: 0.7316; avg_loss: 3.0473
20-03-23 22:07-INFO-training batch acc: 0.5508; avg_acc: 0.5309
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 11, Global step 11:
20-03-23 22:07-INFO-training batch loss: 0.7227; avg_loss: 2.8360
20-03-23 22:07-INFO-training batch acc: 0.5938; avg_acc: 0.5366
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 12, Global step 12:
20-03-23 22:07-INFO-training batch loss: 0.7436; avg_loss: 2.6616
20-03-23 22:07-INFO-training batch acc: 0.5625; avg_acc: 0.5387
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 13, Global step 13:
20-03-23 22:07-INFO-training batch loss: 0.6891; avg_loss: 2.5099
20-03-23 22:07-INFO-training batch acc: 0.6211; avg_acc: 0.5451
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 14, Global step 14:
20-03-23 22:07-INFO-training batch loss: 0.6679; avg_loss: 2.3783
20-03-23 22:07-INFO-training batch acc: 0.5898; avg_acc: 0.5483
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 15, Global step 15:
20-03-23 22:07-INFO-training batch loss: 0.7049; avg_loss: 2.2667
20-03-23 22:07-INFO-training batch acc: 0.5469; avg_acc: 0.5482
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 16, Global step 16:
20-03-23 22:07-INFO-training batch loss: 0.6824; avg_loss: 2.1677
20-03-23 22:07-INFO-training batch acc: 0.6016; avg_acc: 0.5515
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 17, Global step 17:
20-03-23 22:07-INFO-training batch loss: 0.6871; avg_loss: 2.0806
20-03-23 22:07-INFO-training batch acc: 0.5938; avg_acc: 0.5540
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 18, Global step 18:
20-03-23 22:07-INFO-training batch loss: 0.7076; avg_loss: 2.0043
20-03-23 22:07-INFO-training batch acc: 0.5273; avg_acc: 0.5525
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 19, Global step 19:
20-03-23 22:07-INFO-training batch loss: 0.6651; avg_loss: 1.9339
20-03-23 22:07-INFO-training batch acc: 0.5977; avg_acc: 0.5549
20-03-23 22:07-INFO-
20-03-23 22:07-INFO-Epoch 0, Batch 20, Global step 20:
20-03-23 22:07-INFO-training batch loss: 0.7008; avg_loss: 1.8722
20-03-23 22:07-INFO-training batch acc: 0.5430; avg_acc: 0.5543
20-03-23 22:07-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 21, Global step 21:
20-03-23 22:08-INFO-training batch loss: 0.6853; avg_loss: 1.8157
20-03-23 22:08-INFO-training batch acc: 0.5859; avg_acc: 0.5558
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 22, Global step 22:
20-03-23 22:08-INFO-training batch loss: 0.6897; avg_loss: 1.7645
20-03-23 22:08-INFO-training batch acc: 0.5742; avg_acc: 0.5566
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 23, Global step 23:
20-03-23 22:08-INFO-training batch loss: 0.6764; avg_loss: 1.7172
20-03-23 22:08-INFO-training batch acc: 0.5625; avg_acc: 0.5569
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 24, Global step 24:
20-03-23 22:08-INFO-training batch loss: 0.6596; avg_loss: 1.6731
20-03-23 22:08-INFO-training batch acc: 0.6016; avg_acc: 0.5588
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 25, Global step 25:
20-03-23 22:08-INFO-training batch loss: 0.6485; avg_loss: 1.6321
20-03-23 22:08-INFO-training batch acc: 0.6094; avg_acc: 0.5608
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 26, Global step 26:
20-03-23 22:08-INFO-training batch loss: 0.6781; avg_loss: 1.5954
20-03-23 22:08-INFO-training batch acc: 0.5859; avg_acc: 0.5617
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 27, Global step 27:
20-03-23 22:08-INFO-training batch loss: 0.6732; avg_loss: 1.5613
20-03-23 22:08-INFO-training batch acc: 0.6016; avg_acc: 0.5632
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 28, Global step 28:
20-03-23 22:08-INFO-training batch loss: 0.6506; avg_loss: 1.5288
20-03-23 22:08-INFO-training batch acc: 0.5742; avg_acc: 0.5636
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 29, Global step 29:
20-03-23 22:08-INFO-training batch loss: 0.6529; avg_loss: 1.4986
20-03-23 22:08-INFO-training batch acc: 0.5898; avg_acc: 0.5645
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 30, Global step 30:
20-03-23 22:08-INFO-training batch loss: 0.6584; avg_loss: 1.4706
20-03-23 22:08-INFO-training batch acc: 0.5938; avg_acc: 0.5655
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 31, Global step 31:
20-03-23 22:08-INFO-training batch loss: 0.7159; avg_loss: 1.4462
20-03-23 22:08-INFO-training batch acc: 0.5547; avg_acc: 0.5651
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 32, Global step 32:
20-03-23 22:08-INFO-training batch loss: 0.6822; avg_loss: 1.4223
20-03-23 22:08-INFO-training batch acc: 0.5781; avg_acc: 0.5656
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 33, Global step 33:
20-03-23 22:08-INFO-training batch loss: 0.6584; avg_loss: 1.3992
20-03-23 22:08-INFO-training batch acc: 0.5898; avg_acc: 0.5663
20-03-23 22:08-INFO-
20-03-23 22:08-INFO-Epoch 0, Batch 34, Global step 34:
20-03-23 22:08-INFO-training batch loss: 0.6742; avg_loss: 1.3779
20-03-23 22:08-INFO-training batch acc: 0.6055; avg_acc: 0.5674
20-03-23 22:08-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 35, Global step 35:
20-03-23 22:09-INFO-training batch loss: 0.6409; avg_loss: 1.3568
20-03-23 22:09-INFO-training batch acc: 0.6484; avg_acc: 0.5698
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 36, Global step 36:
20-03-23 22:09-INFO-training batch loss: 0.6640; avg_loss: 1.3376
20-03-23 22:09-INFO-training batch acc: 0.5898; avg_acc: 0.5703
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 37, Global step 37:
20-03-23 22:09-INFO-training batch loss: 0.6886; avg_loss: 1.3200
20-03-23 22:09-INFO-training batch acc: 0.5742; avg_acc: 0.5704
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 38, Global step 38:
20-03-23 22:09-INFO-training batch loss: 0.6623; avg_loss: 1.3027
20-03-23 22:09-INFO-training batch acc: 0.6133; avg_acc: 0.5715
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 39, Global step 39:
20-03-23 22:09-INFO-training batch loss: 0.6676; avg_loss: 1.2864
20-03-23 22:09-INFO-training batch acc: 0.5859; avg_acc: 0.5719
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 40, Global step 40:
20-03-23 22:09-INFO-training batch loss: 0.6593; avg_loss: 1.2708
20-03-23 22:09-INFO-training batch acc: 0.6016; avg_acc: 0.5727
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 41, Global step 41:
20-03-23 22:09-INFO-training batch loss: 0.6511; avg_loss: 1.2556
20-03-23 22:09-INFO-training batch acc: 0.6562; avg_acc: 0.5747
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 42, Global step 42:
20-03-23 22:09-INFO-training batch loss: 0.6656; avg_loss: 1.2416
20-03-23 22:09-INFO-training batch acc: 0.5781; avg_acc: 0.5748
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 43, Global step 43:
20-03-23 22:09-INFO-training batch loss: 0.6689; avg_loss: 1.2283
20-03-23 22:09-INFO-training batch acc: 0.5820; avg_acc: 0.5749
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 44, Global step 44:
20-03-23 22:09-INFO-training batch loss: 0.6537; avg_loss: 1.2152
20-03-23 22:09-INFO-training batch acc: 0.5859; avg_acc: 0.5752
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 45, Global step 45:
20-03-23 22:09-INFO-training batch loss: 0.6670; avg_loss: 1.2030
20-03-23 22:09-INFO-training batch acc: 0.6172; avg_acc: 0.5761
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 46, Global step 46:
20-03-23 22:09-INFO-training batch loss: 0.6364; avg_loss: 1.1907
20-03-23 22:09-INFO-training batch acc: 0.6367; avg_acc: 0.5774
20-03-23 22:09-INFO-
20-03-23 22:09-INFO-Epoch 0, Batch 47, Global step 47:
20-03-23 22:09-INFO-training batch loss: 0.6558; avg_loss: 1.1793
20-03-23 22:09-INFO-training batch acc: 0.6250; avg_acc: 0.5785
20-03-23 22:09-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 48, Global step 48:
20-03-23 22:10-INFO-training batch loss: 0.6498; avg_loss: 1.1683
20-03-23 22:10-INFO-training batch acc: 0.6367; avg_acc: 0.5797
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 49, Global step 49:
20-03-23 22:10-INFO-training batch loss: 0.6605; avg_loss: 1.1579
20-03-23 22:10-INFO-training batch acc: 0.6172; avg_acc: 0.5804
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 50, Global step 50:
20-03-23 22:10-INFO-training batch loss: 0.6722; avg_loss: 1.1482
20-03-23 22:10-INFO-training batch acc: 0.6211; avg_acc: 0.5813
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 51, Global step 51:
20-03-23 22:10-INFO-training batch loss: 0.6674; avg_loss: 1.1388
20-03-23 22:10-INFO-training batch acc: 0.6094; avg_acc: 0.5818
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 52, Global step 52:
20-03-23 22:10-INFO-training batch loss: 0.6366; avg_loss: 1.1291
20-03-23 22:10-INFO-training batch acc: 0.6523; avg_acc: 0.5832
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 53, Global step 53:
20-03-23 22:10-INFO-training batch loss: 0.6469; avg_loss: 1.1200
20-03-23 22:10-INFO-training batch acc: 0.6094; avg_acc: 0.5837
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 54, Global step 54:
20-03-23 22:10-INFO-training batch loss: 0.6527; avg_loss: 1.1114
20-03-23 22:10-INFO-training batch acc: 0.6406; avg_acc: 0.5847
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 55, Global step 55:
20-03-23 22:10-INFO-training batch loss: 0.6406; avg_loss: 1.1028
20-03-23 22:10-INFO-training batch acc: 0.6445; avg_acc: 0.5858
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 56, Global step 56:
20-03-23 22:10-INFO-training batch loss: 0.6389; avg_loss: 1.0945
20-03-23 22:10-INFO-training batch acc: 0.6641; avg_acc: 0.5872
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 57, Global step 57:
20-03-23 22:10-INFO-training batch loss: 0.6499; avg_loss: 1.0867
20-03-23 22:10-INFO-training batch acc: 0.6406; avg_acc: 0.5881
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 58, Global step 58:
20-03-23 22:10-INFO-training batch loss: 0.6237; avg_loss: 1.0788
20-03-23 22:10-INFO-training batch acc: 0.6406; avg_acc: 0.5890
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 59, Global step 59:
20-03-23 22:10-INFO-training batch loss: 0.6240; avg_loss: 1.0711
20-03-23 22:10-INFO-training batch acc: 0.6445; avg_acc: 0.5900
20-03-23 22:10-INFO-
20-03-23 22:10-INFO-Epoch 0, Batch 60, Global step 60:
20-03-23 22:10-INFO-training batch loss: 0.6134; avg_loss: 1.0634
20-03-23 22:10-INFO-training batch acc: 0.6602; avg_acc: 0.5911
20-03-23 22:10-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 61, Global step 61:
20-03-23 22:11-INFO-training batch loss: 0.6212; avg_loss: 1.0562
20-03-23 22:11-INFO-training batch acc: 0.6797; avg_acc: 0.5926
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 62, Global step 62:
20-03-23 22:11-INFO-training batch loss: 0.5911; avg_loss: 1.0487
20-03-23 22:11-INFO-training batch acc: 0.6641; avg_acc: 0.5938
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 63, Global step 63:
20-03-23 22:11-INFO-training batch loss: 0.5866; avg_loss: 1.0413
20-03-23 22:11-INFO-training batch acc: 0.6680; avg_acc: 0.5949
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 64, Global step 64:
20-03-23 22:11-INFO-training batch loss: 0.5219; avg_loss: 1.0332
20-03-23 22:11-INFO-training batch acc: 0.7422; avg_acc: 0.5972
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 65, Global step 65:
20-03-23 22:11-INFO-training batch loss: 0.5495; avg_loss: 1.0258
20-03-23 22:11-INFO-training batch acc: 0.6836; avg_acc: 0.5986
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 66, Global step 66:
20-03-23 22:11-INFO-training batch loss: 0.5536; avg_loss: 1.0186
20-03-23 22:11-INFO-training batch acc: 0.6641; avg_acc: 0.5996
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 67, Global step 67:
20-03-23 22:11-INFO-training batch loss: 0.5193; avg_loss: 1.0112
20-03-23 22:11-INFO-training batch acc: 0.7070; avg_acc: 0.6012
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 68, Global step 68:
20-03-23 22:11-INFO-training batch loss: 0.5319; avg_loss: 1.0041
20-03-23 22:11-INFO-training batch acc: 0.6719; avg_acc: 0.6022
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 69, Global step 69:
20-03-23 22:11-INFO-training batch loss: 0.4911; avg_loss: 0.9967
20-03-23 22:11-INFO-training batch acc: 0.7266; avg_acc: 0.6040
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 70, Global step 70:
20-03-23 22:11-INFO-training batch loss: 0.4730; avg_loss: 0.9892
20-03-23 22:11-INFO-training batch acc: 0.7656; avg_acc: 0.6063
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 71, Global step 71:
20-03-23 22:11-INFO-training batch loss: 0.4372; avg_loss: 0.9814
20-03-23 22:11-INFO-training batch acc: 0.7930; avg_acc: 0.6089
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 72, Global step 72:
20-03-23 22:11-INFO-training batch loss: 0.4913; avg_loss: 0.9746
20-03-23 22:11-INFO-training batch acc: 0.7344; avg_acc: 0.6107
20-03-23 22:11-INFO-
20-03-23 22:11-INFO-Epoch 0, Batch 73, Global step 73:
20-03-23 22:11-INFO-training batch loss: 0.4294; avg_loss: 0.9672
20-03-23 22:11-INFO-training batch acc: 0.7812; avg_acc: 0.6130
20-03-23 22:11-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 74, Global step 74:
20-03-23 22:12-INFO-training batch loss: 0.4265; avg_loss: 0.9599
20-03-23 22:12-INFO-training batch acc: 0.8164; avg_acc: 0.6158
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 75, Global step 75:
20-03-23 22:12-INFO-training batch loss: 0.3489; avg_loss: 0.9517
20-03-23 22:12-INFO-training batch acc: 0.8555; avg_acc: 0.6190
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 76, Global step 76:
20-03-23 22:12-INFO-training batch loss: 0.3495; avg_loss: 0.9438
20-03-23 22:12-INFO-training batch acc: 0.8633; avg_acc: 0.6222
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 77, Global step 77:
20-03-23 22:12-INFO-training batch loss: 0.3900; avg_loss: 0.9366
20-03-23 22:12-INFO-training batch acc: 0.8359; avg_acc: 0.6249
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 78, Global step 78:
20-03-23 22:12-INFO-training batch loss: 0.4316; avg_loss: 0.9301
20-03-23 22:12-INFO-training batch acc: 0.8477; avg_acc: 0.6278
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 79, Global step 79:
20-03-23 22:12-INFO-training batch loss: 0.3292; avg_loss: 0.9225
20-03-23 22:12-INFO-training batch acc: 0.8477; avg_acc: 0.6306
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 80, Global step 80:
20-03-23 22:12-INFO-training batch loss: 0.2932; avg_loss: 0.9146
20-03-23 22:12-INFO-training batch acc: 0.8867; avg_acc: 0.6338
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 81, Global step 81:
20-03-23 22:12-INFO-training batch loss: 0.3744; avg_loss: 0.9080
20-03-23 22:12-INFO-training batch acc: 0.8242; avg_acc: 0.6361
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 82, Global step 82:
20-03-23 22:12-INFO-training batch loss: 0.3459; avg_loss: 0.9011
20-03-23 22:12-INFO-training batch acc: 0.8438; avg_acc: 0.6387
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 83, Global step 83:
20-03-23 22:12-INFO-training batch loss: 0.3311; avg_loss: 0.8943
20-03-23 22:12-INFO-training batch acc: 0.8555; avg_acc: 0.6413
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 84, Global step 84:
20-03-23 22:12-INFO-training batch loss: 0.3183; avg_loss: 0.8874
20-03-23 22:12-INFO-training batch acc: 0.8711; avg_acc: 0.6440
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 85, Global step 85:
20-03-23 22:12-INFO-training batch loss: 0.3059; avg_loss: 0.8806
20-03-23 22:12-INFO-training batch acc: 0.8867; avg_acc: 0.6469
20-03-23 22:12-INFO-
20-03-23 22:12-INFO-Epoch 0, Batch 86, Global step 86:
20-03-23 22:12-INFO-training batch loss: 0.3760; avg_loss: 0.8747
20-03-23 22:12-INFO-training batch acc: 0.8398; avg_acc: 0.6491
20-03-23 22:12-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 87, Global step 87:
20-03-23 22:13-INFO-training batch loss: 0.2790; avg_loss: 0.8678
20-03-23 22:13-INFO-training batch acc: 0.8789; avg_acc: 0.6518
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 88, Global step 88:
20-03-23 22:13-INFO-training batch loss: 0.2618; avg_loss: 0.8610
20-03-23 22:13-INFO-training batch acc: 0.8828; avg_acc: 0.6544
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 89, Global step 89:
20-03-23 22:13-INFO-training batch loss: 0.2492; avg_loss: 0.8541
20-03-23 22:13-INFO-training batch acc: 0.9180; avg_acc: 0.6573
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 90, Global step 90:
20-03-23 22:13-INFO-training batch loss: 0.2879; avg_loss: 0.8478
20-03-23 22:13-INFO-training batch acc: 0.8672; avg_acc: 0.6597
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 91, Global step 91:
20-03-23 22:13-INFO-training batch loss: 0.2147; avg_loss: 0.8408
20-03-23 22:13-INFO-training batch acc: 0.9023; avg_acc: 0.6623
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 92, Global step 92:
20-03-23 22:13-INFO-training batch loss: 0.2703; avg_loss: 0.8346
20-03-23 22:13-INFO-training batch acc: 0.8867; avg_acc: 0.6648
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 93, Global step 93:
20-03-23 22:13-INFO-training batch loss: 0.1530; avg_loss: 0.8273
20-03-23 22:13-INFO-training batch acc: 0.9336; avg_acc: 0.6677
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 94, Global step 94:
20-03-23 22:13-INFO-training batch loss: 0.1755; avg_loss: 0.8204
20-03-23 22:13-INFO-training batch acc: 0.9375; avg_acc: 0.6705
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 95, Global step 95:
20-03-23 22:13-INFO-training batch loss: 0.2316; avg_loss: 0.8142
20-03-23 22:13-INFO-training batch acc: 0.9219; avg_acc: 0.6732
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 96, Global step 96:
20-03-23 22:13-INFO-training batch loss: 0.2172; avg_loss: 0.8080
20-03-23 22:13-INFO-training batch acc: 0.9180; avg_acc: 0.6757
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 97, Global step 97:
20-03-23 22:13-INFO-training batch loss: 0.2863; avg_loss: 0.8026
20-03-23 22:13-INFO-training batch acc: 0.9023; avg_acc: 0.6781
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 98, Global step 98:
20-03-23 22:13-INFO-training batch loss: 0.1468; avg_loss: 0.7959
20-03-23 22:13-INFO-training batch acc: 0.9609; avg_acc: 0.6810
20-03-23 22:13-INFO-
20-03-23 22:13-INFO-Epoch 0, Batch 99, Global step 99:
20-03-23 22:13-INFO-training batch loss: 0.1980; avg_loss: 0.7898
20-03-23 22:13-INFO-training batch acc: 0.9219; avg_acc: 0.6834
20-03-23 22:13-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 100, Global step 100:
20-03-23 22:14-INFO-training batch loss: 0.1659; avg_loss: 0.7836
20-03-23 22:14-INFO-training batch acc: 0.9453; avg_acc: 0.6860
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 101, Global step 101:
20-03-23 22:14-INFO-training batch loss: 0.1398; avg_loss: 0.7772
20-03-23 22:14-INFO-training batch acc: 0.9531; avg_acc: 0.6887
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 102, Global step 102:
20-03-23 22:14-INFO-training batch loss: 0.2154; avg_loss: 0.7717
20-03-23 22:14-INFO-training batch acc: 0.9258; avg_acc: 0.6910
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 103, Global step 103:
20-03-23 22:14-INFO-training batch loss: 0.1695; avg_loss: 0.7659
20-03-23 22:14-INFO-training batch acc: 0.9531; avg_acc: 0.6935
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 104, Global step 104:
20-03-23 22:14-INFO-training batch loss: 0.1363; avg_loss: 0.7598
20-03-23 22:14-INFO-training batch acc: 0.9453; avg_acc: 0.6960
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 105, Global step 105:
20-03-23 22:14-INFO-training batch loss: 0.1284; avg_loss: 0.7538
20-03-23 22:14-INFO-training batch acc: 0.9688; avg_acc: 0.6985
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 106, Global step 106:
20-03-23 22:14-INFO-training batch loss: 0.1493; avg_loss: 0.7481
20-03-23 22:14-INFO-training batch acc: 0.9531; avg_acc: 0.7010
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 107, Global step 107:
20-03-23 22:14-INFO-training batch loss: 0.0774; avg_loss: 0.7418
20-03-23 22:14-INFO-training batch acc: 0.9805; avg_acc: 0.7036
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 108, Global step 108:
20-03-23 22:14-INFO-training batch loss: 0.1373; avg_loss: 0.7362
20-03-23 22:14-INFO-training batch acc: 0.9570; avg_acc: 0.7059
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 109, Global step 109:
20-03-23 22:14-INFO-training batch loss: 0.1229; avg_loss: 0.7306
20-03-23 22:14-INFO-training batch acc: 0.9648; avg_acc: 0.7083
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 110, Global step 110:
20-03-23 22:14-INFO-training batch loss: 0.1073; avg_loss: 0.7249
20-03-23 22:14-INFO-training batch acc: 0.9688; avg_acc: 0.7107
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 111, Global step 111:
20-03-23 22:14-INFO-training batch loss: 0.1197; avg_loss: 0.7195
20-03-23 22:14-INFO-training batch acc: 0.9492; avg_acc: 0.7128
20-03-23 22:14-INFO-
20-03-23 22:14-INFO-Epoch 0, Batch 112, Global step 112:
20-03-23 22:14-INFO-training batch loss: 0.1042; avg_loss: 0.7140
20-03-23 22:14-INFO-training batch acc: 0.9727; avg_acc: 0.7151
20-03-23 22:14-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 113, Global step 113:
20-03-23 22:15-INFO-training batch loss: 0.0979; avg_loss: 0.7085
20-03-23 22:15-INFO-training batch acc: 0.9531; avg_acc: 0.7172
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 114, Global step 114:
20-03-23 22:15-INFO-training batch loss: 0.0846; avg_loss: 0.7031
20-03-23 22:15-INFO-training batch acc: 0.9766; avg_acc: 0.7195
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 115, Global step 115:
20-03-23 22:15-INFO-training batch loss: 0.0830; avg_loss: 0.6977
20-03-23 22:15-INFO-training batch acc: 0.9766; avg_acc: 0.7217
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 116, Global step 116:
20-03-23 22:15-INFO-training batch loss: 0.1355; avg_loss: 0.6928
20-03-23 22:15-INFO-training batch acc: 0.9453; avg_acc: 0.7237
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 117, Global step 117:
20-03-23 22:15-INFO-training batch loss: 0.0496; avg_loss: 0.6873
20-03-23 22:15-INFO-training batch acc: 0.9922; avg_acc: 0.7260
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 118, Global step 118:
20-03-23 22:15-INFO-training batch loss: 0.0782; avg_loss: 0.6822
20-03-23 22:15-INFO-training batch acc: 0.9727; avg_acc: 0.7281
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 119, Global step 119:
20-03-23 22:15-INFO-training batch loss: 0.0843; avg_loss: 0.6771
20-03-23 22:15-INFO-training batch acc: 0.9727; avg_acc: 0.7301
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 120, Global step 120:
20-03-23 22:15-INFO-training batch loss: 0.1192; avg_loss: 0.6725
20-03-23 22:15-INFO-training batch acc: 0.9688; avg_acc: 0.7321
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 121, Global step 121:
20-03-23 22:15-INFO-training batch loss: 0.1106; avg_loss: 0.6679
20-03-23 22:15-INFO-training batch acc: 0.9648; avg_acc: 0.7340
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 122, Global step 122:
20-03-23 22:15-INFO-training batch loss: 0.0728; avg_loss: 0.6630
20-03-23 22:15-INFO-training batch acc: 0.9727; avg_acc: 0.7360
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 123, Global step 123:
20-03-23 22:15-INFO-training batch loss: 0.0619; avg_loss: 0.6581
20-03-23 22:15-INFO-training batch acc: 0.9805; avg_acc: 0.7380
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 124, Global step 124:
20-03-23 22:15-INFO-training batch loss: 0.1039; avg_loss: 0.6536
20-03-23 22:15-INFO-training batch acc: 0.9570; avg_acc: 0.7397
20-03-23 22:15-INFO-
20-03-23 22:15-INFO-Epoch 0, Batch 125, Global step 125:
20-03-23 22:15-INFO-training batch loss: 0.0750; avg_loss: 0.6490
20-03-23 22:15-INFO-training batch acc: 0.9805; avg_acc: 0.7417
20-03-23 22:15-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 126, Global step 126:
20-03-23 22:16-INFO-training batch loss: 0.1058; avg_loss: 0.6447
20-03-23 22:16-INFO-training batch acc: 0.9648; avg_acc: 0.7434
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 127, Global step 127:
20-03-23 22:16-INFO-training batch loss: 0.0508; avg_loss: 0.6400
20-03-23 22:16-INFO-training batch acc: 0.9805; avg_acc: 0.7453
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 128, Global step 128:
20-03-23 22:16-INFO-training batch loss: 0.0631; avg_loss: 0.6355
20-03-23 22:16-INFO-training batch acc: 0.9844; avg_acc: 0.7472
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 129, Global step 129:
20-03-23 22:16-INFO-training batch loss: 0.0841; avg_loss: 0.6312
20-03-23 22:16-INFO-training batch acc: 0.9727; avg_acc: 0.7489
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 130, Global step 130:
20-03-23 22:16-INFO-training batch loss: 0.0941; avg_loss: 0.6271
20-03-23 22:16-INFO-training batch acc: 0.9531; avg_acc: 0.7505
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 131, Global step 131:
20-03-23 22:16-INFO-training batch loss: 0.0935; avg_loss: 0.6230
20-03-23 22:16-INFO-training batch acc: 0.9805; avg_acc: 0.7522
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 132, Global step 132:
20-03-23 22:16-INFO-training batch loss: 0.0965; avg_loss: 0.6190
20-03-23 22:16-INFO-training batch acc: 0.9648; avg_acc: 0.7538
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 133, Global step 133:
20-03-23 22:16-INFO-training batch loss: 0.0541; avg_loss: 0.6148
20-03-23 22:16-INFO-training batch acc: 0.9805; avg_acc: 0.7556
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 134, Global step 134:
20-03-23 22:16-INFO-training batch loss: 0.0645; avg_loss: 0.6107
20-03-23 22:16-INFO-training batch acc: 0.9727; avg_acc: 0.7572
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 135, Global step 135:
20-03-23 22:16-INFO-training batch loss: 0.0449; avg_loss: 0.6065
20-03-23 22:16-INFO-training batch acc: 0.9883; avg_acc: 0.7589
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 136, Global step 136:
20-03-23 22:16-INFO-training batch loss: 0.1129; avg_loss: 0.6029
20-03-23 22:16-INFO-training batch acc: 0.9570; avg_acc: 0.7603
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 137, Global step 137:
20-03-23 22:16-INFO-training batch loss: 0.0668; avg_loss: 0.5989
20-03-23 22:16-INFO-training batch acc: 0.9688; avg_acc: 0.7619
20-03-23 22:16-INFO-
20-03-23 22:16-INFO-Epoch 0, Batch 138, Global step 138:
20-03-23 22:16-INFO-training batch loss: 0.0890; avg_loss: 0.5952
20-03-23 22:16-INFO-training batch acc: 0.9805; avg_acc: 0.7634
20-03-23 22:16-INFO-
20-03-23 22:17-INFO-Epoch 0, Batch 139, Global step 139:
20-03-23 22:17-INFO-training batch loss: 0.1195; avg_loss: 0.5918
20-03-23 22:17-INFO-training batch acc: 0.9648; avg_acc: 0.7649
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 0, Batch 140, Global step 140:
20-03-23 22:17-INFO-training batch loss: 0.0557; avg_loss: 0.5880
20-03-23 22:17-INFO-training batch acc: 0.9883; avg_acc: 0.7665
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 0, Batch 141, Global step 141:
20-03-23 22:17-INFO-training batch loss: 0.0626; avg_loss: 0.5843
20-03-23 22:17-INFO-training batch acc: 0.9805; avg_acc: 0.7680
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 0, Batch 142, Global step 142:
20-03-23 22:17-INFO-training batch loss: 0.0481; avg_loss: 0.5805
20-03-23 22:17-INFO-training batch acc: 0.9946; avg_acc: 0.7696
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 0, training batch loss: 0.0481; avg_loss: 0.5805
20-03-23 22:17-INFO-Epoch 0, training batch accuracy: 0.9946; avg_accuracy: 0.7696
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 0, evaluating batch loss: 0.8133; avg_loss: 0.3801
20-03-23 22:17-INFO-Epoch 0, evaluating batch accuracy: 0.8182; avg_accuracy: 0.9029
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 1, Global step 143:
20-03-23 22:17-INFO-training batch loss: 0.0792; avg_loss: 0.0792
20-03-23 22:17-INFO-training batch acc: 0.9609; avg_acc: 0.9609
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 2, Global step 144:
20-03-23 22:17-INFO-training batch loss: 0.0770; avg_loss: 0.0781
20-03-23 22:17-INFO-training batch acc: 0.9648; avg_acc: 0.9629
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 3, Global step 145:
20-03-23 22:17-INFO-training batch loss: 0.0506; avg_loss: 0.0689
20-03-23 22:17-INFO-training batch acc: 0.9766; avg_acc: 0.9674
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 4, Global step 146:
20-03-23 22:17-INFO-training batch loss: 0.0760; avg_loss: 0.0707
20-03-23 22:17-INFO-training batch acc: 0.9648; avg_acc: 0.9668
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 5, Global step 147:
20-03-23 22:17-INFO-training batch loss: 0.0534; avg_loss: 0.0672
20-03-23 22:17-INFO-training batch acc: 0.9805; avg_acc: 0.9695
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 6, Global step 148:
20-03-23 22:17-INFO-training batch loss: 0.0610; avg_loss: 0.0662
20-03-23 22:17-INFO-training batch acc: 0.9805; avg_acc: 0.9714
20-03-23 22:17-INFO-
20-03-23 22:17-INFO-Epoch 1, Batch 7, Global step 149:
20-03-23 22:17-INFO-training batch loss: 0.0306; avg_loss: 0.0611
20-03-23 22:17-INFO-training batch acc: 0.9961; avg_acc: 0.9749
20-03-23 22:17-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 8, Global step 150:
20-03-23 22:18-INFO-training batch loss: 0.0620; avg_loss: 0.0612
20-03-23 22:18-INFO-training batch acc: 0.9727; avg_acc: 0.9746
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 9, Global step 151:
20-03-23 22:18-INFO-training batch loss: 0.0528; avg_loss: 0.0603
20-03-23 22:18-INFO-training batch acc: 0.9766; avg_acc: 0.9748
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 10, Global step 152:
20-03-23 22:18-INFO-training batch loss: 0.0845; avg_loss: 0.0627
20-03-23 22:18-INFO-training batch acc: 0.9727; avg_acc: 0.9746
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 11, Global step 153:
20-03-23 22:18-INFO-training batch loss: 0.0442; avg_loss: 0.0610
20-03-23 22:18-INFO-training batch acc: 0.9922; avg_acc: 0.9762
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 12, Global step 154:
20-03-23 22:18-INFO-training batch loss: 0.0610; avg_loss: 0.0610
20-03-23 22:18-INFO-training batch acc: 0.9688; avg_acc: 0.9756
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 13, Global step 155:
20-03-23 22:18-INFO-training batch loss: 0.0497; avg_loss: 0.0602
20-03-23 22:18-INFO-training batch acc: 0.9805; avg_acc: 0.9760
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 14, Global step 156:
20-03-23 22:18-INFO-training batch loss: 0.0270; avg_loss: 0.0578
20-03-23 22:18-INFO-training batch acc: 0.9922; avg_acc: 0.9771
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 15, Global step 157:
20-03-23 22:18-INFO-training batch loss: 0.0456; avg_loss: 0.0570
20-03-23 22:18-INFO-training batch acc: 0.9883; avg_acc: 0.9779
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 16, Global step 158:
20-03-23 22:18-INFO-training batch loss: 0.0314; avg_loss: 0.0554
20-03-23 22:18-INFO-training batch acc: 0.9805; avg_acc: 0.9780
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 17, Global step 159:
20-03-23 22:18-INFO-training batch loss: 0.0212; avg_loss: 0.0534
20-03-23 22:18-INFO-training batch acc: 0.9961; avg_acc: 0.9791
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 18, Global step 160:
20-03-23 22:18-INFO-training batch loss: 0.0460; avg_loss: 0.0530
20-03-23 22:18-INFO-training batch acc: 0.9844; avg_acc: 0.9794
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 19, Global step 161:
20-03-23 22:18-INFO-training batch loss: 0.0402; avg_loss: 0.0523
20-03-23 22:18-INFO-training batch acc: 0.9844; avg_acc: 0.9796
20-03-23 22:18-INFO-
20-03-23 22:18-INFO-Epoch 1, Batch 20, Global step 162:
20-03-23 22:18-INFO-training batch loss: 0.0363; avg_loss: 0.0515
20-03-23 22:18-INFO-training batch acc: 0.9922; avg_acc: 0.9803
20-03-23 22:18-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 21, Global step 163:
20-03-23 22:19-INFO-training batch loss: 0.0701; avg_loss: 0.0524
20-03-23 22:19-INFO-training batch acc: 0.9688; avg_acc: 0.9797
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 22, Global step 164:
20-03-23 22:19-INFO-training batch loss: 0.0421; avg_loss: 0.0519
20-03-23 22:19-INFO-training batch acc: 0.9844; avg_acc: 0.9799
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 23, Global step 165:
20-03-23 22:19-INFO-training batch loss: 0.0217; avg_loss: 0.0506
20-03-23 22:19-INFO-training batch acc: 0.9961; avg_acc: 0.9806
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 24, Global step 166:
20-03-23 22:19-INFO-training batch loss: 0.0445; avg_loss: 0.0503
20-03-23 22:19-INFO-training batch acc: 0.9844; avg_acc: 0.9808
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 25, Global step 167:
20-03-23 22:19-INFO-training batch loss: 0.1062; avg_loss: 0.0526
20-03-23 22:19-INFO-training batch acc: 0.9648; avg_acc: 0.9802
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 26, Global step 168:
20-03-23 22:19-INFO-training batch loss: 0.1116; avg_loss: 0.0548
20-03-23 22:19-INFO-training batch acc: 0.9805; avg_acc: 0.9802
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 27, Global step 169:
20-03-23 22:19-INFO-training batch loss: 0.0457; avg_loss: 0.0545
20-03-23 22:19-INFO-training batch acc: 0.9805; avg_acc: 0.9802
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 28, Global step 170:
20-03-23 22:19-INFO-training batch loss: 0.0243; avg_loss: 0.0534
20-03-23 22:19-INFO-training batch acc: 0.9883; avg_acc: 0.9805
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 29, Global step 171:
20-03-23 22:19-INFO-training batch loss: 0.0266; avg_loss: 0.0525
20-03-23 22:19-INFO-training batch acc: 0.9961; avg_acc: 0.9810
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 30, Global step 172:
20-03-23 22:19-INFO-training batch loss: 0.0308; avg_loss: 0.0518
20-03-23 22:19-INFO-training batch acc: 0.9961; avg_acc: 0.9815
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 31, Global step 173:
20-03-23 22:19-INFO-training batch loss: 0.0490; avg_loss: 0.0517
20-03-23 22:19-INFO-training batch acc: 0.9844; avg_acc: 0.9816
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 32, Global step 174:
20-03-23 22:19-INFO-training batch loss: 0.0279; avg_loss: 0.0509
20-03-23 22:19-INFO-training batch acc: 0.9922; avg_acc: 0.9819
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 33, Global step 175:
20-03-23 22:19-INFO-training batch loss: 0.0343; avg_loss: 0.0504
20-03-23 22:19-INFO-training batch acc: 0.9961; avg_acc: 0.9824
20-03-23 22:19-INFO-
20-03-23 22:19-INFO-Epoch 1, Batch 34, Global step 176:
20-03-23 22:19-INFO-training batch loss: 0.0237; avg_loss: 0.0497
20-03-23 22:19-INFO-training batch acc: 0.9961; avg_acc: 0.9828
20-03-23 22:19-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 35, Global step 177:
20-03-23 22:20-INFO-training batch loss: 0.0475; avg_loss: 0.0496
20-03-23 22:20-INFO-training batch acc: 0.9844; avg_acc: 0.9828
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 36, Global step 178:
20-03-23 22:20-INFO-training batch loss: 0.0191; avg_loss: 0.0487
20-03-23 22:20-INFO-training batch acc: 0.9961; avg_acc: 0.9832
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 37, Global step 179:
20-03-23 22:20-INFO-training batch loss: 0.0259; avg_loss: 0.0481
20-03-23 22:20-INFO-training batch acc: 0.9883; avg_acc: 0.9833
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 38, Global step 180:
20-03-23 22:20-INFO-training batch loss: 0.0335; avg_loss: 0.0477
20-03-23 22:20-INFO-training batch acc: 0.9961; avg_acc: 0.9837
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 39, Global step 181:
20-03-23 22:20-INFO-training batch loss: 0.0655; avg_loss: 0.0482
20-03-23 22:20-INFO-training batch acc: 0.9688; avg_acc: 0.9833
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 40, Global step 182:
20-03-23 22:20-INFO-training batch loss: 0.0252; avg_loss: 0.0476
20-03-23 22:20-INFO-training batch acc: 0.9961; avg_acc: 0.9836
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 41, Global step 183:
20-03-23 22:20-INFO-training batch loss: 0.0545; avg_loss: 0.0478
20-03-23 22:20-INFO-training batch acc: 0.9844; avg_acc: 0.9836
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 42, Global step 184:
20-03-23 22:20-INFO-training batch loss: 0.0639; avg_loss: 0.0482
20-03-23 22:20-INFO-training batch acc: 0.9805; avg_acc: 0.9835
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 43, Global step 185:
20-03-23 22:20-INFO-training batch loss: 0.0624; avg_loss: 0.0485
20-03-23 22:20-INFO-training batch acc: 0.9766; avg_acc: 0.9834
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 44, Global step 186:
20-03-23 22:20-INFO-training batch loss: 0.0293; avg_loss: 0.0481
20-03-23 22:20-INFO-training batch acc: 0.9805; avg_acc: 0.9833
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 45, Global step 187:
20-03-23 22:20-INFO-training batch loss: 0.0418; avg_loss: 0.0479
20-03-23 22:20-INFO-training batch acc: 0.9844; avg_acc: 0.9833
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 46, Global step 188:
20-03-23 22:20-INFO-training batch loss: 0.0248; avg_loss: 0.0474
20-03-23 22:20-INFO-training batch acc: 0.9961; avg_acc: 0.9836
20-03-23 22:20-INFO-
20-03-23 22:20-INFO-Epoch 1, Batch 47, Global step 189:
20-03-23 22:20-INFO-training batch loss: 0.0100; avg_loss: 0.0466
20-03-23 22:20-INFO-training batch acc: 1.0000; avg_acc: 0.9840
20-03-23 22:20-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 48, Global step 190:
20-03-23 22:21-INFO-training batch loss: 0.0225; avg_loss: 0.0461
20-03-23 22:21-INFO-training batch acc: 0.9922; avg_acc: 0.9841
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 49, Global step 191:
20-03-23 22:21-INFO-training batch loss: 0.0681; avg_loss: 0.0466
20-03-23 22:21-INFO-training batch acc: 0.9844; avg_acc: 0.9841
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 50, Global step 192:
20-03-23 22:21-INFO-training batch loss: 0.0275; avg_loss: 0.0462
20-03-23 22:21-INFO-training batch acc: 0.9883; avg_acc: 0.9842
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 51, Global step 193:
20-03-23 22:21-INFO-training batch loss: 0.0252; avg_loss: 0.0458
20-03-23 22:21-INFO-training batch acc: 0.9922; avg_acc: 0.9844
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 52, Global step 194:
20-03-23 22:21-INFO-training batch loss: 0.0161; avg_loss: 0.0452
20-03-23 22:21-INFO-training batch acc: 0.9961; avg_acc: 0.9846
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 53, Global step 195:
20-03-23 22:21-INFO-training batch loss: 0.0700; avg_loss: 0.0457
20-03-23 22:21-INFO-training batch acc: 0.9766; avg_acc: 0.9844
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 54, Global step 196:
20-03-23 22:21-INFO-training batch loss: 0.0721; avg_loss: 0.0462
20-03-23 22:21-INFO-training batch acc: 0.9766; avg_acc: 0.9843
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 55, Global step 197:
20-03-23 22:21-INFO-training batch loss: 0.0235; avg_loss: 0.0458
20-03-23 22:21-INFO-training batch acc: 0.9844; avg_acc: 0.9843
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 56, Global step 198:
20-03-23 22:21-INFO-training batch loss: 0.0567; avg_loss: 0.0460
20-03-23 22:21-INFO-training batch acc: 0.9805; avg_acc: 0.9842
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 57, Global step 199:
20-03-23 22:21-INFO-training batch loss: 0.0251; avg_loss: 0.0456
20-03-23 22:21-INFO-training batch acc: 0.9922; avg_acc: 0.9844
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 58, Global step 200:
20-03-23 22:21-INFO-training batch loss: 0.0285; avg_loss: 0.0453
20-03-23 22:21-INFO-training batch acc: 0.9922; avg_acc: 0.9845
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 59, Global step 201:
20-03-23 22:21-INFO-training batch loss: 0.0261; avg_loss: 0.0450
20-03-23 22:21-INFO-training batch acc: 0.9883; avg_acc: 0.9846
20-03-23 22:21-INFO-
20-03-23 22:21-INFO-Epoch 1, Batch 60, Global step 202:
20-03-23 22:21-INFO-training batch loss: 0.0177; avg_loss: 0.0445
20-03-23 22:21-INFO-training batch acc: 1.0000; avg_acc: 0.9848
20-03-23 22:21-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 61, Global step 203:
20-03-23 22:22-INFO-training batch loss: 0.0535; avg_loss: 0.0447
20-03-23 22:22-INFO-training batch acc: 0.9766; avg_acc: 0.9847
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 62, Global step 204:
20-03-23 22:22-INFO-training batch loss: 0.0318; avg_loss: 0.0445
20-03-23 22:22-INFO-training batch acc: 0.9883; avg_acc: 0.9848
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 63, Global step 205:
20-03-23 22:22-INFO-training batch loss: 0.0224; avg_loss: 0.0441
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9849
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 64, Global step 206:
20-03-23 22:22-INFO-training batch loss: 0.0224; avg_loss: 0.0438
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9851
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 65, Global step 207:
20-03-23 22:22-INFO-training batch loss: 0.0207; avg_loss: 0.0434
20-03-23 22:22-INFO-training batch acc: 0.9922; avg_acc: 0.9852
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 66, Global step 208:
20-03-23 22:22-INFO-training batch loss: 0.0379; avg_loss: 0.0433
20-03-23 22:22-INFO-training batch acc: 0.9922; avg_acc: 0.9853
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 67, Global step 209:
20-03-23 22:22-INFO-training batch loss: 0.0175; avg_loss: 0.0429
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9855
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 68, Global step 210:
20-03-23 22:22-INFO-training batch loss: 0.0138; avg_loss: 0.0425
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9856
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 69, Global step 211:
20-03-23 22:22-INFO-training batch loss: 0.0122; avg_loss: 0.0421
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9858
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 70, Global step 212:
20-03-23 22:22-INFO-training batch loss: 0.0142; avg_loss: 0.0417
20-03-23 22:22-INFO-training batch acc: 1.0000; avg_acc: 0.9860
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 71, Global step 213:
20-03-23 22:22-INFO-training batch loss: 0.0226; avg_loss: 0.0414
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9861
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 72, Global step 214:
20-03-23 22:22-INFO-training batch loss: 0.0112; avg_loss: 0.0410
20-03-23 22:22-INFO-training batch acc: 0.9961; avg_acc: 0.9863
20-03-23 22:22-INFO-
20-03-23 22:22-INFO-Epoch 1, Batch 73, Global step 215:
20-03-23 22:22-INFO-training batch loss: 0.0278; avg_loss: 0.0408
20-03-23 22:22-INFO-training batch acc: 0.9883; avg_acc: 0.9863
20-03-23 22:22-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 74, Global step 216:
20-03-23 22:23-INFO-training batch loss: 0.0105; avg_loss: 0.0404
20-03-23 22:23-INFO-training batch acc: 1.0000; avg_acc: 0.9865
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 75, Global step 217:
20-03-23 22:23-INFO-training batch loss: 0.0241; avg_loss: 0.0402
20-03-23 22:23-INFO-training batch acc: 0.9883; avg_acc: 0.9865
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 76, Global step 218:
20-03-23 22:23-INFO-training batch loss: 0.0091; avg_loss: 0.0398
20-03-23 22:23-INFO-training batch acc: 1.0000; avg_acc: 0.9867
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 77, Global step 219:
20-03-23 22:23-INFO-training batch loss: 0.0305; avg_loss: 0.0397
20-03-23 22:23-INFO-training batch acc: 0.9883; avg_acc: 0.9867
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 78, Global step 220:
20-03-23 22:23-INFO-training batch loss: 0.0087; avg_loss: 0.0393
20-03-23 22:23-INFO-training batch acc: 0.9961; avg_acc: 0.9868
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 79, Global step 221:
20-03-23 22:23-INFO-training batch loss: 0.0078; avg_loss: 0.0389
20-03-23 22:23-INFO-training batch acc: 1.0000; avg_acc: 0.9870
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 80, Global step 222:
20-03-23 22:23-INFO-training batch loss: 0.0152; avg_loss: 0.0386
20-03-23 22:23-INFO-training batch acc: 0.9922; avg_acc: 0.9871
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 81, Global step 223:
20-03-23 22:23-INFO-training batch loss: 0.0155; avg_loss: 0.0383
20-03-23 22:23-INFO-training batch acc: 0.9922; avg_acc: 0.9871
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 82, Global step 224:
20-03-23 22:23-INFO-training batch loss: 0.0190; avg_loss: 0.0380
20-03-23 22:23-INFO-training batch acc: 0.9922; avg_acc: 0.9872
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 83, Global step 225:
20-03-23 22:23-INFO-training batch loss: 0.0048; avg_loss: 0.0376
20-03-23 22:23-INFO-training batch acc: 1.0000; avg_acc: 0.9873
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 84, Global step 226:
20-03-23 22:23-INFO-training batch loss: 0.0114; avg_loss: 0.0373
20-03-23 22:23-INFO-training batch acc: 0.9961; avg_acc: 0.9874
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 85, Global step 227:
20-03-23 22:23-INFO-training batch loss: 0.0202; avg_loss: 0.0371
20-03-23 22:23-INFO-training batch acc: 0.9922; avg_acc: 0.9875
20-03-23 22:23-INFO-
20-03-23 22:23-INFO-Epoch 1, Batch 86, Global step 228:
20-03-23 22:23-INFO-training batch loss: 0.0218; avg_loss: 0.0369
20-03-23 22:23-INFO-training batch acc: 0.9922; avg_acc: 0.9876
20-03-23 22:23-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 87, Global step 229:
20-03-23 22:24-INFO-training batch loss: 0.0123; avg_loss: 0.0367
20-03-23 22:24-INFO-training batch acc: 1.0000; avg_acc: 0.9877
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 88, Global step 230:
20-03-23 22:24-INFO-training batch loss: 0.0272; avg_loss: 0.0366
20-03-23 22:24-INFO-training batch acc: 0.9922; avg_acc: 0.9877
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 89, Global step 231:
20-03-23 22:24-INFO-training batch loss: 0.0071; avg_loss: 0.0362
20-03-23 22:24-INFO-training batch acc: 1.0000; avg_acc: 0.9879
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 90, Global step 232:
20-03-23 22:24-INFO-training batch loss: 0.0054; avg_loss: 0.0359
20-03-23 22:24-INFO-training batch acc: 1.0000; avg_acc: 0.9880
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 91, Global step 233:
20-03-23 22:24-INFO-training batch loss: 0.0097; avg_loss: 0.0356
20-03-23 22:24-INFO-training batch acc: 0.9961; avg_acc: 0.9881
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 92, Global step 234:
20-03-23 22:24-INFO-training batch loss: 0.0096; avg_loss: 0.0353
20-03-23 22:24-INFO-training batch acc: 0.9961; avg_acc: 0.9882
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 93, Global step 235:
20-03-23 22:24-INFO-training batch loss: 0.0152; avg_loss: 0.0351
20-03-23 22:24-INFO-training batch acc: 0.9961; avg_acc: 0.9883
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 94, Global step 236:
20-03-23 22:24-INFO-training batch loss: 0.0042; avg_loss: 0.0348
20-03-23 22:24-INFO-training batch acc: 1.0000; avg_acc: 0.9884
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 95, Global step 237:
20-03-23 22:24-INFO-training batch loss: 0.0114; avg_loss: 0.0345
20-03-23 22:24-INFO-training batch acc: 0.9961; avg_acc: 0.9885
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 96, Global step 238:
20-03-23 22:24-INFO-training batch loss: 0.0141; avg_loss: 0.0343
20-03-23 22:24-INFO-training batch acc: 1.0000; avg_acc: 0.9886
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 97, Global step 239:
20-03-23 22:24-INFO-training batch loss: 0.0126; avg_loss: 0.0341
20-03-23 22:24-INFO-training batch acc: 0.9961; avg_acc: 0.9887
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 98, Global step 240:
20-03-23 22:24-INFO-training batch loss: 0.0124; avg_loss: 0.0339
20-03-23 22:24-INFO-training batch acc: 0.9961; avg_acc: 0.9888
20-03-23 22:24-INFO-
20-03-23 22:24-INFO-Epoch 1, Batch 99, Global step 241:
20-03-23 22:24-INFO-training batch loss: 0.0168; avg_loss: 0.0337
20-03-23 22:24-INFO-training batch acc: 0.9922; avg_acc: 0.9888
20-03-23 22:24-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 100, Global step 242:
20-03-23 22:25-INFO-training batch loss: 0.0073; avg_loss: 0.0334
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9889
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 101, Global step 243:
20-03-23 22:25-INFO-training batch loss: 0.0101; avg_loss: 0.0332
20-03-23 22:25-INFO-training batch acc: 0.9961; avg_acc: 0.9890
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 102, Global step 244:
20-03-23 22:25-INFO-training batch loss: 0.0053; avg_loss: 0.0329
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9891
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 103, Global step 245:
20-03-23 22:25-INFO-training batch loss: 0.0114; avg_loss: 0.0327
20-03-23 22:25-INFO-training batch acc: 0.9961; avg_acc: 0.9892
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 104, Global step 246:
20-03-23 22:25-INFO-training batch loss: 0.0089; avg_loss: 0.0325
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9893
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 105, Global step 247:
20-03-23 22:25-INFO-training batch loss: 0.0130; avg_loss: 0.0323
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9894
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 106, Global step 248:
20-03-23 22:25-INFO-training batch loss: 0.0077; avg_loss: 0.0321
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9895
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 107, Global step 249:
20-03-23 22:25-INFO-training batch loss: 0.0046; avg_loss: 0.0318
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9896
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 108, Global step 250:
20-03-23 22:25-INFO-training batch loss: 0.0056; avg_loss: 0.0316
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9897
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 109, Global step 251:
20-03-23 22:25-INFO-training batch loss: 0.0042; avg_loss: 0.0313
20-03-23 22:25-INFO-training batch acc: 1.0000; avg_acc: 0.9898
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 110, Global step 252:
20-03-23 22:25-INFO-training batch loss: 0.0079; avg_loss: 0.0311
20-03-23 22:25-INFO-training batch acc: 0.9961; avg_acc: 0.9898
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 111, Global step 253:
20-03-23 22:25-INFO-training batch loss: 0.0126; avg_loss: 0.0309
20-03-23 22:25-INFO-training batch acc: 0.9961; avg_acc: 0.9899
20-03-23 22:25-INFO-
20-03-23 22:25-INFO-Epoch 1, Batch 112, Global step 254:
20-03-23 22:25-INFO-training batch loss: 0.0110; avg_loss: 0.0308
20-03-23 22:25-INFO-training batch acc: 0.9961; avg_acc: 0.9899
20-03-23 22:25-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 113, Global step 255:
20-03-23 22:26-INFO-training batch loss: 0.0033; avg_loss: 0.0305
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9900
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 114, Global step 256:
20-03-23 22:26-INFO-training batch loss: 0.0146; avg_loss: 0.0304
20-03-23 22:26-INFO-training batch acc: 0.9961; avg_acc: 0.9901
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 115, Global step 257:
20-03-23 22:26-INFO-training batch loss: 0.0035; avg_loss: 0.0301
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9901
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 116, Global step 258:
20-03-23 22:26-INFO-training batch loss: 0.0050; avg_loss: 0.0299
20-03-23 22:26-INFO-training batch acc: 0.9961; avg_acc: 0.9902
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 117, Global step 259:
20-03-23 22:26-INFO-training batch loss: 0.0030; avg_loss: 0.0297
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9903
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 118, Global step 260:
20-03-23 22:26-INFO-training batch loss: 0.0051; avg_loss: 0.0295
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9904
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 119, Global step 261:
20-03-23 22:26-INFO-training batch loss: 0.0020; avg_loss: 0.0293
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9904
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 120, Global step 262:
20-03-23 22:26-INFO-training batch loss: 0.0047; avg_loss: 0.0291
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9905
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 121, Global step 263:
20-03-23 22:26-INFO-training batch loss: 0.0045; avg_loss: 0.0288
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9906
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 122, Global step 264:
20-03-23 22:26-INFO-training batch loss: 0.0039; avg_loss: 0.0286
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9907
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 123, Global step 265:
20-03-23 22:26-INFO-training batch loss: 0.0042; avg_loss: 0.0284
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9908
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 124, Global step 266:
20-03-23 22:26-INFO-training batch loss: 0.0075; avg_loss: 0.0283
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9908
20-03-23 22:26-INFO-
20-03-23 22:26-INFO-Epoch 1, Batch 125, Global step 267:
20-03-23 22:26-INFO-training batch loss: 0.0057; avg_loss: 0.0281
20-03-23 22:26-INFO-training batch acc: 1.0000; avg_acc: 0.9909
20-03-23 22:26-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 126, Global step 268:
20-03-23 22:27-INFO-training batch loss: 0.0121; avg_loss: 0.0280
20-03-23 22:27-INFO-training batch acc: 0.9961; avg_acc: 0.9909
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 127, Global step 269:
20-03-23 22:27-INFO-training batch loss: 0.0066; avg_loss: 0.0278
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9910
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 128, Global step 270:
20-03-23 22:27-INFO-training batch loss: 0.0045; avg_loss: 0.0276
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9911
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 129, Global step 271:
20-03-23 22:27-INFO-training batch loss: 0.0027; avg_loss: 0.0274
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9912
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 130, Global step 272:
20-03-23 22:27-INFO-training batch loss: 0.0052; avg_loss: 0.0273
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9912
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 131, Global step 273:
20-03-23 22:27-INFO-training batch loss: 0.0079; avg_loss: 0.0271
20-03-23 22:27-INFO-training batch acc: 0.9961; avg_acc: 0.9913
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 132, Global step 274:
20-03-23 22:27-INFO-training batch loss: 0.0034; avg_loss: 0.0269
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9913
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 133, Global step 275:
20-03-23 22:27-INFO-training batch loss: 0.0063; avg_loss: 0.0268
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9914
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 134, Global step 276:
20-03-23 22:27-INFO-training batch loss: 0.0028; avg_loss: 0.0266
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 135, Global step 277:
20-03-23 22:27-INFO-training batch loss: 0.0142; avg_loss: 0.0265
20-03-23 22:27-INFO-training batch acc: 0.9922; avg_acc: 0.9915
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 136, Global step 278:
20-03-23 22:27-INFO-training batch loss: 0.0084; avg_loss: 0.0264
20-03-23 22:27-INFO-training batch acc: 0.9961; avg_acc: 0.9915
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 137, Global step 279:
20-03-23 22:27-INFO-training batch loss: 0.0031; avg_loss: 0.0262
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 22:27-INFO-
20-03-23 22:27-INFO-Epoch 1, Batch 138, Global step 280:
20-03-23 22:27-INFO-training batch loss: 0.0065; avg_loss: 0.0261
20-03-23 22:27-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 22:27-INFO-
20-03-23 22:28-INFO-Epoch 1, Batch 139, Global step 281:
20-03-23 22:28-INFO-training batch loss: 0.0078; avg_loss: 0.0259
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 1, Batch 140, Global step 282:
20-03-23 22:28-INFO-training batch loss: 0.0057; avg_loss: 0.0258
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 1, Batch 141, Global step 283:
20-03-23 22:28-INFO-training batch loss: 0.0077; avg_loss: 0.0257
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 1, Batch 142, Global step 284:
20-03-23 22:28-INFO-training batch loss: 0.0060; avg_loss: 0.0255
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 1, training batch loss: 0.0060; avg_loss: 0.0255
20-03-23 22:28-INFO-Epoch 1, training batch accuracy: 1.0000; avg_accuracy: 0.9919
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 1, evaluating batch loss: 0.9614; avg_loss: 0.4413
20-03-23 22:28-INFO-Epoch 1, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9452
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 1, Global step 285:
20-03-23 22:28-INFO-training batch loss: 0.0030; avg_loss: 0.0030
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 2, Global step 286:
20-03-23 22:28-INFO-training batch loss: 0.0037; avg_loss: 0.0034
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 3, Global step 287:
20-03-23 22:28-INFO-training batch loss: 0.0033; avg_loss: 0.0034
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 4, Global step 288:
20-03-23 22:28-INFO-training batch loss: 0.0044; avg_loss: 0.0036
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 5, Global step 289:
20-03-23 22:28-INFO-training batch loss: 0.0043; avg_loss: 0.0037
20-03-23 22:28-INFO-training batch acc: 0.9961; avg_acc: 0.9992
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 6, Global step 290:
20-03-23 22:28-INFO-training batch loss: 0.0070; avg_loss: 0.0043
20-03-23 22:28-INFO-training batch acc: 0.9961; avg_acc: 0.9987
20-03-23 22:28-INFO-
20-03-23 22:28-INFO-Epoch 2, Batch 7, Global step 291:
20-03-23 22:28-INFO-training batch loss: 0.0040; avg_loss: 0.0042
20-03-23 22:28-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:28-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 8, Global step 292:
20-03-23 22:29-INFO-training batch loss: 0.0168; avg_loss: 0.0058
20-03-23 22:29-INFO-training batch acc: 0.9922; avg_acc: 0.9980
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 9, Global step 293:
20-03-23 22:29-INFO-training batch loss: 0.0030; avg_loss: 0.0055
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 10, Global step 294:
20-03-23 22:29-INFO-training batch loss: 0.0041; avg_loss: 0.0054
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9984
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 11, Global step 295:
20-03-23 22:29-INFO-training batch loss: 0.0053; avg_loss: 0.0054
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9986
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 12, Global step 296:
20-03-23 22:29-INFO-training batch loss: 0.0059; avg_loss: 0.0054
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 13, Global step 297:
20-03-23 22:29-INFO-training batch loss: 0.0071; avg_loss: 0.0055
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 14, Global step 298:
20-03-23 22:29-INFO-training batch loss: 0.0051; avg_loss: 0.0055
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 15, Global step 299:
20-03-23 22:29-INFO-training batch loss: 0.0124; avg_loss: 0.0060
20-03-23 22:29-INFO-training batch acc: 0.9922; avg_acc: 0.9984
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 16, Global step 300:
20-03-23 22:29-INFO-training batch loss: 0.0098; avg_loss: 0.0062
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9985
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 17, Global step 301:
20-03-23 22:29-INFO-training batch loss: 0.0024; avg_loss: 0.0060
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9986
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 18, Global step 302:
20-03-23 22:29-INFO-training batch loss: 0.0082; avg_loss: 0.0061
20-03-23 22:29-INFO-training batch acc: 0.9961; avg_acc: 0.9985
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 19, Global step 303:
20-03-23 22:29-INFO-training batch loss: 0.0030; avg_loss: 0.0059
20-03-23 22:29-INFO-training batch acc: 1.0000; avg_acc: 0.9986
20-03-23 22:29-INFO-
20-03-23 22:29-INFO-Epoch 2, Batch 20, Global step 304:
20-03-23 22:29-INFO-training batch loss: 0.0270; avg_loss: 0.0070
20-03-23 22:29-INFO-training batch acc: 0.9883; avg_acc: 0.9980
20-03-23 22:29-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 21, Global step 305:
20-03-23 22:30-INFO-training batch loss: 0.0047; avg_loss: 0.0069
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9981
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 22, Global step 306:
20-03-23 22:30-INFO-training batch loss: 0.0055; avg_loss: 0.0068
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9982
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 23, Global step 307:
20-03-23 22:30-INFO-training batch loss: 0.0062; avg_loss: 0.0068
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9983
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 24, Global step 308:
20-03-23 22:30-INFO-training batch loss: 0.0052; avg_loss: 0.0067
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9984
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 25, Global step 309:
20-03-23 22:30-INFO-training batch loss: 0.0123; avg_loss: 0.0070
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9984
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 26, Global step 310:
20-03-23 22:30-INFO-training batch loss: 0.0161; avg_loss: 0.0073
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9985
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 27, Global step 311:
20-03-23 22:30-INFO-training batch loss: 0.0088; avg_loss: 0.0074
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9986
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 28, Global step 312:
20-03-23 22:30-INFO-training batch loss: 0.0039; avg_loss: 0.0072
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9986
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 29, Global step 313:
20-03-23 22:30-INFO-training batch loss: 0.0033; avg_loss: 0.0071
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 30, Global step 314:
20-03-23 22:30-INFO-training batch loss: 0.0047; avg_loss: 0.0070
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 31, Global step 315:
20-03-23 22:30-INFO-training batch loss: 0.0038; avg_loss: 0.0069
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 32, Global step 316:
20-03-23 22:30-INFO-training batch loss: 0.0075; avg_loss: 0.0069
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 22:30-INFO-
20-03-23 22:30-INFO-Epoch 2, Batch 33, Global step 317:
20-03-23 22:30-INFO-training batch loss: 0.0038; avg_loss: 0.0068
20-03-23 22:30-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 22:30-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 34, Global step 318:
20-03-23 22:31-INFO-training batch loss: 0.0024; avg_loss: 0.0067
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 35, Global step 319:
20-03-23 22:31-INFO-training batch loss: 0.0055; avg_loss: 0.0067
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 36, Global step 320:
20-03-23 22:31-INFO-training batch loss: 0.0065; avg_loss: 0.0067
20-03-23 22:31-INFO-training batch acc: 0.9961; avg_acc: 0.9988
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 37, Global step 321:
20-03-23 22:31-INFO-training batch loss: 0.0033; avg_loss: 0.0066
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 38, Global step 322:
20-03-23 22:31-INFO-training batch loss: 0.0056; avg_loss: 0.0065
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 39, Global step 323:
20-03-23 22:31-INFO-training batch loss: 0.0016; avg_loss: 0.0064
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 40, Global step 324:
20-03-23 22:31-INFO-training batch loss: 0.0023; avg_loss: 0.0063
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 41, Global step 325:
20-03-23 22:31-INFO-training batch loss: 0.0133; avg_loss: 0.0065
20-03-23 22:31-INFO-training batch acc: 0.9961; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 42, Global step 326:
20-03-23 22:31-INFO-training batch loss: 0.0073; avg_loss: 0.0065
20-03-23 22:31-INFO-training batch acc: 0.9961; avg_acc: 0.9988
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 43, Global step 327:
20-03-23 22:31-INFO-training batch loss: 0.0016; avg_loss: 0.0064
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 44, Global step 328:
20-03-23 22:31-INFO-training batch loss: 0.0020; avg_loss: 0.0063
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 45, Global step 329:
20-03-23 22:31-INFO-training batch loss: 0.0052; avg_loss: 0.0063
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 46, Global step 330:
20-03-23 22:31-INFO-training batch loss: 0.0035; avg_loss: 0.0062
20-03-23 22:31-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:31-INFO-
20-03-23 22:31-INFO-Epoch 2, Batch 47, Global step 331:
20-03-23 22:31-INFO-training batch loss: 0.0055; avg_loss: 0.0062
20-03-23 22:31-INFO-training batch acc: 0.9961; avg_acc: 0.9988
20-03-23 22:31-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 48, Global step 332:
20-03-23 22:32-INFO-training batch loss: 0.0023; avg_loss: 0.0061
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 49, Global step 333:
20-03-23 22:32-INFO-training batch loss: 0.0049; avg_loss: 0.0061
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 50, Global step 334:
20-03-23 22:32-INFO-training batch loss: 0.0049; avg_loss: 0.0061
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 51, Global step 335:
20-03-23 22:32-INFO-training batch loss: 0.0034; avg_loss: 0.0060
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 52, Global step 336:
20-03-23 22:32-INFO-training batch loss: 0.0036; avg_loss: 0.0060
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 53, Global step 337:
20-03-23 22:32-INFO-training batch loss: 0.0059; avg_loss: 0.0060
20-03-23 22:32-INFO-training batch acc: 0.9961; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 54, Global step 338:
20-03-23 22:32-INFO-training batch loss: 0.0033; avg_loss: 0.0059
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 55, Global step 339:
20-03-23 22:32-INFO-training batch loss: 0.0028; avg_loss: 0.0059
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 56, Global step 340:
20-03-23 22:32-INFO-training batch loss: 0.0013; avg_loss: 0.0058
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 57, Global step 341:
20-03-23 22:32-INFO-training batch loss: 0.0016; avg_loss: 0.0057
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 58, Global step 342:
20-03-23 22:32-INFO-training batch loss: 0.0114; avg_loss: 0.0058
20-03-23 22:32-INFO-training batch acc: 0.9961; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 59, Global step 343:
20-03-23 22:32-INFO-training batch loss: 0.0054; avg_loss: 0.0058
20-03-23 22:32-INFO-training batch acc: 0.9961; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:32-INFO-Epoch 2, Batch 60, Global step 344:
20-03-23 22:32-INFO-training batch loss: 0.0018; avg_loss: 0.0057
20-03-23 22:32-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:32-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 61, Global step 345:
20-03-23 22:33-INFO-training batch loss: 0.0024; avg_loss: 0.0057
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 62, Global step 346:
20-03-23 22:33-INFO-training batch loss: 0.0035; avg_loss: 0.0056
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 63, Global step 347:
20-03-23 22:33-INFO-training batch loss: 0.0035; avg_loss: 0.0056
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 64, Global step 348:
20-03-23 22:33-INFO-training batch loss: 0.0026; avg_loss: 0.0056
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 65, Global step 349:
20-03-23 22:33-INFO-training batch loss: 0.0049; avg_loss: 0.0056
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 66, Global step 350:
20-03-23 22:33-INFO-training batch loss: 0.0041; avg_loss: 0.0055
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 67, Global step 351:
20-03-23 22:33-INFO-training batch loss: 0.0049; avg_loss: 0.0055
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 68, Global step 352:
20-03-23 22:33-INFO-training batch loss: 0.0055; avg_loss: 0.0055
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 69, Global step 353:
20-03-23 22:33-INFO-training batch loss: 0.0082; avg_loss: 0.0056
20-03-23 22:33-INFO-training batch acc: 0.9961; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 70, Global step 354:
20-03-23 22:33-INFO-training batch loss: 0.0021; avg_loss: 0.0055
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 71, Global step 355:
20-03-23 22:33-INFO-training batch loss: 0.0022; avg_loss: 0.0055
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 72, Global step 356:
20-03-23 22:33-INFO-training batch loss: 0.0028; avg_loss: 0.0054
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:33-INFO-Epoch 2, Batch 73, Global step 357:
20-03-23 22:33-INFO-training batch loss: 0.0030; avg_loss: 0.0054
20-03-23 22:33-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:33-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 74, Global step 358:
20-03-23 22:34-INFO-training batch loss: 0.0030; avg_loss: 0.0054
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 75, Global step 359:
20-03-23 22:34-INFO-training batch loss: 0.0089; avg_loss: 0.0054
20-03-23 22:34-INFO-training batch acc: 0.9961; avg_acc: 0.9990
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 76, Global step 360:
20-03-23 22:34-INFO-training batch loss: 0.0063; avg_loss: 0.0054
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 77, Global step 361:
20-03-23 22:34-INFO-training batch loss: 0.0029; avg_loss: 0.0054
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 78, Global step 362:
20-03-23 22:34-INFO-training batch loss: 0.0023; avg_loss: 0.0053
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 79, Global step 363:
20-03-23 22:34-INFO-training batch loss: 0.0022; avg_loss: 0.0053
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 80, Global step 364:
20-03-23 22:34-INFO-training batch loss: 0.0032; avg_loss: 0.0053
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 81, Global step 365:
20-03-23 22:34-INFO-training batch loss: 0.0013; avg_loss: 0.0052
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 82, Global step 366:
20-03-23 22:34-INFO-training batch loss: 0.0020; avg_loss: 0.0052
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 83, Global step 367:
20-03-23 22:34-INFO-training batch loss: 0.0035; avg_loss: 0.0052
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 84, Global step 368:
20-03-23 22:34-INFO-training batch loss: 0.0023; avg_loss: 0.0051
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 85, Global step 369:
20-03-23 22:34-INFO-training batch loss: 0.0028; avg_loss: 0.0051
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:34-INFO-Epoch 2, Batch 86, Global step 370:
20-03-23 22:34-INFO-training batch loss: 0.0025; avg_loss: 0.0051
20-03-23 22:34-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:34-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 87, Global step 371:
20-03-23 22:35-INFO-training batch loss: 0.0034; avg_loss: 0.0051
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 88, Global step 372:
20-03-23 22:35-INFO-training batch loss: 0.0026; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 89, Global step 373:
20-03-23 22:35-INFO-training batch loss: 0.0068; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 0.9961; avg_acc: 0.9991
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 90, Global step 374:
20-03-23 22:35-INFO-training batch loss: 0.0032; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 91, Global step 375:
20-03-23 22:35-INFO-training batch loss: 0.0051; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 92, Global step 376:
20-03-23 22:35-INFO-training batch loss: 0.0021; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 93, Global step 377:
20-03-23 22:35-INFO-training batch loss: 0.0025; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 94, Global step 378:
20-03-23 22:35-INFO-training batch loss: 0.0013; avg_loss: 0.0049
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 95, Global step 379:
20-03-23 22:35-INFO-training batch loss: 0.0060; avg_loss: 0.0049
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 96, Global step 380:
20-03-23 22:35-INFO-training batch loss: 0.0029; avg_loss: 0.0049
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 97, Global step 381:
20-03-23 22:35-INFO-training batch loss: 0.0020; avg_loss: 0.0049
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 98, Global step 382:
20-03-23 22:35-INFO-training batch loss: 0.0107; avg_loss: 0.0050
20-03-23 22:35-INFO-training batch acc: 0.9961; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:35-INFO-Epoch 2, Batch 99, Global step 383:
20-03-23 22:35-INFO-training batch loss: 0.0035; avg_loss: 0.0049
20-03-23 22:35-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:35-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 100, Global step 384:
20-03-23 22:36-INFO-training batch loss: 0.0036; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 101, Global step 385:
20-03-23 22:36-INFO-training batch loss: 0.0016; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 102, Global step 386:
20-03-23 22:36-INFO-training batch loss: 0.0049; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 103, Global step 387:
20-03-23 22:36-INFO-training batch loss: 0.0029; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 104, Global step 388:
20-03-23 22:36-INFO-training batch loss: 0.0080; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 105, Global step 389:
20-03-23 22:36-INFO-training batch loss: 0.0039; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 106, Global step 390:
20-03-23 22:36-INFO-training batch loss: 0.0026; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 107, Global step 391:
20-03-23 22:36-INFO-training batch loss: 0.0091; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 0.9961; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 108, Global step 392:
20-03-23 22:36-INFO-training batch loss: 0.0029; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 109, Global step 393:
20-03-23 22:36-INFO-training batch loss: 0.0089; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 0.9961; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 110, Global step 394:
20-03-23 22:36-INFO-training batch loss: 0.0050; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 111, Global step 395:
20-03-23 22:36-INFO-training batch loss: 0.0064; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 0.9961; avg_acc: 0.9992
20-03-23 22:36-INFO-
20-03-23 22:36-INFO-Epoch 2, Batch 112, Global step 396:
20-03-23 22:36-INFO-training batch loss: 0.0056; avg_loss: 0.0049
20-03-23 22:36-INFO-training batch acc: 0.9961; avg_acc: 0.9991
20-03-23 22:36-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 113, Global step 397:
20-03-23 22:37-INFO-training batch loss: 0.0026; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 114, Global step 398:
20-03-23 22:37-INFO-training batch loss: 0.0041; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 115, Global step 399:
20-03-23 22:37-INFO-training batch loss: 0.0028; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 116, Global step 400:
20-03-23 22:37-INFO-training batch loss: 0.0056; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 117, Global step 401:
20-03-23 22:37-INFO-training batch loss: 0.0052; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 118, Global step 402:
20-03-23 22:37-INFO-training batch loss: 0.0035; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 119, Global step 403:
20-03-23 22:37-INFO-training batch loss: 0.0030; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 120, Global step 404:
20-03-23 22:37-INFO-training batch loss: 0.0045; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 121, Global step 405:
20-03-23 22:37-INFO-training batch loss: 0.0019; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 122, Global step 406:
20-03-23 22:37-INFO-training batch loss: 0.0027; avg_loss: 0.0048
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 123, Global step 407:
20-03-23 22:37-INFO-training batch loss: 0.0020; avg_loss: 0.0048
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 124, Global step 408:
20-03-23 22:37-INFO-training batch loss: 0.0036; avg_loss: 0.0048
20-03-23 22:37-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:37-INFO-Epoch 2, Batch 125, Global step 409:
20-03-23 22:37-INFO-training batch loss: 0.0125; avg_loss: 0.0049
20-03-23 22:37-INFO-training batch acc: 0.9961; avg_acc: 0.9992
20-03-23 22:37-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 126, Global step 410:
20-03-23 22:38-INFO-training batch loss: 0.0035; avg_loss: 0.0049
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 127, Global step 411:
20-03-23 22:38-INFO-training batch loss: 0.0045; avg_loss: 0.0049
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 128, Global step 412:
20-03-23 22:38-INFO-training batch loss: 0.0013; avg_loss: 0.0048
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 129, Global step 413:
20-03-23 22:38-INFO-training batch loss: 0.0014; avg_loss: 0.0048
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 130, Global step 414:
20-03-23 22:38-INFO-training batch loss: 0.0021; avg_loss: 0.0048
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 131, Global step 415:
20-03-23 22:38-INFO-training batch loss: 0.0022; avg_loss: 0.0048
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 132, Global step 416:
20-03-23 22:38-INFO-training batch loss: 0.0014; avg_loss: 0.0047
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 133, Global step 417:
20-03-23 22:38-INFO-training batch loss: 0.0041; avg_loss: 0.0047
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 134, Global step 418:
20-03-23 22:38-INFO-training batch loss: 0.0026; avg_loss: 0.0047
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 135, Global step 419:
20-03-23 22:38-INFO-training batch loss: 0.0022; avg_loss: 0.0047
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 136, Global step 420:
20-03-23 22:38-INFO-training batch loss: 0.0020; avg_loss: 0.0047
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 137, Global step 421:
20-03-23 22:38-INFO-training batch loss: 0.0017; avg_loss: 0.0047
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:38-INFO-
20-03-23 22:38-INFO-Epoch 2, Batch 138, Global step 422:
20-03-23 22:38-INFO-training batch loss: 0.0044; avg_loss: 0.0046
20-03-23 22:38-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:38-INFO-
20-03-23 22:39-INFO-Epoch 2, Batch 139, Global step 423:
20-03-23 22:39-INFO-training batch loss: 0.0017; avg_loss: 0.0046
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 2, Batch 140, Global step 424:
20-03-23 22:39-INFO-training batch loss: 0.0020; avg_loss: 0.0046
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 2, Batch 141, Global step 425:
20-03-23 22:39-INFO-training batch loss: 0.0023; avg_loss: 0.0046
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 2, Batch 142, Global step 426:
20-03-23 22:39-INFO-training batch loss: 0.0033; avg_loss: 0.0046
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 2, training batch loss: 0.0033; avg_loss: 0.0046
20-03-23 22:39-INFO-Epoch 2, training batch accuracy: 1.0000; avg_accuracy: 0.9993
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 2, evaluating batch loss: 1.2898; avg_loss: 0.5368
20-03-23 22:39-INFO-Epoch 2, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9478
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 1, Global step 427:
20-03-23 22:39-INFO-training batch loss: 0.0065; avg_loss: 0.0065
20-03-23 22:39-INFO-training batch acc: 0.9961; avg_acc: 0.9961
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 2, Global step 428:
20-03-23 22:39-INFO-training batch loss: 0.0016; avg_loss: 0.0040
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 3, Global step 429:
20-03-23 22:39-INFO-training batch loss: 0.0024; avg_loss: 0.0035
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 4, Global step 430:
20-03-23 22:39-INFO-training batch loss: 0.0024; avg_loss: 0.0032
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 5, Global step 431:
20-03-23 22:39-INFO-training batch loss: 0.0013; avg_loss: 0.0028
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 6, Global step 432:
20-03-23 22:39-INFO-training batch loss: 0.0057; avg_loss: 0.0033
20-03-23 22:39-INFO-training batch acc: 0.9961; avg_acc: 0.9987
20-03-23 22:39-INFO-
20-03-23 22:39-INFO-Epoch 3, Batch 7, Global step 433:
20-03-23 22:39-INFO-training batch loss: 0.0023; avg_loss: 0.0032
20-03-23 22:39-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 22:39-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 8, Global step 434:
20-03-23 22:40-INFO-training batch loss: 0.0027; avg_loss: 0.0031
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 9, Global step 435:
20-03-23 22:40-INFO-training batch loss: 0.0042; avg_loss: 0.0032
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 10, Global step 436:
20-03-23 22:40-INFO-training batch loss: 0.0022; avg_loss: 0.0031
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 11, Global step 437:
20-03-23 22:40-INFO-training batch loss: 0.0021; avg_loss: 0.0030
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 12, Global step 438:
20-03-23 22:40-INFO-training batch loss: 0.0039; avg_loss: 0.0031
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 13, Global step 439:
20-03-23 22:40-INFO-training batch loss: 0.0041; avg_loss: 0.0032
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 14, Global step 440:
20-03-23 22:40-INFO-training batch loss: 0.0031; avg_loss: 0.0032
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 15, Global step 441:
20-03-23 22:40-INFO-training batch loss: 0.0015; avg_loss: 0.0031
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 16, Global step 442:
20-03-23 22:40-INFO-training batch loss: 0.0027; avg_loss: 0.0030
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 17, Global step 443:
20-03-23 22:40-INFO-training batch loss: 0.0019; avg_loss: 0.0030
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 18, Global step 444:
20-03-23 22:40-INFO-training batch loss: 0.0023; avg_loss: 0.0029
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 19, Global step 445:
20-03-23 22:40-INFO-training batch loss: 0.0013; avg_loss: 0.0028
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:40-INFO-
20-03-23 22:40-INFO-Epoch 3, Batch 20, Global step 446:
20-03-23 22:40-INFO-training batch loss: 0.0024; avg_loss: 0.0028
20-03-23 22:40-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:40-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 21, Global step 447:
20-03-23 22:41-INFO-training batch loss: 0.0016; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 22, Global step 448:
20-03-23 22:41-INFO-training batch loss: 0.0019; avg_loss: 0.0027
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 23, Global step 449:
20-03-23 22:41-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 24, Global step 450:
20-03-23 22:41-INFO-training batch loss: 0.0033; avg_loss: 0.0027
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 25, Global step 451:
20-03-23 22:41-INFO-training batch loss: 0.0055; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 0.9961; avg_acc: 0.9995
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 26, Global step 452:
20-03-23 22:41-INFO-training batch loss: 0.0019; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 27, Global step 453:
20-03-23 22:41-INFO-training batch loss: 0.0035; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 28, Global step 454:
20-03-23 22:41-INFO-training batch loss: 0.0018; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 29, Global step 455:
20-03-23 22:41-INFO-training batch loss: 0.0049; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 30, Global step 456:
20-03-23 22:41-INFO-training batch loss: 0.0023; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 31, Global step 457:
20-03-23 22:41-INFO-training batch loss: 0.0052; avg_loss: 0.0029
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 32, Global step 458:
20-03-23 22:41-INFO-training batch loss: 0.0020; avg_loss: 0.0029
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:41-INFO-Epoch 3, Batch 33, Global step 459:
20-03-23 22:41-INFO-training batch loss: 0.0016; avg_loss: 0.0028
20-03-23 22:41-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 22:41-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 34, Global step 460:
20-03-23 22:42-INFO-training batch loss: 0.0032; avg_loss: 0.0028
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 35, Global step 461:
20-03-23 22:42-INFO-training batch loss: 0.0050; avg_loss: 0.0029
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 36, Global step 462:
20-03-23 22:42-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 37, Global step 463:
20-03-23 22:42-INFO-training batch loss: 0.0033; avg_loss: 0.0029
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 38, Global step 464:
20-03-23 22:42-INFO-training batch loss: 0.0029; avg_loss: 0.0029
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 39, Global step 465:
20-03-23 22:42-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 40, Global step 466:
20-03-23 22:42-INFO-training batch loss: 0.0018; avg_loss: 0.0028
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 41, Global step 467:
20-03-23 22:42-INFO-training batch loss: 0.0016; avg_loss: 0.0028
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 42, Global step 468:
20-03-23 22:42-INFO-training batch loss: 0.0036; avg_loss: 0.0028
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 43, Global step 469:
20-03-23 22:42-INFO-training batch loss: 0.0018; avg_loss: 0.0028
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 44, Global step 470:
20-03-23 22:42-INFO-training batch loss: 0.0026; avg_loss: 0.0028
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 45, Global step 471:
20-03-23 22:42-INFO-training batch loss: 0.0009; avg_loss: 0.0027
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:42-INFO-Epoch 3, Batch 46, Global step 472:
20-03-23 22:42-INFO-training batch loss: 0.0011; avg_loss: 0.0027
20-03-23 22:42-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:42-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 47, Global step 473:
20-03-23 22:43-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 48, Global step 474:
20-03-23 22:43-INFO-training batch loss: 0.0029; avg_loss: 0.0027
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 49, Global step 475:
20-03-23 22:43-INFO-training batch loss: 0.0025; avg_loss: 0.0027
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 50, Global step 476:
20-03-23 22:43-INFO-training batch loss: 0.0024; avg_loss: 0.0027
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 51, Global step 477:
20-03-23 22:43-INFO-training batch loss: 0.0024; avg_loss: 0.0027
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 52, Global step 478:
20-03-23 22:43-INFO-training batch loss: 0.0013; avg_loss: 0.0027
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 53, Global step 479:
20-03-23 22:43-INFO-training batch loss: 0.0010; avg_loss: 0.0026
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 54, Global step 480:
20-03-23 22:43-INFO-training batch loss: 0.0018; avg_loss: 0.0026
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 55, Global step 481:
20-03-23 22:43-INFO-training batch loss: 0.0017; avg_loss: 0.0026
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 56, Global step 482:
20-03-23 22:43-INFO-training batch loss: 0.0021; avg_loss: 0.0026
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 57, Global step 483:
20-03-23 22:43-INFO-training batch loss: 0.0024; avg_loss: 0.0026
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 58, Global step 484:
20-03-23 22:43-INFO-training batch loss: 0.0008; avg_loss: 0.0026
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:43-INFO-Epoch 3, Batch 59, Global step 485:
20-03-23 22:43-INFO-training batch loss: 0.0007; avg_loss: 0.0025
20-03-23 22:43-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:43-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 60, Global step 486:
20-03-23 22:44-INFO-training batch loss: 0.0021; avg_loss: 0.0025
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 61, Global step 487:
20-03-23 22:44-INFO-training batch loss: 0.0020; avg_loss: 0.0025
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 62, Global step 488:
20-03-23 22:44-INFO-training batch loss: 0.0008; avg_loss: 0.0025
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 63, Global step 489:
20-03-23 22:44-INFO-training batch loss: 0.0017; avg_loss: 0.0025
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 64, Global step 490:
20-03-23 22:44-INFO-training batch loss: 0.0007; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 65, Global step 491:
20-03-23 22:44-INFO-training batch loss: 0.0020; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 66, Global step 492:
20-03-23 22:44-INFO-training batch loss: 0.0025; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 67, Global step 493:
20-03-23 22:44-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 68, Global step 494:
20-03-23 22:44-INFO-training batch loss: 0.0020; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 69, Global step 495:
20-03-23 22:44-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 70, Global step 496:
20-03-23 22:44-INFO-training batch loss: 0.0012; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 71, Global step 497:
20-03-23 22:44-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 72, Global step 498:
20-03-23 22:44-INFO-training batch loss: 0.0018; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:44-INFO-Epoch 3, Batch 73, Global step 499:
20-03-23 22:44-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:44-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:44-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 74, Global step 500:
20-03-23 22:45-INFO-training batch loss: 0.0042; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 75, Global step 501:
20-03-23 22:45-INFO-training batch loss: 0.0013; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 76, Global step 502:
20-03-23 22:45-INFO-training batch loss: 0.0019; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 77, Global step 503:
20-03-23 22:45-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 78, Global step 504:
20-03-23 22:45-INFO-training batch loss: 0.0067; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 79, Global step 505:
20-03-23 22:45-INFO-training batch loss: 0.0030; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 80, Global step 506:
20-03-23 22:45-INFO-training batch loss: 0.0022; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 81, Global step 507:
20-03-23 22:45-INFO-training batch loss: 0.0017; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 82, Global step 508:
20-03-23 22:45-INFO-training batch loss: 0.0029; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 83, Global step 509:
20-03-23 22:45-INFO-training batch loss: 0.0014; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 84, Global step 510:
20-03-23 22:45-INFO-training batch loss: 0.0017; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:45-INFO-Epoch 3, Batch 85, Global step 511:
20-03-23 22:45-INFO-training batch loss: 0.0020; avg_loss: 0.0024
20-03-23 22:45-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:45-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 86, Global step 512:
20-03-23 22:46-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 87, Global step 513:
20-03-23 22:46-INFO-training batch loss: 0.0015; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 88, Global step 514:
20-03-23 22:46-INFO-training batch loss: 0.0016; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 89, Global step 515:
20-03-23 22:46-INFO-training batch loss: 0.0023; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 90, Global step 516:
20-03-23 22:46-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 91, Global step 517:
20-03-23 22:46-INFO-training batch loss: 0.0018; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 92, Global step 518:
20-03-23 22:46-INFO-training batch loss: 0.0059; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 93, Global step 519:
20-03-23 22:46-INFO-training batch loss: 0.0018; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 94, Global step 520:
20-03-23 22:46-INFO-training batch loss: 0.0025; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 95, Global step 521:
20-03-23 22:46-INFO-training batch loss: 0.0013; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 96, Global step 522:
20-03-23 22:46-INFO-training batch loss: 0.0031; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 97, Global step 523:
20-03-23 22:46-INFO-training batch loss: 0.0031; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 98, Global step 524:
20-03-23 22:46-INFO-training batch loss: 0.0033; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:46-INFO-Epoch 3, Batch 99, Global step 525:
20-03-23 22:46-INFO-training batch loss: 0.0028; avg_loss: 0.0024
20-03-23 22:46-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:46-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 100, Global step 526:
20-03-23 22:47-INFO-training batch loss: 0.0023; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 101, Global step 527:
20-03-23 22:47-INFO-training batch loss: 0.0019; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 102, Global step 528:
20-03-23 22:47-INFO-training batch loss: 0.0035; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 103, Global step 529:
20-03-23 22:47-INFO-training batch loss: 0.0031; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 104, Global step 530:
20-03-23 22:47-INFO-training batch loss: 0.0020; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 105, Global step 531:
20-03-23 22:47-INFO-training batch loss: 0.0027; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 106, Global step 532:
20-03-23 22:47-INFO-training batch loss: 0.0017; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 107, Global step 533:
20-03-23 22:47-INFO-training batch loss: 0.0048; avg_loss: 0.0025
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 108, Global step 534:
20-03-23 22:47-INFO-training batch loss: 0.0027; avg_loss: 0.0025
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 109, Global step 535:
20-03-23 22:47-INFO-training batch loss: 0.0016; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 110, Global step 536:
20-03-23 22:47-INFO-training batch loss: 0.0022; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 111, Global step 537:
20-03-23 22:47-INFO-training batch loss: 0.0011; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:47-INFO-Epoch 3, Batch 112, Global step 538:
20-03-23 22:47-INFO-training batch loss: 0.0018; avg_loss: 0.0024
20-03-23 22:47-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:47-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 113, Global step 539:
20-03-23 22:48-INFO-training batch loss: 0.0014; avg_loss: 0.0024
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 114, Global step 540:
20-03-23 22:48-INFO-training batch loss: 0.0016; avg_loss: 0.0024
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 115, Global step 541:
20-03-23 22:48-INFO-training batch loss: 0.0007; avg_loss: 0.0024
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 116, Global step 542:
20-03-23 22:48-INFO-training batch loss: 0.0006; avg_loss: 0.0024
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 117, Global step 543:
20-03-23 22:48-INFO-training batch loss: 0.0011; avg_loss: 0.0024
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 118, Global step 544:
20-03-23 22:48-INFO-training batch loss: 0.0010; avg_loss: 0.0024
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 119, Global step 545:
20-03-23 22:48-INFO-training batch loss: 0.0012; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 120, Global step 546:
20-03-23 22:48-INFO-training batch loss: 0.0021; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 121, Global step 547:
20-03-23 22:48-INFO-training batch loss: 0.0007; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 122, Global step 548:
20-03-23 22:48-INFO-training batch loss: 0.0017; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 123, Global step 549:
20-03-23 22:48-INFO-training batch loss: 0.0009; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 124, Global step 550:
20-03-23 22:48-INFO-training batch loss: 0.0010; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:48-INFO-Epoch 3, Batch 125, Global step 551:
20-03-23 22:48-INFO-training batch loss: 0.0030; avg_loss: 0.0023
20-03-23 22:48-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:48-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 126, Global step 552:
20-03-23 22:49-INFO-training batch loss: 0.0023; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 127, Global step 553:
20-03-23 22:49-INFO-training batch loss: 0.0016; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 128, Global step 554:
20-03-23 22:49-INFO-training batch loss: 0.0013; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 129, Global step 555:
20-03-23 22:49-INFO-training batch loss: 0.0019; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 130, Global step 556:
20-03-23 22:49-INFO-training batch loss: 0.0008; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 131, Global step 557:
20-03-23 22:49-INFO-training batch loss: 0.0020; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 132, Global step 558:
20-03-23 22:49-INFO-training batch loss: 0.0018; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 133, Global step 559:
20-03-23 22:49-INFO-training batch loss: 0.0011; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 134, Global step 560:
20-03-23 22:49-INFO-training batch loss: 0.0013; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 135, Global step 561:
20-03-23 22:49-INFO-training batch loss: 0.0015; avg_loss: 0.0023
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 136, Global step 562:
20-03-23 22:49-INFO-training batch loss: 0.0006; avg_loss: 0.0022
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 137, Global step 563:
20-03-23 22:49-INFO-training batch loss: 0.0011; avg_loss: 0.0022
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:49-INFO-Epoch 3, Batch 138, Global step 564:
20-03-23 22:49-INFO-training batch loss: 0.0010; avg_loss: 0.0022
20-03-23 22:49-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:49-INFO-
20-03-23 22:50-INFO-Epoch 3, Batch 139, Global step 565:
20-03-23 22:50-INFO-training batch loss: 0.0014; avg_loss: 0.0022
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 3, Batch 140, Global step 566:
20-03-23 22:50-INFO-training batch loss: 0.0012; avg_loss: 0.0022
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 3, Batch 141, Global step 567:
20-03-23 22:50-INFO-training batch loss: 0.0010; avg_loss: 0.0022
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 3, Batch 142, Global step 568:
20-03-23 22:50-INFO-training batch loss: 0.0027; avg_loss: 0.0022
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 3, training batch loss: 0.0027; avg_loss: 0.0022
20-03-23 22:50-INFO-Epoch 3, training batch accuracy: 1.0000; avg_accuracy: 0.9999
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 3, evaluating batch loss: 0.9142; avg_loss: 0.4193
20-03-23 22:50-INFO-Epoch 3, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9478
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 1, Global step 569:
20-03-23 22:50-INFO-training batch loss: 0.0014; avg_loss: 0.0014
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 2, Global step 570:
20-03-23 22:50-INFO-training batch loss: 0.0027; avg_loss: 0.0020
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 3, Global step 571:
20-03-23 22:50-INFO-training batch loss: 0.0014; avg_loss: 0.0018
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 4, Global step 572:
20-03-23 22:50-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 5, Global step 573:
20-03-23 22:50-INFO-training batch loss: 0.0014; avg_loss: 0.0016
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 6, Global step 574:
20-03-23 22:50-INFO-training batch loss: 0.0014; avg_loss: 0.0015
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:50-INFO-Epoch 4, Batch 7, Global step 575:
20-03-23 22:50-INFO-training batch loss: 0.0018; avg_loss: 0.0016
20-03-23 22:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:50-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 8, Global step 576:
20-03-23 22:51-INFO-training batch loss: 0.0021; avg_loss: 0.0016
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 9, Global step 577:
20-03-23 22:51-INFO-training batch loss: 0.0025; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 10, Global step 578:
20-03-23 22:51-INFO-training batch loss: 0.0017; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 11, Global step 579:
20-03-23 22:51-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 12, Global step 580:
20-03-23 22:51-INFO-training batch loss: 0.0010; avg_loss: 0.0016
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 13, Global step 581:
20-03-23 22:51-INFO-training batch loss: 0.0013; avg_loss: 0.0016
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 14, Global step 582:
20-03-23 22:51-INFO-training batch loss: 0.0020; avg_loss: 0.0016
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 15, Global step 583:
20-03-23 22:51-INFO-training batch loss: 0.0027; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 16, Global step 584:
20-03-23 22:51-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 17, Global step 585:
20-03-23 22:51-INFO-training batch loss: 0.0023; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 18, Global step 586:
20-03-23 22:51-INFO-training batch loss: 0.0020; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 19, Global step 587:
20-03-23 22:51-INFO-training batch loss: 0.0017; avg_loss: 0.0017
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:51-INFO-Epoch 4, Batch 20, Global step 588:
20-03-23 22:51-INFO-training batch loss: 0.0029; avg_loss: 0.0018
20-03-23 22:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:51-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 21, Global step 589:
20-03-23 22:52-INFO-training batch loss: 0.0017; avg_loss: 0.0018
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 22, Global step 590:
20-03-23 22:52-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 23, Global step 591:
20-03-23 22:52-INFO-training batch loss: 0.0017; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 24, Global step 592:
20-03-23 22:52-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 25, Global step 593:
20-03-23 22:52-INFO-training batch loss: 0.0013; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 26, Global step 594:
20-03-23 22:52-INFO-training batch loss: 0.0021; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 27, Global step 595:
20-03-23 22:52-INFO-training batch loss: 0.0014; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 28, Global step 596:
20-03-23 22:52-INFO-training batch loss: 0.0016; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 29, Global step 597:
20-03-23 22:52-INFO-training batch loss: 0.0014; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 30, Global step 598:
20-03-23 22:52-INFO-training batch loss: 0.0018; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 31, Global step 599:
20-03-23 22:52-INFO-training batch loss: 0.0026; avg_loss: 0.0017
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 32, Global step 600:
20-03-23 22:52-INFO-training batch loss: 0.0039; avg_loss: 0.0018
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:52-INFO-Epoch 4, Batch 33, Global step 601:
20-03-23 22:52-INFO-training batch loss: 0.0018; avg_loss: 0.0018
20-03-23 22:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:52-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 34, Global step 602:
20-03-23 22:53-INFO-training batch loss: 0.0017; avg_loss: 0.0018
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 35, Global step 603:
20-03-23 22:53-INFO-training batch loss: 0.0024; avg_loss: 0.0018
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 36, Global step 604:
20-03-23 22:53-INFO-training batch loss: 0.0030; avg_loss: 0.0018
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 37, Global step 605:
20-03-23 22:53-INFO-training batch loss: 0.0038; avg_loss: 0.0019
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 38, Global step 606:
20-03-23 22:53-INFO-training batch loss: 0.0029; avg_loss: 0.0019
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 39, Global step 607:
20-03-23 22:53-INFO-training batch loss: 0.0035; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 40, Global step 608:
20-03-23 22:53-INFO-training batch loss: 0.0022; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 41, Global step 609:
20-03-23 22:53-INFO-training batch loss: 0.0015; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 42, Global step 610:
20-03-23 22:53-INFO-training batch loss: 0.0033; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 43, Global step 611:
20-03-23 22:53-INFO-training batch loss: 0.0012; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 44, Global step 612:
20-03-23 22:53-INFO-training batch loss: 0.0021; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 45, Global step 613:
20-03-23 22:53-INFO-training batch loss: 0.0019; avg_loss: 0.0020
20-03-23 22:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 22:53-INFO-
20-03-23 22:53-INFO-Epoch 4, Batch 46, Global step 614:
20-03-23 22:53-INFO-training batch loss: 0.0105; avg_loss: 0.0022
20-03-23 22:53-INFO-training batch acc: 0.9961; avg_acc: 0.9999
20-03-23 22:53-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 47, Global step 615:
20-03-23 22:54-INFO-training batch loss: 0.0011; avg_loss: 0.0021
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 48, Global step 616:
20-03-23 22:54-INFO-training batch loss: 0.0014; avg_loss: 0.0021
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 49, Global step 617:
20-03-23 22:54-INFO-training batch loss: 0.0020; avg_loss: 0.0021
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 50, Global step 618:
20-03-23 22:54-INFO-training batch loss: 0.0110; avg_loss: 0.0023
20-03-23 22:54-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 51, Global step 619:
20-03-23 22:54-INFO-training batch loss: 0.0025; avg_loss: 0.0023
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 52, Global step 620:
20-03-23 22:54-INFO-training batch loss: 0.0037; avg_loss: 0.0023
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 53, Global step 621:
20-03-23 22:54-INFO-training batch loss: 0.0028; avg_loss: 0.0023
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 54, Global step 622:
20-03-23 22:54-INFO-training batch loss: 0.0055; avg_loss: 0.0024
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 55, Global step 623:
20-03-23 22:54-INFO-training batch loss: 0.0067; avg_loss: 0.0025
20-03-23 22:54-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 56, Global step 624:
20-03-23 22:54-INFO-training batch loss: 0.0023; avg_loss: 0.0025
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 57, Global step 625:
20-03-23 22:54-INFO-training batch loss: 0.0024; avg_loss: 0.0025
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 58, Global step 626:
20-03-23 22:54-INFO-training batch loss: 0.0049; avg_loss: 0.0025
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:54-INFO-Epoch 4, Batch 59, Global step 627:
20-03-23 22:54-INFO-training batch loss: 0.0020; avg_loss: 0.0025
20-03-23 22:54-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:54-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 60, Global step 628:
20-03-23 22:55-INFO-training batch loss: 0.0061; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 61, Global step 629:
20-03-23 22:55-INFO-training batch loss: 0.0039; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 62, Global step 630:
20-03-23 22:55-INFO-training batch loss: 0.0016; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 63, Global step 631:
20-03-23 22:55-INFO-training batch loss: 0.0043; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 64, Global step 632:
20-03-23 22:55-INFO-training batch loss: 0.0029; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 65, Global step 633:
20-03-23 22:55-INFO-training batch loss: 0.0045; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 66, Global step 634:
20-03-23 22:55-INFO-training batch loss: 0.0019; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 67, Global step 635:
20-03-23 22:55-INFO-training batch loss: 0.0036; avg_loss: 0.0026
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 68, Global step 636:
20-03-23 22:55-INFO-training batch loss: 0.0067; avg_loss: 0.0027
20-03-23 22:55-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 69, Global step 637:
20-03-23 22:55-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 70, Global step 638:
20-03-23 22:55-INFO-training batch loss: 0.0025; avg_loss: 0.0027
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 71, Global step 639:
20-03-23 22:55-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:55-INFO-Epoch 4, Batch 72, Global step 640:
20-03-23 22:55-INFO-training batch loss: 0.0032; avg_loss: 0.0027
20-03-23 22:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:55-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 73, Global step 641:
20-03-23 22:56-INFO-training batch loss: 0.0020; avg_loss: 0.0027
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 74, Global step 642:
20-03-23 22:56-INFO-training batch loss: 0.0029; avg_loss: 0.0027
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 75, Global step 643:
20-03-23 22:56-INFO-training batch loss: 0.0017; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 76, Global step 644:
20-03-23 22:56-INFO-training batch loss: 0.0011; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 77, Global step 645:
20-03-23 22:56-INFO-training batch loss: 0.0026; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 78, Global step 646:
20-03-23 22:56-INFO-training batch loss: 0.0022; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 79, Global step 647:
20-03-23 22:56-INFO-training batch loss: 0.0014; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 80, Global step 648:
20-03-23 22:56-INFO-training batch loss: 0.0021; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 81, Global step 649:
20-03-23 22:56-INFO-training batch loss: 0.0005; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 82, Global step 650:
20-03-23 22:56-INFO-training batch loss: 0.0039; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 83, Global step 651:
20-03-23 22:56-INFO-training batch loss: 0.0012; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 84, Global step 652:
20-03-23 22:56-INFO-training batch loss: 0.0086; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:56-INFO-Epoch 4, Batch 85, Global step 653:
20-03-23 22:56-INFO-training batch loss: 0.0013; avg_loss: 0.0026
20-03-23 22:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:56-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 86, Global step 654:
20-03-23 22:57-INFO-training batch loss: 0.0010; avg_loss: 0.0026
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 87, Global step 655:
20-03-23 22:57-INFO-training batch loss: 0.0027; avg_loss: 0.0026
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 88, Global step 656:
20-03-23 22:57-INFO-training batch loss: 0.0079; avg_loss: 0.0027
20-03-23 22:57-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 89, Global step 657:
20-03-23 22:57-INFO-training batch loss: 0.0052; avg_loss: 0.0027
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 90, Global step 658:
20-03-23 22:57-INFO-training batch loss: 0.0066; avg_loss: 0.0027
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 91, Global step 659:
20-03-23 22:57-INFO-training batch loss: 0.0036; avg_loss: 0.0028
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 92, Global step 660:
20-03-23 22:57-INFO-training batch loss: 0.0040; avg_loss: 0.0028
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 93, Global step 661:
20-03-23 22:57-INFO-training batch loss: 0.0016; avg_loss: 0.0028
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 94, Global step 662:
20-03-23 22:57-INFO-training batch loss: 0.0024; avg_loss: 0.0028
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 95, Global step 663:
20-03-23 22:57-INFO-training batch loss: 0.0042; avg_loss: 0.0028
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 96, Global step 664:
20-03-23 22:57-INFO-training batch loss: 0.0023; avg_loss: 0.0028
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 97, Global step 665:
20-03-23 22:57-INFO-training batch loss: 0.0015; avg_loss: 0.0027
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:57-INFO-Epoch 4, Batch 98, Global step 666:
20-03-23 22:57-INFO-training batch loss: 0.0024; avg_loss: 0.0027
20-03-23 22:57-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:57-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 99, Global step 667:
20-03-23 22:58-INFO-training batch loss: 0.0029; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 100, Global step 668:
20-03-23 22:58-INFO-training batch loss: 0.0044; avg_loss: 0.0028
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 101, Global step 669:
20-03-23 22:58-INFO-training batch loss: 0.0013; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 102, Global step 670:
20-03-23 22:58-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 103, Global step 671:
20-03-23 22:58-INFO-training batch loss: 0.0026; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 104, Global step 672:
20-03-23 22:58-INFO-training batch loss: 0.0023; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 105, Global step 673:
20-03-23 22:58-INFO-training batch loss: 0.0040; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 106, Global step 674:
20-03-23 22:58-INFO-training batch loss: 0.0029; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 107, Global step 675:
20-03-23 22:58-INFO-training batch loss: 0.0013; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 108, Global step 676:
20-03-23 22:58-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 109, Global step 677:
20-03-23 22:58-INFO-training batch loss: 0.0033; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 110, Global step 678:
20-03-23 22:58-INFO-training batch loss: 0.0023; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:58-INFO-Epoch 4, Batch 111, Global step 679:
20-03-23 22:58-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 22:58-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:58-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 112, Global step 680:
20-03-23 22:59-INFO-training batch loss: 0.0013; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 113, Global step 681:
20-03-23 22:59-INFO-training batch loss: 0.0008; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 114, Global step 682:
20-03-23 22:59-INFO-training batch loss: 0.0042; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 115, Global step 683:
20-03-23 22:59-INFO-training batch loss: 0.0017; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 116, Global step 684:
20-03-23 22:59-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 117, Global step 685:
20-03-23 22:59-INFO-training batch loss: 0.0031; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 118, Global step 686:
20-03-23 22:59-INFO-training batch loss: 0.0012; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 119, Global step 687:
20-03-23 22:59-INFO-training batch loss: 0.0009; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 120, Global step 688:
20-03-23 22:59-INFO-training batch loss: 0.0012; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 121, Global step 689:
20-03-23 22:59-INFO-training batch loss: 0.0016; avg_loss: 0.0026
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 122, Global step 690:
20-03-23 22:59-INFO-training batch loss: 0.0011; avg_loss: 0.0026
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 123, Global step 691:
20-03-23 22:59-INFO-training batch loss: 0.0045; avg_loss: 0.0027
20-03-23 22:59-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 22:59-INFO-Epoch 4, Batch 124, Global step 692:
20-03-23 22:59-INFO-training batch loss: 0.0015; avg_loss: 0.0026
20-03-23 22:59-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 22:59-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 125, Global step 693:
20-03-23 23:00-INFO-training batch loss: 0.0018; avg_loss: 0.0026
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 126, Global step 694:
20-03-23 23:00-INFO-training batch loss: 0.0018; avg_loss: 0.0026
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 127, Global step 695:
20-03-23 23:00-INFO-training batch loss: 0.0013; avg_loss: 0.0026
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 128, Global step 696:
20-03-23 23:00-INFO-training batch loss: 0.0012; avg_loss: 0.0026
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 129, Global step 697:
20-03-23 23:00-INFO-training batch loss: 0.0017; avg_loss: 0.0026
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 130, Global step 698:
20-03-23 23:00-INFO-training batch loss: 0.0011; avg_loss: 0.0026
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 131, Global step 699:
20-03-23 23:00-INFO-training batch loss: 0.0200; avg_loss: 0.0027
20-03-23 23:00-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 132, Global step 700:
20-03-23 23:00-INFO-training batch loss: 0.0026; avg_loss: 0.0027
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 133, Global step 701:
20-03-23 23:00-INFO-training batch loss: 0.0054; avg_loss: 0.0027
20-03-23 23:00-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 134, Global step 702:
20-03-23 23:00-INFO-training batch loss: 0.0044; avg_loss: 0.0028
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 135, Global step 703:
20-03-23 23:00-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 136, Global step 704:
20-03-23 23:00-INFO-training batch loss: 0.0030; avg_loss: 0.0028
20-03-23 23:00-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:00-INFO-
20-03-23 23:00-INFO-Epoch 4, Batch 137, Global step 705:
20-03-23 23:00-INFO-training batch loss: 0.0093; avg_loss: 0.0028
20-03-23 23:00-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:00-INFO-
20-03-23 23:01-INFO-Epoch 4, Batch 138, Global step 706:
20-03-23 23:01-INFO-training batch loss: 0.0019; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 4, Batch 139, Global step 707:
20-03-23 23:01-INFO-training batch loss: 0.0029; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 4, Batch 140, Global step 708:
20-03-23 23:01-INFO-training batch loss: 0.0034; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 4, Batch 141, Global step 709:
20-03-23 23:01-INFO-training batch loss: 0.0050; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 4, Batch 142, Global step 710:
20-03-23 23:01-INFO-training batch loss: 0.0070; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 0.9946; avg_acc: 0.9997
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 4, training batch loss: 0.0070; avg_loss: 0.0028
20-03-23 23:01-INFO-Epoch 4, training batch accuracy: 0.9946; avg_accuracy: 0.9997
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 4, evaluating batch loss: 0.9100; avg_loss: 0.4043
20-03-23 23:01-INFO-Epoch 4, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9452
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 5, Batch 1, Global step 711:
20-03-23 23:01-INFO-training batch loss: 0.0023; avg_loss: 0.0023
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 5, Batch 2, Global step 712:
20-03-23 23:01-INFO-training batch loss: 0.0036; avg_loss: 0.0030
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 5, Batch 3, Global step 713:
20-03-23 23:01-INFO-training batch loss: 0.0031; avg_loss: 0.0030
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 5, Batch 4, Global step 714:
20-03-23 23:01-INFO-training batch loss: 0.0021; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 5, Batch 5, Global step 715:
20-03-23 23:01-INFO-training batch loss: 0.0028; avg_loss: 0.0028
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:01-INFO-
20-03-23 23:01-INFO-Epoch 5, Batch 6, Global step 716:
20-03-23 23:01-INFO-training batch loss: 0.0034; avg_loss: 0.0029
20-03-23 23:01-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:01-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 7, Global step 717:
20-03-23 23:02-INFO-training batch loss: 0.0051; avg_loss: 0.0032
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 8, Global step 718:
20-03-23 23:02-INFO-training batch loss: 0.0042; avg_loss: 0.0033
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 9, Global step 719:
20-03-23 23:02-INFO-training batch loss: 0.0025; avg_loss: 0.0032
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 10, Global step 720:
20-03-23 23:02-INFO-training batch loss: 0.0022; avg_loss: 0.0031
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 11, Global step 721:
20-03-23 23:02-INFO-training batch loss: 0.0015; avg_loss: 0.0030
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 12, Global step 722:
20-03-23 23:02-INFO-training batch loss: 0.0030; avg_loss: 0.0030
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 13, Global step 723:
20-03-23 23:02-INFO-training batch loss: 0.0016; avg_loss: 0.0029
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 14, Global step 724:
20-03-23 23:02-INFO-training batch loss: 0.0014; avg_loss: 0.0028
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 15, Global step 725:
20-03-23 23:02-INFO-training batch loss: 0.0020; avg_loss: 0.0027
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 16, Global step 726:
20-03-23 23:02-INFO-training batch loss: 0.0054; avg_loss: 0.0029
20-03-23 23:02-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 17, Global step 727:
20-03-23 23:02-INFO-training batch loss: 0.0026; avg_loss: 0.0029
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 18, Global step 728:
20-03-23 23:02-INFO-training batch loss: 0.0015; avg_loss: 0.0028
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:02-INFO-
20-03-23 23:02-INFO-Epoch 5, Batch 19, Global step 729:
20-03-23 23:02-INFO-training batch loss: 0.0020; avg_loss: 0.0027
20-03-23 23:02-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:02-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 20, Global step 730:
20-03-23 23:03-INFO-training batch loss: 0.0014; avg_loss: 0.0027
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 21, Global step 731:
20-03-23 23:03-INFO-training batch loss: 0.0007; avg_loss: 0.0026
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 22, Global step 732:
20-03-23 23:03-INFO-training batch loss: 0.0013; avg_loss: 0.0025
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 23, Global step 733:
20-03-23 23:03-INFO-training batch loss: 0.0016; avg_loss: 0.0025
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 24, Global step 734:
20-03-23 23:03-INFO-training batch loss: 0.0014; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 25, Global step 735:
20-03-23 23:03-INFO-training batch loss: 0.0009; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 26, Global step 736:
20-03-23 23:03-INFO-training batch loss: 0.0048; avg_loss: 0.0025
20-03-23 23:03-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 27, Global step 737:
20-03-23 23:03-INFO-training batch loss: 0.0020; avg_loss: 0.0025
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 28, Global step 738:
20-03-23 23:03-INFO-training batch loss: 0.0010; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 29, Global step 739:
20-03-23 23:03-INFO-training batch loss: 0.0021; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 30, Global step 740:
20-03-23 23:03-INFO-training batch loss: 0.0029; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 31, Global step 741:
20-03-23 23:03-INFO-training batch loss: 0.0036; avg_loss: 0.0025
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 32, Global step 742:
20-03-23 23:03-INFO-training batch loss: 0.0012; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:03-INFO-Epoch 5, Batch 33, Global step 743:
20-03-23 23:03-INFO-training batch loss: 0.0010; avg_loss: 0.0024
20-03-23 23:03-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:03-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 34, Global step 744:
20-03-23 23:04-INFO-training batch loss: 0.0005; avg_loss: 0.0023
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 35, Global step 745:
20-03-23 23:04-INFO-training batch loss: 0.0015; avg_loss: 0.0023
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 36, Global step 746:
20-03-23 23:04-INFO-training batch loss: 0.0007; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 37, Global step 747:
20-03-23 23:04-INFO-training batch loss: 0.0012; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 38, Global step 748:
20-03-23 23:04-INFO-training batch loss: 0.0038; avg_loss: 0.0023
20-03-23 23:04-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 39, Global step 749:
20-03-23 23:04-INFO-training batch loss: 0.0012; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 40, Global step 750:
20-03-23 23:04-INFO-training batch loss: 0.0015; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 41, Global step 751:
20-03-23 23:04-INFO-training batch loss: 0.0018; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 42, Global step 752:
20-03-23 23:04-INFO-training batch loss: 0.0013; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 43, Global step 753:
20-03-23 23:04-INFO-training batch loss: 0.0018; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 44, Global step 754:
20-03-23 23:04-INFO-training batch loss: 0.0029; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 45, Global step 755:
20-03-23 23:04-INFO-training batch loss: 0.0022; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:04-INFO-Epoch 5, Batch 46, Global step 756:
20-03-23 23:04-INFO-training batch loss: 0.0018; avg_loss: 0.0022
20-03-23 23:04-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:04-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 47, Global step 757:
20-03-23 23:05-INFO-training batch loss: 0.0016; avg_loss: 0.0022
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 48, Global step 758:
20-03-23 23:05-INFO-training batch loss: 0.0018; avg_loss: 0.0022
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 49, Global step 759:
20-03-23 23:05-INFO-training batch loss: 0.0012; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 50, Global step 760:
20-03-23 23:05-INFO-training batch loss: 0.0016; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 51, Global step 761:
20-03-23 23:05-INFO-training batch loss: 0.0015; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 52, Global step 762:
20-03-23 23:05-INFO-training batch loss: 0.0012; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 53, Global step 763:
20-03-23 23:05-INFO-training batch loss: 0.0014; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 54, Global step 764:
20-03-23 23:05-INFO-training batch loss: 0.0010; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 55, Global step 765:
20-03-23 23:05-INFO-training batch loss: 0.0020; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 56, Global step 766:
20-03-23 23:05-INFO-training batch loss: 0.0018; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 57, Global step 767:
20-03-23 23:05-INFO-training batch loss: 0.0035; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 58, Global step 768:
20-03-23 23:05-INFO-training batch loss: 0.0012; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:05-INFO-Epoch 5, Batch 59, Global step 769:
20-03-23 23:05-INFO-training batch loss: 0.0015; avg_loss: 0.0021
20-03-23 23:05-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:05-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 60, Global step 770:
20-03-23 23:06-INFO-training batch loss: 0.0015; avg_loss: 0.0021
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 61, Global step 771:
20-03-23 23:06-INFO-training batch loss: 0.0013; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 62, Global step 772:
20-03-23 23:06-INFO-training batch loss: 0.0012; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 63, Global step 773:
20-03-23 23:06-INFO-training batch loss: 0.0014; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 64, Global step 774:
20-03-23 23:06-INFO-training batch loss: 0.0011; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 65, Global step 775:
20-03-23 23:06-INFO-training batch loss: 0.0009; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 66, Global step 776:
20-03-23 23:06-INFO-training batch loss: 0.0020; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 67, Global step 777:
20-03-23 23:06-INFO-training batch loss: 0.0009; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 68, Global step 778:
20-03-23 23:06-INFO-training batch loss: 0.0018; avg_loss: 0.0020
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 69, Global step 779:
20-03-23 23:06-INFO-training batch loss: 0.0006; avg_loss: 0.0019
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 70, Global step 780:
20-03-23 23:06-INFO-training batch loss: 0.0013; avg_loss: 0.0019
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 71, Global step 781:
20-03-23 23:06-INFO-training batch loss: 0.0011; avg_loss: 0.0019
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:06-INFO-Epoch 5, Batch 72, Global step 782:
20-03-23 23:06-INFO-training batch loss: 0.0006; avg_loss: 0.0019
20-03-23 23:06-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:06-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 73, Global step 783:
20-03-23 23:07-INFO-training batch loss: 0.0010; avg_loss: 0.0019
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 74, Global step 784:
20-03-23 23:07-INFO-training batch loss: 0.0006; avg_loss: 0.0019
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 75, Global step 785:
20-03-23 23:07-INFO-training batch loss: 0.0009; avg_loss: 0.0019
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 76, Global step 786:
20-03-23 23:07-INFO-training batch loss: 0.0009; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 77, Global step 787:
20-03-23 23:07-INFO-training batch loss: 0.0005; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 78, Global step 788:
20-03-23 23:07-INFO-training batch loss: 0.0010; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 79, Global step 789:
20-03-23 23:07-INFO-training batch loss: 0.0011; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 80, Global step 790:
20-03-23 23:07-INFO-training batch loss: 0.0006; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 81, Global step 791:
20-03-23 23:07-INFO-training batch loss: 0.0007; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 82, Global step 792:
20-03-23 23:07-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 83, Global step 793:
20-03-23 23:07-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 84, Global step 794:
20-03-23 23:07-INFO-training batch loss: 0.0011; avg_loss: 0.0018
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:07-INFO-Epoch 5, Batch 85, Global step 795:
20-03-23 23:07-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:07-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:07-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 86, Global step 796:
20-03-23 23:08-INFO-training batch loss: 0.0011; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 87, Global step 797:
20-03-23 23:08-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 88, Global step 798:
20-03-23 23:08-INFO-training batch loss: 0.0020; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 89, Global step 799:
20-03-23 23:08-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 90, Global step 800:
20-03-23 23:08-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 91, Global step 801:
20-03-23 23:08-INFO-training batch loss: 0.0014; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 92, Global step 802:
20-03-23 23:08-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 93, Global step 803:
20-03-23 23:08-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 94, Global step 804:
20-03-23 23:08-INFO-training batch loss: 0.0008; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 95, Global step 805:
20-03-23 23:08-INFO-training batch loss: 0.0013; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 96, Global step 806:
20-03-23 23:08-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 97, Global step 807:
20-03-23 23:08-INFO-training batch loss: 0.0011; avg_loss: 0.0017
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:08-INFO-Epoch 5, Batch 98, Global step 808:
20-03-23 23:08-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:08-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:08-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 99, Global step 809:
20-03-23 23:09-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 100, Global step 810:
20-03-23 23:09-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 101, Global step 811:
20-03-23 23:09-INFO-training batch loss: 0.0010; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 102, Global step 812:
20-03-23 23:09-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 103, Global step 813:
20-03-23 23:09-INFO-training batch loss: 0.0013; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 104, Global step 814:
20-03-23 23:09-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 105, Global step 815:
20-03-23 23:09-INFO-training batch loss: 0.0010; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 106, Global step 816:
20-03-23 23:09-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 107, Global step 817:
20-03-23 23:09-INFO-training batch loss: 0.0008; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 108, Global step 818:
20-03-23 23:09-INFO-training batch loss: 0.0023; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 109, Global step 819:
20-03-23 23:09-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 110, Global step 820:
20-03-23 23:09-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:09-INFO-Epoch 5, Batch 111, Global step 821:
20-03-23 23:09-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 23:09-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:09-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 112, Global step 822:
20-03-23 23:10-INFO-training batch loss: 0.0008; avg_loss: 0.0016
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 113, Global step 823:
20-03-23 23:10-INFO-training batch loss: 0.0010; avg_loss: 0.0016
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 114, Global step 824:
20-03-23 23:10-INFO-training batch loss: 0.0007; avg_loss: 0.0016
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 115, Global step 825:
20-03-23 23:10-INFO-training batch loss: 0.0007; avg_loss: 0.0016
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 116, Global step 826:
20-03-23 23:10-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 117, Global step 827:
20-03-23 23:10-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 118, Global step 828:
20-03-23 23:10-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 119, Global step 829:
20-03-23 23:10-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 120, Global step 830:
20-03-23 23:10-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 121, Global step 831:
20-03-23 23:10-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 122, Global step 832:
20-03-23 23:10-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 123, Global step 833:
20-03-23 23:10-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 124, Global step 834:
20-03-23 23:10-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:10-INFO-Epoch 5, Batch 125, Global step 835:
20-03-23 23:10-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 23:10-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:10-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 126, Global step 836:
20-03-23 23:11-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 127, Global step 837:
20-03-23 23:11-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 128, Global step 838:
20-03-23 23:11-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 129, Global step 839:
20-03-23 23:11-INFO-training batch loss: 0.0016; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 130, Global step 840:
20-03-23 23:11-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 131, Global step 841:
20-03-23 23:11-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 132, Global step 842:
20-03-23 23:11-INFO-training batch loss: 0.0013; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 133, Global step 843:
20-03-23 23:11-INFO-training batch loss: 0.0022; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 134, Global step 844:
20-03-23 23:11-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 135, Global step 845:
20-03-23 23:11-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 136, Global step 846:
20-03-23 23:11-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 137, Global step 847:
20-03-23 23:11-INFO-training batch loss: 0.0017; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:11-INFO-Epoch 5, Batch 138, Global step 848:
20-03-23 23:11-INFO-training batch loss: 0.0010; avg_loss: 0.0015
20-03-23 23:11-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:11-INFO-
20-03-23 23:12-INFO-Epoch 5, Batch 139, Global step 849:
20-03-23 23:12-INFO-training batch loss: 0.0018; avg_loss: 0.0015
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 5, Batch 140, Global step 850:
20-03-23 23:12-INFO-training batch loss: 0.0009; avg_loss: 0.0015
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 5, Batch 141, Global step 851:
20-03-23 23:12-INFO-training batch loss: 0.0012; avg_loss: 0.0015
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 5, Batch 142, Global step 852:
20-03-23 23:12-INFO-training batch loss: 0.0012; avg_loss: 0.0015
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 5, training batch loss: 0.0012; avg_loss: 0.0015
20-03-23 23:12-INFO-Epoch 5, training batch accuracy: 1.0000; avg_accuracy: 0.9999
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 5, evaluating batch loss: 1.1460; avg_loss: 0.5026
20-03-23 23:12-INFO-Epoch 5, evaluating batch accuracy: 0.8636; avg_accuracy: 0.9376
20-03-23 23:12-INFO-
20-03-23 23:12-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
20-03-23 23:12-INFO-Epoch 6, Batch 1, Global step 853:
20-03-23 23:12-INFO-training batch loss: 0.0015; avg_loss: 0.0015
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 6, Batch 2, Global step 854:
20-03-23 23:12-INFO-training batch loss: 0.0013; avg_loss: 0.0014
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 6, Batch 3, Global step 855:
20-03-23 23:12-INFO-training batch loss: 0.0050; avg_loss: 0.0026
20-03-23 23:12-INFO-training batch acc: 0.9961; avg_acc: 0.9987
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 6, Batch 4, Global step 856:
20-03-23 23:12-INFO-training batch loss: 0.0013; avg_loss: 0.0023
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 6, Batch 5, Global step 857:
20-03-23 23:12-INFO-training batch loss: 0.0013; avg_loss: 0.0021
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 6, Batch 6, Global step 858:
20-03-23 23:12-INFO-training batch loss: 0.0020; avg_loss: 0.0021
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 23:12-INFO-
20-03-23 23:12-INFO-Epoch 6, Batch 7, Global step 859:
20-03-23 23:12-INFO-training batch loss: 0.0021; avg_loss: 0.0021
20-03-23 23:12-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 23:12-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 8, Global step 860:
20-03-23 23:13-INFO-training batch loss: 0.0038; avg_loss: 0.0023
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 9, Global step 861:
20-03-23 23:13-INFO-training batch loss: 0.0031; avg_loss: 0.0024
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 10, Global step 862:
20-03-23 23:13-INFO-training batch loss: 0.0022; avg_loss: 0.0024
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 11, Global step 863:
20-03-23 23:13-INFO-training batch loss: 0.0013; avg_loss: 0.0023
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 12, Global step 864:
20-03-23 23:13-INFO-training batch loss: 0.0015; avg_loss: 0.0022
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 13, Global step 865:
20-03-23 23:13-INFO-training batch loss: 0.0030; avg_loss: 0.0023
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 14, Global step 866:
20-03-23 23:13-INFO-training batch loss: 0.0034; avg_loss: 0.0023
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 15, Global step 867:
20-03-23 23:13-INFO-training batch loss: 0.0050; avg_loss: 0.0025
20-03-23 23:13-INFO-training batch acc: 0.9961; avg_acc: 0.9995
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 16, Global step 868:
20-03-23 23:13-INFO-training batch loss: 0.0017; avg_loss: 0.0025
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 17, Global step 869:
20-03-23 23:13-INFO-training batch loss: 0.0018; avg_loss: 0.0024
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 18, Global step 870:
20-03-23 23:13-INFO-training batch loss: 0.0023; avg_loss: 0.0024
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 19, Global step 871:
20-03-23 23:13-INFO-training batch loss: 0.0018; avg_loss: 0.0024
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:13-INFO-
20-03-23 23:13-INFO-Epoch 6, Batch 20, Global step 872:
20-03-23 23:13-INFO-training batch loss: 0.0029; avg_loss: 0.0024
20-03-23 23:13-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:13-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 21, Global step 873:
20-03-23 23:14-INFO-training batch loss: 0.0011; avg_loss: 0.0024
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 22, Global step 874:
20-03-23 23:14-INFO-training batch loss: 0.0011; avg_loss: 0.0023
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 23, Global step 875:
20-03-23 23:14-INFO-training batch loss: 0.0012; avg_loss: 0.0023
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 24, Global step 876:
20-03-23 23:14-INFO-training batch loss: 0.0016; avg_loss: 0.0022
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 25, Global step 877:
20-03-23 23:14-INFO-training batch loss: 0.0027; avg_loss: 0.0022
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 26, Global step 878:
20-03-23 23:14-INFO-training batch loss: 0.0010; avg_loss: 0.0022
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 27, Global step 879:
20-03-23 23:14-INFO-training batch loss: 0.0010; avg_loss: 0.0022
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 28, Global step 880:
20-03-23 23:14-INFO-training batch loss: 0.0006; avg_loss: 0.0021
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 29, Global step 881:
20-03-23 23:14-INFO-training batch loss: 0.0018; avg_loss: 0.0021
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 30, Global step 882:
20-03-23 23:14-INFO-training batch loss: 0.0010; avg_loss: 0.0021
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 31, Global step 883:
20-03-23 23:14-INFO-training batch loss: 0.0015; avg_loss: 0.0020
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 32, Global step 884:
20-03-23 23:14-INFO-training batch loss: 0.0023; avg_loss: 0.0020
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:14-INFO-
20-03-23 23:14-INFO-Epoch 6, Batch 33, Global step 885:
20-03-23 23:14-INFO-training batch loss: 0.0016; avg_loss: 0.0020
20-03-23 23:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:14-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 34, Global step 886:
20-03-23 23:15-INFO-training batch loss: 0.0009; avg_loss: 0.0020
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 35, Global step 887:
20-03-23 23:15-INFO-training batch loss: 0.0007; avg_loss: 0.0020
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 36, Global step 888:
20-03-23 23:15-INFO-training batch loss: 0.0009; avg_loss: 0.0019
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 37, Global step 889:
20-03-23 23:15-INFO-training batch loss: 0.0008; avg_loss: 0.0019
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 38, Global step 890:
20-03-23 23:15-INFO-training batch loss: 0.0015; avg_loss: 0.0019
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 39, Global step 891:
20-03-23 23:15-INFO-training batch loss: 0.0006; avg_loss: 0.0019
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 40, Global step 892:
20-03-23 23:15-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 41, Global step 893:
20-03-23 23:15-INFO-training batch loss: 0.0020; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 42, Global step 894:
20-03-23 23:15-INFO-training batch loss: 0.0009; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 43, Global step 895:
20-03-23 23:15-INFO-training batch loss: 0.0009; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 44, Global step 896:
20-03-23 23:15-INFO-training batch loss: 0.0016; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 45, Global step 897:
20-03-23 23:15-INFO-training batch loss: 0.0010; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:15-INFO-Epoch 6, Batch 46, Global step 898:
20-03-23 23:15-INFO-training batch loss: 0.0015; avg_loss: 0.0018
20-03-23 23:15-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:15-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 47, Global step 899:
20-03-23 23:16-INFO-training batch loss: 0.0011; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 48, Global step 900:
20-03-23 23:16-INFO-training batch loss: 0.0019; avg_loss: 0.0018
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 49, Global step 901:
20-03-23 23:16-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 50, Global step 902:
20-03-23 23:16-INFO-training batch loss: 0.0024; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 51, Global step 903:
20-03-23 23:16-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 52, Global step 904:
20-03-23 23:16-INFO-training batch loss: 0.0046; avg_loss: 0.0018
20-03-23 23:16-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 53, Global step 905:
20-03-23 23:16-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 54, Global step 906:
20-03-23 23:16-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 55, Global step 907:
20-03-23 23:16-INFO-training batch loss: 0.0010; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 56, Global step 908:
20-03-23 23:16-INFO-training batch loss: 0.0016; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 57, Global step 909:
20-03-23 23:16-INFO-training batch loss: 0.0010; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:16-INFO-Epoch 6, Batch 58, Global step 910:
20-03-23 23:16-INFO-training batch loss: 0.0026; avg_loss: 0.0017
20-03-23 23:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:16-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 59, Global step 911:
20-03-23 23:17-INFO-training batch loss: 0.0008; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 60, Global step 912:
20-03-23 23:17-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 61, Global step 913:
20-03-23 23:17-INFO-training batch loss: 0.0017; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 62, Global step 914:
20-03-23 23:17-INFO-training batch loss: 0.0023; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 63, Global step 915:
20-03-23 23:17-INFO-training batch loss: 0.0013; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 64, Global step 916:
20-03-23 23:17-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 65, Global step 917:
20-03-23 23:17-INFO-training batch loss: 0.0014; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 66, Global step 918:
20-03-23 23:17-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 67, Global step 919:
20-03-23 23:17-INFO-training batch loss: 0.0014; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 68, Global step 920:
20-03-23 23:17-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 69, Global step 921:
20-03-23 23:17-INFO-training batch loss: 0.0013; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 70, Global step 922:
20-03-23 23:17-INFO-training batch loss: 0.0035; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:17-INFO-Epoch 6, Batch 71, Global step 923:
20-03-23 23:17-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:17-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:17-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 72, Global step 924:
20-03-23 23:18-INFO-training batch loss: 0.0016; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 73, Global step 925:
20-03-23 23:18-INFO-training batch loss: 0.0040; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 74, Global step 926:
20-03-23 23:18-INFO-training batch loss: 0.0022; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 75, Global step 927:
20-03-23 23:18-INFO-training batch loss: 0.0024; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 76, Global step 928:
20-03-23 23:18-INFO-training batch loss: 0.0024; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 77, Global step 929:
20-03-23 23:18-INFO-training batch loss: 0.0017; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 78, Global step 930:
20-03-23 23:18-INFO-training batch loss: 0.0020; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 79, Global step 931:
20-03-23 23:18-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 80, Global step 932:
20-03-23 23:18-INFO-training batch loss: 0.0016; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 81, Global step 933:
20-03-23 23:18-INFO-training batch loss: 0.0020; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 82, Global step 934:
20-03-23 23:18-INFO-training batch loss: 0.0036; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 83, Global step 935:
20-03-23 23:18-INFO-training batch loss: 0.0011; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:18-INFO-
20-03-23 23:18-INFO-Epoch 6, Batch 84, Global step 936:
20-03-23 23:18-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:18-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:18-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 85, Global step 937:
20-03-23 23:19-INFO-training batch loss: 0.0016; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 86, Global step 938:
20-03-23 23:19-INFO-training batch loss: 0.0011; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 87, Global step 939:
20-03-23 23:19-INFO-training batch loss: 0.0022; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 88, Global step 940:
20-03-23 23:19-INFO-training batch loss: 0.0016; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 89, Global step 941:
20-03-23 23:19-INFO-training batch loss: 0.0012; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 90, Global step 942:
20-03-23 23:19-INFO-training batch loss: 0.0010; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 91, Global step 943:
20-03-23 23:19-INFO-training batch loss: 0.0015; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 92, Global step 944:
20-03-23 23:19-INFO-training batch loss: 0.0025; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 93, Global step 945:
20-03-23 23:19-INFO-training batch loss: 0.0008; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 94, Global step 946:
20-03-23 23:19-INFO-training batch loss: 0.0015; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 95, Global step 947:
20-03-23 23:19-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 96, Global step 948:
20-03-23 23:19-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:19-INFO-Epoch 6, Batch 97, Global step 949:
20-03-23 23:19-INFO-training batch loss: 0.0008; avg_loss: 0.0017
20-03-23 23:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:19-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 98, Global step 950:
20-03-23 23:20-INFO-training batch loss: 0.0006; avg_loss: 0.0017
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 99, Global step 951:
20-03-23 23:20-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 100, Global step 952:
20-03-23 23:20-INFO-training batch loss: 0.0007; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 101, Global step 953:
20-03-23 23:20-INFO-training batch loss: 0.0012; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 102, Global step 954:
20-03-23 23:20-INFO-training batch loss: 0.0014; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 103, Global step 955:
20-03-23 23:20-INFO-training batch loss: 0.0016; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 104, Global step 956:
20-03-23 23:20-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 105, Global step 957:
20-03-23 23:20-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 106, Global step 958:
20-03-23 23:20-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 107, Global step 959:
20-03-23 23:20-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 108, Global step 960:
20-03-23 23:20-INFO-training batch loss: 0.0012; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 109, Global step 961:
20-03-23 23:20-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:20-INFO-Epoch 6, Batch 110, Global step 962:
20-03-23 23:20-INFO-training batch loss: 0.0010; avg_loss: 0.0016
20-03-23 23:20-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:20-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 111, Global step 963:
20-03-23 23:21-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 112, Global step 964:
20-03-23 23:21-INFO-training batch loss: 0.0014; avg_loss: 0.0016
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 113, Global step 965:
20-03-23 23:21-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 114, Global step 966:
20-03-23 23:21-INFO-training batch loss: 0.0008; avg_loss: 0.0016
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 115, Global step 967:
20-03-23 23:21-INFO-training batch loss: 0.0004; avg_loss: 0.0016
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 116, Global step 968:
20-03-23 23:21-INFO-training batch loss: 0.0004; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 117, Global step 969:
20-03-23 23:21-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 118, Global step 970:
20-03-23 23:21-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 119, Global step 971:
20-03-23 23:21-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 120, Global step 972:
20-03-23 23:21-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 121, Global step 973:
20-03-23 23:21-INFO-training batch loss: 0.0006; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 122, Global step 974:
20-03-23 23:21-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:21-INFO-Epoch 6, Batch 123, Global step 975:
20-03-23 23:21-INFO-training batch loss: 0.0005; avg_loss: 0.0015
20-03-23 23:21-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:21-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 124, Global step 976:
20-03-23 23:22-INFO-training batch loss: 0.0012; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 125, Global step 977:
20-03-23 23:22-INFO-training batch loss: 0.0014; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 126, Global step 978:
20-03-23 23:22-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 127, Global step 979:
20-03-23 23:22-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 128, Global step 980:
20-03-23 23:22-INFO-training batch loss: 0.0009; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 129, Global step 981:
20-03-23 23:22-INFO-training batch loss: 0.0003; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 130, Global step 982:
20-03-23 23:22-INFO-training batch loss: 0.0014; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 131, Global step 983:
20-03-23 23:22-INFO-training batch loss: 0.0007; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 132, Global step 984:
20-03-23 23:22-INFO-training batch loss: 0.0008; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 133, Global step 985:
20-03-23 23:22-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 134, Global step 986:
20-03-23 23:22-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 135, Global step 987:
20-03-23 23:22-INFO-training batch loss: 0.0011; avg_loss: 0.0015
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:22-INFO-Epoch 6, Batch 136, Global step 988:
20-03-23 23:22-INFO-training batch loss: 0.0008; avg_loss: 0.0014
20-03-23 23:22-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:22-INFO-
20-03-23 23:23-INFO-Epoch 6, Batch 137, Global step 989:
20-03-23 23:23-INFO-training batch loss: 0.0009; avg_loss: 0.0014
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, Batch 138, Global step 990:
20-03-23 23:23-INFO-training batch loss: 0.0004; avg_loss: 0.0014
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, Batch 139, Global step 991:
20-03-23 23:23-INFO-training batch loss: 0.0007; avg_loss: 0.0014
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, Batch 140, Global step 992:
20-03-23 23:23-INFO-training batch loss: 0.0005; avg_loss: 0.0014
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, Batch 141, Global step 993:
20-03-23 23:23-INFO-training batch loss: 0.0010; avg_loss: 0.0014
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, Batch 142, Global step 994:
20-03-23 23:23-INFO-training batch loss: 0.0006; avg_loss: 0.0014
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, training batch loss: 0.0006; avg_loss: 0.0014
20-03-23 23:23-INFO-Epoch 6, training batch accuracy: 1.0000; avg_accuracy: 0.9999
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 6, evaluating batch loss: 0.6427; avg_loss: 0.2973
20-03-23 23:23-INFO-Epoch 6, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9478
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 7, Batch 1, Global step 995:
20-03-23 23:23-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 7, Batch 2, Global step 996:
20-03-23 23:23-INFO-training batch loss: 0.0012; avg_loss: 0.0010
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 7, Batch 3, Global step 997:
20-03-23 23:23-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 7, Batch 4, Global step 998:
20-03-23 23:23-INFO-training batch loss: 0.0013; avg_loss: 0.0010
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:23-INFO-
20-03-23 23:23-INFO-Epoch 7, Batch 5, Global step 999:
20-03-23 23:23-INFO-training batch loss: 0.0008; avg_loss: 0.0010
20-03-23 23:23-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:23-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 6, Global step 1000:
20-03-23 23:24-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 7, Global step 1001:
20-03-23 23:24-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 8, Global step 1002:
20-03-23 23:24-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 9, Global step 1003:
20-03-23 23:24-INFO-training batch loss: 0.0011; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 10, Global step 1004:
20-03-23 23:24-INFO-training batch loss: 0.0011; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 11, Global step 1005:
20-03-23 23:24-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 12, Global step 1006:
20-03-23 23:24-INFO-training batch loss: 0.0010; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 13, Global step 1007:
20-03-23 23:24-INFO-training batch loss: 0.0013; avg_loss: 0.0010
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 14, Global step 1008:
20-03-23 23:24-INFO-training batch loss: 0.0011; avg_loss: 0.0010
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 15, Global step 1009:
20-03-23 23:24-INFO-training batch loss: 0.0009; avg_loss: 0.0010
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 16, Global step 1010:
20-03-23 23:24-INFO-training batch loss: 0.0009; avg_loss: 0.0010
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 17, Global step 1011:
20-03-23 23:24-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:24-INFO-Epoch 7, Batch 18, Global step 1012:
20-03-23 23:24-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:24-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:24-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 19, Global step 1013:
20-03-23 23:25-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 20, Global step 1014:
20-03-23 23:25-INFO-training batch loss: 0.0004; avg_loss: 0.0009
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 21, Global step 1015:
20-03-23 23:25-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 22, Global step 1016:
20-03-23 23:25-INFO-training batch loss: 0.0037; avg_loss: 0.0010
20-03-23 23:25-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 23, Global step 1017:
20-03-23 23:25-INFO-training batch loss: 0.0033; avg_loss: 0.0011
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 24, Global step 1018:
20-03-23 23:25-INFO-training batch loss: 0.0023; avg_loss: 0.0012
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 25, Global step 1019:
20-03-23 23:25-INFO-training batch loss: 0.0034; avg_loss: 0.0013
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 26, Global step 1020:
20-03-23 23:25-INFO-training batch loss: 0.0047; avg_loss: 0.0014
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 27, Global step 1021:
20-03-23 23:25-INFO-training batch loss: 0.0028; avg_loss: 0.0014
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 28, Global step 1022:
20-03-23 23:25-INFO-training batch loss: 0.0018; avg_loss: 0.0015
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 29, Global step 1023:
20-03-23 23:25-INFO-training batch loss: 0.0022; avg_loss: 0.0015
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 30, Global step 1024:
20-03-23 23:25-INFO-training batch loss: 0.0070; avg_loss: 0.0017
20-03-23 23:25-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:25-INFO-
20-03-23 23:25-INFO-Epoch 7, Batch 31, Global step 1025:
20-03-23 23:25-INFO-training batch loss: 0.0017; avg_loss: 0.0017
20-03-23 23:25-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:25-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 32, Global step 1026:
20-03-23 23:26-INFO-training batch loss: 0.0021; avg_loss: 0.0017
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 33, Global step 1027:
20-03-23 23:26-INFO-training batch loss: 0.0078; avg_loss: 0.0019
20-03-23 23:26-INFO-training batch acc: 0.9961; avg_acc: 0.9996
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 34, Global step 1028:
20-03-23 23:26-INFO-training batch loss: 0.0012; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 35, Global step 1029:
20-03-23 23:26-INFO-training batch loss: 0.0015; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 36, Global step 1030:
20-03-23 23:26-INFO-training batch loss: 0.0013; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 37, Global step 1031:
20-03-23 23:26-INFO-training batch loss: 0.0015; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 38, Global step 1032:
20-03-23 23:26-INFO-training batch loss: 0.0015; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 39, Global step 1033:
20-03-23 23:26-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 40, Global step 1034:
20-03-23 23:26-INFO-training batch loss: 0.0023; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 41, Global step 1035:
20-03-23 23:26-INFO-training batch loss: 0.0006; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 42, Global step 1036:
20-03-23 23:26-INFO-training batch loss: 0.0016; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 43, Global step 1037:
20-03-23 23:26-INFO-training batch loss: 0.0024; avg_loss: 0.0018
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:26-INFO-Epoch 7, Batch 44, Global step 1038:
20-03-23 23:26-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:26-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:26-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 45, Global step 1039:
20-03-23 23:27-INFO-training batch loss: 0.0006; avg_loss: 0.0017
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 46, Global step 1040:
20-03-23 23:27-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 47, Global step 1041:
20-03-23 23:27-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 48, Global step 1042:
20-03-23 23:27-INFO-training batch loss: 0.0007; avg_loss: 0.0016
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 49, Global step 1043:
20-03-23 23:27-INFO-training batch loss: 0.0011; avg_loss: 0.0016
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 50, Global step 1044:
20-03-23 23:27-INFO-training batch loss: 0.0008; avg_loss: 0.0016
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 51, Global step 1045:
20-03-23 23:27-INFO-training batch loss: 0.0017; avg_loss: 0.0016
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 52, Global step 1046:
20-03-23 23:27-INFO-training batch loss: 0.0053; avg_loss: 0.0017
20-03-23 23:27-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 53, Global step 1047:
20-03-23 23:27-INFO-training batch loss: 0.0008; avg_loss: 0.0017
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 54, Global step 1048:
20-03-23 23:27-INFO-training batch loss: 0.0098; avg_loss: 0.0018
20-03-23 23:27-INFO-training batch acc: 0.9961; avg_acc: 0.9996
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 55, Global step 1049:
20-03-23 23:27-INFO-training batch loss: 0.0026; avg_loss: 0.0018
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 56, Global step 1050:
20-03-23 23:27-INFO-training batch loss: 0.0027; avg_loss: 0.0019
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:27-INFO-
20-03-23 23:27-INFO-Epoch 7, Batch 57, Global step 1051:
20-03-23 23:27-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:27-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:27-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 58, Global step 1052:
20-03-23 23:28-INFO-training batch loss: 0.0008; avg_loss: 0.0018
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 59, Global step 1053:
20-03-23 23:28-INFO-training batch loss: 0.0016; avg_loss: 0.0018
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 60, Global step 1054:
20-03-23 23:28-INFO-training batch loss: 0.0062; avg_loss: 0.0019
20-03-23 23:28-INFO-training batch acc: 0.9961; avg_acc: 0.9996
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 61, Global step 1055:
20-03-23 23:28-INFO-training batch loss: 0.0042; avg_loss: 0.0019
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 62, Global step 1056:
20-03-23 23:28-INFO-training batch loss: 0.0007; avg_loss: 0.0019
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 63, Global step 1057:
20-03-23 23:28-INFO-training batch loss: 0.0058; avg_loss: 0.0020
20-03-23 23:28-INFO-training batch acc: 0.9961; avg_acc: 0.9996
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 64, Global step 1058:
20-03-23 23:28-INFO-training batch loss: 0.0084; avg_loss: 0.0021
20-03-23 23:28-INFO-training batch acc: 0.9961; avg_acc: 0.9995
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 65, Global step 1059:
20-03-23 23:28-INFO-training batch loss: 0.0027; avg_loss: 0.0021
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 66, Global step 1060:
20-03-23 23:28-INFO-training batch loss: 0.0036; avg_loss: 0.0021
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 67, Global step 1061:
20-03-23 23:28-INFO-training batch loss: 0.0028; avg_loss: 0.0021
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 68, Global step 1062:
20-03-23 23:28-INFO-training batch loss: 0.0020; avg_loss: 0.0021
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 69, Global step 1063:
20-03-23 23:28-INFO-training batch loss: 0.0080; avg_loss: 0.0022
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 70, Global step 1064:
20-03-23 23:28-INFO-training batch loss: 0.0017; avg_loss: 0.0022
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:28-INFO-
20-03-23 23:28-INFO-Epoch 7, Batch 71, Global step 1065:
20-03-23 23:28-INFO-training batch loss: 0.0016; avg_loss: 0.0022
20-03-23 23:28-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:28-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 72, Global step 1066:
20-03-23 23:29-INFO-training batch loss: 0.0013; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 73, Global step 1067:
20-03-23 23:29-INFO-training batch loss: 0.0013; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 74, Global step 1068:
20-03-23 23:29-INFO-training batch loss: 0.0025; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 75, Global step 1069:
20-03-23 23:29-INFO-training batch loss: 0.0020; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 76, Global step 1070:
20-03-23 23:29-INFO-training batch loss: 0.0014; avg_loss: 0.0021
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 77, Global step 1071:
20-03-23 23:29-INFO-training batch loss: 0.0050; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 78, Global step 1072:
20-03-23 23:29-INFO-training batch loss: 0.0009; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 79, Global step 1073:
20-03-23 23:29-INFO-training batch loss: 0.0009; avg_loss: 0.0022
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 80, Global step 1074:
20-03-23 23:29-INFO-training batch loss: 0.0015; avg_loss: 0.0021
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 81, Global step 1075:
20-03-23 23:29-INFO-training batch loss: 0.0007; avg_loss: 0.0021
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 82, Global step 1076:
20-03-23 23:29-INFO-training batch loss: 0.0021; avg_loss: 0.0021
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:29-INFO-Epoch 7, Batch 83, Global step 1077:
20-03-23 23:29-INFO-training batch loss: 0.0017; avg_loss: 0.0021
20-03-23 23:29-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:29-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 84, Global step 1078:
20-03-23 23:30-INFO-training batch loss: 0.0062; avg_loss: 0.0022
20-03-23 23:30-INFO-training batch acc: 0.9961; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 85, Global step 1079:
20-03-23 23:30-INFO-training batch loss: 0.0019; avg_loss: 0.0022
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 86, Global step 1080:
20-03-23 23:30-INFO-training batch loss: 0.0018; avg_loss: 0.0022
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 87, Global step 1081:
20-03-23 23:30-INFO-training batch loss: 0.0021; avg_loss: 0.0022
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 88, Global step 1082:
20-03-23 23:30-INFO-training batch loss: 0.0010; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 89, Global step 1083:
20-03-23 23:30-INFO-training batch loss: 0.0013; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 90, Global step 1084:
20-03-23 23:30-INFO-training batch loss: 0.0011; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 91, Global step 1085:
20-03-23 23:30-INFO-training batch loss: 0.0019; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 92, Global step 1086:
20-03-23 23:30-INFO-training batch loss: 0.0011; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 93, Global step 1087:
20-03-23 23:30-INFO-training batch loss: 0.0008; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 94, Global step 1088:
20-03-23 23:30-INFO-training batch loss: 0.0013; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 95, Global step 1089:
20-03-23 23:30-INFO-training batch loss: 0.0004; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:30-INFO-Epoch 7, Batch 96, Global step 1090:
20-03-23 23:30-INFO-training batch loss: 0.0005; avg_loss: 0.0021
20-03-23 23:30-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:30-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 97, Global step 1091:
20-03-23 23:31-INFO-training batch loss: 0.0008; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 98, Global step 1092:
20-03-23 23:31-INFO-training batch loss: 0.0016; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 99, Global step 1093:
20-03-23 23:31-INFO-training batch loss: 0.0004; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 100, Global step 1094:
20-03-23 23:31-INFO-training batch loss: 0.0004; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 101, Global step 1095:
20-03-23 23:31-INFO-training batch loss: 0.0008; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 102, Global step 1096:
20-03-23 23:31-INFO-training batch loss: 0.0003; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 103, Global step 1097:
20-03-23 23:31-INFO-training batch loss: 0.0004; avg_loss: 0.0020
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 104, Global step 1098:
20-03-23 23:31-INFO-training batch loss: 0.0006; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 105, Global step 1099:
20-03-23 23:31-INFO-training batch loss: 0.0008; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 106, Global step 1100:
20-03-23 23:31-INFO-training batch loss: 0.0007; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 107, Global step 1101:
20-03-23 23:31-INFO-training batch loss: 0.0005; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 108, Global step 1102:
20-03-23 23:31-INFO-training batch loss: 0.0007; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 109, Global step 1103:
20-03-23 23:31-INFO-training batch loss: 0.0007; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:31-INFO-Epoch 7, Batch 110, Global step 1104:
20-03-23 23:31-INFO-training batch loss: 0.0008; avg_loss: 0.0019
20-03-23 23:31-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:31-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 111, Global step 1105:
20-03-23 23:32-INFO-training batch loss: 0.0008; avg_loss: 0.0019
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 112, Global step 1106:
20-03-23 23:32-INFO-training batch loss: 0.0003; avg_loss: 0.0019
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 113, Global step 1107:
20-03-23 23:32-INFO-training batch loss: 0.0003; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 114, Global step 1108:
20-03-23 23:32-INFO-training batch loss: 0.0007; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 115, Global step 1109:
20-03-23 23:32-INFO-training batch loss: 0.0003; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 116, Global step 1110:
20-03-23 23:32-INFO-training batch loss: 0.0005; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 117, Global step 1111:
20-03-23 23:32-INFO-training batch loss: 0.0011; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 118, Global step 1112:
20-03-23 23:32-INFO-training batch loss: 0.0003; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 119, Global step 1113:
20-03-23 23:32-INFO-training batch loss: 0.0011; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 120, Global step 1114:
20-03-23 23:32-INFO-training batch loss: 0.0005; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 121, Global step 1115:
20-03-23 23:32-INFO-training batch loss: 0.0006; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:32-INFO-Epoch 7, Batch 122, Global step 1116:
20-03-23 23:32-INFO-training batch loss: 0.0005; avg_loss: 0.0018
20-03-23 23:32-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:32-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 123, Global step 1117:
20-03-23 23:33-INFO-training batch loss: 0.0006; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 124, Global step 1118:
20-03-23 23:33-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 125, Global step 1119:
20-03-23 23:33-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 126, Global step 1120:
20-03-23 23:33-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 127, Global step 1121:
20-03-23 23:33-INFO-training batch loss: 0.0004; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 128, Global step 1122:
20-03-23 23:33-INFO-training batch loss: 0.0005; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 129, Global step 1123:
20-03-23 23:33-INFO-training batch loss: 0.0004; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 130, Global step 1124:
20-03-23 23:33-INFO-training batch loss: 0.0006; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 131, Global step 1125:
20-03-23 23:33-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 132, Global step 1126:
20-03-23 23:33-INFO-training batch loss: 0.0007; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 133, Global step 1127:
20-03-23 23:33-INFO-training batch loss: 0.0009; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 134, Global step 1128:
20-03-23 23:33-INFO-training batch loss: 0.0006; avg_loss: 0.0017
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:33-INFO-Epoch 7, Batch 135, Global step 1129:
20-03-23 23:33-INFO-training batch loss: 0.0003; avg_loss: 0.0016
20-03-23 23:33-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:33-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 136, Global step 1130:
20-03-23 23:34-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 137, Global step 1131:
20-03-23 23:34-INFO-training batch loss: 0.0014; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 138, Global step 1132:
20-03-23 23:34-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 139, Global step 1133:
20-03-23 23:34-INFO-training batch loss: 0.0005; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 140, Global step 1134:
20-03-23 23:34-INFO-training batch loss: 0.0009; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 141, Global step 1135:
20-03-23 23:34-INFO-training batch loss: 0.0017; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, Batch 142, Global step 1136:
20-03-23 23:34-INFO-training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, training batch loss: 0.0006; avg_loss: 0.0016
20-03-23 23:34-INFO-Epoch 7, training batch accuracy: 1.0000; avg_accuracy: 0.9998
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 7, evaluating batch loss: 1.0663; avg_loss: 0.4795
20-03-23 23:34-INFO-Epoch 7, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9478
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 8, Batch 1, Global step 1137:
20-03-23 23:34-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 8, Batch 2, Global step 1138:
20-03-23 23:34-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 8, Batch 3, Global step 1139:
20-03-23 23:34-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 8, Batch 4, Global step 1140:
20-03-23 23:34-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:34-INFO-
20-03-23 23:34-INFO-Epoch 8, Batch 5, Global step 1141:
20-03-23 23:34-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:34-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 6, Global step 1142:
20-03-23 23:35-INFO-training batch loss: 0.0004; avg_loss: 0.0008
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 7, Global step 1143:
20-03-23 23:35-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 8, Global step 1144:
20-03-23 23:35-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 9, Global step 1145:
20-03-23 23:35-INFO-training batch loss: 0.0013; avg_loss: 0.0009
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 10, Global step 1146:
20-03-23 23:35-INFO-training batch loss: 0.0022; avg_loss: 0.0010
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 11, Global step 1147:
20-03-23 23:35-INFO-training batch loss: 0.0012; avg_loss: 0.0010
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 12, Global step 1148:
20-03-23 23:35-INFO-training batch loss: 0.0014; avg_loss: 0.0010
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 13, Global step 1149:
20-03-23 23:35-INFO-training batch loss: 0.0008; avg_loss: 0.0010
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 14, Global step 1150:
20-03-23 23:35-INFO-training batch loss: 0.0021; avg_loss: 0.0011
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 15, Global step 1151:
20-03-23 23:35-INFO-training batch loss: 0.0016; avg_loss: 0.0011
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 16, Global step 1152:
20-03-23 23:35-INFO-training batch loss: 0.0011; avg_loss: 0.0011
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 17, Global step 1153:
20-03-23 23:35-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:35-INFO-Epoch 8, Batch 18, Global step 1154:
20-03-23 23:35-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:35-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 19, Global step 1155:
20-03-23 23:36-INFO-training batch loss: 0.0016; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 20, Global step 1156:
20-03-23 23:36-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 21, Global step 1157:
20-03-23 23:36-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 22, Global step 1158:
20-03-23 23:36-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 23, Global step 1159:
20-03-23 23:36-INFO-training batch loss: 0.0013; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 24, Global step 1160:
20-03-23 23:36-INFO-training batch loss: 0.0025; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 25, Global step 1161:
20-03-23 23:36-INFO-training batch loss: 0.0005; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 26, Global step 1162:
20-03-23 23:36-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 27, Global step 1163:
20-03-23 23:36-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 28, Global step 1164:
20-03-23 23:36-INFO-training batch loss: 0.0007; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 29, Global step 1165:
20-03-23 23:36-INFO-training batch loss: 0.0010; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 30, Global step 1166:
20-03-23 23:36-INFO-training batch loss: 0.0011; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:36-INFO-Epoch 8, Batch 31, Global step 1167:
20-03-23 23:36-INFO-training batch loss: 0.0014; avg_loss: 0.0011
20-03-23 23:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:36-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 32, Global step 1168:
20-03-23 23:37-INFO-training batch loss: 0.0015; avg_loss: 0.0011
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 33, Global step 1169:
20-03-23 23:37-INFO-training batch loss: 0.0012; avg_loss: 0.0011
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 34, Global step 1170:
20-03-23 23:37-INFO-training batch loss: 0.0035; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 35, Global step 1171:
20-03-23 23:37-INFO-training batch loss: 0.0007; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 36, Global step 1172:
20-03-23 23:37-INFO-training batch loss: 0.0008; avg_loss: 0.0011
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 37, Global step 1173:
20-03-23 23:37-INFO-training batch loss: 0.0013; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 38, Global step 1174:
20-03-23 23:37-INFO-training batch loss: 0.0014; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 39, Global step 1175:
20-03-23 23:37-INFO-training batch loss: 0.0018; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 40, Global step 1176:
20-03-23 23:37-INFO-training batch loss: 0.0020; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 41, Global step 1177:
20-03-23 23:37-INFO-training batch loss: 0.0007; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 42, Global step 1178:
20-03-23 23:37-INFO-training batch loss: 0.0010; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 43, Global step 1179:
20-03-23 23:37-INFO-training batch loss: 0.0011; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:37-INFO-Epoch 8, Batch 44, Global step 1180:
20-03-23 23:37-INFO-training batch loss: 0.0009; avg_loss: 0.0012
20-03-23 23:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:37-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 45, Global step 1181:
20-03-23 23:38-INFO-training batch loss: 0.0004; avg_loss: 0.0012
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 46, Global step 1182:
20-03-23 23:38-INFO-training batch loss: 0.0011; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 47, Global step 1183:
20-03-23 23:38-INFO-training batch loss: 0.0008; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 48, Global step 1184:
20-03-23 23:38-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 49, Global step 1185:
20-03-23 23:38-INFO-training batch loss: 0.0004; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 50, Global step 1186:
20-03-23 23:38-INFO-training batch loss: 0.0010; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 51, Global step 1187:
20-03-23 23:38-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 52, Global step 1188:
20-03-23 23:38-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 53, Global step 1189:
20-03-23 23:38-INFO-training batch loss: 0.0002; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 54, Global step 1190:
20-03-23 23:38-INFO-training batch loss: 0.0014; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 55, Global step 1191:
20-03-23 23:38-INFO-training batch loss: 0.0010; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 56, Global step 1192:
20-03-23 23:38-INFO-training batch loss: 0.0006; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:38-INFO-Epoch 8, Batch 57, Global step 1193:
20-03-23 23:38-INFO-training batch loss: 0.0007; avg_loss: 0.0011
20-03-23 23:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:38-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 58, Global step 1194:
20-03-23 23:39-INFO-training batch loss: 0.0008; avg_loss: 0.0011
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 59, Global step 1195:
20-03-23 23:39-INFO-training batch loss: 0.0007; avg_loss: 0.0011
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 60, Global step 1196:
20-03-23 23:39-INFO-training batch loss: 0.0009; avg_loss: 0.0011
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 61, Global step 1197:
20-03-23 23:39-INFO-training batch loss: 0.0005; avg_loss: 0.0011
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 62, Global step 1198:
20-03-23 23:39-INFO-training batch loss: 0.0004; avg_loss: 0.0011
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 63, Global step 1199:
20-03-23 23:39-INFO-training batch loss: 0.0005; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 64, Global step 1200:
20-03-23 23:39-INFO-training batch loss: 0.0011; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 65, Global step 1201:
20-03-23 23:39-INFO-training batch loss: 0.0010; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 66, Global step 1202:
20-03-23 23:39-INFO-training batch loss: 0.0005; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 67, Global step 1203:
20-03-23 23:39-INFO-training batch loss: 0.0004; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 68, Global step 1204:
20-03-23 23:39-INFO-training batch loss: 0.0006; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 69, Global step 1205:
20-03-23 23:39-INFO-training batch loss: 0.0007; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:39-INFO-Epoch 8, Batch 70, Global step 1206:
20-03-23 23:39-INFO-training batch loss: 0.0005; avg_loss: 0.0010
20-03-23 23:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:39-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 71, Global step 1207:
20-03-23 23:40-INFO-training batch loss: 0.0012; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 72, Global step 1208:
20-03-23 23:40-INFO-training batch loss: 0.0011; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 73, Global step 1209:
20-03-23 23:40-INFO-training batch loss: 0.0006; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 74, Global step 1210:
20-03-23 23:40-INFO-training batch loss: 0.0007; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 75, Global step 1211:
20-03-23 23:40-INFO-training batch loss: 0.0007; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 76, Global step 1212:
20-03-23 23:40-INFO-training batch loss: 0.0006; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 77, Global step 1213:
20-03-23 23:40-INFO-training batch loss: 0.0005; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 78, Global step 1214:
20-03-23 23:40-INFO-training batch loss: 0.0007; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 79, Global step 1215:
20-03-23 23:40-INFO-training batch loss: 0.0009; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 80, Global step 1216:
20-03-23 23:40-INFO-training batch loss: 0.0019; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 81, Global step 1217:
20-03-23 23:40-INFO-training batch loss: 0.0004; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 82, Global step 1218:
20-03-23 23:40-INFO-training batch loss: 0.0006; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:40-INFO-Epoch 8, Batch 83, Global step 1219:
20-03-23 23:40-INFO-training batch loss: 0.0005; avg_loss: 0.0010
20-03-23 23:40-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:40-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 84, Global step 1220:
20-03-23 23:41-INFO-training batch loss: 0.0006; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 85, Global step 1221:
20-03-23 23:41-INFO-training batch loss: 0.0008; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 86, Global step 1222:
20-03-23 23:41-INFO-training batch loss: 0.0005; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 87, Global step 1223:
20-03-23 23:41-INFO-training batch loss: 0.0008; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 88, Global step 1224:
20-03-23 23:41-INFO-training batch loss: 0.0008; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 89, Global step 1225:
20-03-23 23:41-INFO-training batch loss: 0.0010; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 90, Global step 1226:
20-03-23 23:41-INFO-training batch loss: 0.0006; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 91, Global step 1227:
20-03-23 23:41-INFO-training batch loss: 0.0008; avg_loss: 0.0010
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 92, Global step 1228:
20-03-23 23:41-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 93, Global step 1229:
20-03-23 23:41-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 94, Global step 1230:
20-03-23 23:41-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 95, Global step 1231:
20-03-23 23:41-INFO-training batch loss: 0.0011; avg_loss: 0.0009
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:41-INFO-Epoch 8, Batch 96, Global step 1232:
20-03-23 23:41-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:41-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:41-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 97, Global step 1233:
20-03-23 23:42-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 98, Global step 1234:
20-03-23 23:42-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 99, Global step 1235:
20-03-23 23:42-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 100, Global step 1236:
20-03-23 23:42-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 101, Global step 1237:
20-03-23 23:42-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 102, Global step 1238:
20-03-23 23:42-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 103, Global step 1239:
20-03-23 23:42-INFO-training batch loss: 0.0011; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 104, Global step 1240:
20-03-23 23:42-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 105, Global step 1241:
20-03-23 23:42-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 106, Global step 1242:
20-03-23 23:42-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 107, Global step 1243:
20-03-23 23:42-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 108, Global step 1244:
20-03-23 23:42-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:42-INFO-Epoch 8, Batch 109, Global step 1245:
20-03-23 23:42-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:42-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:42-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 110, Global step 1246:
20-03-23 23:43-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 111, Global step 1247:
20-03-23 23:43-INFO-training batch loss: 0.0004; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 112, Global step 1248:
20-03-23 23:43-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 113, Global step 1249:
20-03-23 23:43-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 114, Global step 1250:
20-03-23 23:43-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 115, Global step 1251:
20-03-23 23:43-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 116, Global step 1252:
20-03-23 23:43-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 117, Global step 1253:
20-03-23 23:43-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 118, Global step 1254:
20-03-23 23:43-INFO-training batch loss: 0.0010; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 119, Global step 1255:
20-03-23 23:43-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 120, Global step 1256:
20-03-23 23:43-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 121, Global step 1257:
20-03-23 23:43-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:43-INFO-Epoch 8, Batch 122, Global step 1258:
20-03-23 23:43-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:43-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:43-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 123, Global step 1259:
20-03-23 23:44-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 124, Global step 1260:
20-03-23 23:44-INFO-training batch loss: 0.0010; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 125, Global step 1261:
20-03-23 23:44-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 126, Global step 1262:
20-03-23 23:44-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 127, Global step 1263:
20-03-23 23:44-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 128, Global step 1264:
20-03-23 23:44-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 129, Global step 1265:
20-03-23 23:44-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 130, Global step 1266:
20-03-23 23:44-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 131, Global step 1267:
20-03-23 23:44-INFO-training batch loss: 0.0004; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 132, Global step 1268:
20-03-23 23:44-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 133, Global step 1269:
20-03-23 23:44-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 134, Global step 1270:
20-03-23 23:44-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:44-INFO-Epoch 8, Batch 135, Global step 1271:
20-03-23 23:44-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:44-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:44-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 136, Global step 1272:
20-03-23 23:45-INFO-training batch loss: 0.0009; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 137, Global step 1273:
20-03-23 23:45-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 138, Global step 1274:
20-03-23 23:45-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 139, Global step 1275:
20-03-23 23:45-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 140, Global step 1276:
20-03-23 23:45-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 141, Global step 1277:
20-03-23 23:45-INFO-training batch loss: 0.0004; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, Batch 142, Global step 1278:
20-03-23 23:45-INFO-training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, training batch loss: 0.0007; avg_loss: 0.0009
20-03-23 23:45-INFO-Epoch 8, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 8, evaluating batch loss: 1.0598; avg_loss: 0.4389
20-03-23 23:45-INFO-Epoch 8, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9478
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 9, Batch 1, Global step 1279:
20-03-23 23:45-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 9, Batch 2, Global step 1280:
20-03-23 23:45-INFO-training batch loss: 0.0007; avg_loss: 0.0007
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 9, Batch 3, Global step 1281:
20-03-23 23:45-INFO-training batch loss: 0.0006; avg_loss: 0.0007
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 9, Batch 4, Global step 1282:
20-03-23 23:45-INFO-training batch loss: 0.0008; avg_loss: 0.0007
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:45-INFO-Epoch 9, Batch 5, Global step 1283:
20-03-23 23:45-INFO-training batch loss: 0.0008; avg_loss: 0.0007
20-03-23 23:45-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:45-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 6, Global step 1284:
20-03-23 23:46-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 7, Global step 1285:
20-03-23 23:46-INFO-training batch loss: 0.0013; avg_loss: 0.0009
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 8, Global step 1286:
20-03-23 23:46-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 9, Global step 1287:
20-03-23 23:46-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 10, Global step 1288:
20-03-23 23:46-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 11, Global step 1289:
20-03-23 23:46-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 12, Global step 1290:
20-03-23 23:46-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 13, Global step 1291:
20-03-23 23:46-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 14, Global step 1292:
20-03-23 23:46-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 15, Global step 1293:
20-03-23 23:46-INFO-training batch loss: 0.0014; avg_loss: 0.0009
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 16, Global step 1294:
20-03-23 23:46-INFO-training batch loss: 0.0021; avg_loss: 0.0009
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 17, Global step 1295:
20-03-23 23:46-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:46-INFO-Epoch 9, Batch 18, Global step 1296:
20-03-23 23:46-INFO-training batch loss: 0.0010; avg_loss: 0.0009
20-03-23 23:46-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:46-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 19, Global step 1297:
20-03-23 23:47-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 20, Global step 1298:
20-03-23 23:47-INFO-training batch loss: 0.0012; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 21, Global step 1299:
20-03-23 23:47-INFO-training batch loss: 0.0013; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 22, Global step 1300:
20-03-23 23:47-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 23, Global step 1301:
20-03-23 23:47-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 24, Global step 1302:
20-03-23 23:47-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 25, Global step 1303:
20-03-23 23:47-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 26, Global step 1304:
20-03-23 23:47-INFO-training batch loss: 0.0010; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 27, Global step 1305:
20-03-23 23:47-INFO-training batch loss: 0.0011; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 28, Global step 1306:
20-03-23 23:47-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 29, Global step 1307:
20-03-23 23:47-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 30, Global step 1308:
20-03-23 23:47-INFO-training batch loss: 0.0006; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:47-INFO-Epoch 9, Batch 31, Global step 1309:
20-03-23 23:47-INFO-training batch loss: 0.0008; avg_loss: 0.0009
20-03-23 23:47-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:47-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 32, Global step 1310:
20-03-23 23:48-INFO-training batch loss: 0.0004; avg_loss: 0.0009
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 33, Global step 1311:
20-03-23 23:48-INFO-training batch loss: 0.0005; avg_loss: 0.0009
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 34, Global step 1312:
20-03-23 23:48-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 35, Global step 1313:
20-03-23 23:48-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 36, Global step 1314:
20-03-23 23:48-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 37, Global step 1315:
20-03-23 23:48-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 38, Global step 1316:
20-03-23 23:48-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 39, Global step 1317:
20-03-23 23:48-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 40, Global step 1318:
20-03-23 23:48-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 41, Global step 1319:
20-03-23 23:48-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 42, Global step 1320:
20-03-23 23:48-INFO-training batch loss: 0.0003; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 43, Global step 1321:
20-03-23 23:48-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:48-INFO-Epoch 9, Batch 44, Global step 1322:
20-03-23 23:48-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:48-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:48-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 45, Global step 1323:
20-03-23 23:49-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 46, Global step 1324:
20-03-23 23:49-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 47, Global step 1325:
20-03-23 23:49-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 48, Global step 1326:
20-03-23 23:49-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 49, Global step 1327:
20-03-23 23:49-INFO-training batch loss: 0.0004; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 50, Global step 1328:
20-03-23 23:49-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 51, Global step 1329:
20-03-23 23:49-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 52, Global step 1330:
20-03-23 23:49-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 53, Global step 1331:
20-03-23 23:49-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 54, Global step 1332:
20-03-23 23:49-INFO-training batch loss: 0.0018; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 55, Global step 1333:
20-03-23 23:49-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 56, Global step 1334:
20-03-23 23:49-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:49-INFO-Epoch 9, Batch 57, Global step 1335:
20-03-23 23:49-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:49-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:49-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 58, Global step 1336:
20-03-23 23:50-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 59, Global step 1337:
20-03-23 23:50-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 60, Global step 1338:
20-03-23 23:50-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 61, Global step 1339:
20-03-23 23:50-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 62, Global step 1340:
20-03-23 23:50-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 63, Global step 1341:
20-03-23 23:50-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 64, Global step 1342:
20-03-23 23:50-INFO-training batch loss: 0.0013; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 65, Global step 1343:
20-03-23 23:50-INFO-training batch loss: 0.0016; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 66, Global step 1344:
20-03-23 23:50-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 67, Global step 1345:
20-03-23 23:50-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 68, Global step 1346:
20-03-23 23:50-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 69, Global step 1347:
20-03-23 23:50-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:50-INFO-Epoch 9, Batch 70, Global step 1348:
20-03-23 23:50-INFO-training batch loss: 0.0012; avg_loss: 0.0008
20-03-23 23:50-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:50-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 71, Global step 1349:
20-03-23 23:51-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 72, Global step 1350:
20-03-23 23:51-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 73, Global step 1351:
20-03-23 23:51-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 74, Global step 1352:
20-03-23 23:51-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 75, Global step 1353:
20-03-23 23:51-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 76, Global step 1354:
20-03-23 23:51-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 77, Global step 1355:
20-03-23 23:51-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 78, Global step 1356:
20-03-23 23:51-INFO-training batch loss: 0.0003; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 79, Global step 1357:
20-03-23 23:51-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 80, Global step 1358:
20-03-23 23:51-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 81, Global step 1359:
20-03-23 23:51-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 82, Global step 1360:
20-03-23 23:51-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:51-INFO-Epoch 9, Batch 83, Global step 1361:
20-03-23 23:51-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:51-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:51-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 84, Global step 1362:
20-03-23 23:52-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 85, Global step 1363:
20-03-23 23:52-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 86, Global step 1364:
20-03-23 23:52-INFO-training batch loss: 0.0004; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 87, Global step 1365:
20-03-23 23:52-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 88, Global step 1366:
20-03-23 23:52-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 89, Global step 1367:
20-03-23 23:52-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 90, Global step 1368:
20-03-23 23:52-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 91, Global step 1369:
20-03-23 23:52-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 92, Global step 1370:
20-03-23 23:52-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 93, Global step 1371:
20-03-23 23:52-INFO-training batch loss: 0.0003; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 94, Global step 1372:
20-03-23 23:52-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 95, Global step 1373:
20-03-23 23:52-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:52-INFO-Epoch 9, Batch 96, Global step 1374:
20-03-23 23:52-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:52-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:52-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 97, Global step 1375:
20-03-23 23:53-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 98, Global step 1376:
20-03-23 23:53-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 99, Global step 1377:
20-03-23 23:53-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 100, Global step 1378:
20-03-23 23:53-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 101, Global step 1379:
20-03-23 23:53-INFO-training batch loss: 0.0004; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 102, Global step 1380:
20-03-23 23:53-INFO-training batch loss: 0.0005; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 103, Global step 1381:
20-03-23 23:53-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 104, Global step 1382:
20-03-23 23:53-INFO-training batch loss: 0.0015; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 105, Global step 1383:
20-03-23 23:53-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 106, Global step 1384:
20-03-23 23:53-INFO-training batch loss: 0.0007; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 107, Global step 1385:
20-03-23 23:53-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 108, Global step 1386:
20-03-23 23:53-INFO-training batch loss: 0.0019; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:53-INFO-Epoch 9, Batch 109, Global step 1387:
20-03-23 23:53-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:53-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:53-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 110, Global step 1388:
20-03-23 23:54-INFO-training batch loss: 0.0013; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 111, Global step 1389:
20-03-23 23:54-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 112, Global step 1390:
20-03-23 23:54-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 113, Global step 1391:
20-03-23 23:54-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 114, Global step 1392:
20-03-23 23:54-INFO-training batch loss: 0.0013; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 115, Global step 1393:
20-03-23 23:54-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 116, Global step 1394:
20-03-23 23:54-INFO-training batch loss: 0.0011; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 117, Global step 1395:
20-03-23 23:54-INFO-training batch loss: 0.0008; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 118, Global step 1396:
20-03-23 23:54-INFO-training batch loss: 0.0009; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 119, Global step 1397:
20-03-23 23:54-INFO-training batch loss: 0.0006; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 120, Global step 1398:
20-03-23 23:54-INFO-training batch loss: 0.0012; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 121, Global step 1399:
20-03-23 23:54-INFO-training batch loss: 0.0010; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:54-INFO-Epoch 9, Batch 122, Global step 1400:
20-03-23 23:54-INFO-training batch loss: 0.0059; avg_loss: 0.0008
20-03-23 23:54-INFO-training batch acc: 0.9961; avg_acc: 1.0000
20-03-23 23:54-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 123, Global step 1401:
20-03-23 23:55-INFO-training batch loss: 0.0050; avg_loss: 0.0009
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 124, Global step 1402:
20-03-23 23:55-INFO-training batch loss: 0.0125; avg_loss: 0.0010
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 125, Global step 1403:
20-03-23 23:55-INFO-training batch loss: 0.0152; avg_loss: 0.0011
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 126, Global step 1404:
20-03-23 23:55-INFO-training batch loss: 0.0026; avg_loss: 0.0011
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 127, Global step 1405:
20-03-23 23:55-INFO-training batch loss: 0.0102; avg_loss: 0.0012
20-03-23 23:55-INFO-training batch acc: 0.9922; avg_acc: 0.9999
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 128, Global step 1406:
20-03-23 23:55-INFO-training batch loss: 0.0144; avg_loss: 0.0013
20-03-23 23:55-INFO-training batch acc: 0.9961; avg_acc: 0.9999
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 129, Global step 1407:
20-03-23 23:55-INFO-training batch loss: 0.0116; avg_loss: 0.0014
20-03-23 23:55-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 130, Global step 1408:
20-03-23 23:55-INFO-training batch loss: 0.0032; avg_loss: 0.0014
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 131, Global step 1409:
20-03-23 23:55-INFO-training batch loss: 0.0044; avg_loss: 0.0014
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 132, Global step 1410:
20-03-23 23:55-INFO-training batch loss: 0.0110; avg_loss: 0.0015
20-03-23 23:55-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 133, Global step 1411:
20-03-23 23:55-INFO-training batch loss: 0.0075; avg_loss: 0.0015
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 134, Global step 1412:
20-03-23 23:55-INFO-training batch loss: 0.0126; avg_loss: 0.0016
20-03-23 23:55-INFO-training batch acc: 0.9961; avg_acc: 0.9998
20-03-23 23:55-INFO-
20-03-23 23:55-INFO-Epoch 9, Batch 135, Global step 1413:
20-03-23 23:55-INFO-training batch loss: 0.0160; avg_loss: 0.0017
20-03-23 23:55-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:55-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 136, Global step 1414:
20-03-23 23:56-INFO-training batch loss: 0.0022; avg_loss: 0.0017
20-03-23 23:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 137, Global step 1415:
20-03-23 23:56-INFO-training batch loss: 0.0036; avg_loss: 0.0017
20-03-23 23:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 138, Global step 1416:
20-03-23 23:56-INFO-training batch loss: 0.0037; avg_loss: 0.0017
20-03-23 23:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 139, Global step 1417:
20-03-23 23:56-INFO-training batch loss: 0.0082; avg_loss: 0.0018
20-03-23 23:56-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 140, Global step 1418:
20-03-23 23:56-INFO-training batch loss: 0.0154; avg_loss: 0.0019
20-03-23 23:56-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 141, Global step 1419:
20-03-23 23:56-INFO-training batch loss: 0.0067; avg_loss: 0.0019
20-03-23 23:56-INFO-training batch acc: 0.9961; avg_acc: 0.9997
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, Batch 142, Global step 1420:
20-03-23 23:56-INFO-training batch loss: 0.0052; avg_loss: 0.0019
20-03-23 23:56-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, training batch loss: 0.0052; avg_loss: 0.0019
20-03-23 23:56-INFO-Epoch 9, training batch accuracy: 1.0000; avg_accuracy: 0.9997
20-03-23 23:56-INFO-
20-03-23 23:56-INFO-Epoch 9, evaluating batch loss: 1.1757; avg_loss: 0.5327
20-03-23 23:56-INFO-Epoch 9, evaluating batch accuracy: 0.8636; avg_accuracy: 0.9363
20-03-23 23:56-INFO-
