20-03-23 11:55-INFO-{'session_length': 24, 'height': 32, 'width': 32, 'num_labels': 8, 'learning_rate': 0.005, 'filter_sizes': [3, 4, 5, 6], 'num_filters': 64, 'filter_sizes_hierarchical': [3, 4, 5], 'num_fitlers_hierarchical': 64, 'is_train': True, 'early_stop': True, 'is_tuning': True}
20-03-23 11:55-WARNING-From ../utils.py:127: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

20-03-23 11:55-WARNING-From ../model/train.py:105: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

20-03-23 11:55-WARNING-From ../model/siamese_network.py:33: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

20-03-23 11:55-WARNING-From ../model/siamese_network.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

20-03-23 11:55-WARNING-From ../model/siamese_network.py:41: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

20-03-23 11:55-WARNING-From ../model/utils/utils.py:26: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb2a92d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb2a92d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-From ../model/utils/utils.py:45: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling1D instead.
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1bb2a9210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1bb2a9210>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb2a9110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb2a9110>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1bb2a9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1bb2a9050>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb2a9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb2a9050>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1bb1f9990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1bb1f9990>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb201f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb201f10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba694b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba694b10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-From ../model/utils/modules.py:205: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
20-03-23 11:55-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe1bb201f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe1bb201f10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba6216d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba6216d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba621750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba621750>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba6400d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba6400d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba640910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba640910>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba68e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba68e310>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba688f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba688f50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-From ../model/utils/modules.py:240: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
20-03-23 11:55-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1ba539990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1ba539990>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-From ../model/utils/modules.py:242: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
20-03-23 11:55-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe1ba688250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe1ba688250>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-From ../model/utils/modules.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba698610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba698610>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba698e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba698e90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba4e06d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba4e06d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba4e0e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba4e0e50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba49fad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba49fad0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba49fe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba49fe90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb1f9090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb1f9090>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba660450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba660450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe1bb26ed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe1bb26ed10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba5a7750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba5a7750>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba5a7750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba5a7750>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba489290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1ba489290>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba496d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba496d90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb201210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fe1bb201210>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba4e03d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fe1ba4e03d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1bb201190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1bb201190>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe1ba49f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fe1ba49f390>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1ba6944d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1ba6944d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1ba694b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe1ba694b50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-23 11:55-WARNING-From ../model/base_model.py:132: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

20-03-23 11:55-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20-03-23 11:55-WARNING-From ../model/train.py:111: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

20-03-23 11:55-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
20-03-23 11:55-INFO-Restoring parameters from /root/data/mentali/IDS/ckpt/hierarchical_cnn/hierarchical_cnn_17
20-03-23 11:55-INFO-Epoch 0, Batch 1, Global step 1:
20-03-23 11:55-INFO-training batch loss: 13.0450; avg_loss: 13.0450
20-03-23 11:55-INFO-training batch acc: 0.5234; avg_acc: 0.5234
20-03-23 11:55-INFO-
20-03-23 11:55-INFO-Epoch 0, Batch 2, Global step 2:
20-03-23 11:55-INFO-training batch loss: 9.1446; avg_loss: 11.0948
20-03-23 11:55-INFO-training batch acc: 0.6016; avg_acc: 0.5625
20-03-23 11:55-INFO-
20-03-23 11:55-INFO-Epoch 0, Batch 3, Global step 3:
20-03-23 11:55-INFO-training batch loss: 3.9700; avg_loss: 8.7199
20-03-23 11:55-INFO-training batch acc: 0.4922; avg_acc: 0.5391
20-03-23 11:55-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 4, Global step 4:
20-03-23 11:56-INFO-training batch loss: 2.4334; avg_loss: 7.1483
20-03-23 11:56-INFO-training batch acc: 0.4219; avg_acc: 0.5098
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 5, Global step 5:
20-03-23 11:56-INFO-training batch loss: 1.4890; avg_loss: 6.0164
20-03-23 11:56-INFO-training batch acc: 0.5312; avg_acc: 0.5141
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 6, Global step 6:
20-03-23 11:56-INFO-training batch loss: 1.0610; avg_loss: 5.1905
20-03-23 11:56-INFO-training batch acc: 0.5469; avg_acc: 0.5195
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 7, Global step 7:
20-03-23 11:56-INFO-training batch loss: 0.8450; avg_loss: 4.5697
20-03-23 11:56-INFO-training batch acc: 0.6172; avg_acc: 0.5335
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 8, Global step 8:
20-03-23 11:56-INFO-training batch loss: 0.7194; avg_loss: 4.0884
20-03-23 11:56-INFO-training batch acc: 0.5781; avg_acc: 0.5391
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 9, Global step 9:
20-03-23 11:56-INFO-training batch loss: 0.6866; avg_loss: 3.7105
20-03-23 11:56-INFO-training batch acc: 0.6094; avg_acc: 0.5469
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 10, Global step 10:
20-03-23 11:56-INFO-training batch loss: 0.7323; avg_loss: 3.4126
20-03-23 11:56-INFO-training batch acc: 0.4844; avg_acc: 0.5406
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 11, Global step 11:
20-03-23 11:56-INFO-training batch loss: 0.6565; avg_loss: 3.1621
20-03-23 11:56-INFO-training batch acc: 0.6250; avg_acc: 0.5483
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 12, Global step 12:
20-03-23 11:56-INFO-training batch loss: 0.6833; avg_loss: 2.9555
20-03-23 11:56-INFO-training batch acc: 0.5859; avg_acc: 0.5514
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 13, Global step 13:
20-03-23 11:56-INFO-training batch loss: 0.6705; avg_loss: 2.7797
20-03-23 11:56-INFO-training batch acc: 0.5391; avg_acc: 0.5505
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 14, Global step 14:
20-03-23 11:56-INFO-training batch loss: 0.6622; avg_loss: 2.6285
20-03-23 11:56-INFO-training batch acc: 0.5469; avg_acc: 0.5502
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 15, Global step 15:
20-03-23 11:56-INFO-training batch loss: 0.6778; avg_loss: 2.4985
20-03-23 11:56-INFO-training batch acc: 0.5547; avg_acc: 0.5505
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 16, Global step 16:
20-03-23 11:56-INFO-training batch loss: 0.6527; avg_loss: 2.3831
20-03-23 11:56-INFO-training batch acc: 0.6328; avg_acc: 0.5557
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 17, Global step 17:
20-03-23 11:56-INFO-training batch loss: 0.6632; avg_loss: 2.2819
20-03-23 11:56-INFO-training batch acc: 0.5469; avg_acc: 0.5551
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 18, Global step 18:
20-03-23 11:56-INFO-training batch loss: 0.6482; avg_loss: 2.1912
20-03-23 11:56-INFO-training batch acc: 0.6094; avg_acc: 0.5582
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 19, Global step 19:
20-03-23 11:56-INFO-training batch loss: 0.6661; avg_loss: 2.1109
20-03-23 11:56-INFO-training batch acc: 0.5234; avg_acc: 0.5563
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 20, Global step 20:
20-03-23 11:56-INFO-training batch loss: 0.6513; avg_loss: 2.0379
20-03-23 11:56-INFO-training batch acc: 0.6328; avg_acc: 0.5602
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 21, Global step 21:
20-03-23 11:56-INFO-training batch loss: 0.6636; avg_loss: 1.9725
20-03-23 11:56-INFO-training batch acc: 0.5781; avg_acc: 0.5610
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 22, Global step 22:
20-03-23 11:56-INFO-training batch loss: 0.6488; avg_loss: 1.9123
20-03-23 11:56-INFO-training batch acc: 0.5859; avg_acc: 0.5621
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 23, Global step 23:
20-03-23 11:56-INFO-training batch loss: 0.6389; avg_loss: 1.8569
20-03-23 11:56-INFO-training batch acc: 0.5859; avg_acc: 0.5632
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 24, Global step 24:
20-03-23 11:56-INFO-training batch loss: 0.6231; avg_loss: 1.8055
20-03-23 11:56-INFO-training batch acc: 0.6562; avg_acc: 0.5671
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 25, Global step 25:
20-03-23 11:56-INFO-training batch loss: 0.6377; avg_loss: 1.7588
20-03-23 11:56-INFO-training batch acc: 0.6172; avg_acc: 0.5691
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 26, Global step 26:
20-03-23 11:56-INFO-training batch loss: 0.6206; avg_loss: 1.7150
20-03-23 11:56-INFO-training batch acc: 0.6172; avg_acc: 0.5709
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 27, Global step 27:
20-03-23 11:56-INFO-training batch loss: 0.6546; avg_loss: 1.6758
20-03-23 11:56-INFO-training batch acc: 0.5859; avg_acc: 0.5715
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 28, Global step 28:
20-03-23 11:56-INFO-training batch loss: 0.6230; avg_loss: 1.6382
20-03-23 11:56-INFO-training batch acc: 0.5938; avg_acc: 0.5723
20-03-23 11:56-INFO-
20-03-23 11:56-INFO-Epoch 0, Batch 29, Global step 29:
20-03-23 11:56-INFO-training batch loss: 0.6712; avg_loss: 1.6048
20-03-23 11:56-INFO-training batch acc: 0.5391; avg_acc: 0.5711
20-03-23 11:56-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 30, Global step 30:
20-03-23 11:57-INFO-training batch loss: 0.6710; avg_loss: 1.5737
20-03-23 11:57-INFO-training batch acc: 0.5781; avg_acc: 0.5714
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 31, Global step 31:
20-03-23 11:57-INFO-training batch loss: 0.6750; avg_loss: 1.5447
20-03-23 11:57-INFO-training batch acc: 0.5469; avg_acc: 0.5706
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 32, Global step 32:
20-03-23 11:57-INFO-training batch loss: 0.6336; avg_loss: 1.5162
20-03-23 11:57-INFO-training batch acc: 0.6094; avg_acc: 0.5718
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 33, Global step 33:
20-03-23 11:57-INFO-training batch loss: 0.6047; avg_loss: 1.4886
20-03-23 11:57-INFO-training batch acc: 0.6172; avg_acc: 0.5732
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 34, Global step 34:
20-03-23 11:57-INFO-training batch loss: 0.6575; avg_loss: 1.4642
20-03-23 11:57-INFO-training batch acc: 0.6328; avg_acc: 0.5749
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 35, Global step 35:
20-03-23 11:57-INFO-training batch loss: 0.7197; avg_loss: 1.4429
20-03-23 11:57-INFO-training batch acc: 0.6016; avg_acc: 0.5757
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 36, Global step 36:
20-03-23 11:57-INFO-training batch loss: 0.6941; avg_loss: 1.4221
20-03-23 11:57-INFO-training batch acc: 0.5625; avg_acc: 0.5753
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 37, Global step 37:
20-03-23 11:57-INFO-training batch loss: 0.6181; avg_loss: 1.4004
20-03-23 11:57-INFO-training batch acc: 0.6250; avg_acc: 0.5766
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 38, Global step 38:
20-03-23 11:57-INFO-training batch loss: 0.6365; avg_loss: 1.3803
20-03-23 11:57-INFO-training batch acc: 0.6484; avg_acc: 0.5785
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 39, Global step 39:
20-03-23 11:57-INFO-training batch loss: 0.6388; avg_loss: 1.3612
20-03-23 11:57-INFO-training batch acc: 0.6094; avg_acc: 0.5793
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 40, Global step 40:
20-03-23 11:57-INFO-training batch loss: 0.6631; avg_loss: 1.3438
20-03-23 11:57-INFO-training batch acc: 0.5312; avg_acc: 0.5781
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 41, Global step 41:
20-03-23 11:57-INFO-training batch loss: 0.6221; avg_loss: 1.3262
20-03-23 11:57-INFO-training batch acc: 0.6250; avg_acc: 0.5793
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 42, Global step 42:
20-03-23 11:57-INFO-training batch loss: 0.5827; avg_loss: 1.3085
20-03-23 11:57-INFO-training batch acc: 0.6719; avg_acc: 0.5815
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 43, Global step 43:
20-03-23 11:57-INFO-training batch loss: 0.6489; avg_loss: 1.2931
20-03-23 11:57-INFO-training batch acc: 0.5781; avg_acc: 0.5814
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 44, Global step 44:
20-03-23 11:57-INFO-training batch loss: 0.5955; avg_loss: 1.2773
20-03-23 11:57-INFO-training batch acc: 0.6328; avg_acc: 0.5826
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 45, Global step 45:
20-03-23 11:57-INFO-training batch loss: 0.6196; avg_loss: 1.2627
20-03-23 11:57-INFO-training batch acc: 0.6250; avg_acc: 0.5835
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 46, Global step 46:
20-03-23 11:57-INFO-training batch loss: 0.5897; avg_loss: 1.2480
20-03-23 11:57-INFO-training batch acc: 0.6719; avg_acc: 0.5854
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 47, Global step 47:
20-03-23 11:57-INFO-training batch loss: 0.5729; avg_loss: 1.2337
20-03-23 11:57-INFO-training batch acc: 0.6719; avg_acc: 0.5873
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 48, Global step 48:
20-03-23 11:57-INFO-training batch loss: 0.5637; avg_loss: 1.2197
20-03-23 11:57-INFO-training batch acc: 0.6875; avg_acc: 0.5894
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 49, Global step 49:
20-03-23 11:57-INFO-training batch loss: 0.5787; avg_loss: 1.2066
20-03-23 11:57-INFO-training batch acc: 0.6875; avg_acc: 0.5914
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 50, Global step 50:
20-03-23 11:57-INFO-training batch loss: 0.5849; avg_loss: 1.1942
20-03-23 11:57-INFO-training batch acc: 0.6484; avg_acc: 0.5925
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 51, Global step 51:
20-03-23 11:57-INFO-training batch loss: 0.6097; avg_loss: 1.1827
20-03-23 11:57-INFO-training batch acc: 0.6484; avg_acc: 0.5936
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 52, Global step 52:
20-03-23 11:57-INFO-training batch loss: 0.5627; avg_loss: 1.1708
20-03-23 11:57-INFO-training batch acc: 0.7344; avg_acc: 0.5963
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 53, Global step 53:
20-03-23 11:57-INFO-training batch loss: 0.5241; avg_loss: 1.1586
20-03-23 11:57-INFO-training batch acc: 0.7031; avg_acc: 0.5983
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 54, Global step 54:
20-03-23 11:57-INFO-training batch loss: 0.5238; avg_loss: 1.1469
20-03-23 11:57-INFO-training batch acc: 0.7266; avg_acc: 0.6007
20-03-23 11:57-INFO-
20-03-23 11:57-INFO-Epoch 0, Batch 55, Global step 55:
20-03-23 11:57-INFO-training batch loss: 0.5536; avg_loss: 1.1361
20-03-23 11:57-INFO-training batch acc: 0.7109; avg_acc: 0.6027
20-03-23 11:57-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 56, Global step 56:
20-03-23 11:58-INFO-training batch loss: 0.4915; avg_loss: 1.1246
20-03-23 11:58-INFO-training batch acc: 0.7656; avg_acc: 0.6056
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 57, Global step 57:
20-03-23 11:58-INFO-training batch loss: 0.5412; avg_loss: 1.1143
20-03-23 11:58-INFO-training batch acc: 0.7031; avg_acc: 0.6073
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 58, Global step 58:
20-03-23 11:58-INFO-training batch loss: 0.4712; avg_loss: 1.1032
20-03-23 11:58-INFO-training batch acc: 0.7734; avg_acc: 0.6102
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 59, Global step 59:
20-03-23 11:58-INFO-training batch loss: 0.4831; avg_loss: 1.0927
20-03-23 11:58-INFO-training batch acc: 0.7188; avg_acc: 0.6120
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 60, Global step 60:
20-03-23 11:58-INFO-training batch loss: 0.5003; avg_loss: 1.0829
20-03-23 11:58-INFO-training batch acc: 0.7344; avg_acc: 0.6141
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 61, Global step 61:
20-03-23 11:58-INFO-training batch loss: 0.4594; avg_loss: 1.0726
20-03-23 11:58-INFO-training batch acc: 0.7656; avg_acc: 0.6165
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 62, Global step 62:
20-03-23 11:58-INFO-training batch loss: 0.5206; avg_loss: 1.0637
20-03-23 11:58-INFO-training batch acc: 0.7578; avg_acc: 0.6188
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 63, Global step 63:
20-03-23 11:58-INFO-training batch loss: 0.3857; avg_loss: 1.0530
20-03-23 11:58-INFO-training batch acc: 0.8359; avg_acc: 0.6223
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 64, Global step 64:
20-03-23 11:58-INFO-training batch loss: 0.4120; avg_loss: 1.0429
20-03-23 11:58-INFO-training batch acc: 0.8047; avg_acc: 0.6251
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 65, Global step 65:
20-03-23 11:58-INFO-training batch loss: 0.4003; avg_loss: 1.0331
20-03-23 11:58-INFO-training batch acc: 0.8438; avg_acc: 0.6285
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 66, Global step 66:
20-03-23 11:58-INFO-training batch loss: 0.4114; avg_loss: 1.0236
20-03-23 11:58-INFO-training batch acc: 0.8281; avg_acc: 0.6315
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 67, Global step 67:
20-03-23 11:58-INFO-training batch loss: 0.4074; avg_loss: 1.0144
20-03-23 11:58-INFO-training batch acc: 0.8750; avg_acc: 0.6351
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 68, Global step 68:
20-03-23 11:58-INFO-training batch loss: 0.4328; avg_loss: 1.0059
20-03-23 11:58-INFO-training batch acc: 0.8438; avg_acc: 0.6382
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 69, Global step 69:
20-03-23 11:58-INFO-training batch loss: 0.4318; avg_loss: 0.9976
20-03-23 11:58-INFO-training batch acc: 0.8047; avg_acc: 0.6406
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 70, Global step 70:
20-03-23 11:58-INFO-training batch loss: 0.3212; avg_loss: 0.9879
20-03-23 11:58-INFO-training batch acc: 0.8750; avg_acc: 0.6440
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 71, Global step 71:
20-03-23 11:58-INFO-training batch loss: 0.3595; avg_loss: 0.9791
20-03-23 11:58-INFO-training batch acc: 0.8750; avg_acc: 0.6472
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 72, Global step 72:
20-03-23 11:58-INFO-training batch loss: 0.3881; avg_loss: 0.9708
20-03-23 11:58-INFO-training batch acc: 0.7734; avg_acc: 0.6490
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 73, Global step 73:
20-03-23 11:58-INFO-training batch loss: 0.3497; avg_loss: 0.9623
20-03-23 11:58-INFO-training batch acc: 0.8281; avg_acc: 0.6514
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 74, Global step 74:
20-03-23 11:58-INFO-training batch loss: 0.3031; avg_loss: 0.9534
20-03-23 11:58-INFO-training batch acc: 0.8672; avg_acc: 0.6543
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 75, Global step 75:
20-03-23 11:58-INFO-training batch loss: 0.4135; avg_loss: 0.9462
20-03-23 11:58-INFO-training batch acc: 0.8203; avg_acc: 0.6566
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 76, Global step 76:
20-03-23 11:58-INFO-training batch loss: 0.2263; avg_loss: 0.9368
20-03-23 11:58-INFO-training batch acc: 0.9297; avg_acc: 0.6602
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 77, Global step 77:
20-03-23 11:58-INFO-training batch loss: 0.3294; avg_loss: 0.9289
20-03-23 11:58-INFO-training batch acc: 0.8750; avg_acc: 0.6629
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 78, Global step 78:
20-03-23 11:58-INFO-training batch loss: 0.2526; avg_loss: 0.9202
20-03-23 11:58-INFO-training batch acc: 0.9375; avg_acc: 0.6665
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 79, Global step 79:
20-03-23 11:58-INFO-training batch loss: 0.2642; avg_loss: 0.9119
20-03-23 11:58-INFO-training batch acc: 0.9297; avg_acc: 0.6698
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 80, Global step 80:
20-03-23 11:58-INFO-training batch loss: 0.3297; avg_loss: 0.9046
20-03-23 11:58-INFO-training batch acc: 0.8750; avg_acc: 0.6724
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 81, Global step 81:
20-03-23 11:58-INFO-training batch loss: 0.2417; avg_loss: 0.8964
20-03-23 11:58-INFO-training batch acc: 0.9141; avg_acc: 0.6753
20-03-23 11:58-INFO-
20-03-23 11:58-INFO-Epoch 0, Batch 82, Global step 82:
20-03-23 11:58-INFO-training batch loss: 0.2449; avg_loss: 0.8885
20-03-23 11:58-INFO-training batch acc: 0.9531; avg_acc: 0.6787
20-03-23 11:58-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 83, Global step 83:
20-03-23 11:59-INFO-training batch loss: 0.3058; avg_loss: 0.8815
20-03-23 11:59-INFO-training batch acc: 0.9297; avg_acc: 0.6818
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 84, Global step 84:
20-03-23 11:59-INFO-training batch loss: 0.3498; avg_loss: 0.8751
20-03-23 11:59-INFO-training batch acc: 0.8906; avg_acc: 0.6842
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 85, Global step 85:
20-03-23 11:59-INFO-training batch loss: 0.2923; avg_loss: 0.8683
20-03-23 11:59-INFO-training batch acc: 0.8594; avg_acc: 0.6863
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 86, Global step 86:
20-03-23 11:59-INFO-training batch loss: 0.2479; avg_loss: 0.8611
20-03-23 11:59-INFO-training batch acc: 0.9062; avg_acc: 0.6889
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 87, Global step 87:
20-03-23 11:59-INFO-training batch loss: 0.2042; avg_loss: 0.8535
20-03-23 11:59-INFO-training batch acc: 0.9375; avg_acc: 0.6917
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 88, Global step 88:
20-03-23 11:59-INFO-training batch loss: 0.1806; avg_loss: 0.8459
20-03-23 11:59-INFO-training batch acc: 0.9531; avg_acc: 0.6947
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 89, Global step 89:
20-03-23 11:59-INFO-training batch loss: 0.1858; avg_loss: 0.8385
20-03-23 11:59-INFO-training batch acc: 0.9609; avg_acc: 0.6977
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 90, Global step 90:
20-03-23 11:59-INFO-training batch loss: 0.2279; avg_loss: 0.8317
20-03-23 11:59-INFO-training batch acc: 0.9297; avg_acc: 0.7003
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 91, Global step 91:
20-03-23 11:59-INFO-training batch loss: 0.2259; avg_loss: 0.8250
20-03-23 11:59-INFO-training batch acc: 0.9375; avg_acc: 0.7029
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 92, Global step 92:
20-03-23 11:59-INFO-training batch loss: 0.1406; avg_loss: 0.8176
20-03-23 11:59-INFO-training batch acc: 0.9609; avg_acc: 0.7057
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 93, Global step 93:
20-03-23 11:59-INFO-training batch loss: 0.1752; avg_loss: 0.8107
20-03-23 11:59-INFO-training batch acc: 0.9609; avg_acc: 0.7084
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 94, Global step 94:
20-03-23 11:59-INFO-training batch loss: 0.3081; avg_loss: 0.8053
20-03-23 11:59-INFO-training batch acc: 0.9141; avg_acc: 0.7106
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 95, Global step 95:
20-03-23 11:59-INFO-training batch loss: 0.1770; avg_loss: 0.7987
20-03-23 11:59-INFO-training batch acc: 0.9375; avg_acc: 0.7130
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 96, Global step 96:
20-03-23 11:59-INFO-training batch loss: 0.3322; avg_loss: 0.7938
20-03-23 11:59-INFO-training batch acc: 0.9062; avg_acc: 0.7150
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 97, Global step 97:
20-03-23 11:59-INFO-training batch loss: 0.1478; avg_loss: 0.7872
20-03-23 11:59-INFO-training batch acc: 0.9609; avg_acc: 0.7175
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 98, Global step 98:
20-03-23 11:59-INFO-training batch loss: 0.2376; avg_loss: 0.7816
20-03-23 11:59-INFO-training batch acc: 0.9453; avg_acc: 0.7199
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 99, Global step 99:
20-03-23 11:59-INFO-training batch loss: 0.1891; avg_loss: 0.7756
20-03-23 11:59-INFO-training batch acc: 0.9453; avg_acc: 0.7221
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 100, Global step 100:
20-03-23 11:59-INFO-training batch loss: 0.1603; avg_loss: 0.7694
20-03-23 11:59-INFO-training batch acc: 0.9609; avg_acc: 0.7245
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 101, Global step 101:
20-03-23 11:59-INFO-training batch loss: 0.2439; avg_loss: 0.7642
20-03-23 11:59-INFO-training batch acc: 0.9297; avg_acc: 0.7266
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 102, Global step 102:
20-03-23 11:59-INFO-training batch loss: 0.2292; avg_loss: 0.7590
20-03-23 11:59-INFO-training batch acc: 0.9219; avg_acc: 0.7285
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 103, Global step 103:
20-03-23 11:59-INFO-training batch loss: 0.1521; avg_loss: 0.7531
20-03-23 11:59-INFO-training batch acc: 0.9453; avg_acc: 0.7306
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 104, Global step 104:
20-03-23 11:59-INFO-training batch loss: 0.1607; avg_loss: 0.7474
20-03-23 11:59-INFO-training batch acc: 0.9531; avg_acc: 0.7327
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 105, Global step 105:
20-03-23 11:59-INFO-training batch loss: 0.1562; avg_loss: 0.7418
20-03-23 11:59-INFO-training batch acc: 0.9531; avg_acc: 0.7348
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 106, Global step 106:
20-03-23 11:59-INFO-training batch loss: 0.2519; avg_loss: 0.7372
20-03-23 11:59-INFO-training batch acc: 0.9375; avg_acc: 0.7367
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 107, Global step 107:
20-03-23 11:59-INFO-training batch loss: 0.1299; avg_loss: 0.7315
20-03-23 11:59-INFO-training batch acc: 0.9766; avg_acc: 0.7390
20-03-23 11:59-INFO-
20-03-23 11:59-INFO-Epoch 0, Batch 108, Global step 108:
20-03-23 11:59-INFO-training batch loss: 0.1198; avg_loss: 0.7258
20-03-23 11:59-INFO-training batch acc: 0.9609; avg_acc: 0.7410
20-03-23 11:59-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 109, Global step 109:
20-03-23 12:00-INFO-training batch loss: 0.1478; avg_loss: 0.7205
20-03-23 12:00-INFO-training batch acc: 0.9688; avg_acc: 0.7431
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 110, Global step 110:
20-03-23 12:00-INFO-training batch loss: 0.1180; avg_loss: 0.7150
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7452
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 111, Global step 111:
20-03-23 12:00-INFO-training batch loss: 0.1520; avg_loss: 0.7100
20-03-23 12:00-INFO-training batch acc: 0.9375; avg_acc: 0.7470
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 112, Global step 112:
20-03-23 12:00-INFO-training batch loss: 0.0975; avg_loss: 0.7045
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7490
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 113, Global step 113:
20-03-23 12:00-INFO-training batch loss: 0.1368; avg_loss: 0.6995
20-03-23 12:00-INFO-training batch acc: 0.9609; avg_acc: 0.7509
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 114, Global step 114:
20-03-23 12:00-INFO-training batch loss: 0.2091; avg_loss: 0.6952
20-03-23 12:00-INFO-training batch acc: 0.9219; avg_acc: 0.7524
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 115, Global step 115:
20-03-23 12:00-INFO-training batch loss: 0.1746; avg_loss: 0.6906
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7543
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 116, Global step 116:
20-03-23 12:00-INFO-training batch loss: 0.1905; avg_loss: 0.6863
20-03-23 12:00-INFO-training batch acc: 0.9375; avg_acc: 0.7559
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 117, Global step 117:
20-03-23 12:00-INFO-training batch loss: 0.1684; avg_loss: 0.6819
20-03-23 12:00-INFO-training batch acc: 0.9297; avg_acc: 0.7574
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 118, Global step 118:
20-03-23 12:00-INFO-training batch loss: 0.1028; avg_loss: 0.6770
20-03-23 12:00-INFO-training batch acc: 0.9609; avg_acc: 0.7591
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 119, Global step 119:
20-03-23 12:00-INFO-training batch loss: 0.1803; avg_loss: 0.6728
20-03-23 12:00-INFO-training batch acc: 0.9453; avg_acc: 0.7607
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 120, Global step 120:
20-03-23 12:00-INFO-training batch loss: 0.1622; avg_loss: 0.6686
20-03-23 12:00-INFO-training batch acc: 0.9688; avg_acc: 0.7624
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 121, Global step 121:
20-03-23 12:00-INFO-training batch loss: 0.2826; avg_loss: 0.6654
20-03-23 12:00-INFO-training batch acc: 0.9375; avg_acc: 0.7639
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 122, Global step 122:
20-03-23 12:00-INFO-training batch loss: 0.1577; avg_loss: 0.6612
20-03-23 12:00-INFO-training batch acc: 0.9531; avg_acc: 0.7654
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 123, Global step 123:
20-03-23 12:00-INFO-training batch loss: 0.2097; avg_loss: 0.6575
20-03-23 12:00-INFO-training batch acc: 0.9375; avg_acc: 0.7668
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 124, Global step 124:
20-03-23 12:00-INFO-training batch loss: 0.1184; avg_loss: 0.6532
20-03-23 12:00-INFO-training batch acc: 0.9609; avg_acc: 0.7684
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 125, Global step 125:
20-03-23 12:00-INFO-training batch loss: 0.0804; avg_loss: 0.6486
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7701
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 126, Global step 126:
20-03-23 12:00-INFO-training batch loss: 0.1641; avg_loss: 0.6448
20-03-23 12:00-INFO-training batch acc: 0.9688; avg_acc: 0.7716
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 127, Global step 127:
20-03-23 12:00-INFO-training batch loss: 0.0919; avg_loss: 0.6404
20-03-23 12:00-INFO-training batch acc: 0.9922; avg_acc: 0.7734
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 128, Global step 128:
20-03-23 12:00-INFO-training batch loss: 0.1004; avg_loss: 0.6362
20-03-23 12:00-INFO-training batch acc: 0.9688; avg_acc: 0.7749
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 129, Global step 129:
20-03-23 12:00-INFO-training batch loss: 0.1539; avg_loss: 0.6325
20-03-23 12:00-INFO-training batch acc: 0.9609; avg_acc: 0.7763
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 130, Global step 130:
20-03-23 12:00-INFO-training batch loss: 0.1491; avg_loss: 0.6287
20-03-23 12:00-INFO-training batch acc: 0.9453; avg_acc: 0.7776
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 131, Global step 131:
20-03-23 12:00-INFO-training batch loss: 0.1932; avg_loss: 0.6254
20-03-23 12:00-INFO-training batch acc: 0.9531; avg_acc: 0.7790
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 132, Global step 132:
20-03-23 12:00-INFO-training batch loss: 0.1188; avg_loss: 0.6216
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7805
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 133, Global step 133:
20-03-23 12:00-INFO-training batch loss: 0.1239; avg_loss: 0.6178
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7820
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 134, Global step 134:
20-03-23 12:00-INFO-training batch loss: 0.0981; avg_loss: 0.6140
20-03-23 12:00-INFO-training batch acc: 0.9766; avg_acc: 0.7834
20-03-23 12:00-INFO-
20-03-23 12:00-INFO-Epoch 0, Batch 135, Global step 135:
20-03-23 12:00-INFO-training batch loss: 0.1316; avg_loss: 0.6104
20-03-23 12:00-INFO-training batch acc: 0.9453; avg_acc: 0.7846
20-03-23 12:00-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 136, Global step 136:
20-03-23 12:01-INFO-training batch loss: 0.1889; avg_loss: 0.6073
20-03-23 12:01-INFO-training batch acc: 0.9766; avg_acc: 0.7860
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 137, Global step 137:
20-03-23 12:01-INFO-training batch loss: 0.1129; avg_loss: 0.6037
20-03-23 12:01-INFO-training batch acc: 0.9609; avg_acc: 0.7873
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 138, Global step 138:
20-03-23 12:01-INFO-training batch loss: 0.1178; avg_loss: 0.6002
20-03-23 12:01-INFO-training batch acc: 0.9609; avg_acc: 0.7886
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 139, Global step 139:
20-03-23 12:01-INFO-training batch loss: 0.0675; avg_loss: 0.5963
20-03-23 12:01-INFO-training batch acc: 0.9922; avg_acc: 0.7900
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 140, Global step 140:
20-03-23 12:01-INFO-training batch loss: 0.0534; avg_loss: 0.5924
20-03-23 12:01-INFO-training batch acc: 1.0000; avg_acc: 0.7915
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 141, Global step 141:
20-03-23 12:01-INFO-training batch loss: 0.1416; avg_loss: 0.5892
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.7928
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 142, Global step 142:
20-03-23 12:01-INFO-training batch loss: 0.0967; avg_loss: 0.5858
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.7940
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 143, Global step 143:
20-03-23 12:01-INFO-training batch loss: 0.1074; avg_loss: 0.5824
20-03-23 12:01-INFO-training batch acc: 0.9531; avg_acc: 0.7951
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 144, Global step 144:
20-03-23 12:01-INFO-training batch loss: 0.1553; avg_loss: 0.5795
20-03-23 12:01-INFO-training batch acc: 0.9609; avg_acc: 0.7963
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 145, Global step 145:
20-03-23 12:01-INFO-training batch loss: 0.0853; avg_loss: 0.5761
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.7975
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 146, Global step 146:
20-03-23 12:01-INFO-training batch loss: 0.1532; avg_loss: 0.5732
20-03-23 12:01-INFO-training batch acc: 0.9375; avg_acc: 0.7984
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 147, Global step 147:
20-03-23 12:01-INFO-training batch loss: 0.0839; avg_loss: 0.5698
20-03-23 12:01-INFO-training batch acc: 0.9766; avg_acc: 0.7996
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 148, Global step 148:
20-03-23 12:01-INFO-training batch loss: 0.0519; avg_loss: 0.5663
20-03-23 12:01-INFO-training batch acc: 1.0000; avg_acc: 0.8010
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 149, Global step 149:
20-03-23 12:01-INFO-training batch loss: 0.1591; avg_loss: 0.5636
20-03-23 12:01-INFO-training batch acc: 0.9609; avg_acc: 0.8021
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 150, Global step 150:
20-03-23 12:01-INFO-training batch loss: 0.0743; avg_loss: 0.5603
20-03-23 12:01-INFO-training batch acc: 0.9766; avg_acc: 0.8032
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 151, Global step 151:
20-03-23 12:01-INFO-training batch loss: 0.1252; avg_loss: 0.5575
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.8043
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 152, Global step 152:
20-03-23 12:01-INFO-training batch loss: 0.1366; avg_loss: 0.5547
20-03-23 12:01-INFO-training batch acc: 0.9531; avg_acc: 0.8053
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 153, Global step 153:
20-03-23 12:01-INFO-training batch loss: 0.1103; avg_loss: 0.5518
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.8064
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 154, Global step 154:
20-03-23 12:01-INFO-training batch loss: 0.1585; avg_loss: 0.5492
20-03-23 12:01-INFO-training batch acc: 0.9531; avg_acc: 0.8073
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 155, Global step 155:
20-03-23 12:01-INFO-training batch loss: 0.4325; avg_loss: 0.5485
20-03-23 12:01-INFO-training batch acc: 0.8750; avg_acc: 0.8078
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 156, Global step 156:
20-03-23 12:01-INFO-training batch loss: 0.3081; avg_loss: 0.5469
20-03-23 12:01-INFO-training batch acc: 0.8984; avg_acc: 0.8083
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 157, Global step 157:
20-03-23 12:01-INFO-training batch loss: 0.1547; avg_loss: 0.5444
20-03-23 12:01-INFO-training batch acc: 0.9297; avg_acc: 0.8091
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 158, Global step 158:
20-03-23 12:01-INFO-training batch loss: 0.1133; avg_loss: 0.5417
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.8101
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 159, Global step 159:
20-03-23 12:01-INFO-training batch loss: 0.0534; avg_loss: 0.5386
20-03-23 12:01-INFO-training batch acc: 0.9922; avg_acc: 0.8113
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 160, Global step 160:
20-03-23 12:01-INFO-training batch loss: 0.0943; avg_loss: 0.5359
20-03-23 12:01-INFO-training batch acc: 0.9688; avg_acc: 0.8123
20-03-23 12:01-INFO-
20-03-23 12:01-INFO-Epoch 0, Batch 161, Global step 161:
20-03-23 12:01-INFO-training batch loss: 0.1209; avg_loss: 0.5333
20-03-23 12:01-INFO-training batch acc: 0.9531; avg_acc: 0.8131
20-03-23 12:01-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 162, Global step 162:
20-03-23 12:02-INFO-training batch loss: 0.1581; avg_loss: 0.5310
20-03-23 12:02-INFO-training batch acc: 0.9297; avg_acc: 0.8139
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 163, Global step 163:
20-03-23 12:02-INFO-training batch loss: 0.0532; avg_loss: 0.5280
20-03-23 12:02-INFO-training batch acc: 1.0000; avg_acc: 0.8150
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 164, Global step 164:
20-03-23 12:02-INFO-training batch loss: 0.0718; avg_loss: 0.5253
20-03-23 12:02-INFO-training batch acc: 0.9766; avg_acc: 0.8160
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 165, Global step 165:
20-03-23 12:02-INFO-training batch loss: 0.0748; avg_loss: 0.5225
20-03-23 12:02-INFO-training batch acc: 0.9844; avg_acc: 0.8170
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 166, Global step 166:
20-03-23 12:02-INFO-training batch loss: 0.0796; avg_loss: 0.5199
20-03-23 12:02-INFO-training batch acc: 0.9688; avg_acc: 0.8179
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 167, Global step 167:
20-03-23 12:02-INFO-training batch loss: 0.0974; avg_loss: 0.5173
20-03-23 12:02-INFO-training batch acc: 0.9531; avg_acc: 0.8187
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 168, Global step 168:
20-03-23 12:02-INFO-training batch loss: 0.1241; avg_loss: 0.5150
20-03-23 12:02-INFO-training batch acc: 0.9609; avg_acc: 0.8196
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 169, Global step 169:
20-03-23 12:02-INFO-training batch loss: 0.1072; avg_loss: 0.5126
20-03-23 12:02-INFO-training batch acc: 0.9609; avg_acc: 0.8204
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 170, Global step 170:
20-03-23 12:02-INFO-training batch loss: 0.1468; avg_loss: 0.5104
20-03-23 12:02-INFO-training batch acc: 0.9688; avg_acc: 0.8213
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 171, Global step 171:
20-03-23 12:02-INFO-training batch loss: 0.1080; avg_loss: 0.5081
20-03-23 12:02-INFO-training batch acc: 0.9766; avg_acc: 0.8222
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 172, Global step 172:
20-03-23 12:02-INFO-training batch loss: 0.1433; avg_loss: 0.5059
20-03-23 12:02-INFO-training batch acc: 0.9844; avg_acc: 0.8231
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 173, Global step 173:
20-03-23 12:02-INFO-training batch loss: 0.1243; avg_loss: 0.5037
20-03-23 12:02-INFO-training batch acc: 0.9766; avg_acc: 0.8240
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 174, Global step 174:
20-03-23 12:02-INFO-training batch loss: 0.0654; avg_loss: 0.5012
20-03-23 12:02-INFO-training batch acc: 0.9844; avg_acc: 0.8249
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 175, Global step 175:
20-03-23 12:02-INFO-training batch loss: 0.0374; avg_loss: 0.4986
20-03-23 12:02-INFO-training batch acc: 1.0000; avg_acc: 0.8259
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 176, Global step 176:
20-03-23 12:02-INFO-training batch loss: 0.0615; avg_loss: 0.4961
20-03-23 12:02-INFO-training batch acc: 0.9922; avg_acc: 0.8269
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 177, Global step 177:
20-03-23 12:02-INFO-training batch loss: 0.0752; avg_loss: 0.4937
20-03-23 12:02-INFO-training batch acc: 0.9844; avg_acc: 0.8278
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 178, Global step 178:
20-03-23 12:02-INFO-training batch loss: 0.0468; avg_loss: 0.4912
20-03-23 12:02-INFO-training batch acc: 0.9922; avg_acc: 0.8287
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 179, Global step 179:
20-03-23 12:02-INFO-training batch loss: 0.0576; avg_loss: 0.4888
20-03-23 12:02-INFO-training batch acc: 0.9844; avg_acc: 0.8296
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 180, Global step 180:
20-03-23 12:02-INFO-training batch loss: 0.0705; avg_loss: 0.4865
20-03-23 12:02-INFO-training batch acc: 0.9844; avg_acc: 0.8304
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 181, Global step 181:
20-03-23 12:02-INFO-training batch loss: 0.1042; avg_loss: 0.4843
20-03-23 12:02-INFO-training batch acc: 0.9688; avg_acc: 0.8312
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 182, Global step 182:
20-03-23 12:02-INFO-training batch loss: 0.0787; avg_loss: 0.4821
20-03-23 12:02-INFO-training batch acc: 0.9609; avg_acc: 0.8319
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 183, Global step 183:
20-03-23 12:02-INFO-training batch loss: 0.0810; avg_loss: 0.4799
20-03-23 12:02-INFO-training batch acc: 0.9688; avg_acc: 0.8327
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 184, Global step 184:
20-03-23 12:02-INFO-training batch loss: 0.0468; avg_loss: 0.4776
20-03-23 12:02-INFO-training batch acc: 0.9922; avg_acc: 0.8335
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 185, Global step 185:
20-03-23 12:02-INFO-training batch loss: 0.0229; avg_loss: 0.4751
20-03-23 12:02-INFO-training batch acc: 1.0000; avg_acc: 0.8344
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 186, Global step 186:
20-03-23 12:02-INFO-training batch loss: 0.0209; avg_loss: 0.4727
20-03-23 12:02-INFO-training batch acc: 1.0000; avg_acc: 0.8353
20-03-23 12:02-INFO-
20-03-23 12:02-INFO-Epoch 0, Batch 187, Global step 187:
20-03-23 12:02-INFO-training batch loss: 0.0369; avg_loss: 0.4703
20-03-23 12:02-INFO-training batch acc: 0.9922; avg_acc: 0.8361
20-03-23 12:02-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 188, Global step 188:
20-03-23 12:03-INFO-training batch loss: 0.0825; avg_loss: 0.4683
20-03-23 12:03-INFO-training batch acc: 0.9922; avg_acc: 0.8370
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 189, Global step 189:
20-03-23 12:03-INFO-training batch loss: 0.0853; avg_loss: 0.4662
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8378
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 190, Global step 190:
20-03-23 12:03-INFO-training batch loss: 0.0515; avg_loss: 0.4641
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8385
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 191, Global step 191:
20-03-23 12:03-INFO-training batch loss: 0.0382; avg_loss: 0.4618
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8394
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 192, Global step 192:
20-03-23 12:03-INFO-training batch loss: 0.0235; avg_loss: 0.4596
20-03-23 12:03-INFO-training batch acc: 0.9922; avg_acc: 0.8402
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 193, Global step 193:
20-03-23 12:03-INFO-training batch loss: 0.0422; avg_loss: 0.4574
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8409
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 194, Global step 194:
20-03-23 12:03-INFO-training batch loss: 0.0401; avg_loss: 0.4552
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8417
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 195, Global step 195:
20-03-23 12:03-INFO-training batch loss: 0.0456; avg_loss: 0.4531
20-03-23 12:03-INFO-training batch acc: 0.9766; avg_acc: 0.8423
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 196, Global step 196:
20-03-23 12:03-INFO-training batch loss: 0.0527; avg_loss: 0.4511
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8431
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 197, Global step 197:
20-03-23 12:03-INFO-training batch loss: 0.0461; avg_loss: 0.4490
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8438
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 198, Global step 198:
20-03-23 12:03-INFO-training batch loss: 0.0301; avg_loss: 0.4469
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8445
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 199, Global step 199:
20-03-23 12:03-INFO-training batch loss: 0.0174; avg_loss: 0.4448
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8453
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 200, Global step 200:
20-03-23 12:03-INFO-training batch loss: 0.0574; avg_loss: 0.4428
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8460
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 201, Global step 201:
20-03-23 12:03-INFO-training batch loss: 0.0297; avg_loss: 0.4408
20-03-23 12:03-INFO-training batch acc: 0.9922; avg_acc: 0.8467
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 202, Global step 202:
20-03-23 12:03-INFO-training batch loss: 0.0147; avg_loss: 0.4387
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8475
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 203, Global step 203:
20-03-23 12:03-INFO-training batch loss: 0.0736; avg_loss: 0.4369
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8481
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 204, Global step 204:
20-03-23 12:03-INFO-training batch loss: 0.0570; avg_loss: 0.4350
20-03-23 12:03-INFO-training batch acc: 0.9766; avg_acc: 0.8488
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 205, Global step 205:
20-03-23 12:03-INFO-training batch loss: 0.0279; avg_loss: 0.4330
20-03-23 12:03-INFO-training batch acc: 0.9922; avg_acc: 0.8495
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 206, Global step 206:
20-03-23 12:03-INFO-training batch loss: 0.0219; avg_loss: 0.4310
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8502
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 207, Global step 207:
20-03-23 12:03-INFO-training batch loss: 0.0347; avg_loss: 0.4291
20-03-23 12:03-INFO-training batch acc: 0.9844; avg_acc: 0.8508
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 208, Global step 208:
20-03-23 12:03-INFO-training batch loss: 0.0260; avg_loss: 0.4272
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8516
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 209, Global step 209:
20-03-23 12:03-INFO-training batch loss: 0.0330; avg_loss: 0.4253
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8523
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 210, Global step 210:
20-03-23 12:03-INFO-training batch loss: 0.0155; avg_loss: 0.4233
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8530
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 211, Global step 211:
20-03-23 12:03-INFO-training batch loss: 0.0219; avg_loss: 0.4214
20-03-23 12:03-INFO-training batch acc: 0.9922; avg_acc: 0.8536
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 212, Global step 212:
20-03-23 12:03-INFO-training batch loss: 0.0243; avg_loss: 0.4196
20-03-23 12:03-INFO-training batch acc: 0.9922; avg_acc: 0.8543
20-03-23 12:03-INFO-
20-03-23 12:03-INFO-Epoch 0, Batch 213, Global step 213:
20-03-23 12:03-INFO-training batch loss: 0.0264; avg_loss: 0.4177
20-03-23 12:03-INFO-training batch acc: 1.0000; avg_acc: 0.8550
20-03-23 12:03-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 214, Global step 214:
20-03-23 12:04-INFO-training batch loss: 0.0198; avg_loss: 0.4159
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8557
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 215, Global step 215:
20-03-23 12:04-INFO-training batch loss: 0.0229; avg_loss: 0.4140
20-03-23 12:04-INFO-training batch acc: 0.9922; avg_acc: 0.8563
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 216, Global step 216:
20-03-23 12:04-INFO-training batch loss: 0.0421; avg_loss: 0.4123
20-03-23 12:04-INFO-training batch acc: 0.9844; avg_acc: 0.8569
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 217, Global step 217:
20-03-23 12:04-INFO-training batch loss: 0.0276; avg_loss: 0.4105
20-03-23 12:04-INFO-training batch acc: 0.9922; avg_acc: 0.8575
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 218, Global step 218:
20-03-23 12:04-INFO-training batch loss: 0.0290; avg_loss: 0.4088
20-03-23 12:04-INFO-training batch acc: 0.9922; avg_acc: 0.8581
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 219, Global step 219:
20-03-23 12:04-INFO-training batch loss: 0.0250; avg_loss: 0.4070
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8588
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 220, Global step 220:
20-03-23 12:04-INFO-training batch loss: 0.0200; avg_loss: 0.4053
20-03-23 12:04-INFO-training batch acc: 0.9922; avg_acc: 0.8594
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 221, Global step 221:
20-03-23 12:04-INFO-training batch loss: 0.0237; avg_loss: 0.4035
20-03-23 12:04-INFO-training batch acc: 0.9922; avg_acc: 0.8600
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 222, Global step 222:
20-03-23 12:04-INFO-training batch loss: 0.0130; avg_loss: 0.4018
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8606
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 223, Global step 223:
20-03-23 12:04-INFO-training batch loss: 0.0220; avg_loss: 0.4001
20-03-23 12:04-INFO-training batch acc: 0.9922; avg_acc: 0.8612
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 224, Global step 224:
20-03-23 12:04-INFO-training batch loss: 0.0208; avg_loss: 0.3984
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8618
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 225, Global step 225:
20-03-23 12:04-INFO-training batch loss: 0.0322; avg_loss: 0.3968
20-03-23 12:04-INFO-training batch acc: 0.9844; avg_acc: 0.8624
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 226, Global step 226:
20-03-23 12:04-INFO-training batch loss: 0.0200; avg_loss: 0.3951
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8630
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 227, Global step 227:
20-03-23 12:04-INFO-training batch loss: 0.0271; avg_loss: 0.3935
20-03-23 12:04-INFO-training batch acc: 0.9844; avg_acc: 0.8635
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 228, Global step 228:
20-03-23 12:04-INFO-training batch loss: 0.0115; avg_loss: 0.3918
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8641
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 229, Global step 229:
20-03-23 12:04-INFO-training batch loss: 0.0148; avg_loss: 0.3901
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8647
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 230, Global step 230:
20-03-23 12:04-INFO-training batch loss: 0.0181; avg_loss: 0.3885
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8653
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 231, Global step 231:
20-03-23 12:04-INFO-training batch loss: 0.0095; avg_loss: 0.3869
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8659
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 232, Global step 232:
20-03-23 12:04-INFO-training batch loss: 0.0110; avg_loss: 0.3853
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8664
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 233, Global step 233:
20-03-23 12:04-INFO-training batch loss: 0.0157; avg_loss: 0.3837
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8670
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 234, Global step 234:
20-03-23 12:04-INFO-training batch loss: 0.0126; avg_loss: 0.3821
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8676
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 235, Global step 235:
20-03-23 12:04-INFO-training batch loss: 0.0116; avg_loss: 0.3805
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8682
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 236, Global step 236:
20-03-23 12:04-INFO-training batch loss: 0.0080; avg_loss: 0.3789
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8687
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 237, Global step 237:
20-03-23 12:04-INFO-training batch loss: 0.0113; avg_loss: 0.3774
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8693
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 238, Global step 238:
20-03-23 12:04-INFO-training batch loss: 0.0077; avg_loss: 0.3758
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8698
20-03-23 12:04-INFO-
20-03-23 12:04-INFO-Epoch 0, Batch 239, Global step 239:
20-03-23 12:04-INFO-training batch loss: 0.0120; avg_loss: 0.3743
20-03-23 12:04-INFO-training batch acc: 1.0000; avg_acc: 0.8704
20-03-23 12:04-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 240, Global step 240:
20-03-23 12:05-INFO-training batch loss: 0.0118; avg_loss: 0.3728
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8709
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 241, Global step 241:
20-03-23 12:05-INFO-training batch loss: 0.0088; avg_loss: 0.3713
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8714
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 242, Global step 242:
20-03-23 12:05-INFO-training batch loss: 0.0048; avg_loss: 0.3698
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8720
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 243, Global step 243:
20-03-23 12:05-INFO-training batch loss: 0.0105; avg_loss: 0.3683
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8725
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 244, Global step 244:
20-03-23 12:05-INFO-training batch loss: 0.0097; avg_loss: 0.3668
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8730
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 245, Global step 245:
20-03-23 12:05-INFO-training batch loss: 0.0089; avg_loss: 0.3654
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8735
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 246, Global step 246:
20-03-23 12:05-INFO-training batch loss: 0.0086; avg_loss: 0.3639
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8740
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 247, Global step 247:
20-03-23 12:05-INFO-training batch loss: 0.0124; avg_loss: 0.3625
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8746
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 248, Global step 248:
20-03-23 12:05-INFO-training batch loss: 0.0246; avg_loss: 0.3611
20-03-23 12:05-INFO-training batch acc: 0.9922; avg_acc: 0.8750
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 249, Global step 249:
20-03-23 12:05-INFO-training batch loss: 0.0056; avg_loss: 0.3597
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8755
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 250, Global step 250:
20-03-23 12:05-INFO-training batch loss: 0.0367; avg_loss: 0.3584
20-03-23 12:05-INFO-training batch acc: 0.9844; avg_acc: 0.8760
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 251, Global step 251:
20-03-23 12:05-INFO-training batch loss: 0.0130; avg_loss: 0.3570
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8765
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 252, Global step 252:
20-03-23 12:05-INFO-training batch loss: 0.0189; avg_loss: 0.3557
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8770
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 253, Global step 253:
20-03-23 12:05-INFO-training batch loss: 0.0070; avg_loss: 0.3543
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8774
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 254, Global step 254:
20-03-23 12:05-INFO-training batch loss: 0.0132; avg_loss: 0.3530
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8779
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 255, Global step 255:
20-03-23 12:05-INFO-training batch loss: 0.0084; avg_loss: 0.3516
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8784
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 256, Global step 256:
20-03-23 12:05-INFO-training batch loss: 0.0085; avg_loss: 0.3503
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8789
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 257, Global step 257:
20-03-23 12:05-INFO-training batch loss: 0.0085; avg_loss: 0.3490
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8793
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 258, Global step 258:
20-03-23 12:05-INFO-training batch loss: 0.0067; avg_loss: 0.3476
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8798
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 259, Global step 259:
20-03-23 12:05-INFO-training batch loss: 0.0146; avg_loss: 0.3463
20-03-23 12:05-INFO-training batch acc: 0.9922; avg_acc: 0.8802
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 260, Global step 260:
20-03-23 12:05-INFO-training batch loss: 0.0178; avg_loss: 0.3451
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8807
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 261, Global step 261:
20-03-23 12:05-INFO-training batch loss: 0.0077; avg_loss: 0.3438
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8812
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 262, Global step 262:
20-03-23 12:05-INFO-training batch loss: 0.0147; avg_loss: 0.3425
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8816
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 263, Global step 263:
20-03-23 12:05-INFO-training batch loss: 0.0082; avg_loss: 0.3413
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8821
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 264, Global step 264:
20-03-23 12:05-INFO-training batch loss: 0.0314; avg_loss: 0.3401
20-03-23 12:05-INFO-training batch acc: 0.9922; avg_acc: 0.8825
20-03-23 12:05-INFO-
20-03-23 12:05-INFO-Epoch 0, Batch 265, Global step 265:
20-03-23 12:05-INFO-training batch loss: 0.0081; avg_loss: 0.3388
20-03-23 12:05-INFO-training batch acc: 1.0000; avg_acc: 0.8829
20-03-23 12:05-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 266, Global step 266:
20-03-23 12:06-INFO-training batch loss: 0.0069; avg_loss: 0.3376
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8834
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 267, Global step 267:
20-03-23 12:06-INFO-training batch loss: 0.0055; avg_loss: 0.3363
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8838
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 268, Global step 268:
20-03-23 12:06-INFO-training batch loss: 0.0187; avg_loss: 0.3352
20-03-23 12:06-INFO-training batch acc: 0.9922; avg_acc: 0.8842
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 269, Global step 269:
20-03-23 12:06-INFO-training batch loss: 0.0067; avg_loss: 0.3339
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8846
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 270, Global step 270:
20-03-23 12:06-INFO-training batch loss: 0.0149; avg_loss: 0.3328
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8851
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 271, Global step 271:
20-03-23 12:06-INFO-training batch loss: 0.0099; avg_loss: 0.3316
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8855
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 272, Global step 272:
20-03-23 12:06-INFO-training batch loss: 0.0144; avg_loss: 0.3304
20-03-23 12:06-INFO-training batch acc: 0.9922; avg_acc: 0.8859
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 273, Global step 273:
20-03-23 12:06-INFO-training batch loss: 0.0084; avg_loss: 0.3292
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8863
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 274, Global step 274:
20-03-23 12:06-INFO-training batch loss: 0.0113; avg_loss: 0.3281
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8867
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 275, Global step 275:
20-03-23 12:06-INFO-training batch loss: 0.0066; avg_loss: 0.3269
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8871
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 276, Global step 276:
20-03-23 12:06-INFO-training batch loss: 0.0084; avg_loss: 0.3257
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8875
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 277, Global step 277:
20-03-23 12:06-INFO-training batch loss: 0.0044; avg_loss: 0.3246
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8879
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 278, Global step 278:
20-03-23 12:06-INFO-training batch loss: 0.0210; avg_loss: 0.3235
20-03-23 12:06-INFO-training batch acc: 0.9922; avg_acc: 0.8883
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 279, Global step 279:
20-03-23 12:06-INFO-training batch loss: 0.0036; avg_loss: 0.3223
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8887
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 280, Global step 280:
20-03-23 12:06-INFO-training batch loss: 0.0072; avg_loss: 0.3212
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8891
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 281, Global step 281:
20-03-23 12:06-INFO-training batch loss: 0.0105; avg_loss: 0.3201
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8895
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 282, Global step 282:
20-03-23 12:06-INFO-training batch loss: 0.0052; avg_loss: 0.3190
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8899
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 283, Global step 283:
20-03-23 12:06-INFO-training batch loss: 0.0061; avg_loss: 0.3179
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8903
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, Batch 284, Global step 284:
20-03-23 12:06-INFO-training batch loss: 0.0043; avg_loss: 0.3168
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.8907
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, training batch loss: 0.0043; avg_loss: 0.3168
20-03-23 12:06-INFO-Epoch 0, training batch accuracy: 1.0000; avg_accuracy: 0.8907
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 0, evaluating batch loss: 2.0810; avg_loss: 0.7781
20-03-23 12:06-INFO-Epoch 0, evaluating batch accuracy: 0.8409; avg_accuracy: 0.9229
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 1, Batch 1, Global step 285:
20-03-23 12:06-INFO-training batch loss: 0.0148; avg_loss: 0.0148
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 1, Batch 2, Global step 286:
20-03-23 12:06-INFO-training batch loss: 0.0182; avg_loss: 0.0165
20-03-23 12:06-INFO-training batch acc: 0.9922; avg_acc: 0.9961
20-03-23 12:06-INFO-
20-03-23 12:06-INFO-Epoch 1, Batch 3, Global step 287:
20-03-23 12:06-INFO-training batch loss: 0.0123; avg_loss: 0.0151
20-03-23 12:06-INFO-training batch acc: 1.0000; avg_acc: 0.9974
20-03-23 12:06-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 4, Global step 288:
20-03-23 12:07-INFO-training batch loss: 0.0098; avg_loss: 0.0137
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9980
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 5, Global step 289:
20-03-23 12:07-INFO-training batch loss: 0.0052; avg_loss: 0.0120
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9984
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 6, Global step 290:
20-03-23 12:07-INFO-training batch loss: 0.0057; avg_loss: 0.0110
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 7, Global step 291:
20-03-23 12:07-INFO-training batch loss: 0.0095; avg_loss: 0.0108
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 8, Global step 292:
20-03-23 12:07-INFO-training batch loss: 0.0072; avg_loss: 0.0103
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 9, Global step 293:
20-03-23 12:07-INFO-training batch loss: 0.0200; avg_loss: 0.0114
20-03-23 12:07-INFO-training batch acc: 0.9922; avg_acc: 0.9983
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 10, Global step 294:
20-03-23 12:07-INFO-training batch loss: 0.0069; avg_loss: 0.0109
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9984
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 11, Global step 295:
20-03-23 12:07-INFO-training batch loss: 0.0062; avg_loss: 0.0105
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9986
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 12, Global step 296:
20-03-23 12:07-INFO-training batch loss: 0.0136; avg_loss: 0.0108
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9987
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 13, Global step 297:
20-03-23 12:07-INFO-training batch loss: 0.0138; avg_loss: 0.0110
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 14, Global step 298:
20-03-23 12:07-INFO-training batch loss: 0.0218; avg_loss: 0.0118
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 15, Global step 299:
20-03-23 12:07-INFO-training batch loss: 0.0093; avg_loss: 0.0116
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 16, Global step 300:
20-03-23 12:07-INFO-training batch loss: 0.0088; avg_loss: 0.0114
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 17, Global step 301:
20-03-23 12:07-INFO-training batch loss: 0.0094; avg_loss: 0.0113
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 18, Global step 302:
20-03-23 12:07-INFO-training batch loss: 0.0150; avg_loss: 0.0115
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 19, Global step 303:
20-03-23 12:07-INFO-training batch loss: 0.0165; avg_loss: 0.0118
20-03-23 12:07-INFO-training batch acc: 0.9922; avg_acc: 0.9988
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 20, Global step 304:
20-03-23 12:07-INFO-training batch loss: 0.0067; avg_loss: 0.0115
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9988
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 21, Global step 305:
20-03-23 12:07-INFO-training batch loss: 0.0093; avg_loss: 0.0114
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 22, Global step 306:
20-03-23 12:07-INFO-training batch loss: 0.0059; avg_loss: 0.0112
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 23, Global step 307:
20-03-23 12:07-INFO-training batch loss: 0.0104; avg_loss: 0.0111
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 24, Global step 308:
20-03-23 12:07-INFO-training batch loss: 0.0034; avg_loss: 0.0108
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9990
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 25, Global step 309:
20-03-23 12:07-INFO-training batch loss: 0.0035; avg_loss: 0.0105
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 26, Global step 310:
20-03-23 12:07-INFO-training batch loss: 0.0083; avg_loss: 0.0104
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 27, Global step 311:
20-03-23 12:07-INFO-training batch loss: 0.0084; avg_loss: 0.0104
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 28, Global step 312:
20-03-23 12:07-INFO-training batch loss: 0.0078; avg_loss: 0.0103
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 29, Global step 313:
20-03-23 12:07-INFO-training batch loss: 0.0093; avg_loss: 0.0102
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:07-INFO-
20-03-23 12:07-INFO-Epoch 1, Batch 30, Global step 314:
20-03-23 12:07-INFO-training batch loss: 0.0123; avg_loss: 0.0103
20-03-23 12:07-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:07-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 31, Global step 315:
20-03-23 12:08-INFO-training batch loss: 0.0127; avg_loss: 0.0104
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 32, Global step 316:
20-03-23 12:08-INFO-training batch loss: 0.0068; avg_loss: 0.0103
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 33, Global step 317:
20-03-23 12:08-INFO-training batch loss: 0.0077; avg_loss: 0.0102
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 34, Global step 318:
20-03-23 12:08-INFO-training batch loss: 0.0111; avg_loss: 0.0102
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 35, Global step 319:
20-03-23 12:08-INFO-training batch loss: 0.0094; avg_loss: 0.0102
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 36, Global step 320:
20-03-23 12:08-INFO-training batch loss: 0.0146; avg_loss: 0.0103
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 37, Global step 321:
20-03-23 12:08-INFO-training batch loss: 0.0056; avg_loss: 0.0102
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 38, Global step 322:
20-03-23 12:08-INFO-training batch loss: 0.0068; avg_loss: 0.0101
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 39, Global step 323:
20-03-23 12:08-INFO-training batch loss: 0.0111; avg_loss: 0.0101
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 40, Global step 324:
20-03-23 12:08-INFO-training batch loss: 0.0075; avg_loss: 0.0101
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 41, Global step 325:
20-03-23 12:08-INFO-training batch loss: 0.0040; avg_loss: 0.0099
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 42, Global step 326:
20-03-23 12:08-INFO-training batch loss: 0.0077; avg_loss: 0.0099
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 43, Global step 327:
20-03-23 12:08-INFO-training batch loss: 0.0058; avg_loss: 0.0098
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 44, Global step 328:
20-03-23 12:08-INFO-training batch loss: 0.0196; avg_loss: 0.0100
20-03-23 12:08-INFO-training batch acc: 0.9922; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 45, Global step 329:
20-03-23 12:08-INFO-training batch loss: 0.0072; avg_loss: 0.0099
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 46, Global step 330:
20-03-23 12:08-INFO-training batch loss: 0.0038; avg_loss: 0.0098
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 47, Global step 331:
20-03-23 12:08-INFO-training batch loss: 0.0122; avg_loss: 0.0098
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 48, Global step 332:
20-03-23 12:08-INFO-training batch loss: 0.0045; avg_loss: 0.0097
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9993
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 49, Global step 333:
20-03-23 12:08-INFO-training batch loss: 0.0067; avg_loss: 0.0097
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 50, Global step 334:
20-03-23 12:08-INFO-training batch loss: 0.0073; avg_loss: 0.0096
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 51, Global step 335:
20-03-23 12:08-INFO-training batch loss: 0.0076; avg_loss: 0.0096
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 52, Global step 336:
20-03-23 12:08-INFO-training batch loss: 0.0098; avg_loss: 0.0096
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 53, Global step 337:
20-03-23 12:08-INFO-training batch loss: 0.0035; avg_loss: 0.0095
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 54, Global step 338:
20-03-23 12:08-INFO-training batch loss: 0.0032; avg_loss: 0.0094
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 55, Global step 339:
20-03-23 12:08-INFO-training batch loss: 0.0045; avg_loss: 0.0093
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:08-INFO-Epoch 1, Batch 56, Global step 340:
20-03-23 12:08-INFO-training batch loss: 0.0063; avg_loss: 0.0092
20-03-23 12:08-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:08-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 57, Global step 341:
20-03-23 12:09-INFO-training batch loss: 0.0064; avg_loss: 0.0092
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 58, Global step 342:
20-03-23 12:09-INFO-training batch loss: 0.0066; avg_loss: 0.0091
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 59, Global step 343:
20-03-23 12:09-INFO-training batch loss: 0.0047; avg_loss: 0.0090
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 60, Global step 344:
20-03-23 12:09-INFO-training batch loss: 0.0056; avg_loss: 0.0090
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 61, Global step 345:
20-03-23 12:09-INFO-training batch loss: 0.0081; avg_loss: 0.0090
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 62, Global step 346:
20-03-23 12:09-INFO-training batch loss: 0.0085; avg_loss: 0.0090
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 63, Global step 347:
20-03-23 12:09-INFO-training batch loss: 0.0037; avg_loss: 0.0089
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 64, Global step 348:
20-03-23 12:09-INFO-training batch loss: 0.0041; avg_loss: 0.0088
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 65, Global step 349:
20-03-23 12:09-INFO-training batch loss: 0.0041; avg_loss: 0.0087
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 66, Global step 350:
20-03-23 12:09-INFO-training batch loss: 0.0049; avg_loss: 0.0087
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 67, Global step 351:
20-03-23 12:09-INFO-training batch loss: 0.0038; avg_loss: 0.0086
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 68, Global step 352:
20-03-23 12:09-INFO-training batch loss: 0.0045; avg_loss: 0.0085
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 69, Global step 353:
20-03-23 12:09-INFO-training batch loss: 0.0037; avg_loss: 0.0085
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 70, Global step 354:
20-03-23 12:09-INFO-training batch loss: 0.0023; avg_loss: 0.0084
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 71, Global step 355:
20-03-23 12:09-INFO-training batch loss: 0.0051; avg_loss: 0.0083
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 72, Global step 356:
20-03-23 12:09-INFO-training batch loss: 0.0056; avg_loss: 0.0083
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 73, Global step 357:
20-03-23 12:09-INFO-training batch loss: 0.0057; avg_loss: 0.0083
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 74, Global step 358:
20-03-23 12:09-INFO-training batch loss: 0.0084; avg_loss: 0.0083
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 75, Global step 359:
20-03-23 12:09-INFO-training batch loss: 0.0045; avg_loss: 0.0082
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 76, Global step 360:
20-03-23 12:09-INFO-training batch loss: 0.0037; avg_loss: 0.0082
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 77, Global step 361:
20-03-23 12:09-INFO-training batch loss: 0.0075; avg_loss: 0.0081
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 78, Global step 362:
20-03-23 12:09-INFO-training batch loss: 0.0034; avg_loss: 0.0081
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 79, Global step 363:
20-03-23 12:09-INFO-training batch loss: 0.0037; avg_loss: 0.0080
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 80, Global step 364:
20-03-23 12:09-INFO-training batch loss: 0.0023; avg_loss: 0.0080
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 81, Global step 365:
20-03-23 12:09-INFO-training batch loss: 0.0054; avg_loss: 0.0079
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:09-INFO-Epoch 1, Batch 82, Global step 366:
20-03-23 12:09-INFO-training batch loss: 0.0058; avg_loss: 0.0079
20-03-23 12:09-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:09-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 83, Global step 367:
20-03-23 12:10-INFO-training batch loss: 0.0025; avg_loss: 0.0078
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 84, Global step 368:
20-03-23 12:10-INFO-training batch loss: 0.0033; avg_loss: 0.0078
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 85, Global step 369:
20-03-23 12:10-INFO-training batch loss: 0.0055; avg_loss: 0.0078
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 86, Global step 370:
20-03-23 12:10-INFO-training batch loss: 0.0036; avg_loss: 0.0077
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 87, Global step 371:
20-03-23 12:10-INFO-training batch loss: 0.0044; avg_loss: 0.0077
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 88, Global step 372:
20-03-23 12:10-INFO-training batch loss: 0.0036; avg_loss: 0.0076
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 89, Global step 373:
20-03-23 12:10-INFO-training batch loss: 0.0034; avg_loss: 0.0076
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 90, Global step 374:
20-03-23 12:10-INFO-training batch loss: 0.0031; avg_loss: 0.0075
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 91, Global step 375:
20-03-23 12:10-INFO-training batch loss: 0.0043; avg_loss: 0.0075
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 92, Global step 376:
20-03-23 12:10-INFO-training batch loss: 0.0036; avg_loss: 0.0074
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 93, Global step 377:
20-03-23 12:10-INFO-training batch loss: 0.0030; avg_loss: 0.0074
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 94, Global step 378:
20-03-23 12:10-INFO-training batch loss: 0.0029; avg_loss: 0.0074
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 95, Global step 379:
20-03-23 12:10-INFO-training batch loss: 0.0023; avg_loss: 0.0073
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 96, Global step 380:
20-03-23 12:10-INFO-training batch loss: 0.0034; avg_loss: 0.0073
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 97, Global step 381:
20-03-23 12:10-INFO-training batch loss: 0.0043; avg_loss: 0.0072
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 98, Global step 382:
20-03-23 12:10-INFO-training batch loss: 0.0037; avg_loss: 0.0072
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 99, Global step 383:
20-03-23 12:10-INFO-training batch loss: 0.0033; avg_loss: 0.0072
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 100, Global step 384:
20-03-23 12:10-INFO-training batch loss: 0.0045; avg_loss: 0.0071
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 101, Global step 385:
20-03-23 12:10-INFO-training batch loss: 0.0025; avg_loss: 0.0071
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 102, Global step 386:
20-03-23 12:10-INFO-training batch loss: 0.0115; avg_loss: 0.0071
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 103, Global step 387:
20-03-23 12:10-INFO-training batch loss: 0.0025; avg_loss: 0.0071
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 104, Global step 388:
20-03-23 12:10-INFO-training batch loss: 0.0042; avg_loss: 0.0071
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 105, Global step 389:
20-03-23 12:10-INFO-training batch loss: 0.0024; avg_loss: 0.0070
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 106, Global step 390:
20-03-23 12:10-INFO-training batch loss: 0.0029; avg_loss: 0.0070
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 107, Global step 391:
20-03-23 12:10-INFO-training batch loss: 0.0042; avg_loss: 0.0069
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:10-INFO-Epoch 1, Batch 108, Global step 392:
20-03-23 12:10-INFO-training batch loss: 0.0023; avg_loss: 0.0069
20-03-23 12:10-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:10-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 109, Global step 393:
20-03-23 12:11-INFO-training batch loss: 0.0047; avg_loss: 0.0069
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 110, Global step 394:
20-03-23 12:11-INFO-training batch loss: 0.0030; avg_loss: 0.0068
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 111, Global step 395:
20-03-23 12:11-INFO-training batch loss: 0.0040; avg_loss: 0.0068
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 112, Global step 396:
20-03-23 12:11-INFO-training batch loss: 0.0032; avg_loss: 0.0068
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 113, Global step 397:
20-03-23 12:11-INFO-training batch loss: 0.0030; avg_loss: 0.0068
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 114, Global step 398:
20-03-23 12:11-INFO-training batch loss: 0.0034; avg_loss: 0.0067
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 115, Global step 399:
20-03-23 12:11-INFO-training batch loss: 0.0031; avg_loss: 0.0067
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 116, Global step 400:
20-03-23 12:11-INFO-training batch loss: 0.0040; avg_loss: 0.0067
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 117, Global step 401:
20-03-23 12:11-INFO-training batch loss: 0.0046; avg_loss: 0.0067
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 118, Global step 402:
20-03-23 12:11-INFO-training batch loss: 0.0025; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 119, Global step 403:
20-03-23 12:11-INFO-training batch loss: 0.0039; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 120, Global step 404:
20-03-23 12:11-INFO-training batch loss: 0.0036; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 121, Global step 405:
20-03-23 12:11-INFO-training batch loss: 0.0086; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 122, Global step 406:
20-03-23 12:11-INFO-training batch loss: 0.0057; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 123, Global step 407:
20-03-23 12:11-INFO-training batch loss: 0.0059; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 124, Global step 408:
20-03-23 12:11-INFO-training batch loss: 0.0044; avg_loss: 0.0066
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 125, Global step 409:
20-03-23 12:11-INFO-training batch loss: 0.0037; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 126, Global step 410:
20-03-23 12:11-INFO-training batch loss: 0.0036; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 127, Global step 411:
20-03-23 12:11-INFO-training batch loss: 0.0064; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 128, Global step 412:
20-03-23 12:11-INFO-training batch loss: 0.0035; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 129, Global step 413:
20-03-23 12:11-INFO-training batch loss: 0.0039; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 130, Global step 414:
20-03-23 12:11-INFO-training batch loss: 0.0055; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 131, Global step 415:
20-03-23 12:11-INFO-training batch loss: 0.0083; avg_loss: 0.0065
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 132, Global step 416:
20-03-23 12:11-INFO-training batch loss: 0.0032; avg_loss: 0.0064
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 133, Global step 417:
20-03-23 12:11-INFO-training batch loss: 0.0050; avg_loss: 0.0064
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 134, Global step 418:
20-03-23 12:11-INFO-training batch loss: 0.0042; avg_loss: 0.0064
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:11-INFO-Epoch 1, Batch 135, Global step 419:
20-03-23 12:11-INFO-training batch loss: 0.0050; avg_loss: 0.0064
20-03-23 12:11-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:11-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 136, Global step 420:
20-03-23 12:12-INFO-training batch loss: 0.0035; avg_loss: 0.0064
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 137, Global step 421:
20-03-23 12:12-INFO-training batch loss: 0.0042; avg_loss: 0.0064
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 138, Global step 422:
20-03-23 12:12-INFO-training batch loss: 0.0060; avg_loss: 0.0064
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 139, Global step 423:
20-03-23 12:12-INFO-training batch loss: 0.0024; avg_loss: 0.0063
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 140, Global step 424:
20-03-23 12:12-INFO-training batch loss: 0.0035; avg_loss: 0.0063
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 141, Global step 425:
20-03-23 12:12-INFO-training batch loss: 0.0029; avg_loss: 0.0063
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 142, Global step 426:
20-03-23 12:12-INFO-training batch loss: 0.0034; avg_loss: 0.0063
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 143, Global step 427:
20-03-23 12:12-INFO-training batch loss: 0.0039; avg_loss: 0.0063
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 144, Global step 428:
20-03-23 12:12-INFO-training batch loss: 0.0045; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 145, Global step 429:
20-03-23 12:12-INFO-training batch loss: 0.0024; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 146, Global step 430:
20-03-23 12:12-INFO-training batch loss: 0.0052; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 147, Global step 431:
20-03-23 12:12-INFO-training batch loss: 0.0035; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 148, Global step 432:
20-03-23 12:12-INFO-training batch loss: 0.0024; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 149, Global step 433:
20-03-23 12:12-INFO-training batch loss: 0.0037; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 150, Global step 434:
20-03-23 12:12-INFO-training batch loss: 0.0062; avg_loss: 0.0062
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 151, Global step 435:
20-03-23 12:12-INFO-training batch loss: 0.0020; avg_loss: 0.0061
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 152, Global step 436:
20-03-23 12:12-INFO-training batch loss: 0.0030; avg_loss: 0.0061
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 153, Global step 437:
20-03-23 12:12-INFO-training batch loss: 0.0043; avg_loss: 0.0061
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 154, Global step 438:
20-03-23 12:12-INFO-training batch loss: 0.0040; avg_loss: 0.0061
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 155, Global step 439:
20-03-23 12:12-INFO-training batch loss: 0.0023; avg_loss: 0.0061
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 156, Global step 440:
20-03-23 12:12-INFO-training batch loss: 0.0032; avg_loss: 0.0060
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 157, Global step 441:
20-03-23 12:12-INFO-training batch loss: 0.0022; avg_loss: 0.0060
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 158, Global step 442:
20-03-23 12:12-INFO-training batch loss: 0.0043; avg_loss: 0.0060
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 159, Global step 443:
20-03-23 12:12-INFO-training batch loss: 0.0022; avg_loss: 0.0060
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 160, Global step 444:
20-03-23 12:12-INFO-training batch loss: 0.0043; avg_loss: 0.0060
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:12-INFO-Epoch 1, Batch 161, Global step 445:
20-03-23 12:12-INFO-training batch loss: 0.0024; avg_loss: 0.0059
20-03-23 12:12-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:12-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 162, Global step 446:
20-03-23 12:13-INFO-training batch loss: 0.0042; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 163, Global step 447:
20-03-23 12:13-INFO-training batch loss: 0.0045; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 164, Global step 448:
20-03-23 12:13-INFO-training batch loss: 0.0029; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 165, Global step 449:
20-03-23 12:13-INFO-training batch loss: 0.0029; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 166, Global step 450:
20-03-23 12:13-INFO-training batch loss: 0.0041; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 167, Global step 451:
20-03-23 12:13-INFO-training batch loss: 0.0052; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 168, Global step 452:
20-03-23 12:13-INFO-training batch loss: 0.0033; avg_loss: 0.0059
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 169, Global step 453:
20-03-23 12:13-INFO-training batch loss: 0.0037; avg_loss: 0.0058
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 170, Global step 454:
20-03-23 12:13-INFO-training batch loss: 0.0026; avg_loss: 0.0058
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 171, Global step 455:
20-03-23 12:13-INFO-training batch loss: 0.0033; avg_loss: 0.0058
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 172, Global step 456:
20-03-23 12:13-INFO-training batch loss: 0.0023; avg_loss: 0.0058
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 173, Global step 457:
20-03-23 12:13-INFO-training batch loss: 0.0034; avg_loss: 0.0058
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 174, Global step 458:
20-03-23 12:13-INFO-training batch loss: 0.0036; avg_loss: 0.0058
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 175, Global step 459:
20-03-23 12:13-INFO-training batch loss: 0.0027; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 176, Global step 460:
20-03-23 12:13-INFO-training batch loss: 0.0041; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 177, Global step 461:
20-03-23 12:13-INFO-training batch loss: 0.0026; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 178, Global step 462:
20-03-23 12:13-INFO-training batch loss: 0.0037; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 179, Global step 463:
20-03-23 12:13-INFO-training batch loss: 0.0041; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 180, Global step 464:
20-03-23 12:13-INFO-training batch loss: 0.0041; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 181, Global step 465:
20-03-23 12:13-INFO-training batch loss: 0.0070; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 182, Global step 466:
20-03-23 12:13-INFO-training batch loss: 0.0038; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 183, Global step 467:
20-03-23 12:13-INFO-training batch loss: 0.0067; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 184, Global step 468:
20-03-23 12:13-INFO-training batch loss: 0.0029; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 185, Global step 469:
20-03-23 12:13-INFO-training batch loss: 0.0034; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 186, Global step 470:
20-03-23 12:13-INFO-training batch loss: 0.0032; avg_loss: 0.0057
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 187, Global step 471:
20-03-23 12:13-INFO-training batch loss: 0.0041; avg_loss: 0.0056
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:13-INFO-Epoch 1, Batch 188, Global step 472:
20-03-23 12:13-INFO-training batch loss: 0.0024; avg_loss: 0.0056
20-03-23 12:13-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:13-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 189, Global step 473:
20-03-23 12:14-INFO-training batch loss: 0.0062; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 190, Global step 474:
20-03-23 12:14-INFO-training batch loss: 0.0035; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 191, Global step 475:
20-03-23 12:14-INFO-training batch loss: 0.0048; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 192, Global step 476:
20-03-23 12:14-INFO-training batch loss: 0.0025; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 193, Global step 477:
20-03-23 12:14-INFO-training batch loss: 0.0042; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 194, Global step 478:
20-03-23 12:14-INFO-training batch loss: 0.0032; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 195, Global step 479:
20-03-23 12:14-INFO-training batch loss: 0.0037; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 196, Global step 480:
20-03-23 12:14-INFO-training batch loss: 0.0032; avg_loss: 0.0056
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 197, Global step 481:
20-03-23 12:14-INFO-training batch loss: 0.0036; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 198, Global step 482:
20-03-23 12:14-INFO-training batch loss: 0.0043; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 199, Global step 483:
20-03-23 12:14-INFO-training batch loss: 0.0042; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 200, Global step 484:
20-03-23 12:14-INFO-training batch loss: 0.0036; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 201, Global step 485:
20-03-23 12:14-INFO-training batch loss: 0.0038; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 202, Global step 486:
20-03-23 12:14-INFO-training batch loss: 0.0033; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 203, Global step 487:
20-03-23 12:14-INFO-training batch loss: 0.0030; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 204, Global step 488:
20-03-23 12:14-INFO-training batch loss: 0.0030; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 205, Global step 489:
20-03-23 12:14-INFO-training batch loss: 0.0036; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 206, Global step 490:
20-03-23 12:14-INFO-training batch loss: 0.0032; avg_loss: 0.0055
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 207, Global step 491:
20-03-23 12:14-INFO-training batch loss: 0.0016; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 208, Global step 492:
20-03-23 12:14-INFO-training batch loss: 0.0047; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 209, Global step 493:
20-03-23 12:14-INFO-training batch loss: 0.0028; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 210, Global step 494:
20-03-23 12:14-INFO-training batch loss: 0.0040; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 211, Global step 495:
20-03-23 12:14-INFO-training batch loss: 0.0042; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 212, Global step 496:
20-03-23 12:14-INFO-training batch loss: 0.0045; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 213, Global step 497:
20-03-23 12:14-INFO-training batch loss: 0.0045; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:14-INFO-
20-03-23 12:14-INFO-Epoch 1, Batch 214, Global step 498:
20-03-23 12:14-INFO-training batch loss: 0.0042; avg_loss: 0.0054
20-03-23 12:14-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:14-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 215, Global step 499:
20-03-23 12:15-INFO-training batch loss: 0.0021; avg_loss: 0.0054
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 216, Global step 500:
20-03-23 12:15-INFO-training batch loss: 0.0044; avg_loss: 0.0054
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 217, Global step 501:
20-03-23 12:15-INFO-training batch loss: 0.0031; avg_loss: 0.0054
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 218, Global step 502:
20-03-23 12:15-INFO-training batch loss: 0.0022; avg_loss: 0.0054
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 219, Global step 503:
20-03-23 12:15-INFO-training batch loss: 0.0044; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 220, Global step 504:
20-03-23 12:15-INFO-training batch loss: 0.0029; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 221, Global step 505:
20-03-23 12:15-INFO-training batch loss: 0.0019; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 222, Global step 506:
20-03-23 12:15-INFO-training batch loss: 0.0032; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 223, Global step 507:
20-03-23 12:15-INFO-training batch loss: 0.0066; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 224, Global step 508:
20-03-23 12:15-INFO-training batch loss: 0.0025; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 225, Global step 509:
20-03-23 12:15-INFO-training batch loss: 0.0049; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 226, Global step 510:
20-03-23 12:15-INFO-training batch loss: 0.0037; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 227, Global step 511:
20-03-23 12:15-INFO-training batch loss: 0.0037; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 228, Global step 512:
20-03-23 12:15-INFO-training batch loss: 0.0027; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 229, Global step 513:
20-03-23 12:15-INFO-training batch loss: 0.0040; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 230, Global step 514:
20-03-23 12:15-INFO-training batch loss: 0.0027; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 231, Global step 515:
20-03-23 12:15-INFO-training batch loss: 0.0031; avg_loss: 0.0053
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 232, Global step 516:
20-03-23 12:15-INFO-training batch loss: 0.0042; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 233, Global step 517:
20-03-23 12:15-INFO-training batch loss: 0.0042; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 234, Global step 518:
20-03-23 12:15-INFO-training batch loss: 0.0029; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 235, Global step 519:
20-03-23 12:15-INFO-training batch loss: 0.0028; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 236, Global step 520:
20-03-23 12:15-INFO-training batch loss: 0.0033; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 237, Global step 521:
20-03-23 12:15-INFO-training batch loss: 0.0036; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 238, Global step 522:
20-03-23 12:15-INFO-training batch loss: 0.0029; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 239, Global step 523:
20-03-23 12:15-INFO-training batch loss: 0.0030; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:15-INFO-Epoch 1, Batch 240, Global step 524:
20-03-23 12:15-INFO-training batch loss: 0.0034; avg_loss: 0.0052
20-03-23 12:15-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:15-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 241, Global step 525:
20-03-23 12:16-INFO-training batch loss: 0.0028; avg_loss: 0.0052
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 242, Global step 526:
20-03-23 12:16-INFO-training batch loss: 0.0022; avg_loss: 0.0052
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 243, Global step 527:
20-03-23 12:16-INFO-training batch loss: 0.0047; avg_loss: 0.0052
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 244, Global step 528:
20-03-23 12:16-INFO-training batch loss: 0.0025; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 245, Global step 529:
20-03-23 12:16-INFO-training batch loss: 0.0034; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 246, Global step 530:
20-03-23 12:16-INFO-training batch loss: 0.0028; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 247, Global step 531:
20-03-23 12:16-INFO-training batch loss: 0.0033; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 248, Global step 532:
20-03-23 12:16-INFO-training batch loss: 0.0036; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 249, Global step 533:
20-03-23 12:16-INFO-training batch loss: 0.0021; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 250, Global step 534:
20-03-23 12:16-INFO-training batch loss: 0.0038; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 251, Global step 535:
20-03-23 12:16-INFO-training batch loss: 0.0035; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 252, Global step 536:
20-03-23 12:16-INFO-training batch loss: 0.0027; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 253, Global step 537:
20-03-23 12:16-INFO-training batch loss: 0.0029; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 254, Global step 538:
20-03-23 12:16-INFO-training batch loss: 0.0110; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 0.9922; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 255, Global step 539:
20-03-23 12:16-INFO-training batch loss: 0.0039; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 256, Global step 540:
20-03-23 12:16-INFO-training batch loss: 0.0032; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 257, Global step 541:
20-03-23 12:16-INFO-training batch loss: 0.0024; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 258, Global step 542:
20-03-23 12:16-INFO-training batch loss: 0.0038; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 259, Global step 543:
20-03-23 12:16-INFO-training batch loss: 0.0030; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 260, Global step 544:
20-03-23 12:16-INFO-training batch loss: 0.0025; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 261, Global step 545:
20-03-23 12:16-INFO-training batch loss: 0.0046; avg_loss: 0.0051
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 262, Global step 546:
20-03-23 12:16-INFO-training batch loss: 0.0035; avg_loss: 0.0050
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 263, Global step 547:
20-03-23 12:16-INFO-training batch loss: 0.0040; avg_loss: 0.0050
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 264, Global step 548:
20-03-23 12:16-INFO-training batch loss: 0.0045; avg_loss: 0.0050
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 265, Global step 549:
20-03-23 12:16-INFO-training batch loss: 0.0045; avg_loss: 0.0050
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 266, Global step 550:
20-03-23 12:16-INFO-training batch loss: 0.0046; avg_loss: 0.0050
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:16-INFO-Epoch 1, Batch 267, Global step 551:
20-03-23 12:16-INFO-training batch loss: 0.0042; avg_loss: 0.0050
20-03-23 12:16-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:16-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 268, Global step 552:
20-03-23 12:17-INFO-training batch loss: 0.0042; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 269, Global step 553:
20-03-23 12:17-INFO-training batch loss: 0.0029; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 270, Global step 554:
20-03-23 12:17-INFO-training batch loss: 0.0036; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 271, Global step 555:
20-03-23 12:17-INFO-training batch loss: 0.0040; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 272, Global step 556:
20-03-23 12:17-INFO-training batch loss: 0.0064; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 273, Global step 557:
20-03-23 12:17-INFO-training batch loss: 0.0069; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 274, Global step 558:
20-03-23 12:17-INFO-training batch loss: 0.0030; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 275, Global step 559:
20-03-23 12:17-INFO-training batch loss: 0.0040; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 276, Global step 560:
20-03-23 12:17-INFO-training batch loss: 0.0057; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 277, Global step 561:
20-03-23 12:17-INFO-training batch loss: 0.0027; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 278, Global step 562:
20-03-23 12:17-INFO-training batch loss: 0.0044; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 279, Global step 563:
20-03-23 12:17-INFO-training batch loss: 0.0033; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 280, Global step 564:
20-03-23 12:17-INFO-training batch loss: 0.0029; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 281, Global step 565:
20-03-23 12:17-INFO-training batch loss: 0.0054; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 282, Global step 566:
20-03-23 12:17-INFO-training batch loss: 0.0045; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 283, Global step 567:
20-03-23 12:17-INFO-training batch loss: 0.0030; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, Batch 284, Global step 568:
20-03-23 12:17-INFO-training batch loss: 0.0037; avg_loss: 0.0050
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, training batch loss: 0.0037; avg_loss: 0.0050
20-03-23 12:17-INFO-Epoch 1, training batch accuracy: 1.0000; avg_accuracy: 0.9999
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 1, evaluating batch loss: 1.9677; avg_loss: 0.6836
20-03-23 12:17-INFO-Epoch 1, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9460
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 2, Batch 1, Global step 569:
20-03-23 12:17-INFO-training batch loss: 0.0029; avg_loss: 0.0029
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 2, Batch 2, Global step 570:
20-03-23 12:17-INFO-training batch loss: 0.0036; avg_loss: 0.0033
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 2, Batch 3, Global step 571:
20-03-23 12:17-INFO-training batch loss: 0.0039; avg_loss: 0.0035
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 2, Batch 4, Global step 572:
20-03-23 12:17-INFO-training batch loss: 0.0033; avg_loss: 0.0034
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:17-INFO-
20-03-23 12:17-INFO-Epoch 2, Batch 5, Global step 573:
20-03-23 12:17-INFO-training batch loss: 0.0061; avg_loss: 0.0040
20-03-23 12:17-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:17-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 6, Global step 574:
20-03-23 12:18-INFO-training batch loss: 0.0054; avg_loss: 0.0042
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 7, Global step 575:
20-03-23 12:18-INFO-training batch loss: 0.0066; avg_loss: 0.0046
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 8, Global step 576:
20-03-23 12:18-INFO-training batch loss: 0.0034; avg_loss: 0.0044
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 9, Global step 577:
20-03-23 12:18-INFO-training batch loss: 0.0027; avg_loss: 0.0042
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 10, Global step 578:
20-03-23 12:18-INFO-training batch loss: 0.0051; avg_loss: 0.0043
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 11, Global step 579:
20-03-23 12:18-INFO-training batch loss: 0.0034; avg_loss: 0.0042
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 12, Global step 580:
20-03-23 12:18-INFO-training batch loss: 0.0045; avg_loss: 0.0043
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 13, Global step 581:
20-03-23 12:18-INFO-training batch loss: 0.0030; avg_loss: 0.0042
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 14, Global step 582:
20-03-23 12:18-INFO-training batch loss: 0.0039; avg_loss: 0.0041
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 15, Global step 583:
20-03-23 12:18-INFO-training batch loss: 0.0029; avg_loss: 0.0041
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 16, Global step 584:
20-03-23 12:18-INFO-training batch loss: 0.0033; avg_loss: 0.0040
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 17, Global step 585:
20-03-23 12:18-INFO-training batch loss: 0.0028; avg_loss: 0.0039
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 18, Global step 586:
20-03-23 12:18-INFO-training batch loss: 0.0039; avg_loss: 0.0039
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 19, Global step 587:
20-03-23 12:18-INFO-training batch loss: 0.0031; avg_loss: 0.0039
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 20, Global step 588:
20-03-23 12:18-INFO-training batch loss: 0.0047; avg_loss: 0.0039
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 21, Global step 589:
20-03-23 12:18-INFO-training batch loss: 0.0046; avg_loss: 0.0040
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 22, Global step 590:
20-03-23 12:18-INFO-training batch loss: 0.0024; avg_loss: 0.0039
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 23, Global step 591:
20-03-23 12:18-INFO-training batch loss: 0.0026; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 24, Global step 592:
20-03-23 12:18-INFO-training batch loss: 0.0020; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 25, Global step 593:
20-03-23 12:18-INFO-training batch loss: 0.0023; avg_loss: 0.0037
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 26, Global step 594:
20-03-23 12:18-INFO-training batch loss: 0.0086; avg_loss: 0.0039
20-03-23 12:18-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 27, Global step 595:
20-03-23 12:18-INFO-training batch loss: 0.0026; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 28, Global step 596:
20-03-23 12:18-INFO-training batch loss: 0.0031; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 29, Global step 597:
20-03-23 12:18-INFO-training batch loss: 0.0039; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 30, Global step 598:
20-03-23 12:18-INFO-training batch loss: 0.0031; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 31, Global step 599:
20-03-23 12:18-INFO-training batch loss: 0.0034; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:18-INFO-
20-03-23 12:18-INFO-Epoch 2, Batch 32, Global step 600:
20-03-23 12:18-INFO-training batch loss: 0.0038; avg_loss: 0.0038
20-03-23 12:18-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:18-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 33, Global step 601:
20-03-23 12:19-INFO-training batch loss: 0.0034; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 34, Global step 602:
20-03-23 12:19-INFO-training batch loss: 0.0035; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 35, Global step 603:
20-03-23 12:19-INFO-training batch loss: 0.0032; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 36, Global step 604:
20-03-23 12:19-INFO-training batch loss: 0.0051; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 37, Global step 605:
20-03-23 12:19-INFO-training batch loss: 0.0036; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 38, Global step 606:
20-03-23 12:19-INFO-training batch loss: 0.0032; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 39, Global step 607:
20-03-23 12:19-INFO-training batch loss: 0.0043; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 40, Global step 608:
20-03-23 12:19-INFO-training batch loss: 0.0037; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 41, Global step 609:
20-03-23 12:19-INFO-training batch loss: 0.0073; avg_loss: 0.0039
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 42, Global step 610:
20-03-23 12:19-INFO-training batch loss: 0.0030; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 43, Global step 611:
20-03-23 12:19-INFO-training batch loss: 0.0026; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 44, Global step 612:
20-03-23 12:19-INFO-training batch loss: 0.0041; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 45, Global step 613:
20-03-23 12:19-INFO-training batch loss: 0.0035; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 46, Global step 614:
20-03-23 12:19-INFO-training batch loss: 0.0028; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 47, Global step 615:
20-03-23 12:19-INFO-training batch loss: 0.0034; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 48, Global step 616:
20-03-23 12:19-INFO-training batch loss: 0.0037; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 49, Global step 617:
20-03-23 12:19-INFO-training batch loss: 0.0032; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 50, Global step 618:
20-03-23 12:19-INFO-training batch loss: 0.0042; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 51, Global step 619:
20-03-23 12:19-INFO-training batch loss: 0.0070; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 52, Global step 620:
20-03-23 12:19-INFO-training batch loss: 0.0030; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 53, Global step 621:
20-03-23 12:19-INFO-training batch loss: 0.0035; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 54, Global step 622:
20-03-23 12:19-INFO-training batch loss: 0.0031; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 55, Global step 623:
20-03-23 12:19-INFO-training batch loss: 0.0067; avg_loss: 0.0039
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 56, Global step 624:
20-03-23 12:19-INFO-training batch loss: 0.0047; avg_loss: 0.0039
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 57, Global step 625:
20-03-23 12:19-INFO-training batch loss: 0.0028; avg_loss: 0.0039
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 58, Global step 626:
20-03-23 12:19-INFO-training batch loss: 0.0020; avg_loss: 0.0038
20-03-23 12:19-INFO-training batch acc: 1.0000; avg_acc: 0.9999
20-03-23 12:19-INFO-
20-03-23 12:19-INFO-Epoch 2, Batch 59, Global step 627:
20-03-23 12:19-INFO-training batch loss: 0.0113; avg_loss: 0.0040
20-03-23 12:19-INFO-training batch acc: 0.9922; avg_acc: 0.9997
20-03-23 12:19-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 60, Global step 628:
20-03-23 12:20-INFO-training batch loss: 0.0027; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 61, Global step 629:
20-03-23 12:20-INFO-training batch loss: 0.0023; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 62, Global step 630:
20-03-23 12:20-INFO-training batch loss: 0.0045; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 63, Global step 631:
20-03-23 12:20-INFO-training batch loss: 0.0046; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 64, Global step 632:
20-03-23 12:20-INFO-training batch loss: 0.0029; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9998
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 65, Global step 633:
20-03-23 12:20-INFO-training batch loss: 0.0094; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 66, Global step 634:
20-03-23 12:20-INFO-training batch loss: 0.0027; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 67, Global step 635:
20-03-23 12:20-INFO-training batch loss: 0.0030; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 68, Global step 636:
20-03-23 12:20-INFO-training batch loss: 0.0039; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 69, Global step 637:
20-03-23 12:20-INFO-training batch loss: 0.0035; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 70, Global step 638:
20-03-23 12:20-INFO-training batch loss: 0.0035; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 71, Global step 639:
20-03-23 12:20-INFO-training batch loss: 0.0032; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 72, Global step 640:
20-03-23 12:20-INFO-training batch loss: 0.0035; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 73, Global step 641:
20-03-23 12:20-INFO-training batch loss: 0.0037; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 74, Global step 642:
20-03-23 12:20-INFO-training batch loss: 0.0026; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 75, Global step 643:
20-03-23 12:20-INFO-training batch loss: 0.0052; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 76, Global step 644:
20-03-23 12:20-INFO-training batch loss: 0.0033; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 77, Global step 645:
20-03-23 12:20-INFO-training batch loss: 0.0026; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 78, Global step 646:
20-03-23 12:20-INFO-training batch loss: 0.0025; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 79, Global step 647:
20-03-23 12:20-INFO-training batch loss: 0.0025; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 80, Global step 648:
20-03-23 12:20-INFO-training batch loss: 0.0098; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 81, Global step 649:
20-03-23 12:20-INFO-training batch loss: 0.0037; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 82, Global step 650:
20-03-23 12:20-INFO-training batch loss: 0.0039; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 83, Global step 651:
20-03-23 12:20-INFO-training batch loss: 0.0048; avg_loss: 0.0039
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 84, Global step 652:
20-03-23 12:20-INFO-training batch loss: 0.0043; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:20-INFO-Epoch 2, Batch 85, Global step 653:
20-03-23 12:20-INFO-training batch loss: 0.0059; avg_loss: 0.0040
20-03-23 12:20-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:20-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 86, Global step 654:
20-03-23 12:21-INFO-training batch loss: 0.0097; avg_loss: 0.0040
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 87, Global step 655:
20-03-23 12:21-INFO-training batch loss: 0.0046; avg_loss: 0.0040
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 88, Global step 656:
20-03-23 12:21-INFO-training batch loss: 0.0064; avg_loss: 0.0041
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 89, Global step 657:
20-03-23 12:21-INFO-training batch loss: 0.0071; avg_loss: 0.0041
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 90, Global step 658:
20-03-23 12:21-INFO-training batch loss: 0.0066; avg_loss: 0.0041
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 91, Global step 659:
20-03-23 12:21-INFO-training batch loss: 0.0040; avg_loss: 0.0041
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 92, Global step 660:
20-03-23 12:21-INFO-training batch loss: 0.0070; avg_loss: 0.0042
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 93, Global step 661:
20-03-23 12:21-INFO-training batch loss: 0.0028; avg_loss: 0.0041
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 94, Global step 662:
20-03-23 12:21-INFO-training batch loss: 0.0054; avg_loss: 0.0042
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 95, Global step 663:
20-03-23 12:21-INFO-training batch loss: 0.0043; avg_loss: 0.0042
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9997
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 96, Global step 664:
20-03-23 12:21-INFO-training batch loss: 0.0188; avg_loss: 0.0043
20-03-23 12:21-INFO-training batch acc: 0.9922; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 97, Global step 665:
20-03-23 12:21-INFO-training batch loss: 0.0049; avg_loss: 0.0043
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 98, Global step 666:
20-03-23 12:21-INFO-training batch loss: 0.0061; avg_loss: 0.0043
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 99, Global step 667:
20-03-23 12:21-INFO-training batch loss: 0.0044; avg_loss: 0.0043
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 100, Global step 668:
20-03-23 12:21-INFO-training batch loss: 0.0039; avg_loss: 0.0043
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 101, Global step 669:
20-03-23 12:21-INFO-training batch loss: 0.0139; avg_loss: 0.0044
20-03-23 12:21-INFO-training batch acc: 0.9922; avg_acc: 0.9995
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 102, Global step 670:
20-03-23 12:21-INFO-training batch loss: 0.0054; avg_loss: 0.0044
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 103, Global step 671:
20-03-23 12:21-INFO-training batch loss: 0.0030; avg_loss: 0.0044
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 104, Global step 672:
20-03-23 12:21-INFO-training batch loss: 0.0047; avg_loss: 0.0044
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9995
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 105, Global step 673:
20-03-23 12:21-INFO-training batch loss: 0.0026; avg_loss: 0.0044
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9996
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 106, Global step 674:
20-03-23 12:21-INFO-training batch loss: 0.0179; avg_loss: 0.0045
20-03-23 12:21-INFO-training batch acc: 0.9844; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 107, Global step 675:
20-03-23 12:21-INFO-training batch loss: 0.0140; avg_loss: 0.0046
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 108, Global step 676:
20-03-23 12:21-INFO-training batch loss: 0.0097; avg_loss: 0.0047
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 109, Global step 677:
20-03-23 12:21-INFO-training batch loss: 0.0117; avg_loss: 0.0047
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 110, Global step 678:
20-03-23 12:21-INFO-training batch loss: 0.0050; avg_loss: 0.0047
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 111, Global step 679:
20-03-23 12:21-INFO-training batch loss: 0.0154; avg_loss: 0.0048
20-03-23 12:21-INFO-training batch acc: 0.9922; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:21-INFO-Epoch 2, Batch 112, Global step 680:
20-03-23 12:21-INFO-training batch loss: 0.0026; avg_loss: 0.0048
20-03-23 12:21-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:21-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 113, Global step 681:
20-03-23 12:22-INFO-training batch loss: 0.0046; avg_loss: 0.0048
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 114, Global step 682:
20-03-23 12:22-INFO-training batch loss: 0.0074; avg_loss: 0.0048
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9994
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 115, Global step 683:
20-03-23 12:22-INFO-training batch loss: 0.0138; avg_loss: 0.0049
20-03-23 12:22-INFO-training batch acc: 0.9922; avg_acc: 0.9993
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 116, Global step 684:
20-03-23 12:22-INFO-training batch loss: 0.0293; avg_loss: 0.0051
20-03-23 12:22-INFO-training batch acc: 0.9844; avg_acc: 0.9992
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 117, Global step 685:
20-03-23 12:22-INFO-training batch loss: 0.0079; avg_loss: 0.0052
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 118, Global step 686:
20-03-23 12:22-INFO-training batch loss: 0.0166; avg_loss: 0.0052
20-03-23 12:22-INFO-training batch acc: 0.9922; avg_acc: 0.9991
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 119, Global step 687:
20-03-23 12:22-INFO-training batch loss: 0.0203; avg_loss: 0.0054
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9991
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 120, Global step 688:
20-03-23 12:22-INFO-training batch loss: 0.0037; avg_loss: 0.0054
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 121, Global step 689:
20-03-23 12:22-INFO-training batch loss: 0.0067; avg_loss: 0.0054
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 122, Global step 690:
20-03-23 12:22-INFO-training batch loss: 0.0108; avg_loss: 0.0054
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9992
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 123, Global step 691:
20-03-23 12:22-INFO-training batch loss: 0.0959; avg_loss: 0.0062
20-03-23 12:22-INFO-training batch acc: 0.9688; avg_acc: 0.9989
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 124, Global step 692:
20-03-23 12:22-INFO-training batch loss: 0.0039; avg_loss: 0.0061
20-03-23 12:22-INFO-training batch acc: 1.0000; avg_acc: 0.9989
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 125, Global step 693:
20-03-23 12:22-INFO-training batch loss: 0.0230; avg_loss: 0.0063
20-03-23 12:22-INFO-training batch acc: 0.9922; avg_acc: 0.9989
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 126, Global step 694:
20-03-23 12:22-INFO-training batch loss: 0.0773; avg_loss: 0.0068
20-03-23 12:22-INFO-training batch acc: 0.9688; avg_acc: 0.9986
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 127, Global step 695:
20-03-23 12:22-INFO-training batch loss: 0.1099; avg_loss: 0.0076
20-03-23 12:22-INFO-training batch acc: 0.9609; avg_acc: 0.9983
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 128, Global step 696:
20-03-23 12:22-INFO-training batch loss: 0.0430; avg_loss: 0.0079
20-03-23 12:22-INFO-training batch acc: 0.9766; avg_acc: 0.9982
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 129, Global step 697:
20-03-23 12:22-INFO-training batch loss: 0.2648; avg_loss: 0.0099
20-03-23 12:22-INFO-training batch acc: 0.9453; avg_acc: 0.9978
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 130, Global step 698:
20-03-23 12:22-INFO-training batch loss: 0.1500; avg_loss: 0.0110
20-03-23 12:22-INFO-training batch acc: 0.9609; avg_acc: 0.9975
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 131, Global step 699:
20-03-23 12:22-INFO-training batch loss: 0.1414; avg_loss: 0.0120
20-03-23 12:22-INFO-training batch acc: 0.9531; avg_acc: 0.9971
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 132, Global step 700:
20-03-23 12:22-INFO-training batch loss: 0.2036; avg_loss: 0.0134
20-03-23 12:22-INFO-training batch acc: 0.9219; avg_acc: 0.9966
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 133, Global step 701:
20-03-23 12:22-INFO-training batch loss: 0.0805; avg_loss: 0.0139
20-03-23 12:22-INFO-training batch acc: 0.9766; avg_acc: 0.9964
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 134, Global step 702:
20-03-23 12:22-INFO-training batch loss: 0.1086; avg_loss: 0.0146
20-03-23 12:22-INFO-training batch acc: 0.9531; avg_acc: 0.9961
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 135, Global step 703:
20-03-23 12:22-INFO-training batch loss: 0.2015; avg_loss: 0.0160
20-03-23 12:22-INFO-training batch acc: 0.9219; avg_acc: 0.9955
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 136, Global step 704:
20-03-23 12:22-INFO-training batch loss: 0.1583; avg_loss: 0.0171
20-03-23 12:22-INFO-training batch acc: 0.9297; avg_acc: 0.9951
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 137, Global step 705:
20-03-23 12:22-INFO-training batch loss: 0.0423; avg_loss: 0.0173
20-03-23 12:22-INFO-training batch acc: 0.9922; avg_acc: 0.9950
20-03-23 12:22-INFO-
20-03-23 12:22-INFO-Epoch 2, Batch 138, Global step 706:
20-03-23 12:22-INFO-training batch loss: 0.1379; avg_loss: 0.0181
20-03-23 12:22-INFO-training batch acc: 0.9688; avg_acc: 0.9948
20-03-23 12:22-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 139, Global step 707:
20-03-23 12:23-INFO-training batch loss: 0.1616; avg_loss: 0.0192
20-03-23 12:23-INFO-training batch acc: 0.9375; avg_acc: 0.9944
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 140, Global step 708:
20-03-23 12:23-INFO-training batch loss: 0.0758; avg_loss: 0.0196
20-03-23 12:23-INFO-training batch acc: 0.9688; avg_acc: 0.9943
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 141, Global step 709:
20-03-23 12:23-INFO-training batch loss: 0.0915; avg_loss: 0.0201
20-03-23 12:23-INFO-training batch acc: 0.9688; avg_acc: 0.9941
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 142, Global step 710:
20-03-23 12:23-INFO-training batch loss: 0.0932; avg_loss: 0.0206
20-03-23 12:23-INFO-training batch acc: 0.9766; avg_acc: 0.9939
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 143, Global step 711:
20-03-23 12:23-INFO-training batch loss: 0.1516; avg_loss: 0.0215
20-03-23 12:23-INFO-training batch acc: 0.9297; avg_acc: 0.9935
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 144, Global step 712:
20-03-23 12:23-INFO-training batch loss: 0.0890; avg_loss: 0.0220
20-03-23 12:23-INFO-training batch acc: 0.9531; avg_acc: 0.9932
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 145, Global step 713:
20-03-23 12:23-INFO-training batch loss: 0.0760; avg_loss: 0.0224
20-03-23 12:23-INFO-training batch acc: 0.9766; avg_acc: 0.9931
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 146, Global step 714:
20-03-23 12:23-INFO-training batch loss: 0.0777; avg_loss: 0.0227
20-03-23 12:23-INFO-training batch acc: 0.9609; avg_acc: 0.9929
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 147, Global step 715:
20-03-23 12:23-INFO-training batch loss: 0.0858; avg_loss: 0.0232
20-03-23 12:23-INFO-training batch acc: 0.9609; avg_acc: 0.9927
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 148, Global step 716:
20-03-23 12:23-INFO-training batch loss: 0.0696; avg_loss: 0.0235
20-03-23 12:23-INFO-training batch acc: 0.9844; avg_acc: 0.9926
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 149, Global step 717:
20-03-23 12:23-INFO-training batch loss: 0.0468; avg_loss: 0.0236
20-03-23 12:23-INFO-training batch acc: 0.9922; avg_acc: 0.9926
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 150, Global step 718:
20-03-23 12:23-INFO-training batch loss: 0.0773; avg_loss: 0.0240
20-03-23 12:23-INFO-training batch acc: 0.9766; avg_acc: 0.9925
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 151, Global step 719:
20-03-23 12:23-INFO-training batch loss: 0.0508; avg_loss: 0.0242
20-03-23 12:23-INFO-training batch acc: 0.9844; avg_acc: 0.9924
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 152, Global step 720:
20-03-23 12:23-INFO-training batch loss: 0.1255; avg_loss: 0.0248
20-03-23 12:23-INFO-training batch acc: 0.9688; avg_acc: 0.9923
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 153, Global step 721:
20-03-23 12:23-INFO-training batch loss: 0.0589; avg_loss: 0.0251
20-03-23 12:23-INFO-training batch acc: 0.9844; avg_acc: 0.9922
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 154, Global step 722:
20-03-23 12:23-INFO-training batch loss: 0.1589; avg_loss: 0.0259
20-03-23 12:23-INFO-training batch acc: 0.9531; avg_acc: 0.9920
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 155, Global step 723:
20-03-23 12:23-INFO-training batch loss: 0.0776; avg_loss: 0.0263
20-03-23 12:23-INFO-training batch acc: 0.9688; avg_acc: 0.9918
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 156, Global step 724:
20-03-23 12:23-INFO-training batch loss: 0.0687; avg_loss: 0.0265
20-03-23 12:23-INFO-training batch acc: 0.9766; avg_acc: 0.9917
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 157, Global step 725:
20-03-23 12:23-INFO-training batch loss: 0.0536; avg_loss: 0.0267
20-03-23 12:23-INFO-training batch acc: 0.9766; avg_acc: 0.9916
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 158, Global step 726:
20-03-23 12:23-INFO-training batch loss: 0.0585; avg_loss: 0.0269
20-03-23 12:23-INFO-training batch acc: 0.9766; avg_acc: 0.9915
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 159, Global step 727:
20-03-23 12:23-INFO-training batch loss: 0.0274; avg_loss: 0.0269
20-03-23 12:23-INFO-training batch acc: 0.9922; avg_acc: 0.9915
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 160, Global step 728:
20-03-23 12:23-INFO-training batch loss: 0.0509; avg_loss: 0.0271
20-03-23 12:23-INFO-training batch acc: 0.9844; avg_acc: 0.9915
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 161, Global step 729:
20-03-23 12:23-INFO-training batch loss: 0.0285; avg_loss: 0.0271
20-03-23 12:23-INFO-training batch acc: 0.9922; avg_acc: 0.9915
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 162, Global step 730:
20-03-23 12:23-INFO-training batch loss: 0.0383; avg_loss: 0.0271
20-03-23 12:23-INFO-training batch acc: 0.9844; avg_acc: 0.9915
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 163, Global step 731:
20-03-23 12:23-INFO-training batch loss: 0.0222; avg_loss: 0.0271
20-03-23 12:23-INFO-training batch acc: 1.0000; avg_acc: 0.9915
20-03-23 12:23-INFO-
20-03-23 12:23-INFO-Epoch 2, Batch 164, Global step 732:
20-03-23 12:23-INFO-training batch loss: 0.0338; avg_loss: 0.0271
20-03-23 12:23-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 12:23-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 165, Global step 733:
20-03-23 12:24-INFO-training batch loss: 0.0609; avg_loss: 0.0273
20-03-23 12:24-INFO-training batch acc: 0.9922; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 166, Global step 734:
20-03-23 12:24-INFO-training batch loss: 0.0237; avg_loss: 0.0273
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 167, Global step 735:
20-03-23 12:24-INFO-training batch loss: 0.0313; avg_loss: 0.0274
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 168, Global step 736:
20-03-23 12:24-INFO-training batch loss: 0.0447; avg_loss: 0.0275
20-03-23 12:24-INFO-training batch acc: 0.9844; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 169, Global step 737:
20-03-23 12:24-INFO-training batch loss: 0.0155; avg_loss: 0.0274
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 170, Global step 738:
20-03-23 12:24-INFO-training batch loss: 0.0128; avg_loss: 0.0273
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 171, Global step 739:
20-03-23 12:24-INFO-training batch loss: 0.0461; avg_loss: 0.0274
20-03-23 12:24-INFO-training batch acc: 0.9688; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 172, Global step 740:
20-03-23 12:24-INFO-training batch loss: 0.0150; avg_loss: 0.0273
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 173, Global step 741:
20-03-23 12:24-INFO-training batch loss: 0.0493; avg_loss: 0.0275
20-03-23 12:24-INFO-training batch acc: 0.9844; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 174, Global step 742:
20-03-23 12:24-INFO-training batch loss: 0.0088; avg_loss: 0.0274
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9916
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 175, Global step 743:
20-03-23 12:24-INFO-training batch loss: 0.0171; avg_loss: 0.0273
20-03-23 12:24-INFO-training batch acc: 0.9922; avg_acc: 0.9917
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 176, Global step 744:
20-03-23 12:24-INFO-training batch loss: 0.0255; avg_loss: 0.0273
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 177, Global step 745:
20-03-23 12:24-INFO-training batch loss: 0.0158; avg_loss: 0.0272
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9917
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 178, Global step 746:
20-03-23 12:24-INFO-training batch loss: 0.0153; avg_loss: 0.0272
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 179, Global step 747:
20-03-23 12:24-INFO-training batch loss: 0.0162; avg_loss: 0.0271
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 180, Global step 748:
20-03-23 12:24-INFO-training batch loss: 0.0171; avg_loss: 0.0270
20-03-23 12:24-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 181, Global step 749:
20-03-23 12:24-INFO-training batch loss: 0.0306; avg_loss: 0.0271
20-03-23 12:24-INFO-training batch acc: 0.9922; avg_acc: 0.9918
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 182, Global step 750:
20-03-23 12:24-INFO-training batch loss: 0.0227; avg_loss: 0.0270
20-03-23 12:24-INFO-training batch acc: 0.9844; avg_acc: 0.9918
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 183, Global step 751:
20-03-23 12:24-INFO-training batch loss: 0.0107; avg_loss: 0.0269
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9918
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 184, Global step 752:
20-03-23 12:24-INFO-training batch loss: 0.0135; avg_loss: 0.0269
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 185, Global step 753:
20-03-23 12:24-INFO-training batch loss: 0.0083; avg_loss: 0.0268
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9919
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 186, Global step 754:
20-03-23 12:24-INFO-training batch loss: 0.0046; avg_loss: 0.0267
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 187, Global step 755:
20-03-23 12:24-INFO-training batch loss: 0.0102; avg_loss: 0.0266
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9920
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 188, Global step 756:
20-03-23 12:24-INFO-training batch loss: 0.0069; avg_loss: 0.0265
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 189, Global step 757:
20-03-23 12:24-INFO-training batch loss: 0.0137; avg_loss: 0.0264
20-03-23 12:24-INFO-training batch acc: 0.9922; avg_acc: 0.9921
20-03-23 12:24-INFO-
20-03-23 12:24-INFO-Epoch 2, Batch 190, Global step 758:
20-03-23 12:24-INFO-training batch loss: 0.0134; avg_loss: 0.0263
20-03-23 12:24-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 12:24-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 191, Global step 759:
20-03-23 12:25-INFO-training batch loss: 0.0061; avg_loss: 0.0262
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9921
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 192, Global step 760:
20-03-23 12:25-INFO-training batch loss: 0.0079; avg_loss: 0.0261
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 193, Global step 761:
20-03-23 12:25-INFO-training batch loss: 0.0064; avg_loss: 0.0260
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9922
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 194, Global step 762:
20-03-23 12:25-INFO-training batch loss: 0.0105; avg_loss: 0.0259
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 195, Global step 763:
20-03-23 12:25-INFO-training batch loss: 0.0029; avg_loss: 0.0258
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 196, Global step 764:
20-03-23 12:25-INFO-training batch loss: 0.0067; avg_loss: 0.0257
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9923
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 197, Global step 765:
20-03-23 12:25-INFO-training batch loss: 0.0278; avg_loss: 0.0257
20-03-23 12:25-INFO-training batch acc: 0.9922; avg_acc: 0.9923
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 198, Global step 766:
20-03-23 12:25-INFO-training batch loss: 0.0068; avg_loss: 0.0256
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 199, Global step 767:
20-03-23 12:25-INFO-training batch loss: 0.0056; avg_loss: 0.0255
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9924
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 200, Global step 768:
20-03-23 12:25-INFO-training batch loss: 0.0044; avg_loss: 0.0254
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 201, Global step 769:
20-03-23 12:25-INFO-training batch loss: 0.0064; avg_loss: 0.0253
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 202, Global step 770:
20-03-23 12:25-INFO-training batch loss: 0.0077; avg_loss: 0.0252
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9925
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 203, Global step 771:
20-03-23 12:25-INFO-training batch loss: 0.0057; avg_loss: 0.0252
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 204, Global step 772:
20-03-23 12:25-INFO-training batch loss: 0.0114; avg_loss: 0.0251
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 205, Global step 773:
20-03-23 12:25-INFO-training batch loss: 0.0070; avg_loss: 0.0250
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9926
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 206, Global step 774:
20-03-23 12:25-INFO-training batch loss: 0.0040; avg_loss: 0.0249
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 207, Global step 775:
20-03-23 12:25-INFO-training batch loss: 0.0019; avg_loss: 0.0248
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9927
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 208, Global step 776:
20-03-23 12:25-INFO-training batch loss: 0.0063; avg_loss: 0.0247
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 209, Global step 777:
20-03-23 12:25-INFO-training batch loss: 0.0187; avg_loss: 0.0247
20-03-23 12:25-INFO-training batch acc: 0.9922; avg_acc: 0.9927
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 210, Global step 778:
20-03-23 12:25-INFO-training batch loss: 0.0033; avg_loss: 0.0246
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 211, Global step 779:
20-03-23 12:25-INFO-training batch loss: 0.0039; avg_loss: 0.0245
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9928
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 212, Global step 780:
20-03-23 12:25-INFO-training batch loss: 0.0067; avg_loss: 0.0244
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9929
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 213, Global step 781:
20-03-23 12:25-INFO-training batch loss: 0.0061; avg_loss: 0.0243
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9929
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 214, Global step 782:
20-03-23 12:25-INFO-training batch loss: 0.0033; avg_loss: 0.0242
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9929
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 215, Global step 783:
20-03-23 12:25-INFO-training batch loss: 0.0030; avg_loss: 0.0241
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9930
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 216, Global step 784:
20-03-23 12:25-INFO-training batch loss: 0.0046; avg_loss: 0.0240
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9930
20-03-23 12:25-INFO-
20-03-23 12:25-INFO-Epoch 2, Batch 217, Global step 785:
20-03-23 12:25-INFO-training batch loss: 0.0029; avg_loss: 0.0239
20-03-23 12:25-INFO-training batch acc: 1.0000; avg_acc: 0.9930
20-03-23 12:25-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 218, Global step 786:
20-03-23 12:26-INFO-training batch loss: 0.0032; avg_loss: 0.0238
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9930
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 219, Global step 787:
20-03-23 12:26-INFO-training batch loss: 0.0046; avg_loss: 0.0237
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9931
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 220, Global step 788:
20-03-23 12:26-INFO-training batch loss: 0.0044; avg_loss: 0.0236
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9931
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 221, Global step 789:
20-03-23 12:26-INFO-training batch loss: 0.0059; avg_loss: 0.0236
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9931
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 222, Global step 790:
20-03-23 12:26-INFO-training batch loss: 0.0036; avg_loss: 0.0235
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9932
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 223, Global step 791:
20-03-23 12:26-INFO-training batch loss: 0.0035; avg_loss: 0.0234
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9932
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 224, Global step 792:
20-03-23 12:26-INFO-training batch loss: 0.0019; avg_loss: 0.0233
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9932
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 225, Global step 793:
20-03-23 12:26-INFO-training batch loss: 0.0028; avg_loss: 0.0232
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9933
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 226, Global step 794:
20-03-23 12:26-INFO-training batch loss: 0.0033; avg_loss: 0.0231
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9933
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 227, Global step 795:
20-03-23 12:26-INFO-training batch loss: 0.0022; avg_loss: 0.0230
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9933
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 228, Global step 796:
20-03-23 12:26-INFO-training batch loss: 0.0021; avg_loss: 0.0229
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9934
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 229, Global step 797:
20-03-23 12:26-INFO-training batch loss: 0.0036; avg_loss: 0.0228
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9934
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 230, Global step 798:
20-03-23 12:26-INFO-training batch loss: 0.0036; avg_loss: 0.0228
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9934
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 231, Global step 799:
20-03-23 12:26-INFO-training batch loss: 0.0029; avg_loss: 0.0227
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9934
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 232, Global step 800:
20-03-23 12:26-INFO-training batch loss: 0.0037; avg_loss: 0.0226
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9935
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 233, Global step 801:
20-03-23 12:26-INFO-training batch loss: 0.0026; avg_loss: 0.0225
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9935
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 234, Global step 802:
20-03-23 12:26-INFO-training batch loss: 0.0017; avg_loss: 0.0224
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9935
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 235, Global step 803:
20-03-23 12:26-INFO-training batch loss: 0.0034; avg_loss: 0.0223
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9936
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 236, Global step 804:
20-03-23 12:26-INFO-training batch loss: 0.0015; avg_loss: 0.0222
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9936
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 237, Global step 805:
20-03-23 12:26-INFO-training batch loss: 0.0050; avg_loss: 0.0222
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9936
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 238, Global step 806:
20-03-23 12:26-INFO-training batch loss: 0.0019; avg_loss: 0.0221
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9936
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 239, Global step 807:
20-03-23 12:26-INFO-training batch loss: 0.0026; avg_loss: 0.0220
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9937
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 240, Global step 808:
20-03-23 12:26-INFO-training batch loss: 0.0064; avg_loss: 0.0219
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9937
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 241, Global step 809:
20-03-23 12:26-INFO-training batch loss: 0.0019; avg_loss: 0.0219
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9937
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 242, Global step 810:
20-03-23 12:26-INFO-training batch loss: 0.0019; avg_loss: 0.0218
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9937
20-03-23 12:26-INFO-
20-03-23 12:26-INFO-Epoch 2, Batch 243, Global step 811:
20-03-23 12:26-INFO-training batch loss: 0.0015; avg_loss: 0.0217
20-03-23 12:26-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 12:26-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 244, Global step 812:
20-03-23 12:27-INFO-training batch loss: 0.0023; avg_loss: 0.0216
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 245, Global step 813:
20-03-23 12:27-INFO-training batch loss: 0.0052; avg_loss: 0.0215
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 246, Global step 814:
20-03-23 12:27-INFO-training batch loss: 0.0022; avg_loss: 0.0215
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9938
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 247, Global step 815:
20-03-23 12:27-INFO-training batch loss: 0.0021; avg_loss: 0.0214
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 248, Global step 816:
20-03-23 12:27-INFO-training batch loss: 0.0034; avg_loss: 0.0213
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 249, Global step 817:
20-03-23 12:27-INFO-training batch loss: 0.0052; avg_loss: 0.0213
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 250, Global step 818:
20-03-23 12:27-INFO-training batch loss: 0.0060; avg_loss: 0.0212
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9939
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 251, Global step 819:
20-03-23 12:27-INFO-training batch loss: 0.0029; avg_loss: 0.0211
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 252, Global step 820:
20-03-23 12:27-INFO-training batch loss: 0.0033; avg_loss: 0.0210
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 253, Global step 821:
20-03-23 12:27-INFO-training batch loss: 0.0017; avg_loss: 0.0210
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 254, Global step 822:
20-03-23 12:27-INFO-training batch loss: 0.0030; avg_loss: 0.0209
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9940
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 255, Global step 823:
20-03-23 12:27-INFO-training batch loss: 0.0020; avg_loss: 0.0208
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 256, Global step 824:
20-03-23 12:27-INFO-training batch loss: 0.0029; avg_loss: 0.0208
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 257, Global step 825:
20-03-23 12:27-INFO-training batch loss: 0.0015; avg_loss: 0.0207
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 258, Global step 826:
20-03-23 12:27-INFO-training batch loss: 0.0026; avg_loss: 0.0206
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 259, Global step 827:
20-03-23 12:27-INFO-training batch loss: 0.0031; avg_loss: 0.0205
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9941
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 260, Global step 828:
20-03-23 12:27-INFO-training batch loss: 0.0017; avg_loss: 0.0205
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 261, Global step 829:
20-03-23 12:27-INFO-training batch loss: 0.0030; avg_loss: 0.0204
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 262, Global step 830:
20-03-23 12:27-INFO-training batch loss: 0.0018; avg_loss: 0.0203
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 263, Global step 831:
20-03-23 12:27-INFO-training batch loss: 0.0028; avg_loss: 0.0203
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9942
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 264, Global step 832:
20-03-23 12:27-INFO-training batch loss: 0.0038; avg_loss: 0.0202
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 265, Global step 833:
20-03-23 12:27-INFO-training batch loss: 0.0029; avg_loss: 0.0201
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 266, Global step 834:
20-03-23 12:27-INFO-training batch loss: 0.0031; avg_loss: 0.0201
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 267, Global step 835:
20-03-23 12:27-INFO-training batch loss: 0.0025; avg_loss: 0.0200
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 268, Global step 836:
20-03-23 12:27-INFO-training batch loss: 0.0029; avg_loss: 0.0199
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9943
20-03-23 12:27-INFO-
20-03-23 12:27-INFO-Epoch 2, Batch 269, Global step 837:
20-03-23 12:27-INFO-training batch loss: 0.0018; avg_loss: 0.0199
20-03-23 12:27-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 12:27-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 270, Global step 838:
20-03-23 12:28-INFO-training batch loss: 0.0023; avg_loss: 0.0198
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 271, Global step 839:
20-03-23 12:28-INFO-training batch loss: 0.0020; avg_loss: 0.0197
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 272, Global step 840:
20-03-23 12:28-INFO-training batch loss: 0.0027; avg_loss: 0.0197
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 273, Global step 841:
20-03-23 12:28-INFO-training batch loss: 0.0040; avg_loss: 0.0196
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9944
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 274, Global step 842:
20-03-23 12:28-INFO-training batch loss: 0.0027; avg_loss: 0.0196
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 275, Global step 843:
20-03-23 12:28-INFO-training batch loss: 0.0031; avg_loss: 0.0195
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 276, Global step 844:
20-03-23 12:28-INFO-training batch loss: 0.0022; avg_loss: 0.0194
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 277, Global step 845:
20-03-23 12:28-INFO-training batch loss: 0.0019; avg_loss: 0.0194
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 278, Global step 846:
20-03-23 12:28-INFO-training batch loss: 0.0031; avg_loss: 0.0193
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9945
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 279, Global step 847:
20-03-23 12:28-INFO-training batch loss: 0.0018; avg_loss: 0.0193
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 280, Global step 848:
20-03-23 12:28-INFO-training batch loss: 0.0028; avg_loss: 0.0192
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 281, Global step 849:
20-03-23 12:28-INFO-training batch loss: 0.0017; avg_loss: 0.0191
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 282, Global step 850:
20-03-23 12:28-INFO-training batch loss: 0.0021; avg_loss: 0.0191
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 283, Global step 851:
20-03-23 12:28-INFO-training batch loss: 0.0013; avg_loss: 0.0190
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9946
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, Batch 284, Global step 852:
20-03-23 12:28-INFO-training batch loss: 0.0020; avg_loss: 0.0190
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 0.9947
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, training batch loss: 0.0020; avg_loss: 0.0190
20-03-23 12:28-INFO-Epoch 2, training batch accuracy: 1.0000; avg_accuracy: 0.9947
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 2, evaluating batch loss: 1.8018; avg_loss: 0.6849
20-03-23 12:28-INFO-Epoch 2, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9429
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 1, Global step 853:
20-03-23 12:28-INFO-training batch loss: 0.0023; avg_loss: 0.0023
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 2, Global step 854:
20-03-23 12:28-INFO-training batch loss: 0.0028; avg_loss: 0.0026
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 3, Global step 855:
20-03-23 12:28-INFO-training batch loss: 0.0068; avg_loss: 0.0040
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 4, Global step 856:
20-03-23 12:28-INFO-training batch loss: 0.0052; avg_loss: 0.0043
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 5, Global step 857:
20-03-23 12:28-INFO-training batch loss: 0.0028; avg_loss: 0.0040
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 6, Global step 858:
20-03-23 12:28-INFO-training batch loss: 0.0027; avg_loss: 0.0038
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 7, Global step 859:
20-03-23 12:28-INFO-training batch loss: 0.0045; avg_loss: 0.0039
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:28-INFO-Epoch 3, Batch 8, Global step 860:
20-03-23 12:28-INFO-training batch loss: 0.0030; avg_loss: 0.0038
20-03-23 12:28-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:28-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 9, Global step 861:
20-03-23 12:29-INFO-training batch loss: 0.0025; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 10, Global step 862:
20-03-23 12:29-INFO-training batch loss: 0.0025; avg_loss: 0.0035
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 11, Global step 863:
20-03-23 12:29-INFO-training batch loss: 0.0028; avg_loss: 0.0034
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 12, Global step 864:
20-03-23 12:29-INFO-training batch loss: 0.0044; avg_loss: 0.0035
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 13, Global step 865:
20-03-23 12:29-INFO-training batch loss: 0.0036; avg_loss: 0.0035
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 14, Global step 866:
20-03-23 12:29-INFO-training batch loss: 0.0035; avg_loss: 0.0035
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 15, Global step 867:
20-03-23 12:29-INFO-training batch loss: 0.0041; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 16, Global step 868:
20-03-23 12:29-INFO-training batch loss: 0.0027; avg_loss: 0.0035
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 17, Global step 869:
20-03-23 12:29-INFO-training batch loss: 0.0060; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 18, Global step 870:
20-03-23 12:29-INFO-training batch loss: 0.0031; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 19, Global step 871:
20-03-23 12:29-INFO-training batch loss: 0.0050; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 20, Global step 872:
20-03-23 12:29-INFO-training batch loss: 0.0088; avg_loss: 0.0040
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 21, Global step 873:
20-03-23 12:29-INFO-training batch loss: 0.0017; avg_loss: 0.0038
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 22, Global step 874:
20-03-23 12:29-INFO-training batch loss: 0.0045; avg_loss: 0.0039
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 23, Global step 875:
20-03-23 12:29-INFO-training batch loss: 0.0017; avg_loss: 0.0038
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 24, Global step 876:
20-03-23 12:29-INFO-training batch loss: 0.0038; avg_loss: 0.0038
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 25, Global step 877:
20-03-23 12:29-INFO-training batch loss: 0.0017; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 26, Global step 878:
20-03-23 12:29-INFO-training batch loss: 0.0022; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 27, Global step 879:
20-03-23 12:29-INFO-training batch loss: 0.0023; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 28, Global step 880:
20-03-23 12:29-INFO-training batch loss: 0.0040; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 29, Global step 881:
20-03-23 12:29-INFO-training batch loss: 0.0038; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 30, Global step 882:
20-03-23 12:29-INFO-training batch loss: 0.0068; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 31, Global step 883:
20-03-23 12:29-INFO-training batch loss: 0.0032; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 32, Global step 884:
20-03-23 12:29-INFO-training batch loss: 0.0049; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 33, Global step 885:
20-03-23 12:29-INFO-training batch loss: 0.0029; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 34, Global step 886:
20-03-23 12:29-INFO-training batch loss: 0.0017; avg_loss: 0.0037
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:29-INFO-Epoch 3, Batch 35, Global step 887:
20-03-23 12:29-INFO-training batch loss: 0.0020; avg_loss: 0.0036
20-03-23 12:29-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:29-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 36, Global step 888:
20-03-23 12:30-INFO-training batch loss: 0.0032; avg_loss: 0.0036
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 37, Global step 889:
20-03-23 12:30-INFO-training batch loss: 0.0045; avg_loss: 0.0036
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 38, Global step 890:
20-03-23 12:30-INFO-training batch loss: 0.0023; avg_loss: 0.0036
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 39, Global step 891:
20-03-23 12:30-INFO-training batch loss: 0.0032; avg_loss: 0.0036
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 40, Global step 892:
20-03-23 12:30-INFO-training batch loss: 0.0024; avg_loss: 0.0035
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 41, Global step 893:
20-03-23 12:30-INFO-training batch loss: 0.0026; avg_loss: 0.0035
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 42, Global step 894:
20-03-23 12:30-INFO-training batch loss: 0.0033; avg_loss: 0.0035
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 43, Global step 895:
20-03-23 12:30-INFO-training batch loss: 0.0022; avg_loss: 0.0035
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 44, Global step 896:
20-03-23 12:30-INFO-training batch loss: 0.0022; avg_loss: 0.0035
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 45, Global step 897:
20-03-23 12:30-INFO-training batch loss: 0.0022; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 46, Global step 898:
20-03-23 12:30-INFO-training batch loss: 0.0019; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 47, Global step 899:
20-03-23 12:30-INFO-training batch loss: 0.0054; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 48, Global step 900:
20-03-23 12:30-INFO-training batch loss: 0.0018; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 49, Global step 901:
20-03-23 12:30-INFO-training batch loss: 0.0023; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 50, Global step 902:
20-03-23 12:30-INFO-training batch loss: 0.0045; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 51, Global step 903:
20-03-23 12:30-INFO-training batch loss: 0.0037; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 52, Global step 904:
20-03-23 12:30-INFO-training batch loss: 0.0019; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 53, Global step 905:
20-03-23 12:30-INFO-training batch loss: 0.0017; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 54, Global step 906:
20-03-23 12:30-INFO-training batch loss: 0.0033; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 55, Global step 907:
20-03-23 12:30-INFO-training batch loss: 0.0029; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 56, Global step 908:
20-03-23 12:30-INFO-training batch loss: 0.0049; avg_loss: 0.0034
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 57, Global step 909:
20-03-23 12:30-INFO-training batch loss: 0.0019; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 58, Global step 910:
20-03-23 12:30-INFO-training batch loss: 0.0021; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 59, Global step 911:
20-03-23 12:30-INFO-training batch loss: 0.0017; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 60, Global step 912:
20-03-23 12:30-INFO-training batch loss: 0.0035; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:30-INFO-Epoch 3, Batch 61, Global step 913:
20-03-23 12:30-INFO-training batch loss: 0.0021; avg_loss: 0.0033
20-03-23 12:30-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:30-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 62, Global step 914:
20-03-23 12:31-INFO-training batch loss: 0.0061; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 63, Global step 915:
20-03-23 12:31-INFO-training batch loss: 0.0023; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 64, Global step 916:
20-03-23 12:31-INFO-training batch loss: 0.0032; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 65, Global step 917:
20-03-23 12:31-INFO-training batch loss: 0.0037; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 66, Global step 918:
20-03-23 12:31-INFO-training batch loss: 0.0032; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 67, Global step 919:
20-03-23 12:31-INFO-training batch loss: 0.0018; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 68, Global step 920:
20-03-23 12:31-INFO-training batch loss: 0.0039; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 69, Global step 921:
20-03-23 12:31-INFO-training batch loss: 0.0022; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 70, Global step 922:
20-03-23 12:31-INFO-training batch loss: 0.0026; avg_loss: 0.0033
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 71, Global step 923:
20-03-23 12:31-INFO-training batch loss: 0.0017; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 72, Global step 924:
20-03-23 12:31-INFO-training batch loss: 0.0030; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 73, Global step 925:
20-03-23 12:31-INFO-training batch loss: 0.0029; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 74, Global step 926:
20-03-23 12:31-INFO-training batch loss: 0.0020; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 75, Global step 927:
20-03-23 12:31-INFO-training batch loss: 0.0020; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 76, Global step 928:
20-03-23 12:31-INFO-training batch loss: 0.0023; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 77, Global step 929:
20-03-23 12:31-INFO-training batch loss: 0.0021; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 78, Global step 930:
20-03-23 12:31-INFO-training batch loss: 0.0021; avg_loss: 0.0032
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 79, Global step 931:
20-03-23 12:31-INFO-training batch loss: 0.0016; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 80, Global step 932:
20-03-23 12:31-INFO-training batch loss: 0.0019; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 81, Global step 933:
20-03-23 12:31-INFO-training batch loss: 0.0027; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 82, Global step 934:
20-03-23 12:31-INFO-training batch loss: 0.0036; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 83, Global step 935:
20-03-23 12:31-INFO-training batch loss: 0.0029; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 84, Global step 936:
20-03-23 12:31-INFO-training batch loss: 0.0030; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 85, Global step 937:
20-03-23 12:31-INFO-training batch loss: 0.0024; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 86, Global step 938:
20-03-23 12:31-INFO-training batch loss: 0.0024; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 87, Global step 939:
20-03-23 12:31-INFO-training batch loss: 0.0022; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:31-INFO-Epoch 3, Batch 88, Global step 940:
20-03-23 12:31-INFO-training batch loss: 0.0025; avg_loss: 0.0031
20-03-23 12:31-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:31-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 89, Global step 941:
20-03-23 12:32-INFO-training batch loss: 0.0018; avg_loss: 0.0031
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 90, Global step 942:
20-03-23 12:32-INFO-training batch loss: 0.0020; avg_loss: 0.0031
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 91, Global step 943:
20-03-23 12:32-INFO-training batch loss: 0.0041; avg_loss: 0.0031
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 92, Global step 944:
20-03-23 12:32-INFO-training batch loss: 0.0014; avg_loss: 0.0031
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 93, Global step 945:
20-03-23 12:32-INFO-training batch loss: 0.0022; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 94, Global step 946:
20-03-23 12:32-INFO-training batch loss: 0.0014; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 95, Global step 947:
20-03-23 12:32-INFO-training batch loss: 0.0022; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 96, Global step 948:
20-03-23 12:32-INFO-training batch loss: 0.0057; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 97, Global step 949:
20-03-23 12:32-INFO-training batch loss: 0.0028; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 98, Global step 950:
20-03-23 12:32-INFO-training batch loss: 0.0034; avg_loss: 0.0031
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 99, Global step 951:
20-03-23 12:32-INFO-training batch loss: 0.0021; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 100, Global step 952:
20-03-23 12:32-INFO-training batch loss: 0.0022; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 101, Global step 953:
20-03-23 12:32-INFO-training batch loss: 0.0055; avg_loss: 0.0031
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 102, Global step 954:
20-03-23 12:32-INFO-training batch loss: 0.0016; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 103, Global step 955:
20-03-23 12:32-INFO-training batch loss: 0.0017; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 104, Global step 956:
20-03-23 12:32-INFO-training batch loss: 0.0015; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 105, Global step 957:
20-03-23 12:32-INFO-training batch loss: 0.0046; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 106, Global step 958:
20-03-23 12:32-INFO-training batch loss: 0.0017; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 107, Global step 959:
20-03-23 12:32-INFO-training batch loss: 0.0027; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 108, Global step 960:
20-03-23 12:32-INFO-training batch loss: 0.0024; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 109, Global step 961:
20-03-23 12:32-INFO-training batch loss: 0.0025; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 110, Global step 962:
20-03-23 12:32-INFO-training batch loss: 0.0027; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 111, Global step 963:
20-03-23 12:32-INFO-training batch loss: 0.0024; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 112, Global step 964:
20-03-23 12:32-INFO-training batch loss: 0.0017; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 113, Global step 965:
20-03-23 12:32-INFO-training batch loss: 0.0031; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:32-INFO-Epoch 3, Batch 114, Global step 966:
20-03-23 12:32-INFO-training batch loss: 0.0032; avg_loss: 0.0030
20-03-23 12:32-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:32-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 115, Global step 967:
20-03-23 12:33-INFO-training batch loss: 0.0018; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 116, Global step 968:
20-03-23 12:33-INFO-training batch loss: 0.0013; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 117, Global step 969:
20-03-23 12:33-INFO-training batch loss: 0.0025; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 118, Global step 970:
20-03-23 12:33-INFO-training batch loss: 0.0015; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 119, Global step 971:
20-03-23 12:33-INFO-training batch loss: 0.0050; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 120, Global step 972:
20-03-23 12:33-INFO-training batch loss: 0.0019; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 121, Global step 973:
20-03-23 12:33-INFO-training batch loss: 0.0025; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 122, Global step 974:
20-03-23 12:33-INFO-training batch loss: 0.0031; avg_loss: 0.0030
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 123, Global step 975:
20-03-23 12:33-INFO-training batch loss: 0.0020; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 124, Global step 976:
20-03-23 12:33-INFO-training batch loss: 0.0015; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 125, Global step 977:
20-03-23 12:33-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 126, Global step 978:
20-03-23 12:33-INFO-training batch loss: 0.0021; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 127, Global step 979:
20-03-23 12:33-INFO-training batch loss: 0.0037; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 128, Global step 980:
20-03-23 12:33-INFO-training batch loss: 0.0013; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 129, Global step 981:
20-03-23 12:33-INFO-training batch loss: 0.0018; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 130, Global step 982:
20-03-23 12:33-INFO-training batch loss: 0.0020; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 131, Global step 983:
20-03-23 12:33-INFO-training batch loss: 0.0022; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 132, Global step 984:
20-03-23 12:33-INFO-training batch loss: 0.0033; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 133, Global step 985:
20-03-23 12:33-INFO-training batch loss: 0.0026; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 134, Global step 986:
20-03-23 12:33-INFO-training batch loss: 0.0032; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 135, Global step 987:
20-03-23 12:33-INFO-training batch loss: 0.0047; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 136, Global step 988:
20-03-23 12:33-INFO-training batch loss: 0.0016; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 137, Global step 989:
20-03-23 12:33-INFO-training batch loss: 0.0021; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 138, Global step 990:
20-03-23 12:33-INFO-training batch loss: 0.0021; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 139, Global step 991:
20-03-23 12:33-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 140, Global step 992:
20-03-23 12:33-INFO-training batch loss: 0.0020; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:33-INFO-Epoch 3, Batch 141, Global step 993:
20-03-23 12:33-INFO-training batch loss: 0.0018; avg_loss: 0.0029
20-03-23 12:33-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:33-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 142, Global step 994:
20-03-23 12:34-INFO-training batch loss: 0.0021; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 143, Global step 995:
20-03-23 12:34-INFO-training batch loss: 0.0035; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 144, Global step 996:
20-03-23 12:34-INFO-training batch loss: 0.0054; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 145, Global step 997:
20-03-23 12:34-INFO-training batch loss: 0.0026; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 146, Global step 998:
20-03-23 12:34-INFO-training batch loss: 0.0035; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 147, Global step 999:
20-03-23 12:34-INFO-training batch loss: 0.0020; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 148, Global step 1000:
20-03-23 12:34-INFO-training batch loss: 0.0022; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 149, Global step 1001:
20-03-23 12:34-INFO-training batch loss: 0.0027; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 150, Global step 1002:
20-03-23 12:34-INFO-training batch loss: 0.0022; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 151, Global step 1003:
20-03-23 12:34-INFO-training batch loss: 0.0042; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 152, Global step 1004:
20-03-23 12:34-INFO-training batch loss: 0.0024; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 153, Global step 1005:
20-03-23 12:34-INFO-training batch loss: 0.0031; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 154, Global step 1006:
20-03-23 12:34-INFO-training batch loss: 0.0017; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 155, Global step 1007:
20-03-23 12:34-INFO-training batch loss: 0.0024; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 156, Global step 1008:
20-03-23 12:34-INFO-training batch loss: 0.0043; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 157, Global step 1009:
20-03-23 12:34-INFO-training batch loss: 0.0028; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 158, Global step 1010:
20-03-23 12:34-INFO-training batch loss: 0.0020; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 159, Global step 1011:
20-03-23 12:34-INFO-training batch loss: 0.0013; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 160, Global step 1012:
20-03-23 12:34-INFO-training batch loss: 0.0019; avg_loss: 0.0029
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 161, Global step 1013:
20-03-23 12:34-INFO-training batch loss: 0.0011; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 162, Global step 1014:
20-03-23 12:34-INFO-training batch loss: 0.0017; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 163, Global step 1015:
20-03-23 12:34-INFO-training batch loss: 0.0022; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 164, Global step 1016:
20-03-23 12:34-INFO-training batch loss: 0.0020; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 165, Global step 1017:
20-03-23 12:34-INFO-training batch loss: 0.0021; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 166, Global step 1018:
20-03-23 12:34-INFO-training batch loss: 0.0019; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 167, Global step 1019:
20-03-23 12:34-INFO-training batch loss: 0.0018; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:34-INFO-Epoch 3, Batch 168, Global step 1020:
20-03-23 12:34-INFO-training batch loss: 0.0033; avg_loss: 0.0028
20-03-23 12:34-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:34-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 169, Global step 1021:
20-03-23 12:35-INFO-training batch loss: 0.0035; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 170, Global step 1022:
20-03-23 12:35-INFO-training batch loss: 0.0018; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 171, Global step 1023:
20-03-23 12:35-INFO-training batch loss: 0.0021; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 172, Global step 1024:
20-03-23 12:35-INFO-training batch loss: 0.0031; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 173, Global step 1025:
20-03-23 12:35-INFO-training batch loss: 0.0022; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 174, Global step 1026:
20-03-23 12:35-INFO-training batch loss: 0.0014; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 175, Global step 1027:
20-03-23 12:35-INFO-training batch loss: 0.0032; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 176, Global step 1028:
20-03-23 12:35-INFO-training batch loss: 0.0038; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 177, Global step 1029:
20-03-23 12:35-INFO-training batch loss: 0.0022; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 178, Global step 1030:
20-03-23 12:35-INFO-training batch loss: 0.0037; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 179, Global step 1031:
20-03-23 12:35-INFO-training batch loss: 0.0016; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 180, Global step 1032:
20-03-23 12:35-INFO-training batch loss: 0.0023; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 181, Global step 1033:
20-03-23 12:35-INFO-training batch loss: 0.0022; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 182, Global step 1034:
20-03-23 12:35-INFO-training batch loss: 0.0019; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 183, Global step 1035:
20-03-23 12:35-INFO-training batch loss: 0.0030; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 184, Global step 1036:
20-03-23 12:35-INFO-training batch loss: 0.0025; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 185, Global step 1037:
20-03-23 12:35-INFO-training batch loss: 0.0020; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 186, Global step 1038:
20-03-23 12:35-INFO-training batch loss: 0.0012; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 187, Global step 1039:
20-03-23 12:35-INFO-training batch loss: 0.0017; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 188, Global step 1040:
20-03-23 12:35-INFO-training batch loss: 0.0025; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 189, Global step 1041:
20-03-23 12:35-INFO-training batch loss: 0.0031; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 190, Global step 1042:
20-03-23 12:35-INFO-training batch loss: 0.0022; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 191, Global step 1043:
20-03-23 12:35-INFO-training batch loss: 0.0014; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 192, Global step 1044:
20-03-23 12:35-INFO-training batch loss: 0.0020; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 193, Global step 1045:
20-03-23 12:35-INFO-training batch loss: 0.0023; avg_loss: 0.0028
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:35-INFO-Epoch 3, Batch 194, Global step 1046:
20-03-23 12:35-INFO-training batch loss: 0.0012; avg_loss: 0.0027
20-03-23 12:35-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:35-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 195, Global step 1047:
20-03-23 12:36-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 196, Global step 1048:
20-03-23 12:36-INFO-training batch loss: 0.0017; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 197, Global step 1049:
20-03-23 12:36-INFO-training batch loss: 0.0020; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 198, Global step 1050:
20-03-23 12:36-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 199, Global step 1051:
20-03-23 12:36-INFO-training batch loss: 0.0044; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 200, Global step 1052:
20-03-23 12:36-INFO-training batch loss: 0.0027; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 201, Global step 1053:
20-03-23 12:36-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 202, Global step 1054:
20-03-23 12:36-INFO-training batch loss: 0.0026; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 203, Global step 1055:
20-03-23 12:36-INFO-training batch loss: 0.0020; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 204, Global step 1056:
20-03-23 12:36-INFO-training batch loss: 0.0045; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 205, Global step 1057:
20-03-23 12:36-INFO-training batch loss: 0.0049; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 206, Global step 1058:
20-03-23 12:36-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 207, Global step 1059:
20-03-23 12:36-INFO-training batch loss: 0.0029; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 208, Global step 1060:
20-03-23 12:36-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 209, Global step 1061:
20-03-23 12:36-INFO-training batch loss: 0.0030; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 210, Global step 1062:
20-03-23 12:36-INFO-training batch loss: 0.0042; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 211, Global step 1063:
20-03-23 12:36-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 212, Global step 1064:
20-03-23 12:36-INFO-training batch loss: 0.0023; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 213, Global step 1065:
20-03-23 12:36-INFO-training batch loss: 0.0028; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 214, Global step 1066:
20-03-23 12:36-INFO-training batch loss: 0.0057; avg_loss: 0.0028
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 215, Global step 1067:
20-03-23 12:36-INFO-training batch loss: 0.0017; avg_loss: 0.0028
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 216, Global step 1068:
20-03-23 12:36-INFO-training batch loss: 0.0032; avg_loss: 0.0028
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 217, Global step 1069:
20-03-23 12:36-INFO-training batch loss: 0.0024; avg_loss: 0.0028
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 218, Global step 1070:
20-03-23 12:36-INFO-training batch loss: 0.0017; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 219, Global step 1071:
20-03-23 12:36-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 220, Global step 1072:
20-03-23 12:36-INFO-training batch loss: 0.0031; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:36-INFO-Epoch 3, Batch 221, Global step 1073:
20-03-23 12:36-INFO-training batch loss: 0.0023; avg_loss: 0.0027
20-03-23 12:36-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:36-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 222, Global step 1074:
20-03-23 12:37-INFO-training batch loss: 0.0025; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 223, Global step 1075:
20-03-23 12:37-INFO-training batch loss: 0.0031; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 224, Global step 1076:
20-03-23 12:37-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 225, Global step 1077:
20-03-23 12:37-INFO-training batch loss: 0.0020; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 226, Global step 1078:
20-03-23 12:37-INFO-training batch loss: 0.0051; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 227, Global step 1079:
20-03-23 12:37-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 228, Global step 1080:
20-03-23 12:37-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 229, Global step 1081:
20-03-23 12:37-INFO-training batch loss: 0.0030; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 230, Global step 1082:
20-03-23 12:37-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 231, Global step 1083:
20-03-23 12:37-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 232, Global step 1084:
20-03-23 12:37-INFO-training batch loss: 0.0052; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 233, Global step 1085:
20-03-23 12:37-INFO-training batch loss: 0.0025; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 234, Global step 1086:
20-03-23 12:37-INFO-training batch loss: 0.0028; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 235, Global step 1087:
20-03-23 12:37-INFO-training batch loss: 0.0019; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 236, Global step 1088:
20-03-23 12:37-INFO-training batch loss: 0.0015; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 237, Global step 1089:
20-03-23 12:37-INFO-training batch loss: 0.0045; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 238, Global step 1090:
20-03-23 12:37-INFO-training batch loss: 0.0013; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 239, Global step 1091:
20-03-23 12:37-INFO-training batch loss: 0.0027; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 240, Global step 1092:
20-03-23 12:37-INFO-training batch loss: 0.0025; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 241, Global step 1093:
20-03-23 12:37-INFO-training batch loss: 0.0014; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 242, Global step 1094:
20-03-23 12:37-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 243, Global step 1095:
20-03-23 12:37-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 244, Global step 1096:
20-03-23 12:37-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 245, Global step 1097:
20-03-23 12:37-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 246, Global step 1098:
20-03-23 12:37-INFO-training batch loss: 0.0027; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 247, Global step 1099:
20-03-23 12:37-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:37-INFO-Epoch 3, Batch 248, Global step 1100:
20-03-23 12:37-INFO-training batch loss: 0.0017; avg_loss: 0.0027
20-03-23 12:37-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:37-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 249, Global step 1101:
20-03-23 12:38-INFO-training batch loss: 0.0023; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 250, Global step 1102:
20-03-23 12:38-INFO-training batch loss: 0.0028; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 251, Global step 1103:
20-03-23 12:38-INFO-training batch loss: 0.0017; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 252, Global step 1104:
20-03-23 12:38-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 253, Global step 1105:
20-03-23 12:38-INFO-training batch loss: 0.0012; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 254, Global step 1106:
20-03-23 12:38-INFO-training batch loss: 0.0024; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 255, Global step 1107:
20-03-23 12:38-INFO-training batch loss: 0.0016; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 256, Global step 1108:
20-03-23 12:38-INFO-training batch loss: 0.0012; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 257, Global step 1109:
20-03-23 12:38-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 258, Global step 1110:
20-03-23 12:38-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 259, Global step 1111:
20-03-23 12:38-INFO-training batch loss: 0.0015; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 260, Global step 1112:
20-03-23 12:38-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 261, Global step 1113:
20-03-23 12:38-INFO-training batch loss: 0.0018; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 262, Global step 1114:
20-03-23 12:38-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 263, Global step 1115:
20-03-23 12:38-INFO-training batch loss: 0.0022; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 264, Global step 1116:
20-03-23 12:38-INFO-training batch loss: 0.0017; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 265, Global step 1117:
20-03-23 12:38-INFO-training batch loss: 0.0015; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 266, Global step 1118:
20-03-23 12:38-INFO-training batch loss: 0.0021; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 267, Global step 1119:
20-03-23 12:38-INFO-training batch loss: 0.0023; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 268, Global step 1120:
20-03-23 12:38-INFO-training batch loss: 0.0018; avg_loss: 0.0026
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 269, Global step 1121:
20-03-23 12:38-INFO-training batch loss: 0.0025; avg_loss: 0.0026
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 270, Global step 1122:
20-03-23 12:38-INFO-training batch loss: 0.0032; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 271, Global step 1123:
20-03-23 12:38-INFO-training batch loss: 0.0029; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 272, Global step 1124:
20-03-23 12:38-INFO-training batch loss: 0.0025; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 273, Global step 1125:
20-03-23 12:38-INFO-training batch loss: 0.0023; avg_loss: 0.0026
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:38-INFO-Epoch 3, Batch 274, Global step 1126:
20-03-23 12:38-INFO-training batch loss: 0.0032; avg_loss: 0.0027
20-03-23 12:38-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:38-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 275, Global step 1127:
20-03-23 12:39-INFO-training batch loss: 0.0018; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 276, Global step 1128:
20-03-23 12:39-INFO-training batch loss: 0.0019; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 277, Global step 1129:
20-03-23 12:39-INFO-training batch loss: 0.0015; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 278, Global step 1130:
20-03-23 12:39-INFO-training batch loss: 0.0020; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 279, Global step 1131:
20-03-23 12:39-INFO-training batch loss: 0.0016; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 280, Global step 1132:
20-03-23 12:39-INFO-training batch loss: 0.0024; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 281, Global step 1133:
20-03-23 12:39-INFO-training batch loss: 0.0017; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 282, Global step 1134:
20-03-23 12:39-INFO-training batch loss: 0.0024; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 283, Global step 1135:
20-03-23 12:39-INFO-training batch loss: 0.0016; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, Batch 284, Global step 1136:
20-03-23 12:39-INFO-training batch loss: 0.0021; avg_loss: 0.0026
20-03-23 12:39-INFO-training batch acc: 1.0000; avg_acc: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, training batch loss: 0.0021; avg_loss: 0.0026
20-03-23 12:39-INFO-Epoch 3, training batch accuracy: 1.0000; avg_accuracy: 1.0000
20-03-23 12:39-INFO-
20-03-23 12:39-INFO-Epoch 3, evaluating batch loss: 2.0094; avg_loss: 0.7224
20-03-23 12:39-INFO-Epoch 3, evaluating batch accuracy: 0.8864; avg_accuracy: 0.9460
20-03-23 12:39-INFO-
