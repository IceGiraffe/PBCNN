20-03-22 22:25-INFO-{'session_length': 24, 'height': 32, 'width': 32, 'num_labels': 8, 'learning_rate': 0.0005, 'filter_sizes': [3, 4, 5, 6], 'num_filters': 64, 'filter_sizes_hierarchical': [3, 4, 5], 'num_fitlers_hierarchical': 64, 'is_train': True, 'early_stop': True, 'is_tuning': False}
20-03-22 22:25-WARNING-From ../utils.py:127: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

20-03-22 22:25-WARNING-From ../model/train.py:105: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

20-03-22 22:25-WARNING-From ../model/siamese_network.py:26: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

20-03-22 22:25-WARNING-From ../model/siamese_network.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

20-03-22 22:25-WARNING-From ../model/siamese_network.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

20-03-22 22:25-WARNING-From ../model/utils/utils.py:26: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43261bdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43261bdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-From ../model/utils/utils.py:45: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling1D instead.
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f210>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43263f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43263f4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f310>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43263fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43263fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f390>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd432615310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd432615310>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43261bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43261bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-From ../model/utils/modules.py:205: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
20-03-22 22:25-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fd4344bb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fd4344bb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431a6ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431a6ee50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431a48a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431a48a50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431ad2a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431ad2a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431a54a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431a54a50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43efccf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43efccf90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43263f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-From ../model/utils/modules.py:240: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
20-03-22 22:25-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4319bf090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4319bf090>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-From ../model/utils/modules.py:242: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
20-03-22 22:25-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fd431aa8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fd431aa8110>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-From ../model/utils/modules.py:245: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd4319bfbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd4319bfbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431a7bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431a7bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431931c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431931c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431971950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431971950>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43195f450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43195f450>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431aa8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431aa8490>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd4326dfb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd4326dfb50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43195fed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd43195fed0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fd431ac9790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fd431ac9790>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd4318cf4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd4318cf4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd4326c3110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd4326c3110>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431931a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd431931a10>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431931c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431931c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43190efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7fd43190efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431913d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x7fd431913d50>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4319313d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd4319313d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fd431a779d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fd431a779d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd431a09c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd431a09c90>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd442f190d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd442f190d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
20-03-22 22:25-WARNING-From ../model/base_model.py:132: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

20-03-22 22:25-WARNING-From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20-03-22 22:25-WARNING-From ../model/train.py:113: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

20-03-22 22:25-INFO-Epoch 0, Batch 1, Global step 1:
20-03-22 22:25-INFO-training batch loss: 1.4823; avg_loss: 1.4823
20-03-22 22:25-INFO-training batch acc: 0.6016; avg_acc: 0.6016
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 2, Global step 2:
20-03-22 22:25-INFO-training batch loss: 7.6816; avg_loss: 4.5819
20-03-22 22:25-INFO-training batch acc: 0.4062; avg_acc: 0.5039
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 3, Global step 3:
20-03-22 22:25-INFO-training batch loss: 7.6633; avg_loss: 5.6091
20-03-22 22:25-INFO-training batch acc: 0.4453; avg_acc: 0.4844
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 4, Global step 4:
20-03-22 22:25-INFO-training batch loss: 10.0249; avg_loss: 6.7130
20-03-22 22:25-INFO-training batch acc: 0.3438; avg_acc: 0.4492
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 5, Global step 5:
20-03-22 22:25-INFO-training batch loss: 8.9425; avg_loss: 7.1589
20-03-22 22:25-INFO-training batch acc: 0.4219; avg_acc: 0.4437
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 6, Global step 6:
20-03-22 22:25-INFO-training batch loss: 8.9212; avg_loss: 7.4526
20-03-22 22:25-INFO-training batch acc: 0.3359; avg_acc: 0.4258
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 7, Global step 7:
20-03-22 22:25-INFO-training batch loss: 6.5170; avg_loss: 7.3190
20-03-22 22:25-INFO-training batch acc: 0.3594; avg_acc: 0.4163
20-03-22 22:25-INFO-
20-03-22 22:25-INFO-Epoch 0, Batch 8, Global step 8:
20-03-22 22:25-INFO-training batch loss: 3.3287; avg_loss: 6.8202
20-03-22 22:25-INFO-training batch acc: 0.3906; avg_acc: 0.4131
20-03-22 22:25-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 9, Global step 9:
20-03-22 22:26-INFO-training batch loss: 2.4952; avg_loss: 6.3396
20-03-22 22:26-INFO-training batch acc: 0.4219; avg_acc: 0.4141
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 10, Global step 10:
20-03-22 22:26-INFO-training batch loss: 3.1732; avg_loss: 6.0230
20-03-22 22:26-INFO-training batch acc: 0.5312; avg_acc: 0.4258
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 11, Global step 11:
20-03-22 22:26-INFO-training batch loss: 2.4100; avg_loss: 5.6945
20-03-22 22:26-INFO-training batch acc: 0.6875; avg_acc: 0.4496
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 12, Global step 12:
20-03-22 22:26-INFO-training batch loss: 2.3701; avg_loss: 5.4175
20-03-22 22:26-INFO-training batch acc: 0.6016; avg_acc: 0.4622
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 13, Global step 13:
20-03-22 22:26-INFO-training batch loss: 2.2585; avg_loss: 5.1745
20-03-22 22:26-INFO-training batch acc: 0.5703; avg_acc: 0.4706
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 14, Global step 14:
20-03-22 22:26-INFO-training batch loss: 1.5479; avg_loss: 4.9155
20-03-22 22:26-INFO-training batch acc: 0.6016; avg_acc: 0.4799
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 15, Global step 15:
20-03-22 22:26-INFO-training batch loss: 0.8164; avg_loss: 4.6422
20-03-22 22:26-INFO-training batch acc: 0.6484; avg_acc: 0.4911
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 16, Global step 16:
20-03-22 22:26-INFO-training batch loss: 1.1710; avg_loss: 4.4252
20-03-22 22:26-INFO-training batch acc: 0.5625; avg_acc: 0.4956
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 17, Global step 17:
20-03-22 22:26-INFO-training batch loss: 1.4713; avg_loss: 4.2515
20-03-22 22:26-INFO-training batch acc: 0.5547; avg_acc: 0.4991
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 18, Global step 18:
20-03-22 22:26-INFO-training batch loss: 1.4285; avg_loss: 4.0947
20-03-22 22:26-INFO-training batch acc: 0.4922; avg_acc: 0.4987
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 19, Global step 19:
20-03-22 22:26-INFO-training batch loss: 0.9783; avg_loss: 3.9306
20-03-22 22:26-INFO-training batch acc: 0.5859; avg_acc: 0.5033
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 20, Global step 20:
20-03-22 22:26-INFO-training batch loss: 0.7976; avg_loss: 3.7740
20-03-22 22:26-INFO-training batch acc: 0.6562; avg_acc: 0.5109
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 21, Global step 21:
20-03-22 22:26-INFO-training batch loss: 0.7662; avg_loss: 3.6308
20-03-22 22:26-INFO-training batch acc: 0.6094; avg_acc: 0.5156
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 22, Global step 22:
20-03-22 22:26-INFO-training batch loss: 0.6996; avg_loss: 3.4975
20-03-22 22:26-INFO-training batch acc: 0.5859; avg_acc: 0.5188
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 23, Global step 23:
20-03-22 22:26-INFO-training batch loss: 0.8394; avg_loss: 3.3820
20-03-22 22:26-INFO-training batch acc: 0.5000; avg_acc: 0.5180
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 24, Global step 24:
20-03-22 22:26-INFO-training batch loss: 0.7102; avg_loss: 3.2706
20-03-22 22:26-INFO-training batch acc: 0.5469; avg_acc: 0.5192
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 25, Global step 25:
20-03-22 22:26-INFO-training batch loss: 0.7276; avg_loss: 3.1689
20-03-22 22:26-INFO-training batch acc: 0.6406; avg_acc: 0.5241
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 26, Global step 26:
20-03-22 22:26-INFO-training batch loss: 0.9747; avg_loss: 3.0845
20-03-22 22:26-INFO-training batch acc: 0.6406; avg_acc: 0.5285
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 27, Global step 27:
20-03-22 22:26-INFO-training batch loss: 0.8903; avg_loss: 3.0032
20-03-22 22:26-INFO-training batch acc: 0.5703; avg_acc: 0.5301
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 28, Global step 28:
20-03-22 22:26-INFO-training batch loss: 0.6687; avg_loss: 2.9199
20-03-22 22:26-INFO-training batch acc: 0.6172; avg_acc: 0.5332
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 29, Global step 29:
20-03-22 22:26-INFO-training batch loss: 0.7518; avg_loss: 2.8451
20-03-22 22:26-INFO-training batch acc: 0.5312; avg_acc: 0.5331
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 30, Global step 30:
20-03-22 22:26-INFO-training batch loss: 0.6449; avg_loss: 2.7718
20-03-22 22:26-INFO-training batch acc: 0.6250; avg_acc: 0.5362
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 31, Global step 31:
20-03-22 22:26-INFO-training batch loss: 0.7713; avg_loss: 2.7072
20-03-22 22:26-INFO-training batch acc: 0.5469; avg_acc: 0.5365
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 32, Global step 32:
20-03-22 22:26-INFO-training batch loss: 0.7099; avg_loss: 2.6448
20-03-22 22:26-INFO-training batch acc: 0.6094; avg_acc: 0.5388
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 33, Global step 33:
20-03-22 22:26-INFO-training batch loss: 0.6139; avg_loss: 2.5833
20-03-22 22:26-INFO-training batch acc: 0.6250; avg_acc: 0.5414
20-03-22 22:26-INFO-
20-03-22 22:26-INFO-Epoch 0, Batch 34, Global step 34:
20-03-22 22:26-INFO-training batch loss: 0.7864; avg_loss: 2.5304
20-03-22 22:26-INFO-training batch acc: 0.5156; avg_acc: 0.5407
20-03-22 22:26-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 35, Global step 35:
20-03-22 22:27-INFO-training batch loss: 0.6820; avg_loss: 2.4776
20-03-22 22:27-INFO-training batch acc: 0.5859; avg_acc: 0.5420
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 36, Global step 36:
20-03-22 22:27-INFO-training batch loss: 0.7424; avg_loss: 2.4294
20-03-22 22:27-INFO-training batch acc: 0.5703; avg_acc: 0.5428
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 37, Global step 37:
20-03-22 22:27-INFO-training batch loss: 0.6965; avg_loss: 2.3826
20-03-22 22:27-INFO-training batch acc: 0.5547; avg_acc: 0.5431
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 38, Global step 38:
20-03-22 22:27-INFO-training batch loss: 0.6636; avg_loss: 2.3373
20-03-22 22:27-INFO-training batch acc: 0.6172; avg_acc: 0.5450
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 39, Global step 39:
20-03-22 22:27-INFO-training batch loss: 0.6341; avg_loss: 2.2937
20-03-22 22:27-INFO-training batch acc: 0.6250; avg_acc: 0.5471
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 40, Global step 40:
20-03-22 22:27-INFO-training batch loss: 0.6329; avg_loss: 2.2521
20-03-22 22:27-INFO-training batch acc: 0.5625; avg_acc: 0.5475
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 41, Global step 41:
20-03-22 22:27-INFO-training batch loss: 0.5940; avg_loss: 2.2117
20-03-22 22:27-INFO-training batch acc: 0.6250; avg_acc: 0.5494
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 42, Global step 42:
20-03-22 22:27-INFO-training batch loss: 0.6684; avg_loss: 2.1750
20-03-22 22:27-INFO-training batch acc: 0.6328; avg_acc: 0.5513
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 43, Global step 43:
20-03-22 22:27-INFO-training batch loss: 0.5867; avg_loss: 2.1380
20-03-22 22:27-INFO-training batch acc: 0.6953; avg_acc: 0.5547
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 44, Global step 44:
20-03-22 22:27-INFO-training batch loss: 0.6523; avg_loss: 2.1043
20-03-22 22:27-INFO-training batch acc: 0.6172; avg_acc: 0.5561
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 45, Global step 45:
20-03-22 22:27-INFO-training batch loss: 0.5919; avg_loss: 2.0706
20-03-22 22:27-INFO-training batch acc: 0.6797; avg_acc: 0.5589
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 46, Global step 46:
20-03-22 22:27-INFO-training batch loss: 0.6158; avg_loss: 2.0390
20-03-22 22:27-INFO-training batch acc: 0.6875; avg_acc: 0.5617
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 47, Global step 47:
20-03-22 22:27-INFO-training batch loss: nan; avg_loss: nan
20-03-22 22:27-INFO-training batch acc: 0.0000; avg_acc: 0.5497
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 48, Global step 48:
20-03-22 22:27-INFO-training batch loss: nan; avg_loss: nan
20-03-22 22:27-INFO-training batch acc: 0.0000; avg_acc: 0.5382
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 49, Global step 49:
20-03-22 22:27-INFO-training batch loss: nan; avg_loss: nan
20-03-22 22:27-INFO-training batch acc: 0.0000; avg_acc: 0.5273
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 50, Global step 50:
20-03-22 22:27-INFO-training batch loss: nan; avg_loss: nan
20-03-22 22:27-INFO-training batch acc: 0.0000; avg_acc: 0.5167
20-03-22 22:27-INFO-
20-03-22 22:27-INFO-Epoch 0, Batch 51, Global step 51:
20-03-22 22:27-INFO-training batch loss: nan; avg_loss: nan
20-03-22 22:27-INFO-training batch acc: 0.0000; avg_acc: 0.5066
20-03-22 22:27-INFO-
